This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: Alternate Implementations,  Next: Notation,  Up: Introduction<5>

4.1.1 Alternate Implementations
-------------------------------

Though there is one Python implementation which is by far the most
popular, there are some alternate implementations which are of
particular interest to different audiences.

Known implementations include:

CPython

     This is the original and most-maintained implementation of Python,
     written in C. New language features generally appear here first.

Jython

     Python implemented in Java.  This implementation can be used as a
     scripting language for Java applications, or can be used to create
     applications using the Java class libraries.  It is also often used
     to create tests for Java libraries.  More information can be found
     at the Jython website(1).

Python for .NET

     This implementation actually uses the CPython implementation, but
     is a managed .NET application and makes .NET libraries available.
     It was created by Brian Lloyd.  For more information, see the
     Python for .NET home page(2).

IronPython

     An alternate Python for .NET. Unlike Python.NET, this is a complete
     Python implementation that generates IL, and compiles Python code
     directly to .NET assemblies.  It was created by Jim Hugunin, the
     original creator of Jython.  For more information, see the
     IronPython website(3).

PyPy

     An implementation of Python written completely in Python.  It
     supports several advanced features not found in other
     implementations like stackless support and a Just in Time compiler.
     One of the goals of the project is to encourage experimentation
     with the language itself by making it easier to modify the
     interpreter (since it is written in Python).  Additional
     information is available on the PyPy project’s home page(4).

Each of these implementations varies in some way from the language as
documented in this manual, or introduces specific information beyond
what’s covered in the standard Python documentation.  Please refer to
the implementation-specific documentation to determine what else you
need to know about the specific implementation you’re using.

   ---------- Footnotes ----------

   (1) http://www.jython.org/

   (2) https://pythonnet.github.io/

   (3) http://ironpython.net/

   (4) http://pypy.org/


File: python.info,  Node: Notation,  Prev: Alternate Implementations,  Up: Introduction<5>

4.1.2 Notation
--------------

The descriptions of lexical analysis and syntax use a modified BNF
grammar notation.  This uses the following style of definition:

     name      ::= lc_letter (lc_letter | "_")*
     lc_letter ::= "a"..."z"

The first line says that a ‘name’ is an ‘lc_letter’ followed by a
sequence of zero or more ‘lc_letter’s and underscores.  An ‘lc_letter’
in turn is any of the single characters ‘'a'’ through ‘'z'’.  (This rule
is actually adhered to for the names defined in lexical and grammar
rules in this document.)

Each rule begins with a name (which is the name defined by the rule) and
‘::=’.  A vertical bar (‘|’) is used to separate alternatives; it is the
least binding operator in this notation.  A star (‘*’) means zero or
more repetitions of the preceding item; likewise, a plus (‘+’) means one
or more repetitions, and a phrase enclosed in square brackets (‘[ ]’)
means zero or one occurrences (in other words, the enclosed phrase is
optional).  The ‘*’ and ‘+’ operators bind as tightly as possible;
parentheses are used for grouping.  Literal strings are enclosed in
quotes.  White space is only meaningful to separate tokens.  Rules are
normally contained on a single line; rules with many alternatives may be
formatted alternatively with each line after the first beginning with a
vertical bar.

In lexical definitions (as the example above), two more conventions are
used: Two literal characters separated by three dots mean a choice of
any single character in the given (inclusive) range of ASCII characters.
A phrase between angular brackets (‘<...>’) gives an informal
description of the symbol defined; e.g., this could be used to describe
the notion of ’control character’ if needed.

Even though the notation used is almost the same, there is a big
difference between the meaning of lexical and syntactic definitions: a
lexical definition operates on the individual characters of the input
source, while a syntax definition operates on the stream of tokens
generated by the lexical analysis.  All uses of BNF in the next chapter
("Lexical Analysis") are lexical definitions; uses in subsequent
chapters are syntactic definitions.


File: python.info,  Node: Lexical analysis,  Next: Data model,  Prev: Introduction<5>,  Up: The Python Language Reference

4.2 Lexical analysis
====================

A Python program is read by a `parser'.  Input to the parser is a stream
of `tokens', generated by the `lexical analyzer'.  This chapter
describes how the lexical analyzer breaks a file into tokens.

Python reads program text as Unicode code points; the encoding of a
source file can be given by an encoding declaration and defaults to
UTF-8, see PEP 3120(1) for details.  If the source file cannot be
decoded, a *note SyntaxError: 3a6. is raised.

* Menu:

* Line structure:: 
* Other tokens:: 
* Identifiers and keywords:: 
* Literals:: 
* Operators:: 
* Delimiters:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3120


File: python.info,  Node: Line structure,  Next: Other tokens,  Up: Lexical analysis

4.2.1 Line structure
--------------------

A Python program is divided into a number of `logical lines'.

* Menu:

* Logical lines:: 
* Physical lines:: 
* Comments:: 
* Encoding declarations:: 
* Explicit line joining:: 
* Implicit line joining:: 
* Blank lines:: 
* Indentation:: 
* Whitespace between tokens:: 


File: python.info,  Node: Logical lines,  Next: Physical lines,  Up: Line structure

4.2.1.1 Logical lines
.....................

The end of a logical line is represented by the token NEWLINE.
Statements cannot cross logical line boundaries except where NEWLINE is
allowed by the syntax (e.g., between statements in compound statements).
A logical line is constructed from one or more `physical lines' by
following the explicit or implicit `line joining' rules.


File: python.info,  Node: Physical lines,  Next: Comments,  Prev: Logical lines,  Up: Line structure

4.2.1.2 Physical lines
......................

A physical line is a sequence of characters terminated by an end-of-line
sequence.  In source files, any of the standard platform line
termination sequences can be used - the Unix form using ASCII LF
(linefeed), the Windows form using the ASCII sequence CR LF (return
followed by linefeed), or the old Macintosh form using the ASCII CR
(return) character.  All of these forms can be used equally, regardless
of platform.

When embedding Python, source code strings should be passed to Python
APIs using the standard C conventions for newline characters (the ‘\n’
character, representing ASCII LF, is the line terminator).


File: python.info,  Node: Comments,  Next: Encoding declarations,  Prev: Physical lines,  Up: Line structure

4.2.1.3 Comments
................

A comment starts with a hash character (‘#’) that is not part of a
string literal, and ends at the end of the physical line.  A comment
signifies the end of the logical line unless the implicit line joining
rules are invoked.  Comments are ignored by the syntax; they are not
tokens.


File: python.info,  Node: Encoding declarations,  Next: Explicit line joining,  Prev: Comments,  Up: Line structure

4.2.1.4 Encoding declarations
.............................

If a comment in the first or second line of the Python script matches
the regular expression ‘coding[=:]\s*([-\w.]+)’, this comment is
processed as an encoding declaration; the first group of this expression
names the encoding of the source code file.  The encoding declaration
must appear on a line of its own.  If it is the second line, the first
line must also be a comment-only line.  The recommended forms of an
encoding expression are

     # -*- coding: <encoding-name> -*-

which is recognized also by GNU Emacs, and

     # vim:fileencoding=<encoding-name>

which is recognized by Bram Moolenaar’s VIM.

If no encoding declaration is found, the default encoding is UTF-8.  In
addition, if the first bytes of the file are the UTF-8 byte-order mark
(‘b'\xef\xbb\xbf'’), the declared file encoding is UTF-8 (this is
supported, among others, by Microsoft’s ‘notepad’).

If an encoding is declared, the encoding name must be recognized by
Python.  The encoding is used for all lexical analysis, including string
literals, comments and identifiers.


File: python.info,  Node: Explicit line joining,  Next: Implicit line joining,  Prev: Encoding declarations,  Up: Line structure

4.2.1.5 Explicit line joining
.............................

Two or more physical lines may be joined into logical lines using
backslash characters (‘\’), as follows: when a physical line ends in a
backslash that is not part of a string literal or comment, it is joined
with the following forming a single logical line, deleting the backslash
and the following end-of-line character.  For example:

     if 1900 < year < 2100 and 1 <= month <= 12 \
        and 1 <= day <= 31 and 0 <= hour < 24 \
        and 0 <= minute < 60 and 0 <= second < 60:   # Looks like a valid date
             return 1

A line ending in a backslash cannot carry a comment.  A backslash does
not continue a comment.  A backslash does not continue a token except
for string literals (i.e., tokens other than string literals cannot be
split across physical lines using a backslash).  A backslash is illegal
elsewhere on a line outside a string literal.


File: python.info,  Node: Implicit line joining,  Next: Blank lines,  Prev: Explicit line joining,  Up: Line structure

4.2.1.6 Implicit line joining
.............................

Expressions in parentheses, square brackets or curly braces can be split
over more than one physical line without using backslashes.  For
example:

     month_names = ['Januari', 'Februari', 'Maart',      # These are the
                    'April',   'Mei',      'Juni',       # Dutch names
                    'Juli',    'Augustus', 'September',  # for the months
                    'Oktober', 'November', 'December']   # of the year

Implicitly continued lines can carry comments.  The indentation of the
continuation lines is not important.  Blank continuation lines are
allowed.  There is no NEWLINE token between implicit continuation lines.
Implicitly continued lines can also occur within triple-quoted strings
(see below); in that case they cannot carry comments.


File: python.info,  Node: Blank lines,  Next: Indentation,  Prev: Implicit line joining,  Up: Line structure

4.2.1.7 Blank lines
...................

A logical line that contains only spaces, tabs, formfeeds and possibly a
comment, is ignored (i.e., no NEWLINE token is generated).  During
interactive input of statements, handling of a blank line may differ
depending on the implementation of the read-eval-print loop.  In the
standard interactive interpreter, an entirely blank logical line (i.e.
one containing not even whitespace or a comment) terminates a multi-line
statement.


File: python.info,  Node: Indentation,  Next: Whitespace between tokens,  Prev: Blank lines,  Up: Line structure

4.2.1.8 Indentation
...................

Leading whitespace (spaces and tabs) at the beginning of a logical line
is used to compute the indentation level of the line, which in turn is
used to determine the grouping of statements.

Tabs are replaced (from left to right) by one to eight spaces such that
the total number of characters up to and including the replacement is a
multiple of eight (this is intended to be the same rule as used by
Unix).  The total number of spaces preceding the first non-blank
character then determines the line’s indentation.  Indentation cannot be
split over multiple physical lines using backslashes; the whitespace up
to the first backslash determines the indentation.

Indentation is rejected as inconsistent if a source file mixes tabs and
spaces in a way that makes the meaning dependent on the worth of a tab
in spaces; a *note TabError: afd. is raised in that case.

`Cross-platform compatibility note:' because of the nature of text
editors on non-UNIX platforms, it is unwise to use a mixture of spaces
and tabs for the indentation in a single source file.  It should also be
noted that different platforms may explicitly limit the maximum
indentation level.

A formfeed character may be present at the start of the line; it will be
ignored for the indentation calculations above.  Formfeed characters
occurring elsewhere in the leading whitespace have an undefined effect
(for instance, they may reset the space count to zero).

The indentation levels of consecutive lines are used to generate INDENT
and DEDENT tokens, using a stack, as follows.

Before the first line of the file is read, a single zero is pushed on
the stack; this will never be popped off again.  The numbers pushed on
the stack will always be strictly increasing from bottom to top.  At the
beginning of each logical line, the line’s indentation level is compared
to the top of the stack.  If it is equal, nothing happens.  If it is
larger, it is pushed on the stack, and one INDENT token is generated.
If it is smaller, it `must' be one of the numbers occurring on the
stack; all numbers on the stack that are larger are popped off, and for
each number popped off a DEDENT token is generated.  At the end of the
file, a DEDENT token is generated for each number remaining on the stack
that is larger than zero.

Here is an example of a correctly (though confusingly) indented piece of
Python code:

     def perm(l):
             # Compute the list of all permutations of l
         if len(l) <= 1:
                       return [l]
         r = []
         for i in range(len(l)):
                  s = l[:i] + l[i+1:]
                  p = perm(s)
                  for x in p:
                   r.append(l[i:i+1] + x)
         return r

The following example shows various indentation errors:

      def perm(l):                       # error: first line indented
     for i in range(len(l)):             # error: not indented
         s = l[:i] + l[i+1:]
             p = perm(l[:i] + l[i+1:])   # error: unexpected indent
             for x in p:
                     r.append(l[i:i+1] + x)
                 return r                # error: inconsistent dedent

(Actually, the first three errors are detected by the parser; only the
last error is found by the lexical analyzer — the indentation of ‘return
r’ does not match a level popped off the stack.)


File: python.info,  Node: Whitespace between tokens,  Prev: Indentation,  Up: Line structure

4.2.1.9 Whitespace between tokens
.................................

Except at the beginning of a logical line or in string literals, the
whitespace characters space, tab and formfeed can be used
interchangeably to separate tokens.  Whitespace is needed between two
tokens only if their concatenation could otherwise be interpreted as a
different token (e.g., ab is one token, but a b is two tokens).


File: python.info,  Node: Other tokens,  Next: Identifiers and keywords,  Prev: Line structure,  Up: Lexical analysis

4.2.2 Other tokens
------------------

Besides NEWLINE, INDENT and DEDENT, the following categories of tokens
exist: `identifiers', `keywords', `literals', `operators', and
`delimiters'.  Whitespace characters (other than line terminators,
discussed earlier) are not tokens, but serve to delimit tokens.  Where
ambiguity exists, a token comprises the longest possible string that
forms a legal token, when read from left to right.


File: python.info,  Node: Identifiers and keywords,  Next: Literals,  Prev: Other tokens,  Up: Lexical analysis

4.2.3 Identifiers and keywords
------------------------------

Identifiers (also referred to as `names') are described by the following
lexical definitions.

The syntax of identifiers in Python is based on the Unicode standard
annex UAX-31, with elaboration and changes as defined below; see also
PEP 3131(1) for further details.

Within the ASCII range (U+0001..U+007F), the valid characters for
identifiers are the same as in Python 2.x: the uppercase and lowercase
letters ‘A’ through ‘Z’, the underscore ‘_’ and, except for the first
character, the digits ‘0’ through ‘9’.

Python 3.0 introduces additional characters from outside the ASCII range
(see PEP 3131(2)).  For these characters, the classification uses the
version of the Unicode Character Database as included in the *note
unicodedata: 117. module.

Identifiers are unlimited in length.  Case is significant.

     identifier   ::= xid_start xid_continue*
     id_start     ::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>
     id_continue  ::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>
     xid_start    ::= <all characters in id_start whose NFKC normalization is in "id_start xid_continue*">
     xid_continue ::= <all characters in id_continue whose NFKC normalization is in "id_continue*">

The Unicode category codes mentioned above stand for:

   * `Lu' - uppercase letters

   * `Ll' - lowercase letters

   * `Lt' - titlecase letters

   * `Lm' - modifier letters

   * `Lo' - other letters

   * `Nl' - letter numbers

   * `Mn' - nonspacing marks

   * `Mc' - spacing combining marks

   * `Nd' - decimal numbers

   * `Pc' - connector punctuations

   * `Other_ID_Start' - explicit list of characters in PropList.txt(3)
     to support backwards compatibility

   * `Other_ID_Continue' - likewise

All identifiers are converted into the normal form NFKC while parsing;
comparison of identifiers is based on NFKC.

A non-normative HTML file listing all valid identifier characters for
Unicode 4.1 can be found at
‘http://www.dcl.hpi.uni-potsdam.de/home/loewis/table-3131.html’.

* Menu:

* Keywords:: 
* Reserved classes of identifiers:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3131

   (2) https://www.python.org/dev/peps/pep-3131

   (3) http://www.unicode.org/Public/8.0.0/ucd/PropList.txt


File: python.info,  Node: Keywords,  Next: Reserved classes of identifiers,  Up: Identifiers and keywords

4.2.3.1 Keywords
................

The following identifiers are used as reserved words, or `keywords' of
the language, and cannot be used as ordinary identifiers.  They must be
spelled exactly as written here:

     False      class      finally    is         return
     None       continue   for        lambda     try
     True       def        from       nonlocal   while
     and        del        global     not        with
     as         elif       if         or         yield
     assert     else       import     pass
     break      except     in         raise


File: python.info,  Node: Reserved classes of identifiers,  Prev: Keywords,  Up: Identifiers and keywords

4.2.3.2 Reserved classes of identifiers
.......................................

Certain classes of identifiers (besides keywords) have special meanings.
These classes are identified by the patterns of leading and trailing
underscore characters:

‘_*’

     Not imported by ‘from module import *’.  The special identifier ‘_’
     is used in the interactive interpreter to store the result of the
     last evaluation; it is stored in the *note builtins: 13. module.
     When not in interactive mode, ‘_’ has no special meaning and is not
     defined.  See section *note The import statement: 881.

          Note: The name ‘_’ is often used in conjunction with
          internationalization; refer to the documentation for the *note
          gettext: 88. module for more information on this convention.

‘__*__’

     System-defined names.  These names are defined by the interpreter
     and its implementation (including the standard library).  Current
     system names are discussed in the *note Special method names: d9b.
     section and elsewhere.  More will likely be defined in future
     versions of Python.  `Any' use of ‘__*__’ names, in any context,
     that does not follow explicitly documented use, is subject to
     breakage without warning.

‘__*’

     Class-private names.  Names in this category, when used within the
     context of a class definition, are re-written to use a mangled form
     to help avoid name clashes between "private" attributes of base and
     derived classes.  See section *note Identifiers (Names): d9c.


File: python.info,  Node: Literals,  Next: Operators,  Prev: Identifiers and keywords,  Up: Lexical analysis

4.2.4 Literals
--------------

Literals are notations for constant values of some built-in types.

* Menu:

* String and Bytes literals:: 
* String literal concatenation:: 
* Formatted string literals:: 
* Numeric literals:: 
* Integer literals:: 
* Floating point literals:: 
* Imaginary literals:: 


File: python.info,  Node: String and Bytes literals,  Next: String literal concatenation,  Up: Literals

4.2.4.1 String and Bytes literals
.................................

String literals are described by the following lexical definitions:

     stringliteral   ::= [stringprefix](shortstring | longstring)
     stringprefix    ::= "r" | "u" | "R" | "U" | "f" | "F"
                         | "fr" | "Fr" | "fR" | "FR" | "rf" | "rF" | "Rf" | "RF"
     shortstring     ::= "'" shortstringitem* "'" | '"' shortstringitem* '"'
     longstring      ::= "'''" longstringitem* "'''" | '"""' longstringitem* '"""'
     shortstringitem ::= shortstringchar | stringescapeseq
     longstringitem  ::= longstringchar | stringescapeseq
     shortstringchar ::= <any source character except "\" or newline or the quote>
     longstringchar  ::= <any source character except "\">
     stringescapeseq ::= "\" <any source character>

     bytesliteral   ::= bytesprefix(shortbytes | longbytes)
     bytesprefix    ::= "b" | "B" | "br" | "Br" | "bR" | "BR" | "rb" | "rB" | "Rb" | "RB"
     shortbytes     ::= "'" shortbytesitem* "'" | '"' shortbytesitem* '"'
     longbytes      ::= "'''" longbytesitem* "'''" | '"""' longbytesitem* '"""'
     shortbytesitem ::= shortbyteschar | bytesescapeseq
     longbytesitem  ::= longbyteschar | bytesescapeseq
     shortbyteschar ::= <any ASCII character except "\" or newline or the quote>
     longbyteschar  ::= <any ASCII character except "\">
     bytesescapeseq ::= "\" <any ASCII character>

One syntactic restriction not indicated by these productions is that
whitespace is not allowed between the *note stringprefix: da2. or *note
bytesprefix: dab. and the rest of the literal.  The source character set
is defined by the encoding declaration; it is UTF-8 if no encoding
declaration is given in the source file; see section *note Encoding
declarations: d83.

In plain English: Both types of literals can be enclosed in matching
single quotes (‘'’) or double quotes (‘"’).  They can also be enclosed
in matching groups of three single or double quotes (these are generally
referred to as `triple-quoted strings').  The backslash (‘\’) character
is used to escape characters that otherwise have a special meaning, such
as newline, backslash itself, or the quote character.

Bytes literals are always prefixed with ‘'b'’ or ‘'B'’; they produce an
instance of the *note bytes: 1db. type instead of the *note str: 25a.
type.  They may only contain ASCII characters; bytes with a numeric
value of 128 or greater must be expressed with escapes.

As of Python 3.3 it is possible again to prefix string literals with a
‘u’ prefix to simplify maintenance of dual 2.x and 3.x codebases.

Both string and bytes literals may optionally be prefixed with a letter
‘'r'’ or ‘'R'’; such strings are called `raw strings' and treat
backslashes as literal characters.  As a result, in string literals,
‘'\U'’ and ‘'\u'’ escapes in raw strings are not treated specially.
Given that Python 2.x’s raw unicode literals behave differently than
Python 3.x’s the ‘'ur'’ syntax is not supported.

New in version 3.3: The ‘'rb'’ prefix of raw bytes literals has been
added as a synonym of ‘'br'’.

New in version 3.3: Support for the unicode legacy literal (‘u'value'’)
was reintroduced to simplify the maintenance of dual Python 2.x and 3.x
codebases.  See PEP 414(1) for more information.

A string literal with ‘'f'’ or ‘'F'’ in its prefix is a `formatted
string literal'; see *note Formatted string literals: 14f.  The ‘'f'’
may be combined with ‘'r'’, but not with ‘'b'’ or ‘'u'’, therefore raw
formatted strings are possible, but formatted bytes literals are not.

In triple-quoted literals, unescaped newlines and quotes are allowed
(and are retained), except that three unescaped quotes in a row
terminate the literal.  (A "quote" is the character used to open the
literal, i.e.  either ‘'’ or ‘"’.)

Unless an ‘'r'’ or ‘'R'’ prefix is present, escape sequences in string
and bytes literals are interpreted according to rules similar to those
used by Standard C. The recognized escape sequences are:

Escape Sequence       Meaning                               Notes
                                                            
------------------------------------------------------------------------
                                                            
‘\newline’            Backslash and newline ignored
                      
                                                            
‘\\’                  Backslash (‘\’)
                      
                                                            
‘\'’                  Single quote (‘'’)
                      
                                                            
‘\"’                  Double quote (‘"’)
                      
                                                            
‘\a’                  ASCII Bell (BEL)
                      
                                                            
‘\b’                  ASCII Backspace (BS)
                      
                                                            
‘\f’                  ASCII Formfeed (FF)
                      
                                                            
‘\n’                  ASCII Linefeed (LF)
                      
                                                            
‘\r’                  ASCII Carriage Return (CR)
                      
                                                            
‘\t’                  ASCII Horizontal Tab (TAB)
                      
                                                            
‘\v’                  ASCII Vertical Tab (VT)
                      
                                                            
‘\ooo’                Character with octal value `ooo'      (1,3)
                                                            
                                                            
‘\xhh’                Character with hex value `hh'         (2,3)
                                                            

Escape sequences only recognized in string literals are:

Escape Sequence       Meaning                               Notes
                                                            
------------------------------------------------------------------------
                                                            
‘\N{name}’            Character named `name' in the         (4)
                      Unicode database                      
                      
                                                            
‘\uxxxx’              Character with 16-bit hex value       (5)
                      `xxxx'                                
                      
                                                            
‘\Uxxxxxxxx’          Character with 32-bit hex value       (6)
                      `xxxxxxxx'                            
                      

Notes:

  1. As in Standard C, up to three octal digits are accepted.

  2. Unlike in Standard C, exactly two hex digits are required.

  3. In a bytes literal, hexadecimal and octal escapes denote the byte
     with the given value.  In a string literal, these escapes denote a
     Unicode character with the given value.

  4. 
     Changed in version 3.3: Support for name aliases (2) has been
     added.

  5. Exactly four hex digits are required.

  6. Any Unicode character can be encoded this way.  Exactly eight hex
     digits are required.

Unlike Standard C, all unrecognized escape sequences are left in the
string unchanged, i.e., `the backslash is left in the result'.  (This
behavior is useful when debugging: if an escape sequence is mistyped,
the resulting output is more easily recognized as broken.)  It is also
important to note that the escape sequences only recognized in string
literals fall into the category of unrecognized escapes for bytes
literals.

Even in a raw literal, quotes can be escaped with a backslash, but the
backslash remains in the result; for example, ‘r"\""’ is a valid string
literal consisting of two characters: a backslash and a double quote;
‘r"\"’ is not a valid string literal (even a raw string cannot end in an
odd number of backslashes).  Specifically, `a raw literal cannot end in
a single backslash' (since the backslash would escape the following
quote character).  Note also that a single backslash followed by a
newline is interpreted as those two characters as part of the literal,
`not' as a line continuation.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0414

   (2) ‘http://www.unicode.org/Public/8.0.0/ucd/NameAliases.txt’


File: python.info,  Node: String literal concatenation,  Next: Formatted string literals,  Prev: String and Bytes literals,  Up: Literals

4.2.4.2 String literal concatenation
....................................

Multiple adjacent string or bytes literals (delimited by whitespace),
possibly using different quoting conventions, are allowed, and their
meaning is the same as their concatenation.  Thus, ‘"hello" 'world'’ is
equivalent to ‘"helloworld"’.  This feature can be used to reduce the
number of backslashes needed, to split long strings conveniently across
long lines, or even to add comments to parts of strings, for example:

     re.compile("[A-Za-z_]"       # letter or underscore
                "[A-Za-z0-9_]*"   # letter, digit or underscore
               )

Note that this feature is defined at the syntactical level, but
implemented at compile time.  The ’+’ operator must be used to
concatenate string expressions at run time.  Also note that literal
concatenation can use different quoting styles for each component (even
mixing raw strings and triple quoted strings), and formatted string
literals may be concatenated with plain string literals.


File: python.info,  Node: Formatted string literals,  Next: Numeric literals,  Prev: String literal concatenation,  Up: Literals

4.2.4.3 Formatted string literals
.................................

New in version 3.6.

A `formatted string literal' or `f-string' is a string literal that is
prefixed with ‘'f'’ or ‘'F'’.  These strings may contain replacement
fields, which are expressions delimited by curly braces ‘{}’.  While
other string literals always have a constant value, formatted strings
are really expressions evaluated at run time.

Escape sequences are decoded like in ordinary string literals (except
when a literal is also marked as a raw string).  After decoding, the
grammar for the contents of the string is:

     f_string          ::= (literal_char | "{{" | "}}" | replacement_field)*
     replacement_field ::= "{" f_expression ["!" conversion] [":" format_spec] "}"
     f_expression      ::= conditional_expression ("," conditional_expression)* [","]
                           | yield_expression
     conversion        ::= "s" | "r" | "a"
     format_spec       ::= (literal_char | NULL | replacement_field)*
     literal_char      ::= <any code point except "{", "}" or NULL>

The parts of the string outside curly braces are treated literally,
except that any doubled curly braces ‘'{{'’ or ‘'}}'’ are replaced with
the corresponding single curly brace.  A single opening curly bracket
‘'{'’ marks a replacement field, which starts with a Python expression.
After the expression, there may be a conversion field, introduced by an
exclamation point ‘'!'’.  A format specifier may also be appended,
introduced by a colon ‘':'’.  A replacement field ends with a closing
curly bracket ‘'}'’.

Expressions in formatted string literals are treated like regular Python
expressions surrounded by parentheses, with a few exceptions.  An empty
expression is not allowed, and a *note lambda: 894. expression must be
surrounded by explicit parentheses.  Replacement expressions can contain
line breaks (e.g.  in triple-quoted strings), but they cannot contain
comments.  Each expression is evaluated in the context where the
formatted string literal appears, in order from left to right.

If a conversion is specified, the result of evaluating the expression is
converted before formatting.  Conversion ‘'!s'’ calls *note str(): 25a.
on the result, ‘'!r'’ calls *note repr(): 3bb, and ‘'!a'’ calls *note
ascii(): 9c3.

The result is then formatted using the *note format(): 14e. protocol.
The format specifier is passed to the *note __format__(): 561. method of
the expression or conversion result.  An empty string is passed when the
format specifier is omitted.  The formatted result is then included in
the final value of the whole string.

Top-level format specifiers may include nested replacement fields.
These nested fields may include their own conversion fields and format
specifiers, but may not include more deeply-nested replacement fields.

Formatted string literals may be concatenated, but replacement fields
cannot be split across literals.

Some examples of formatted string literals:

     >>> name = "Fred"
     >>> f"He said his name is {name!r}."
     "He said his name is 'Fred'."
     >>> f"He said his name is {repr(name)}."  # repr() is equivalent to !r
     "He said his name is 'Fred'."
     >>> width = 10
     >>> precision = 4
     >>> value = decimal.Decimal("12.34567")
     >>> f"result: {value:{width}.{precision}}"  # nested fields
     'result:      12.35'

A consequence of sharing the same syntax as regular string literals is
that characters in the replacement fields must not conflict with the
quoting used in the outer formatted string literal.  Also, escape
sequences normally apply to the outer formatted string literal, rather
than inner string literals:

     f"abc {a["x"]} def"    # error: outer string literal ended prematurely
     f"abc {a[\"x\"]} def"  # workaround: escape the inner quotes
     f"abc {a['x']} def"    # workaround: use different quoting

     f"newline: {ord('\n')}"   # error: literal line break in inner string
     f"newline: {ord('\\n')}"  # workaround: double escaping
     fr"newline: {ord('\n')}"  # workaround: raw outer string

See also PEP 498(1) for the proposal that added formatted string
literals, and *note str.format(): 14d, which uses a related format
string mechanism.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0498


File: python.info,  Node: Numeric literals,  Next: Integer literals,  Prev: Formatted string literals,  Up: Literals

4.2.4.4 Numeric literals
........................

There are three types of numeric literals: integers, floating point
numbers, and imaginary numbers.  There are no complex literals (complex
numbers can be formed by adding a real number and an imaginary number).

Note that numeric literals do not include a sign; a phrase like ‘-1’ is
actually an expression composed of the unary operator ’‘-’’ and the
literal ‘1’.


File: python.info,  Node: Integer literals,  Next: Floating point literals,  Prev: Numeric literals,  Up: Literals

4.2.4.5 Integer literals
........................

Integer literals are described by the following lexical definitions:

     integer        ::= decimalinteger | octinteger | hexinteger | bininteger
     decimalinteger ::= nonzerodigit digit* | "0"+
     nonzerodigit   ::= "1"..."9"
     digit          ::= "0"..."9"
     octinteger     ::= "0" ("o" | "O") octdigit+
     hexinteger     ::= "0" ("x" | "X") hexdigit+
     bininteger     ::= "0" ("b" | "B") bindigit+
     octdigit       ::= "0"..."7"
     hexdigit       ::= digit | "a"..."f" | "A"..."F"
     bindigit       ::= "0" | "1"

There is no limit for the length of integer literals apart from what can
be stored in available memory.

Note that leading zeros in a non-zero decimal number are not allowed.
This is for disambiguation with C-style octal literals, which Python
used before version 3.0.

Some examples of integer literals:

     7     2147483647                        0o177    0b100110111
     3     79228162514264337593543950336     0o377    0xdeadbeef


File: python.info,  Node: Floating point literals,  Next: Imaginary literals,  Prev: Integer literals,  Up: Literals

4.2.4.6 Floating point literals
...............................

Floating point literals are described by the following lexical
definitions:

     floatnumber   ::= pointfloat | exponentfloat
     pointfloat    ::= [intpart] fraction | intpart "."
     exponentfloat ::= (intpart | pointfloat) exponent
     intpart       ::= digit+
     fraction      ::= "." digit+
     exponent      ::= ("e" | "E") ["+" | "-"] digit+

Note that the integer and exponent parts are always interpreted using
radix 10.  For example, ‘077e010’ is legal, and denotes the same number
as ‘77e10’.  The allowed range of floating point literals is
implementation-dependent.  Some examples of floating point literals:

     3.14    10.    .001    1e100    3.14e-10    0e0

Note that numeric literals do not include a sign; a phrase like ‘-1’ is
actually an expression composed of the unary operator ‘-’ and the
literal ‘1’.


File: python.info,  Node: Imaginary literals,  Prev: Floating point literals,  Up: Literals

4.2.4.7 Imaginary literals
..........................

Imaginary literals are described by the following lexical definitions:

     imagnumber ::= (floatnumber | intpart) ("j" | "J")

An imaginary literal yields a complex number with a real part of 0.0.
Complex numbers are represented as a pair of floating point numbers and
have the same restrictions on their range.  To create a complex number
with a nonzero real part, add a floating point number to it, e.g.,
‘(3+4j)’.  Some examples of imaginary literals:

     3.14j   10.j    10j     .001j   1e100j  3.14e-10j


File: python.info,  Node: Operators,  Next: Delimiters,  Prev: Literals,  Up: Lexical analysis

4.2.5 Operators
---------------

The following tokens are operators:

     +       -       *       **      /       //      %      @
     <<      >>      &       |       ^       ~
     <       >       <=      >=      ==      !=


File: python.info,  Node: Delimiters,  Prev: Operators,  Up: Lexical analysis

4.2.6 Delimiters
----------------

The following tokens serve as delimiters in the grammar:

     (       )       [       ]       {       }
     ,       :       .       ;       @       =       ->
     +=      -=      *=      /=      //=     %=      @=
     &=      |=      ^=      >>=     <<=     **=

The period can also occur in floating-point and imaginary literals.  A
sequence of three periods has a special meaning as an ellipsis literal.
The second half of the list, the augmented assignment operators, serve
lexically as delimiters, but also perform an operation.

The following printing ASCII characters have special meaning as part of
other tokens or are otherwise significant to the lexical analyzer:

     '       "       #       \

The following printing ASCII characters are not used in Python.  Their
occurrence outside string literals and comments is an unconditional
error:

     $       ?       `


File: python.info,  Node: Data model,  Next: Execution model,  Prev: Lexical analysis,  Up: The Python Language Reference

4.3 Data model
==============

* Menu:

* Objects, values and types: Objects values and types. 
* The standard type hierarchy:: 
* Special method names:: 
* Coroutines:: 


File: python.info,  Node: Objects values and types,  Next: The standard type hierarchy,  Up: Data model

4.3.1 Objects, values and types
-------------------------------

`Objects' are Python’s abstraction for data.  All data in a Python
program is represented by objects or by relations between objects.  (In
a sense, and in conformance to Von Neumann’s model of a "stored program
computer," code is also represented by objects.)

Every object has an identity, a type and a value.  An object’s
`identity' never changes once it has been created; you may think of it
as the object’s address in memory.  The ’*note is: dde.’ operator
compares the identity of two objects; the *note id(): a00. function
returns an integer representing its identity.

`CPython implementation detail:' For CPython, ‘id(x)’ is the memory
address where ‘x’ is stored.

An object’s type determines the operations that the object supports
(e.g., "does it have a length?")  and also defines the possible values
for objects of that type.  The *note type(): 376. function returns an
object’s type (which is an object itself).  Like its identity, an
object’s `type' is also unchangeable.  (1)

The `value' of some objects can change.  Objects whose value can change
are said to be `mutable'; objects whose value is unchangeable once they
are created are called `immutable'.  (The value of an immutable
container object that contains a reference to a mutable object can
change when the latter’s value is changed; however the container is
still considered immutable, because the collection of objects it
contains cannot be changed.  So, immutability is not strictly the same
as having an unchangeable value, it is more subtle.)  An object’s
mutability is determined by its type; for instance, numbers, strings and
tuples are immutable, while dictionaries and lists are mutable.

Objects are never explicitly destroyed; however, when they become
unreachable they may be garbage-collected.  An implementation is allowed
to postpone garbage collection or omit it altogether — it is a matter of
implementation quality how garbage collection is implemented, as long as
no objects are collected that are still reachable.

`CPython implementation detail:' CPython currently uses a
reference-counting scheme with (optional) delayed detection of
cyclically linked garbage, which collects most objects as soon as they
become unreachable, but is not guaranteed to collect garbage containing
circular references.  See the documentation of the *note gc: 85. module
for information on controlling the collection of cyclic garbage.  Other
implementations act differently and CPython may change.  Do not depend
on immediate finalization of objects when they become unreachable (so
you should always close files explicitly).

Note that the use of the implementation’s tracing or debugging
facilities may keep objects alive that would normally be collectable.
Also note that catching an exception with a ’*note try: 9e9...*note
except: 785.’ statement may keep objects alive.

Some objects contain references to "external" resources such as open
files or windows.  It is understood that these resources are freed when
the object is garbage-collected, but since garbage collection is not
guaranteed to happen, such objects also provide an explicit way to
release the external resource, usually a ‘close()’ method.  Programs are
strongly recommended to explicitly close such objects.  The ’*note try:
9e9...*note finally: 526.’ statement and the ’*note with: 29d.’
statement provide convenient ways to do this.

Some objects contain references to other objects; these are called
`containers'.  Examples of containers are tuples, lists and
dictionaries.  The references are part of a container’s value.  In most
cases, when we talk about the value of a container, we imply the values,
not the identities of the contained objects; however, when we talk about
the mutability of a container, only the identities of the immediately
contained objects are implied.  So, if an immutable container (like a
tuple) contains a reference to a mutable object, its value changes if
that mutable object is changed.

Types affect almost all aspects of object behavior.  Even the importance
of object identity is affected in some sense: for immutable types,
operations that compute new values may actually return a reference to
any existing object with the same type and value, while for mutable
objects this is not allowed.  E.g., after ‘a = 1; b = 1’, ‘a’ and ‘b’
may or may not refer to the same object with the value one, depending on
the implementation, but after ‘c = []; d = []’, ‘c’ and ‘d’ are
guaranteed to refer to two different, unique, newly created empty lists.
(Note that ‘c = d = []’ assigns the same object to both ‘c’ and ‘d’.)

   ---------- Footnotes ----------

   (1) It `is' possible in some cases to change an object’s type, under
certain controlled conditions.  It generally isn’t a good idea though,
since it can lead to some very strange behaviour if it is handled
incorrectly.


File: python.info,  Node: The standard type hierarchy,  Next: Special method names,  Prev: Objects values and types,  Up: Data model

4.3.2 The standard type hierarchy
---------------------------------

Below is a list of the types that are built into Python.  Extension
modules (written in C, Java, or other languages, depending on the
implementation) can define additional types.  Future versions of Python
may add types to the type hierarchy (e.g., rational numbers, efficiently
stored arrays of integers, etc.), although such additions will often be
provided via the standard library instead.

Some of the type descriptions below contain a paragraph listing ’special
attributes.’ These are attributes that provide access to the
implementation and are not intended for general use.  Their definition
may change in the future.

None

     This type has a single value.  There is a single object with this
     value.  This object is accessed through the built-in name ‘None’.
     It is used to signify the absence of a value in many situations,
     e.g., it is returned from functions that don’t explicitly return
     anything.  Its truth value is false.

NotImplemented

     This type has a single value.  There is a single object with this
     value.  This object is accessed through the built-in name
     ‘NotImplemented’.  Numeric methods and rich comparison methods
     should return this value if they do not implement the operation for
     the operands provided.  (The interpreter will then try the
     reflected operation, or some other fallback, depending on the
     operator.)  Its truth value is true.

     See *note Implementing the arithmetic operations: de1. for more
     details.

Ellipsis

     This type has a single value.  There is a single object with this
     value.  This object is accessed through the literal ‘...’ or the
     built-in name ‘Ellipsis’.  Its truth value is true.

*note numbers.Number: de2.

     These are created by numeric literals and returned as results by
     arithmetic operators and arithmetic built-in functions.  Numeric
     objects are immutable; once created their value never changes.
     Python numbers are of course strongly related to mathematical
     numbers, but subject to the limitations of numerical representation
     in computers.

     Python distinguishes between integers, floating point numbers, and
     complex numbers:

     *note numbers.Integral: de3.

          These represent elements from the mathematical set of integers
          (positive and negative).

          There are two types of integers:

          Integers (*note int: 227.)

               These represent numbers in an unlimited range, subject to
               available (virtual) memory only.  For the purpose of
               shift and mask operations, a binary representation is
               assumed, and negative numbers are represented in a
               variant of 2’s complement which gives the illusion of an
               infinite string of sign bits extending to the left.

          Booleans (*note bool: a72.)

               These represent the truth values False and True.  The two
               objects representing the values ‘False’ and ‘True’ are
               the only Boolean objects.  The Boolean type is a subtype
               of the integer type, and Boolean values behave like the
               values 0 and 1, respectively, in almost all contexts, the
               exception being that when converted to a string, the
               strings ‘"False"’ or ‘"True"’ are returned, respectively.

          The rules for integer representation are intended to give the
          most meaningful interpretation of shift and mask operations
          involving negative integers.

     *note numbers.Real: de4. (*note float: 57a.)

          These represent machine-level double precision floating point
          numbers.  You are at the mercy of the underlying machine
          architecture (and C or Java implementation) for the accepted
          range and handling of overflow.  Python does not support
          single-precision floating point numbers; the savings in
          processor and memory usage that are usually the reason for
          using these are dwarfed by the overhead of using objects in
          Python, so there is no reason to complicate the language with
          two kinds of floating point numbers.

     *note numbers.Complex: de5. (*note complex: 579.)

          These represent complex numbers as a pair of machine-level
          double precision floating point numbers.  The same caveats
          apply as for floating point numbers.  The real and imaginary
          parts of a complex number ‘z’ can be retrieved through the
          read-only attributes ‘z.real’ and ‘z.imag’.

Sequences

     These represent finite ordered sets indexed by non-negative
     numbers.  The built-in function *note len(): 5a8. returns the
     number of items of a sequence.  When the length of a sequence is
     `n', the index set contains the numbers 0, 1, ..., `n'-1.  Item `i'
     of sequence `a' is selected by ‘a[i]’.

     Sequences also support slicing: ‘a[i:j]’ selects all items with
     index `k' such that `i' ‘<=’ `k' ‘<’ `j'.  When used as an
     expression, a slice is a sequence of the same type.  This implies
     that the index set is renumbered so that it starts at 0.

     Some sequences also support "extended slicing" with a third "step"
     parameter: ‘a[i:j:k]’ selects all items of `a' with index `x' where
     ‘x = i + n*k’, `n' ‘>=’ ‘0’ and `i' ‘<=’ `x' ‘<’ `j'.

     Sequences are distinguished according to their mutability:

     Immutable sequences

          An object of an immutable sequence type cannot change once it
          is created.  (If the object contains references to other
          objects, these other objects may be mutable and may be
          changed; however, the collection of objects directly
          referenced by an immutable object cannot change.)

          The following types are immutable sequences:

          Strings

               A string is a sequence of values that represent Unicode
               code points.  All the code points in the range ‘U+0000 -
               U+10FFFF’ can be represented in a string.  Python doesn’t
               have a ‘char’ type; instead, every code point in the
               string is represented as a string object with length ‘1’.
               The built-in function *note ord(): de6. converts a code
               point from its string form to an integer in the range ‘0
               - 10FFFF’; *note chr(): de7. converts an integer in the
               range ‘0 - 10FFFF’ to the corresponding length ‘1’ string
               object.  *note str.encode(): 89d. can be used to convert
               a *note str: 25a. to *note bytes: 1db. using the given
               text encoding, and *note bytes.decode(): 89e. can be used
               to achieve the opposite.

          Tuples

               The items of a tuple are arbitrary Python objects.
               Tuples of two or more items are formed by comma-separated
               lists of expressions.  A tuple of one item (a
               ’singleton’) can be formed by affixing a comma to an
               expression (an expression by itself does not create a
               tuple, since parentheses must be usable for grouping of
               expressions).  An empty tuple can be formed by an empty
               pair of parentheses.

          Bytes

               A bytes object is an immutable array.  The items are
               8-bit bytes, represented by integers in the range 0 <= x
               < 256.  Bytes literals (like ‘b'abc'’) and the built-in
               function *note bytes(): 1db. can be used to construct
               bytes objects.  Also, bytes objects can be decoded to
               strings via the *note decode(): 89e. method.

     Mutable sequences

          Mutable sequences can be changed after they are created.  The
          subscription and slicing notations can be used as the target
          of assignment and *note del: c30. (delete) statements.

          There are currently two intrinsic mutable sequence types:

          Lists

               The items of a list are arbitrary Python objects.  Lists
               are formed by placing a comma-separated list of
               expressions in square brackets.  (Note that there are no
               special cases needed to form lists of length 0 or 1.)

          Byte Arrays

               A bytearray object is a mutable array.  They are created
               by the built-in *note bytearray(): 1dc. constructor.
               Aside from being mutable (and hence unhashable), byte
               arrays otherwise provide the same interface and
               functionality as immutable bytes objects.

          The extension module *note array: 7. provides an additional
          example of a mutable sequence type, as does the *note
          collections: 1e. module.

Set types

     These represent unordered, finite sets of unique, immutable
     objects.  As such, they cannot be indexed by any subscript.
     However, they can be iterated over, and the built-in function *note
     len(): 5a8. returns the number of items in a set.  Common uses for
     sets are fast membership testing, removing duplicates from a
     sequence, and computing mathematical operations such as
     intersection, union, difference, and symmetric difference.

     For set elements, the same immutability rules apply as for
     dictionary keys.  Note that numeric types obey the normal rules for
     numeric comparison: if two numbers compare equal (e.g., ‘1’ and
     ‘1.0’), only one of them can be contained in a set.

     There are currently two intrinsic set types:

     Sets

          These represent a mutable set.  They are created by the
          built-in *note set(): 7be. constructor and can be modified
          afterwards by several methods, such as *note add(): de8.

     Frozen sets

          These represent an immutable set.  They are created by the
          built-in *note frozenset(): 84c. constructor.  As a frozenset
          is immutable and *note hashable: de9, it can be used again as
          an element of another set, or as a dictionary key.

Mappings

     These represent finite sets of objects indexed by arbitrary index
     sets.  The subscript notation ‘a[k]’ selects the item indexed by
     ‘k’ from the mapping ‘a’; this can be used in expressions and as
     the target of assignments or *note del: c30. statements.  The
     built-in function *note len(): 5a8. returns the number of items in
     a mapping.

     There is currently a single intrinsic mapping type:

     Dictionaries

          These represent finite sets of objects indexed by nearly
          arbitrary values.  The only types of values not acceptable as
          keys are values containing lists or dictionaries or other
          mutable types that are compared by value rather than by object
          identity, the reason being that the efficient implementation
          of dictionaries requires a key’s hash value to remain
          constant.  Numeric types used for keys obey the normal rules
          for numeric comparison: if two numbers compare equal (e.g.,
          ‘1’ and ‘1.0’) then they can be used interchangeably to index
          the same dictionary entry.

          Dictionaries are mutable; they can be created by the ‘{...}’
          notation (see section *note Dictionary displays: dea.).

          The extension modules *note dbm.ndbm: 33. and *note dbm.gnu:
          32. provide additional examples of mapping types, as does the
          *note collections: 1e. module.

Callable types

     These are the types to which the function call operation (see
     section *note Calls: deb.) can be applied:

     User-defined functions

          A user-defined function object is created by a function
          definition (see section *note Function definitions: c1e.).  It
          should be called with an argument list containing the same
          number of items as the function’s formal parameter list.

          Special attributes:

          Attribute                     Meaning
                                        
          ----------------------------------------------------------------------------------
                                                                            
          ‘__doc__’                     The function’s documentation        Writable
                                        string, or ‘None’ if unavailable;   
                                        not inherited by subclasses
                                        
                                                                            
          *note __name__: 8d3.          The function’s name                 Writable
                                                                            
                                                                            
          ‘__qualname__’                The function’s                      Writable
                                        *note qualified name: dec.          
                                        
                                        New in version 3.3.
                                        
                                                                            
          ‘__module__’                  The name of the module the          Writable
                                        function was defined in, or         
                                        ‘None’ if unavailable.
                                        
                                                                            
          ‘__defaults__’                A tuple containing default          Writable
                                        argument values for those           
                                        arguments that have defaults, or
                                        ‘None’ if no arguments have a
                                        default value
                                        
                                                                            
          ‘__code__’                    The code object representing the    Writable
                                        compiled function body.             
                                        
                                                                            
          ‘__globals__’                 A reference to the dictionary       Read-only
                                        that holds the function’s global    
                                        variables — the global namespace
                                        of the module in which the
                                        function was defined.
                                        
                                                                            
          ‘__dict__’                    The namespace supporting            Writable
                                        arbitrary function attributes.      
                                        
                                                                            
          ‘__closure__’                 ‘None’ or a tuple of cells that     Read-only
                                        contain bindings for the            
                                        function’s free variables.
                                        
                                                                            
          ‘__annotations__’             A dict containing annotations of    Writable
                                        parameters.  The keys of the dict   
                                        are the parameter names, and
                                        ‘'return'’ for the return
                                        annotation, if provided.
                                        
                                                                            
          ‘__kwdefaults__’              A dict containing defaults for      Writable
                                        keyword-only parameters.            
                                        

          Most of the attributes labelled "Writable" check the type of
          the assigned value.

          Function objects also support getting and setting arbitrary
          attributes, which can be used, for example, to attach metadata
          to functions.  Regular attribute dot-notation is used to get
          and set such attributes.  `Note that the current
          implementation only supports function attributes on
          user-defined functions.  Function attributes on built-in
          functions may be supported in the future.'

          Additional information about a function’s definition can be
          retrieved from its code object; see the description of
          internal types below.

     Instance methods

          An instance method object combines a class, a class instance
          and any callable object (normally a user-defined function).

          Special read-only attributes: ‘__self__’ is the class instance
          object, ‘__func__’ is the function object; ‘__doc__’ is the
          method’s documentation (same as ‘__func__.__doc__’); *note
          __name__: 8d3. is the method name (same as
          ‘__func__.__name__’); ‘__module__’ is the name of the module
          the method was defined in, or ‘None’ if unavailable.

          Methods also support accessing (but not setting) the arbitrary
          function attributes on the underlying function object.

          User-defined method objects may be created when getting an
          attribute of a class (perhaps via an instance of that class),
          if that attribute is a user-defined function object or a class
          method object.

          When an instance method object is created by retrieving a
          user-defined function object from a class via one of its
          instances, its ‘__self__’ attribute is the instance, and the
          method object is said to be bound.  The new method’s
          ‘__func__’ attribute is the original function object.

          When a user-defined method object is created by retrieving
          another method object from a class or instance, the behaviour
          is the same as for a function object, except that the
          ‘__func__’ attribute of the new instance is not the original
          method object but its ‘__func__’ attribute.

          When an instance method object is created by retrieving a
          class method object from a class or instance, its ‘__self__’
          attribute is the class itself, and its ‘__func__’ attribute is
          the function object underlying the class method.

          When an instance method object is called, the underlying
          function (‘__func__’) is called, inserting the class instance
          (‘__self__’) in front of the argument list.  For instance,
          when ‘C’ is a class which contains a definition for a function
          ‘f()’, and ‘x’ is an instance of ‘C’, calling ‘x.f(1)’ is
          equivalent to calling ‘C.f(x, 1)’.

          When an instance method object is derived from a class method
          object, the "class instance" stored in ‘__self__’ will
          actually be the class itself, so that calling either ‘x.f(1)’
          or ‘C.f(1)’ is equivalent to calling ‘f(C,1)’ where ‘f’ is the
          underlying function.

          Note that the transformation from function object to instance
          method object happens each time the attribute is retrieved
          from the instance.  In some cases, a fruitful optimization is
          to assign the attribute to a local variable and call that
          local variable.  Also notice that this transformation only
          happens for user-defined functions; other callable objects
          (and all non-callable objects) are retrieved without
          transformation.  It is also important to note that
          user-defined functions which are attributes of a class
          instance are not converted to bound methods; this `only'
          happens when the function is an attribute of the class.

     Generator functions

          A function or method which uses the *note yield: 480.
          statement (see section *note The yield statement: 480.) is
          called a `generator function'.  Such a function, when called,
          always returns an iterator object which can be used to execute
          the body of the function: calling the iterator’s *note
          iterator.__next__(): 8cf. method will cause the function to
          execute until it provides a value using the *note yield: 480.
          statement.  When the function executes a *note return: 981.
          statement or falls off the end, a *note StopIteration: 191.
          exception is raised and the iterator will have reached the end
          of the set of values to be returned.

     Coroutine functions

          A function or method which is defined using *note async def:
          1ce. is called a `coroutine function'.  Such a function, when
          called, returns a *note coroutine: 2ad. object.  It may
          contain *note await: 1cf. expressions, as well as *note async
          with: 1d2. and *note async for: 1d1. statements.  See also the
          *note Coroutine Objects: ded. section.

     Built-in functions

          A built-in function object is a wrapper around a C function.
          Examples of built-in functions are *note len(): 5a8. and *note
          math.sin(): a8f. (*note math: b0. is a standard built-in
          module).  The number and type of the arguments are determined
          by the C function.  Special read-only attributes: ‘__doc__’ is
          the function’s documentation string, or ‘None’ if unavailable;
          *note __name__: 8d3. is the function’s name; ‘__self__’ is set
          to ‘None’ (but see the next item); ‘__module__’ is the name of
          the module the function was defined in or ‘None’ if
          unavailable.

     Built-in methods

          This is really a different disguise of a built-in function,
          this time containing an object passed to the C function as an
          implicit extra argument.  An example of a built-in method is
          ‘alist.append()’, assuming `alist' is a list object.  In this
          case, the special read-only attribute ‘__self__’ is set to the
          object denoted by `alist'.

     Classes

          Classes are callable.  These objects normally act as factories
          for new instances of themselves, but variations are possible
          for class types that override *note __new__(): 484.  The
          arguments of the call are passed to *note __new__(): 484. and,
          in the typical case, to *note __init__(): 9d5. to initialize
          the new instance.

     Class Instances

          Instances of arbitrary classes can be made callable by
          defining a *note __call__(): dee. method in their class.

Modules

     Modules are a basic organizational unit of Python code, and are
     created by the *note import system: def. as invoked either by the
     *note import: 881. statement (see *note import: 881.), or by
     calling functions such as *note importlib.import_module(): 754. and
     built-in *note __import__(): 5cd.  A module object has a namespace
     implemented by a dictionary object (this is the dictionary
     referenced by the ‘__globals__’ attribute of functions defined in
     the module).  Attribute references are translated to lookups in
     this dictionary, e.g., ‘m.x’ is equivalent to ‘m.__dict__["x"]’.  A
     module object does not contain the code object used to initialize
     the module (since it isn’t needed once the initialization is done).

     Attribute assignment updates the module’s namespace dictionary,
     e.g., ‘m.x = 1’ is equivalent to ‘m.__dict__["x"] = 1’.

     Special read-only attribute: ‘__dict__’ is the module’s namespace
     as a dictionary object.

     `CPython implementation detail:' Because of the way CPython clears
     module dictionaries, the module dictionary will be cleared when the
     module falls out of scope even if the dictionary still has live
     references.  To avoid this, copy the dictionary or keep the module
     around while using its dictionary directly.

     Predefined (writable) attributes: *note __name__: 8d3. is the
     module’s name; ‘__doc__’ is the module’s documentation string, or
     ‘None’ if unavailable; *note __file__: df0. is the pathname of the
     file from which the module was loaded, if it was loaded from a
     file.  The *note __file__: df0. attribute may be missing for
     certain types of modules, such as C modules that are statically
     linked into the interpreter; for extension modules loaded
     dynamically from a shared library, it is the pathname of the shared
     library file.

Custom classes

     Custom class types are typically created by class definitions (see
     section *note Class definitions: 8d6.).  A class has a namespace
     implemented by a dictionary object.  Class attribute references are
     translated to lookups in this dictionary, e.g., ‘C.x’ is translated
     to ‘C.__dict__["x"]’ (although there are a number of hooks which
     allow for other means of locating attributes).  When the attribute
     name is not found there, the attribute search continues in the base
     classes.  This search of the base classes uses the C3 method
     resolution order which behaves correctly even in the presence of
     ’diamond’ inheritance structures where there are multiple
     inheritance paths leading back to a common ancestor.  Additional
     details on the C3 MRO used by Python can be found in the
     documentation accompanying the 2.3 release at
     ‘https://www.python.org/download/releases/2.3/mro/’.

     When a class attribute reference (for class ‘C’, say) would yield a
     class method object, it is transformed into an instance method
     object whose ‘__self__’ attributes is ‘C’.  When it would yield a
     static method object, it is transformed into the object wrapped by
     the static method object.  See section *note Implementing
     Descriptors: df1. for another way in which attributes retrieved
     from a class may differ from those actually contained in its
     ‘__dict__’.

     Class attribute assignments update the class’s dictionary, never
     the dictionary of a base class.

     A class object can be called (see above) to yield a class instance
     (see below).

     Special attributes: *note __name__: 8d3. is the class name;
     ‘__module__’ is the module name in which the class was defined;
     ‘__dict__’ is the dictionary containing the class’s namespace;
     *note __bases__: df2. is a tuple (possibly empty or a singleton)
     containing the base classes, in the order of their occurrence in
     the base class list; ‘__doc__’ is the class’s documentation string,
     or None if undefined.

Class instances

     A class instance is created by calling a class object (see above).
     A class instance has a namespace implemented as a dictionary which
     is the first place in which attribute references are searched.
     When an attribute is not found there, and the instance’s class has
     an attribute by that name, the search continues with the class
     attributes.  If a class attribute is found that is a user-defined
     function object, it is transformed into an instance method object
     whose ‘__self__’ attribute is the instance.  Static method and
     class method objects are also transformed; see above under
     "Classes".  See section *note Implementing Descriptors: df1. for
     another way in which attributes of a class retrieved via its
     instances may differ from the objects actually stored in the
     class’s ‘__dict__’.  If no class attribute is found, and the
     object’s class has a *note __getattr__(): 782. method, that is
     called to satisfy the lookup.

     Attribute assignments and deletions update the instance’s
     dictionary, never a class’s dictionary.  If the class has a *note
     __setattr__(): aaf. or *note __delattr__(): df3. method, this is
     called instead of updating the instance dictionary directly.

     Class instances can pretend to be numbers, sequences, or mappings
     if they have methods with certain special names.  See section *note
     Special method names: d9b.

     Special attributes: *note __dict__: df4. is the attribute
     dictionary; *note __class__: df5. is the instance’s class.

I/O objects (also known as file objects)

     A *note file object: 78b. represents an open file.  Various
     shortcuts are available to create file objects: the *note open():
     1e8. built-in function, and also *note os.popen(): 7d7, *note
     os.fdopen(): df6, and the *note makefile(): 75b. method of socket
     objects (and perhaps by other functions or methods provided by
     extension modules).

     The objects ‘sys.stdin’, ‘sys.stdout’ and ‘sys.stderr’ are
     initialized to file objects corresponding to the interpreter’s
     standard input, output and error streams; they are all open in text
     mode and therefore follow the interface defined by the *note
     io.TextIOBase: 89f. abstract class.

Internal types

     A few types used internally by the interpreter are exposed to the
     user.  Their definitions may change with future versions of the
     interpreter, but they are mentioned here for completeness.

     Code objects

          Code objects represent `byte-compiled' executable Python code,
          or *note bytecode: d06.  The difference between a code object
          and a function object is that the function object contains an
          explicit reference to the function’s globals (the module in
          which it was defined), while a code object contains no
          context; also the default argument values are stored in the
          function object, not in the code object (because they
          represent values calculated at run-time).  Unlike function
          objects, code objects are immutable and contain no references
          (directly or indirectly) to mutable objects.

          Special read-only attributes: ‘co_name’ gives the function
          name; ‘co_argcount’ is the number of positional arguments
          (including arguments with default values); ‘co_nlocals’ is the
          number of local variables used by the function (including
          arguments); ‘co_varnames’ is a tuple containing the names of
          the local variables (starting with the argument names);
          ‘co_cellvars’ is a tuple containing the names of local
          variables that are referenced by nested functions;
          ‘co_freevars’ is a tuple containing the names of free
          variables; ‘co_code’ is a string representing the sequence of
          bytecode instructions; ‘co_consts’ is a tuple containing the
          literals used by the bytecode; ‘co_names’ is a tuple
          containing the names used by the bytecode; ‘co_filename’ is
          the filename from which the code was compiled;
          ‘co_firstlineno’ is the first line number of the function;
          ‘co_lnotab’ is a string encoding the mapping from bytecode
          offsets to line numbers (for details see the source code of
          the interpreter); ‘co_stacksize’ is the required stack size
          (including local variables); ‘co_flags’ is an integer encoding
          a number of flags for the interpreter.

          The following flag bits are defined for ‘co_flags’: bit ‘0x04’
          is set if the function uses the ‘*arguments’ syntax to accept
          an arbitrary number of positional arguments; bit ‘0x08’ is set
          if the function uses the ‘**keywords’ syntax to accept
          arbitrary keyword arguments; bit ‘0x20’ is set if the function
          is a generator.

          Future feature declarations (‘from __future__ import
          division’) also use bits in ‘co_flags’ to indicate whether a
          code object was compiled with a particular feature enabled:
          bit ‘0x2000’ is set if the function was compiled with future
          division enabled; bits ‘0x10’ and ‘0x1000’ were used in
          earlier versions of Python.

          Other bits in ‘co_flags’ are reserved for internal use.

          If a code object represents a function, the first item in
          ‘co_consts’ is the documentation string of the function, or
          ‘None’ if undefined.

     Frame objects

          Frame objects represent execution frames.  They may occur in
          traceback objects (see below).

          Special read-only attributes: ‘f_back’ is to the previous
          stack frame (towards the caller), or ‘None’ if this is the
          bottom stack frame; ‘f_code’ is the code object being executed
          in this frame; ‘f_locals’ is the dictionary used to look up
          local variables; ‘f_globals’ is used for global variables;
          ‘f_builtins’ is used for built-in (intrinsic) names; ‘f_lasti’
          gives the precise instruction (this is an index into the
          bytecode string of the code object).

          Special writable attributes: ‘f_trace’, if not ‘None’, is a
          function called at the start of each source code line (this is
          used by the debugger); ‘f_lineno’ is the current line number
          of the frame — writing to this from within a trace function
          jumps to the given line (only for the bottom-most frame).  A
          debugger can implement a Jump command (aka Set Next Statement)
          by writing to f_lineno.

          Frame objects support one method:

           -- Method: frame.clear ()

               This method clears all references to local variables held
               by the frame.  Also, if the frame belonged to a
               generator, the generator is finalized.  This helps break
               reference cycles involving frame objects (for example
               when catching an exception and storing its traceback for
               later use).

               *note RuntimeError: 193. is raised if the frame is
               currently executing.

               New in version 3.4.

     Traceback objects

          Traceback objects represent a stack trace of an exception.  A
          traceback object is created when an exception occurs.  When
          the search for an exception handler unwinds the execution
          stack, at each unwound level a traceback object is inserted in
          front of the current traceback.  When an exception handler is
          entered, the stack trace is made available to the program.
          (See section *note The try statement: 9e9.)  It is accessible
          as the third item of the tuple returned by ‘sys.exc_info()’.
          When the program contains no suitable handler, the stack trace
          is written (nicely formatted) to the standard error stream; if
          the interpreter is interactive, it is also made available to
          the user as ‘sys.last_traceback’.

          Special read-only attributes: ‘tb_next’ is the next level in
          the stack trace (towards the frame where the exception
          occurred), or ‘None’ if there is no next level; ‘tb_frame’
          points to the execution frame of the current level;
          ‘tb_lineno’ gives the line number where the exception
          occurred; ‘tb_lasti’ indicates the precise instruction.  The
          line number and last instruction in the traceback may differ
          from the line number of its frame object if the exception
          occurred in a *note try: 9e9. statement with no matching
          except clause or with a finally clause.

     Slice objects

          Slice objects are used to represent slices for *note
          __getitem__(): a84. methods.  They are also created by the
          built-in *note slice(): a85. function.

          Special read-only attributes: ‘start’ is the lower bound;
          ‘stop’ is the upper bound; ‘step’ is the step value; each is
          ‘None’ if omitted.  These attributes can have any type.

          Slice objects support one method:

           -- Method: slice.indices (self, length)

               This method takes a single integer argument `length' and
               computes information about the slice that the slice
               object would describe if applied to a sequence of
               `length' items.  It returns a tuple of three integers;
               respectively these are the `start' and `stop' indices and
               the `step' or stride length of the slice.  Missing or
               out-of-bounds indices are handled in a manner consistent
               with regular slices.

     Static method objects

          Static method objects provide a way of defeating the
          transformation of function objects to method objects described
          above.  A static method object is a wrapper around any other
          object, usually a user-defined method object.  When a static
          method object is retrieved from a class or a class instance,
          the object actually returned is the wrapped object, which is
          not subject to any further transformation.  Static method
          objects are not themselves callable, although the objects they
          wrap usually are.  Static method objects are created by the
          built-in *note staticmethod(): 5f6. constructor.

     Class method objects

          A class method object, like a static method object, is a
          wrapper around another object that alters the way in which
          that object is retrieved from classes and class instances.
          The behaviour of class method objects upon such retrieval is
          described above, under "User-defined methods".  Class method
          objects are created by the built-in *note classmethod(): 5f4.
          constructor.


File: python.info,  Node: Special method names,  Next: Coroutines,  Prev: The standard type hierarchy,  Up: Data model

4.3.3 Special method names
--------------------------

A class can implement certain operations that are invoked by special
syntax (such as arithmetic operations or subscripting and slicing) by
defining methods with special names.  This is Python’s approach to
`operator overloading', allowing classes to define their own behavior
with respect to language operators.  For instance, if a class defines a
method named *note __getitem__(): a84, and ‘x’ is an instance of this
class, then ‘x[i]’ is roughly equivalent to ‘type(x).__getitem__(x, i)’.
Except where mentioned, attempts to execute an operation raise an
exception when no appropriate method is defined (typically *note
AttributeError: 356. or *note TypeError: 562.).

When implementing a class that emulates any built-in type, it is
important that the emulation only be implemented to the degree that it
makes sense for the object being modelled.  For example, some sequences
may work well with retrieval of individual elements, but extracting a
slice may not make sense.  (One example of this is the ‘NodeList’
interface in the W3C’s Document Object Model.)

* Menu:

* Basic customization:: 
* Customizing attribute access:: 
* Customizing class creation:: 
* Customizing instance and subclass checks:: 
* Emulating callable objects:: 
* Emulating container types:: 
* Emulating numeric types:: 
* With Statement Context Managers:: 
* Special method lookup:: 


File: python.info,  Node: Basic customization,  Next: Customizing attribute access,  Up: Special method names

4.3.3.1 Basic customization
...........................

 -- Method: object.__new__ (cls[, ...])

     Called to create a new instance of class `cls'.  *note __new__():
     484. is a static method (special-cased so you need not declare it
     as such) that takes the class of which an instance was requested as
     its first argument.  The remaining arguments are those passed to
     the object constructor expression (the call to the class).  The
     return value of *note __new__(): 484. should be the new object
     instance (usually an instance of `cls').

     Typical implementations create a new instance of the class by
     invoking the superclass’s *note __new__(): 484. method using
     ‘super(currentclass, cls).__new__(cls[, ...])’ with appropriate
     arguments and then modifying the newly-created instance as
     necessary before returning it.

     If *note __new__(): 484. returns an instance of `cls', then the new
     instance’s *note __init__(): 9d5. method will be invoked like
     ‘__init__(self[, ...])’, where `self' is the new instance and the
     remaining arguments are the same as were passed to *note __new__():
     484.

     If *note __new__(): 484. does not return an instance of `cls', then
     the new instance’s *note __init__(): 9d5. method will not be
     invoked.

     *note __new__(): 484. is intended mainly to allow subclasses of
     immutable types (like int, str, or tuple) to customize instance
     creation.  It is also commonly overridden in custom metaclasses in
     order to customize class creation.

 -- Method: object.__init__ (self[, ...])

     Called after the instance has been created (by *note __new__():
     484.), but before it is returned to the caller.  The arguments are
     those passed to the class constructor expression.  If a base class
     has an *note __init__(): 9d5. method, the derived class’s *note
     __init__(): 9d5. method, if any, must explicitly call it to ensure
     proper initialization of the base class part of the instance; for
     example: ‘BaseClass.__init__(self, [args...])’.

     Because *note __new__(): 484. and *note __init__(): 9d5. work
     together in constructing objects (*note __new__(): 484. to create
     it, and *note __init__(): 9d5. to customise it), no non-‘None’
     value may be returned by *note __init__(): 9d5.; doing so will
     cause a *note TypeError: 562. to be raised at runtime.

 -- Method: object.__del__ (self)

     Called when the instance is about to be destroyed.  This is also
     called a destructor.  If a base class has a *note __del__(): 525.
     method, the derived class’s *note __del__(): 525. method, if any,
     must explicitly call it to ensure proper deletion of the base class
     part of the instance.  Note that it is possible (though not
     recommended!)  for the *note __del__(): 525. method to postpone
     destruction of the instance by creating a new reference to it.  It
     may then be called at a later time when this new reference is
     deleted.  It is not guaranteed that *note __del__(): 525. methods
     are called for objects that still exist when the interpreter exits.

          Note: ‘del x’ doesn’t directly call ‘x.__del__()’ — the former
          decrements the reference count for ‘x’ by one, and the latter
          is only called when ‘x’’s reference count reaches zero.  Some
          common situations that may prevent the reference count of an
          object from going to zero include: circular references between
          objects (e.g., a doubly-linked list or a tree data structure
          with parent and child pointers); a reference to the object on
          the stack frame of a function that caught an exception (the
          traceback stored in ‘sys.exc_info()[2]’ keeps the stack frame
          alive); or a reference to the object on the stack frame that
          raised an unhandled exception in interactive mode (the
          traceback stored in ‘sys.last_traceback’ keeps the stack frame
          alive).  The first situation can only be remedied by
          explicitly breaking the cycles; the second can be resolved by
          freeing the reference to the traceback object when it is no
          longer useful, and the third can be resolved by storing ‘None’
          in ‘sys.last_traceback’.  Circular references which are
          garbage are detected and cleaned up when the cyclic garbage
          collector is enabled (it’s on by default).  Refer to the
          documentation for the *note gc: 85. module for more
          information about this topic.

          Warning: Due to the precarious circumstances under which *note
          __del__(): 525. methods are invoked, exceptions that occur
          during their execution are ignored, and a warning is printed
          to ‘sys.stderr’ instead.  Also, when *note __del__(): 525. is
          invoked in response to a module being deleted (e.g., when
          execution of the program is done), other globals referenced by
          the *note __del__(): 525. method may already have been deleted
          or in the process of being torn down (e.g.  the import
          machinery shutting down).  For this reason, *note __del__():
          525. methods should do the absolute minimum needed to maintain
          external invariants.  Starting with version 1.5, Python
          guarantees that globals whose name begins with a single
          underscore are deleted from their module before other globals
          are deleted; if no other references to such globals exist,
          this may help in assuring that imported modules are still
          available at the time when the *note __del__(): 525. method is
          called.

 -- Method: object.__repr__ (self)

     Called by the *note repr(): 3bb. built-in function to compute the
     "official" string representation of an object.  If at all possible,
     this should look like a valid Python expression that could be used
     to recreate an object with the same value (given an appropriate
     environment).  If this is not possible, a string of the form
     ‘<...some useful description...>’ should be returned.  The return
     value must be a string object.  If a class defines *note
     __repr__(): 7bd. but not *note __str__(): ab9, then *note
     __repr__(): 7bd. is also used when an "informal" string
     representation of instances of that class is required.

     This is typically used for debugging, so it is important that the
     representation is information-rich and unambiguous.

 -- Method: object.__str__ (self)

     Called by *note str(object): 25a. and the built-in functions *note
     format(): 14e. and *note print(): 481. to compute the "informal" or
     nicely printable string representation of an object.  The return
     value must be a *note string: bea. object.

     This method differs from *note object.__repr__(): 7bd. in that
     there is no expectation that *note __str__(): ab9. return a valid
     Python expression: a more convenient or concise representation can
     be used.

     The default implementation defined by the built-in type *note
     object: 5cb. calls *note object.__repr__(): 7bd.

 -- Method: object.__bytes__ (self)

     Called by *note bytes(): 1db. to compute a byte-string
     representation of an object.  This should return a ‘bytes’ object.

 -- Method: object.__format__ (self, format_spec)

     Called by the *note format(): 14e. built-in function, and by
     extension, evaluation of *note formatted string literals: 14f. and
     the *note str.format(): 14d. method, to produce a "formatted"
     string representation of an object.  The ‘format_spec’ argument is
     a string that contains a description of the formatting options
     desired.  The interpretation of the ‘format_spec’ argument is up to
     the type implementing *note __format__(): 561, however most classes
     will either delegate formatting to one of the built-in types, or
     use a similar formatting option syntax.

     See *note Format Specification Mini-Language: dfc. for a
     description of the standard formatting syntax.

     The return value must be a string object.

     Changed in version 3.4: The __format__ method of ‘object’ itself
     raises a *note TypeError: 562. if passed any non-empty string.

 -- Method: object.__lt__ (self, other)
 -- Method: object.__le__ (self, other)
 -- Method: object.__eq__ (self, other)
 -- Method: object.__ne__ (self, other)
 -- Method: object.__gt__ (self, other)
 -- Method: object.__ge__ (self, other)

     These are the so-called "rich comparison" methods.  The
     correspondence between operator symbols and method names is as
     follows: ‘x<y’ calls ‘x.__lt__(y)’, ‘x<=y’ calls ‘x.__le__(y)’,
     ‘x==y’ calls ‘x.__eq__(y)’, ‘x!=y’ calls ‘x.__ne__(y)’, ‘x>y’ calls
     ‘x.__gt__(y)’, and ‘x>=y’ calls ‘x.__ge__(y)’.

     A rich comparison method may return the singleton ‘NotImplemented’
     if it does not implement the operation for a given pair of
     arguments.  By convention, ‘False’ and ‘True’ are returned for a
     successful comparison.  However, these methods can return any
     value, so if the comparison operator is used in a Boolean context
     (e.g., in the condition of an ‘if’ statement), Python will call
     *note bool(): a72. on the value to determine if the result is true
     or false.

     By default, *note __ne__(): adb. delegates to *note __eq__(): 89a.
     and inverts the result unless it is ‘NotImplemented’.  There are no
     other implied relationships among the comparison operators, for
     example, the truth of ‘(x<y or x==y)’ does not imply ‘x<=y’.  To
     automatically generate ordering operations from a single root
     operation, see *note functools.total_ordering(): 440.

     See the paragraph on *note __hash__(): 5e7. for some important
     notes on creating *note hashable: de9. objects which support custom
     comparison operations and are usable as dictionary keys.

     There are no swapped-argument versions of these methods (to be used
     when the left argument does not support the operation but the right
     argument does); rather, *note __lt__(): 899. and *note __gt__():
     914. are each other’s reflection, *note __le__(): 913. and *note
     __ge__(): 915. are each other’s reflection, and *note __eq__():
     89a. and *note __ne__(): adb. are their own reflection.  If the
     operands are of different types, and right operand’s type is a
     direct or indirect subclass of the left operand’s type, the
     reflected method of the right operand has priority, otherwise the
     left operand’s method has priority.  Virtual subclassing is not
     considered.

 -- Method: object.__hash__ (self)

     Called by built-in function *note hash(): 5e6. and for operations
     on members of hashed collections including *note set: 7be, *note
     frozenset: 84c, and *note dict: 3b0.  *note __hash__(): 5e7. should
     return an integer.  The only required property is that objects
     which compare equal have the same hash value; it is advised to
     somehow mix together (e.g.  using exclusive or) the hash values for
     the components of the object that also play a part in comparison of
     objects.

          Note: *note hash(): 5e6. truncates the value returned from an
          object’s custom *note __hash__(): 5e7. method to the size of a
          ‘Py_ssize_t’.  This is typically 8 bytes on 64-bit builds and
          4 bytes on 32-bit builds.  If an object’s *note __hash__():
          5e7. must interoperate on builds of different bit sizes, be
          sure to check the width on all supported builds.  An easy way
          to do this is with ‘python -c "import sys;
          print(sys.hash_info.width)"’.

     If a class does not define an *note __eq__(): 89a. method it should
     not define a *note __hash__(): 5e7. operation either; if it defines
     *note __eq__(): 89a. but not *note __hash__(): 5e7, its instances
     will not be usable as items in hashable collections.  If a class
     defines mutable objects and implements an *note __eq__(): 89a.
     method, it should not implement *note __hash__(): 5e7, since the
     implementation of hashable collections requires that a key’s hash
     value is immutable (if the object’s hash value changes, it will be
     in the wrong hash bucket).

     User-defined classes have *note __eq__(): 89a. and *note
     __hash__(): 5e7. methods by default; with them, all objects compare
     unequal (except with themselves) and ‘x.__hash__()’ returns an
     appropriate value such that ‘x == y’ implies both that ‘x is y’ and
     ‘hash(x) == hash(y)’.

     A class that overrides *note __eq__(): 89a. and does not define
     *note __hash__(): 5e7. will have its *note __hash__(): 5e7.
     implicitly set to ‘None’.  When the *note __hash__(): 5e7. method
     of a class is ‘None’, instances of the class will raise an
     appropriate *note TypeError: 562. when a program attempts to
     retrieve their hash value, and will also be correctly identified as
     unhashable when checking ‘isinstance(obj, collections.Hashable)’.

     If a class that overrides *note __eq__(): 89a. needs to retain the
     implementation of *note __hash__(): 5e7. from a parent class, the
     interpreter must be told this explicitly by setting ‘__hash__ =
     <ParentClass>.__hash__’.

     If a class that does not override *note __eq__(): 89a. wishes to
     suppress hash support, it should include ‘__hash__ = None’ in the
     class definition.  A class which defines its own *note __hash__():
     5e7. that explicitly raises a *note TypeError: 562. would be
     incorrectly identified as hashable by an ‘isinstance(obj,
     collections.Hashable)’ call.

          Note: By default, the *note __hash__(): 5e7. values of str,
          bytes and datetime objects are "salted" with an unpredictable
          random value.  Although they remain constant within an
          individual Python process, they are not predictable between
          repeated invocations of Python.

          This is intended to provide protection against a
          denial-of-service caused by carefully-chosen inputs that
          exploit the worst case performance of a dict insertion, O(n^2)
          complexity.  See
          ‘http://www.ocert.org/advisories/ocert-2011-003.html’ for
          details.

          Changing hash values affects the iteration order of dicts,
          sets and other mappings.  Python has never made guarantees
          about this ordering (and it typically varies between 32-bit
          and 64-bit builds).

          See also *note PYTHONHASHSEED: 5e8.

     Changed in version 3.3: Hash randomization is enabled by default.

 -- Method: object.__bool__ (self)

     Called to implement truth value testing and the built-in operation
     ‘bool()’; should return ‘False’ or ‘True’.  When this method is not
     defined, *note __len__(): a47. is called, if it is defined, and the
     object is considered true if its result is nonzero.  If a class
     defines neither *note __len__(): a47. nor *note __bool__(): 8d4,
     all its instances are considered true.


File: python.info,  Node: Customizing attribute access,  Next: Customizing class creation,  Prev: Basic customization,  Up: Special method names

4.3.3.2 Customizing attribute access
....................................

The following methods can be defined to customize the meaning of
attribute access (use of, assignment to, or deletion of ‘x.name’) for
class instances.

 -- Method: object.__getattr__ (self, name)

     Called when an attribute lookup has not found the attribute in the
     usual places (i.e.  it is not an instance attribute nor is it found
     in the class tree for ‘self’).  ‘name’ is the attribute name.  This
     method should return the (computed) attribute value or raise an
     *note AttributeError: 356. exception.

     Note that if the attribute is found through the normal mechanism,
     *note __getattr__(): 782. is not called.  (This is an intentional
     asymmetry between *note __getattr__(): 782. and *note
     __setattr__(): aaf.)  This is done both for efficiency reasons and
     because otherwise *note __getattr__(): 782. would have no way to
     access other attributes of the instance.  Note that at least for
     instance variables, you can fake total control by not inserting any
     values in the instance attribute dictionary (but instead inserting
     them in another object).  See the *note __getattribute__(): 783.
     method below for a way to actually get total control over attribute
     access.

 -- Method: object.__getattribute__ (self, name)

     Called unconditionally to implement attribute accesses for
     instances of the class.  If the class also defines *note
     __getattr__(): 782, the latter will not be called unless *note
     __getattribute__(): 783. either calls it explicitly or raises an
     *note AttributeError: 356.  This method should return the
     (computed) attribute value or raise an *note AttributeError: 356.
     exception.  In order to avoid infinite recursion in this method,
     its implementation should always call the base class method with
     the same name to access any attributes it needs, for example,
     ‘object.__getattribute__(self, name)’.

          Note: This method may still be bypassed when looking up
          special methods as the result of implicit invocation via
          language syntax or built-in functions.  See *note Special
          method lookup: e00.

 -- Method: object.__setattr__ (self, name, value)

     Called when an attribute assignment is attempted.  This is called
     instead of the normal mechanism (i.e.  store the value in the
     instance dictionary).  `name' is the attribute name, `value' is the
     value to be assigned to it.

     If *note __setattr__(): aaf. wants to assign to an instance
     attribute, it should call the base class method with the same name,
     for example, ‘object.__setattr__(self, name, value)’.

 -- Method: object.__delattr__ (self, name)

     Like *note __setattr__(): aaf. but for attribute deletion instead
     of assignment.  This should only be implemented if ‘del obj.name’
     is meaningful for the object.

 -- Method: object.__dir__ (self)

     Called when *note dir(): 16a. is called on the object.  A sequence
     must be returned.  *note dir(): 16a. converts the returned sequence
     to a list and sorts it.

* Menu:

* Implementing Descriptors:: 
* Invoking Descriptors:: 
* __slots__:: 


File: python.info,  Node: Implementing Descriptors,  Next: Invoking Descriptors,  Up: Customizing attribute access

4.3.3.3 Implementing Descriptors
................................

The following methods only apply when an instance of the class
containing the method (a so-called `descriptor' class) appears in an
`owner' class (the descriptor must be in either the owner’s class
dictionary or in the class dictionary for one of its parents).  In the
examples below, "the attribute" refers to the attribute whose name is
the key of the property in the owner class’ ‘__dict__’.

 -- Method: object.__get__ (self, instance, owner)

     Called to get the attribute of the owner class (class attribute
     access) or of an instance of that class (instance attribute
     access).  `owner' is always the owner class, while `instance' is
     the instance that the attribute was accessed through, or ‘None’
     when the attribute is accessed through the `owner'.  This method
     should return the (computed) attribute value or raise an *note
     AttributeError: 356. exception.

 -- Method: object.__set__ (self, instance, value)

     Called to set the attribute on an instance `instance' of the owner
     class to a new value, `value'.

 -- Method: object.__delete__ (self, instance)

     Called to delete the attribute on an instance `instance' of the
     owner class.

The attribute ‘__objclass__’ is interpreted by the *note inspect: 9e.
module as specifying the class where this object was defined (setting
this appropriately can assist in runtime introspection of dynamic class
attributes).  For callables, it may indicate that an instance of the
given type (or a subclass) is expected or required as the first
positional argument (for example, CPython sets this attribute for
unbound methods that are implemented in C).


File: python.info,  Node: Invoking Descriptors,  Next: __slots__,  Prev: Implementing Descriptors,  Up: Customizing attribute access

4.3.3.4 Invoking Descriptors
............................

In general, a descriptor is an object attribute with "binding behavior",
one whose attribute access has been overridden by methods in the
descriptor protocol: *note __get__(): e02, *note __set__(): e03, and
*note __delete__(): e04.  If any of those methods are defined for an
object, it is said to be a descriptor.

The default behavior for attribute access is to get, set, or delete the
attribute from an object’s dictionary.  For instance, ‘a.x’ has a lookup
chain starting with ‘a.__dict__['x']’, then ‘type(a).__dict__['x']’, and
continuing through the base classes of ‘type(a)’ excluding metaclasses.

However, if the looked-up value is an object defining one of the
descriptor methods, then Python may override the default behavior and
invoke the descriptor method instead.  Where this occurs in the
precedence chain depends on which descriptor methods were defined and
how they were called.

The starting point for descriptor invocation is a binding, ‘a.x’.  How
the arguments are assembled depends on ‘a’:

Direct Call

     The simplest and least common call is when user code directly
     invokes a descriptor method: ‘x.__get__(a)’.

Instance Binding

     If binding to an object instance, ‘a.x’ is transformed into the
     call: ‘type(a).__dict__['x'].__get__(a, type(a))’.

Class Binding

     If binding to a class, ‘A.x’ is transformed into the call:
     ‘A.__dict__['x'].__get__(None, A)’.

Super Binding

     If ‘a’ is an instance of *note super: 56a, then the binding
     ‘super(B, obj).m()’ searches ‘obj.__class__.__mro__’ for the base
     class ‘A’ immediately preceding ‘B’ and then invokes the descriptor
     with the call: ‘A.__dict__['m'].__get__(obj, obj.__class__)’.

For instance bindings, the precedence of descriptor invocation depends
on the which descriptor methods are defined.  A descriptor can define
any combination of *note __get__(): e02, *note __set__(): e03. and *note
__delete__(): e04.  If it does not define *note __get__(): e02, then
accessing the attribute will return the descriptor object itself unless
there is a value in the object’s instance dictionary.  If the descriptor
defines *note __set__(): e03. and/or *note __delete__(): e04, it is a
data descriptor; if it defines neither, it is a non-data descriptor.
Normally, data descriptors define both *note __get__(): e02. and *note
__set__(): e03, while non-data descriptors have just the *note
__get__(): e02. method.  Data descriptors with *note __set__(): e03. and
*note __get__(): e02. defined always override a redefinition in an
instance dictionary.  In contrast, non-data descriptors can be
overridden by instances.

Python methods (including *note staticmethod(): 5f6. and *note
classmethod(): 5f4.) are implemented as non-data descriptors.
Accordingly, instances can redefine and override methods.  This allows
individual instances to acquire behaviors that differ from other
instances of the same class.

The *note property(): 377. function is implemented as a data descriptor.
Accordingly, instances cannot override the behavior of a property.


File: python.info,  Node: __slots__,  Prev: Invoking Descriptors,  Up: Customizing attribute access

4.3.3.5 __slots__
.................

By default, instances of classes have a dictionary for attribute
storage.  This wastes space for objects having very few instance
variables.  The space consumption can become acute when creating large
numbers of instances.

The default can be overridden by defining `__slots__' in a class
definition.  The `__slots__' declaration takes a sequence of instance
variables and reserves just enough space in each instance to hold a
value for each variable.  Space is saved because `__dict__' is not
created for each instance.

 -- Data: object.__slots__

     This class variable can be assigned a string, iterable, or sequence
     of strings with variable names used by instances.  `__slots__'
     reserves space for the declared variables and prevents the
     automatic creation of `__dict__' and `__weakref__' for each
     instance.

* Menu:

* Notes on using __slots__:: 


File: python.info,  Node: Notes on using __slots__,  Up: __slots__

4.3.3.6 Notes on using `__slots__'
..................................

   * When inheriting from a class without `__slots__', the `__dict__'
     attribute of that class will always be accessible, so a `__slots__'
     definition in the subclass is meaningless.

   * Without a `__dict__' variable, instances cannot be assigned new
     variables not listed in the `__slots__' definition.  Attempts to
     assign to an unlisted variable name raises *note AttributeError:
     356.  If dynamic assignment of new variables is desired, then add
     ‘'__dict__'’ to the sequence of strings in the `__slots__'
     declaration.

   * Without a `__weakref__' variable for each instance, classes
     defining `__slots__' do not support weak references to its
     instances.  If weak reference support is needed, then add
     ‘'__weakref__'’ to the sequence of strings in the `__slots__'
     declaration.

   * `__slots__' are implemented at the class level by creating
     descriptors (*note Implementing Descriptors: df1.) for each
     variable name.  As a result, class attributes cannot be used to set
     default values for instance variables defined by `__slots__';
     otherwise, the class attribute would overwrite the descriptor
     assignment.

   * The action of a `__slots__' declaration is limited to the class
     where it is defined.  As a result, subclasses will have a
     `__dict__' unless they also define `__slots__' (which must only
     contain names of any `additional' slots).

   * If a class defines a slot also defined in a base class, the
     instance variable defined by the base class slot is inaccessible
     (except by retrieving its descriptor directly from the base class).
     This renders the meaning of the program undefined.  In the future,
     a check may be added to prevent this.

   * Nonempty `__slots__' does not work for classes derived from
     "variable-length" built-in types such as *note int: 227, *note
     bytes: 1db. and *note tuple: 25c.

   * Any non-string iterable may be assigned to `__slots__'.  Mappings
     may also be used; however, in the future, special meaning may be
     assigned to the values corresponding to each key.

   * `__class__' assignment works only if both classes have the same
     `__slots__'.


File: python.info,  Node: Customizing class creation,  Next: Customizing instance and subclass checks,  Prev: Customizing attribute access,  Up: Special method names

4.3.3.7 Customizing class creation
..................................

By default, classes are constructed using *note type(): 376.  The class
body is executed in a new namespace and the class name is bound locally
to the result of ‘type(name, bases, namespace)’.

The class creation process can be customised by passing the ‘metaclass’
keyword argument in the class definition line, or by inheriting from an
existing class that included such an argument.  In the following
example, both ‘MyClass’ and ‘MySubclass’ are instances of ‘Meta’:

     class Meta(type):
         pass

     class MyClass(metaclass=Meta):
         pass

     class MySubclass(MyClass):
         pass

Any other keyword arguments that are specified in the class definition
are passed through to all metaclass operations described below.

When a class definition is executed, the following steps occur:

   * the appropriate metaclass is determined

   * the class namespace is prepared

   * the class body is executed

   * the class object is created

* Menu:

* Determining the appropriate metaclass:: 
* Preparing the class namespace:: 
* Executing the class body:: 
* Creating the class object:: 
* Metaclass example:: 


File: python.info,  Node: Determining the appropriate metaclass,  Next: Preparing the class namespace,  Up: Customizing class creation

4.3.3.8 Determining the appropriate metaclass
.............................................

The appropriate metaclass for a class definition is determined as
follows:

   * if no bases and no explicit metaclass are given, then *note type():
     376. is used

   * if an explicit metaclass is given and it is `not' an instance of
     *note type(): 376, then it is used directly as the metaclass

   * if an instance of *note type(): 376. is given as the explicit
     metaclass, or bases are defined, then the most derived metaclass is
     used

The most derived metaclass is selected from the explicitly specified
metaclass (if any) and the metaclasses (i.e.  ‘type(cls)’) of all
specified base classes.  The most derived metaclass is one which is a
subtype of `all' of these candidate metaclasses.  If none of the
candidate metaclasses meets that criterion, then the class definition
will fail with ‘TypeError’.


File: python.info,  Node: Preparing the class namespace,  Next: Executing the class body,  Prev: Determining the appropriate metaclass,  Up: Customizing class creation

4.3.3.9 Preparing the class namespace
.....................................

Once the appropriate metaclass has been identified, then the class
namespace is prepared.  If the metaclass has a ‘__prepare__’ attribute,
it is called as ‘namespace = metaclass.__prepare__(name, bases, **kwds)’
(where the additional keyword arguments, if any, come from the class
definition).

If the metaclass has no ‘__prepare__’ attribute, then the class
namespace is initialised as an empty *note dict(): 3b0. instance.

See also
........

PEP 3115(1) - Metaclasses in Python 3000

     Introduced the ‘__prepare__’ namespace hook

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3115


File: python.info,  Node: Executing the class body,  Next: Creating the class object,  Prev: Preparing the class namespace,  Up: Customizing class creation

4.3.3.10 Executing the class body
.................................

The class body is executed (approximately) as ‘exec(body, globals(),
namespace)’.  The key difference from a normal call to *note exec():
8ac. is that lexical scoping allows the class body (including any
methods) to reference names from the current and outer scopes when the
class definition occurs inside a function.

However, even when the class definition occurs inside the function,
methods defined inside the class still cannot see names defined at the
class scope.  Class variables must be accessed through the first
parameter of instance or class methods, and cannot be accessed at all
from static methods.


File: python.info,  Node: Creating the class object,  Next: Metaclass example,  Prev: Executing the class body,  Up: Customizing class creation

4.3.3.11 Creating the class object
..................................

Once the class namespace has been populated by executing the class body,
the class object is created by calling ‘metaclass(name, bases,
namespace, **kwds)’ (the additional keywords passed here are the same as
those passed to ‘__prepare__’).

This class object is the one that will be referenced by the
zero-argument form of *note super(): 56a.  ‘__class__’ is an implicit
closure reference created by the compiler if any methods in a class body
refer to either ‘__class__’ or ‘super’.  This allows the zero argument
form of *note super(): 56a. to correctly identify the class being
defined based on lexical scoping, while the class or instance that was
used to make the current call is identified based on the first argument
passed to the method.

After the class object is created, it is passed to the class decorators
included in the class definition (if any) and the resulting object is
bound in the local namespace as the defined class.

See also
........

PEP 3135(1) - New super

     Describes the implicit ‘__class__’ closure reference

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3135


File: python.info,  Node: Metaclass example,  Prev: Creating the class object,  Up: Customizing class creation

4.3.3.12 Metaclass example
..........................

The potential uses for metaclasses are boundless.  Some ideas that have
been explored include logging, interface checking, automatic delegation,
automatic property creation, proxies, frameworks, and automatic resource
locking/synchronization.

Here is an example of a metaclass that uses an *note
collections.OrderedDict: 1bd. to remember the order that class variables
are defined:

     class OrderedClass(type):

          @classmethod
          def __prepare__(metacls, name, bases, **kwds):
             return collections.OrderedDict()

          def __new__(cls, name, bases, namespace, **kwds):
             result = type.__new__(cls, name, bases, dict(namespace))
             result.members = tuple(namespace)
             return result

     class A(metaclass=OrderedClass):
         def one(self): pass
         def two(self): pass
         def three(self): pass
         def four(self): pass

     >>> A.members
     ('__module__', 'one', 'two', 'three', 'four')

When the class definition for `A' gets executed, the process begins with
calling the metaclass’s ‘__prepare__()’ method which returns an empty
*note collections.OrderedDict: 1bd.  That mapping records the methods
and attributes of `A' as they are defined within the body of the class
statement.  Once those definitions are executed, the ordered dictionary
is fully populated and the metaclass’s *note __new__(): 484. method gets
invoked.  That method builds the new type and it saves the ordered
dictionary keys in an attribute called ‘members’.


File: python.info,  Node: Customizing instance and subclass checks,  Next: Emulating callable objects,  Prev: Customizing class creation,  Up: Special method names

4.3.3.13 Customizing instance and subclass checks
.................................................

The following methods are used to override the default behavior of the
*note isinstance(): 998. and *note issubclass(): 999. built-in
functions.

In particular, the metaclass *note abc.ABCMeta: 409. implements these
methods in order to allow the addition of Abstract Base Classes (ABCs)
as "virtual base classes" to any class or type (including built-in
types), including other ABCs.

 -- Method: class.__instancecheck__ (self, instance)

     Return true if `instance' should be considered a (direct or
     indirect) instance of `class'.  If defined, called to implement
     ‘isinstance(instance, class)’.

 -- Method: class.__subclasscheck__ (self, subclass)

     Return true if `subclass' should be considered a (direct or
     indirect) subclass of `class'.  If defined, called to implement
     ‘issubclass(subclass, class)’.

Note that these methods are looked up on the type (metaclass) of a
class.  They cannot be defined as class methods in the actual class.
This is consistent with the lookup of special methods that are called on
instances, only in this case the instance is itself a class.

See also
........

PEP 3119(1) - Introducing Abstract Base Classes

     Includes the specification for customizing *note isinstance(): 998.
     and *note issubclass(): 999. behavior through *note
     __instancecheck__(): e13. and *note __subclasscheck__(): e14, with
     motivation for this functionality in the context of adding Abstract
     Base Classes (see the *note abc: 4. module) to the language.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3119


File: python.info,  Node: Emulating callable objects,  Next: Emulating container types,  Prev: Customizing instance and subclass checks,  Up: Special method names

4.3.3.14 Emulating callable objects
...................................

 -- Method: object.__call__ (self[, args...])

     Called when the instance is "called" as a function; if this method
     is defined, ‘x(arg1, arg2, ...)’ is a shorthand for
     ‘x.__call__(arg1, arg2, ...)’.


File: python.info,  Node: Emulating container types,  Next: Emulating numeric types,  Prev: Emulating callable objects,  Up: Special method names

4.3.3.15 Emulating container types
..................................

The following methods can be defined to implement container objects.
Containers usually are sequences (such as lists or tuples) or mappings
(like dictionaries), but can represent other containers as well.  The
first set of methods is used either to emulate a sequence or to emulate
a mapping; the difference is that for a sequence, the allowable keys
should be the integers `k' for which ‘0 <= k < N’ where `N' is the
length of the sequence, or slice objects, which define a range of items.
It is also recommended that mappings provide the methods ‘keys()’,
‘values()’, ‘items()’, ‘get()’, ‘clear()’, ‘setdefault()’, ‘pop()’,
‘popitem()’, ‘copy()’, and ‘update()’ behaving similar to those for
Python’s standard dictionary objects.  The *note collections: 1e. module
provides a *note MutableMapping: 61d. abstract base class to help create
those methods from a base set of *note __getitem__(): a84, *note
__setitem__(): 8cd, *note __delitem__(): 8ce, and ‘keys()’.  Mutable
sequences should provide methods ‘append()’, ‘count()’, ‘index()’,
‘extend()’, ‘insert()’, ‘pop()’, ‘remove()’, ‘reverse()’ and ‘sort()’,
like Python standard list objects.  Finally, sequence types should
implement addition (meaning concatenation) and multiplication (meaning
repetition) by defining the methods *note __add__(): e19, *note
__radd__(): e1a, *note __iadd__(): af5, *note __mul__(): e1b, *note
__rmul__(): e1c. and *note __imul__(): e1d. described below; they should
not define other numerical operators.  It is recommended that both
mappings and sequences implement the *note __contains__(): 99c. method
to allow efficient use of the ‘in’ operator; for mappings, ‘in’ should
search the mapping’s keys; for sequences, it should search through the
values.  It is further recommended that both mappings and sequences
implement the *note __iter__(): 99b. method to allow efficient iteration
through the container; for mappings, *note __iter__(): 99b. should be
the same as ‘keys()’; for sequences, it should iterate through the
values.

 -- Method: object.__len__ (self)

     Called to implement the built-in function *note len(): 5a8.  Should
     return the length of the object, an integer ‘>=’ 0.  Also, an
     object that doesn’t define a *note __bool__(): 8d4. method and
     whose *note __len__(): a47. method returns zero is considered to be
     false in a Boolean context.

 -- Method: object.__length_hint__ (self)

     Called to implement *note operator.length_hint(): 476.  Should
     return an estimated length for the object (which may be greater or
     less than the actual length).  The length must be an integer ‘>=’
     0.  This method is purely an optimization and is never required for
     correctness.

     New in version 3.4.

     Note: Slicing is done exclusively with the following three methods.
     A call like

          a[1:2] = b

     is translated to

          a[slice(1, 2, None)] = b

     and so forth.  Missing slice items are always filled in with
     ‘None’.

 -- Method: object.__getitem__ (self, key)

     Called to implement evaluation of ‘self[key]’.  For sequence types,
     the accepted keys should be integers and slice objects.  Note that
     the special interpretation of negative indexes (if the class wishes
     to emulate a sequence type) is up to the *note __getitem__(): a84.
     method.  If `key' is of an inappropriate type, *note TypeError:
     562. may be raised; if of a value outside the set of indexes for
     the sequence (after any special interpretation of negative values),
     *note IndexError: afb. should be raised.  For mapping types, if
     `key' is missing (not in the container), *note KeyError: 1a7.
     should be raised.

          Note: *note for: 895. loops expect that an *note IndexError:
          afb. will be raised for illegal indexes to allow proper
          detection of the end of the sequence.

 -- Method: object.__missing__ (self, key)

     Called by *note dict: 3b0.*note __getitem__(): a84. to implement
     ‘self[key]’ for dict subclasses when key is not in the dictionary.

 -- Method: object.__setitem__ (self, key, value)

     Called to implement assignment to ‘self[key]’.  Same note as for
     *note __getitem__(): a84.  This should only be implemented for
     mappings if the objects support changes to the values for keys, or
     if new keys can be added, or for sequences if elements can be
     replaced.  The same exceptions should be raised for improper `key'
     values as for the *note __getitem__(): a84. method.

 -- Method: object.__delitem__ (self, key)

     Called to implement deletion of ‘self[key]’.  Same note as for
     *note __getitem__(): a84.  This should only be implemented for
     mappings if the objects support removal of keys, or for sequences
     if elements can be removed from the sequence.  The same exceptions
     should be raised for improper `key' values as for the *note
     __getitem__(): a84. method.

 -- Method: object.__iter__ (self)

     This method is called when an iterator is required for a container.
     This method should return a new iterator object that can iterate
     over all the objects in the container.  For mappings, it should
     iterate over the keys of the container.

     Iterator objects also need to implement this method; they are
     required to return themselves.  For more information on iterator
     objects, see *note Iterator Types: e1e.

 -- Method: object.__reversed__ (self)

     Called (if present) by the *note reversed(): 24d. built-in to
     implement reverse iteration.  It should return a new iterator
     object that iterates over all the objects in the container in
     reverse order.

     If the *note __reversed__(): e1f. method is not provided, the *note
     reversed(): 24d. built-in will fall back to using the sequence
     protocol (*note __len__(): a47. and *note __getitem__(): a84.).
     Objects that support the sequence protocol should only provide
     *note __reversed__(): e1f. if they can provide an implementation
     that is more efficient than the one provided by *note reversed():
     24d.

The membership test operators (*note in: 37d. and *note not in: e20.)
are normally implemented as an iteration through a sequence.  However,
container objects can supply the following special method with a more
efficient implementation, which also does not require the object be a
sequence.

 -- Method: object.__contains__ (self, item)

     Called to implement membership test operators.  Should return true
     if `item' is in `self', false otherwise.  For mapping objects, this
     should consider the keys of the mapping rather than the values or
     the key-item pairs.

     For objects that don’t define *note __contains__(): 99c, the
     membership test first tries iteration via *note __iter__(): 99b,
     then the old sequence iteration protocol via *note __getitem__():
     a84, see *note this section in the language reference: e21.


File: python.info,  Node: Emulating numeric types,  Next: With Statement Context Managers,  Prev: Emulating container types,  Up: Special method names

4.3.3.16 Emulating numeric types
................................

The following methods can be defined to emulate numeric objects.
Methods corresponding to operations that are not supported by the
particular kind of number implemented (e.g., bitwise operations for
non-integral numbers) should be left undefined.

 -- Method: object.__add__ (self, other)
 -- Method: object.__sub__ (self, other)
 -- Method: object.__mul__ (self, other)
 -- Method: object.__matmul__ (self, other)
 -- Method: object.__truediv__ (self, other)
 -- Method: object.__floordiv__ (self, other)
 -- Method: object.__mod__ (self, other)
 -- Method: object.__divmod__ (self, other)
 -- Method: object.__pow__ (self, other[, modulo])
 -- Method: object.__lshift__ (self, other)
 -- Method: object.__rshift__ (self, other)
 -- Method: object.__and__ (self, other)
 -- Method: object.__xor__ (self, other)
 -- Method: object.__or__ (self, other)

     These methods are called to implement the binary arithmetic
     operations (‘+’, ‘-’, ‘*’, ‘@’, ‘/’, ‘//’, ‘%’, *note divmod():
     e2c, *note pow(): ad3, ‘**’, ‘<<’, ‘>>’, ‘&’, ‘^’, ‘|’).  For
     instance, to evaluate the expression ‘x + y’, where `x' is an
     instance of a class that has an *note __add__(): e19. method,
     ‘x.__add__(y)’ is called.  The *note __divmod__(): 35a. method
     should be the equivalent to using *note __floordiv__(): ab7. and
     *note __mod__(): e25.; it should not be related to *note
     __truediv__(): 359.  Note that *note __pow__(): e26. should be
     defined to accept an optional third argument if the ternary version
     of the built-in *note pow(): ad3. function is to be supported.

     If one of those methods does not support the operation with the
     supplied arguments, it should return ‘NotImplemented’.

 -- Method: object.__radd__ (self, other)
 -- Method: object.__rsub__ (self, other)
 -- Method: object.__rmul__ (self, other)
 -- Method: object.__rmatmul__ (self, other)
 -- Method: object.__rtruediv__ (self, other)
 -- Method: object.__rfloordiv__ (self, other)
 -- Method: object.__rmod__ (self, other)
 -- Method: object.__rdivmod__ (self, other)
 -- Method: object.__rpow__ (self, other)
 -- Method: object.__rlshift__ (self, other)
 -- Method: object.__rrshift__ (self, other)
 -- Method: object.__rand__ (self, other)
 -- Method: object.__rxor__ (self, other)
 -- Method: object.__ror__ (self, other)

     These methods are called to implement the binary arithmetic
     operations (‘+’, ‘-’, ‘*’, ‘@’, ‘/’, ‘//’, ‘%’, *note divmod():
     e2c, *note pow(): ad3, ‘**’, ‘<<’, ‘>>’, ‘&’, ‘^’, ‘|’) with
     reflected (swapped) operands.  These functions are only called if
     the left operand does not support the corresponding operation and
     the operands are of different types.  (1) For instance, to evaluate
     the expression ‘x - y’, where `y' is an instance of a class that
     has an *note __rsub__(): e2d. method, ‘y.__rsub__(x)’ is called if
     ‘x.__sub__(y)’ returns `NotImplemented'.

     Note that ternary *note pow(): ad3. will not try calling *note
     __rpow__(): e31. (the coercion rules would become too complicated).

          Note: If the right operand’s type is a subclass of the left
          operand’s type and that subclass provides the reflected method
          for the operation, this method will be called before the left
          operand’s non-reflected method.  This behavior allows
          subclasses to override their ancestors’ operations.

 -- Method: object.__iadd__ (self, other)
 -- Method: object.__isub__ (self, other)
 -- Method: object.__imul__ (self, other)
 -- Method: object.__imatmul__ (self, other)
 -- Method: object.__itruediv__ (self, other)
 -- Method: object.__ifloordiv__ (self, other)
 -- Method: object.__imod__ (self, other)
 -- Method: object.__ipow__ (self, other[, modulo])
 -- Method: object.__ilshift__ (self, other)
 -- Method: object.__irshift__ (self, other)
 -- Method: object.__iand__ (self, other)
 -- Method: object.__ixor__ (self, other)
 -- Method: object.__ior__ (self, other)

     These methods are called to implement the augmented arithmetic
     assignments (‘+=’, ‘-=’, ‘*=’, ‘@=’, ‘/=’, ‘//=’, ‘%=’, ‘**=’,
     ‘<<=’, ‘>>=’, ‘&=’, ‘^=’, ‘|=’).  These methods should attempt to
     do the operation in-place (modifying `self') and return the result
     (which could be, but does not have to be, `self').  If a specific
     method is not defined, the augmented assignment falls back to the
     normal methods.  For instance, if `x' is an instance of a class
     with an *note __iadd__(): af5. method, ‘x += y’ is equivalent to ‘x
     = x.__iadd__(y)’ .  Otherwise, ‘x.__add__(y)’ and ‘y.__radd__(x)’
     are considered, as with the evaluation of ‘x + y’.  In certain
     situations, augmented assignment can result in unexpected errors
     (see *note Why does a_tuple[i] += [’item’] raise an exception when
     the addition works?: e40.), but this behavior is in fact part of
     the data model.

 -- Method: object.__neg__ (self)
 -- Method: object.__pos__ (self)
 -- Method: object.__abs__ (self)
 -- Method: object.__invert__ (self)

     Called to implement the unary arithmetic operations (‘-’, ‘+’,
     *note abs(): c7c. and ‘~’).

 -- Method: object.__complex__ (self)
 -- Method: object.__int__ (self)
 -- Method: object.__float__ (self)
 -- Method: object.__round__ (self[, n])

     Called to implement the built-in functions *note complex(): 579,
     *note int(): 227, *note float(): 57a. and *note round(): 8d9.
     Should return a value of the appropriate type.

 -- Method: object.__index__ (self)

     Called to implement *note operator.index(): e47, and whenever
     Python needs to losslessly convert the numeric object to an integer
     object (such as in slicing, or in the built-in *note bin(): 8a7,
     *note hex(): 8d1. and *note oct(): 8d0. functions).  Presence of
     this method indicates that the numeric object is an integer type.
     Must return an integer.

          Note: In order to have a coherent integer type class, when
          *note __index__(): 8d2. is defined *note __int__(): 929.
          should also be defined, and both should return the same value.

   ---------- Footnotes ----------

   (1) For operands of the same type, it is assumed that if the
non-reflected method (such as *note __add__(): e19.) fails the operation
is not supported, which is why the reflected method is not called.


File: python.info,  Node: With Statement Context Managers,  Next: Special method lookup,  Prev: Emulating numeric types,  Up: Special method names

4.3.3.17 With Statement Context Managers
........................................

A `context manager' is an object that defines the runtime context to be
established when executing a *note with: 29d. statement.  The context
manager handles the entry into, and the exit from, the desired runtime
context for the execution of the block of code.  Context managers are
normally invoked using the *note with: 29d. statement (described in
section *note The with statement: 29d.), but can also be used by
directly invoking their methods.

Typical uses of context managers include saving and restoring various
kinds of global state, locking and unlocking resources, closing opened
files, etc.

For more information on context managers, see *note Context Manager
Types: e4a.

 -- Method: object.__enter__ (self)

     Enter the runtime context related to this object.  The *note with:
     29d. statement will bind this method’s return value to the
     target(s) specified in the *note as: 8aa. clause of the statement,
     if any.

 -- Method: object.__exit__ (self, exc_type, exc_value, traceback)

     Exit the runtime context related to this object.  The parameters
     describe the exception that caused the context to be exited.  If
     the context was exited without an exception, all three arguments
     will be *note None: 19d.

     If an exception is supplied, and the method wishes to suppress the
     exception (i.e., prevent it from being propagated), it should
     return a true value.  Otherwise, the exception will be processed
     normally upon exit from this method.

     Note that *note __exit__(): 908. methods should not reraise the
     passed-in exception; this is the caller’s responsibility.

See also
........

PEP 343(1) - The "with" statement

     The specification, background, and examples for the Python *note
     with: 29d. statement.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0343


File: python.info,  Node: Special method lookup,  Prev: With Statement Context Managers,  Up: Special method names

4.3.3.18 Special method lookup
..............................

For custom classes, implicit invocations of special methods are only
guaranteed to work correctly if defined on an object’s type, not in the
object’s instance dictionary.  That behaviour is the reason why the
following code raises an exception:

     >>> class C:
     ...     pass
     ...
     >>> c = C()
     >>> c.__len__ = lambda: 5
     >>> len(c)
     Traceback (most recent call last):
       File "<stdin>", line 1, in <module>
     TypeError: object of type 'C' has no len()

The rationale behind this behaviour lies with a number of special
methods such as *note __hash__(): 5e7. and *note __repr__(): 7bd. that
are implemented by all objects, including type objects.  If the implicit
lookup of these methods used the conventional lookup process, they would
fail when invoked on the type object itself:

     >>> 1 .__hash__() == hash(1)
     True
     >>> int.__hash__() == hash(int)
     Traceback (most recent call last):
       File "<stdin>", line 1, in <module>
     TypeError: descriptor '__hash__' of 'int' object needs an argument

Incorrectly attempting to invoke an unbound method of a class in this
way is sometimes referred to as ’metaclass confusion’, and is avoided by
bypassing the instance when looking up special methods:

     >>> type(1).__hash__(1) == hash(1)
     True
     >>> type(int).__hash__(int) == hash(int)
     True

In addition to bypassing any instance attributes in the interest of
correctness, implicit special method lookup generally also bypasses the
*note __getattribute__(): 783. method even of the object’s metaclass:

     >>> class Meta(type):
     ...     def __getattribute__(*args):
     ...         print("Metaclass getattribute invoked")
     ...         return type.__getattribute__(*args)
     ...
     >>> class C(object, metaclass=Meta):
     ...     def __len__(self):
     ...         return 10
     ...     def __getattribute__(*args):
     ...         print("Class getattribute invoked")
     ...         return object.__getattribute__(*args)
     ...
     >>> c = C()
     >>> c.__len__()                 # Explicit lookup via instance
     Class getattribute invoked
     10
     >>> type(c).__len__(c)          # Explicit lookup via type
     Metaclass getattribute invoked
     10
     >>> len(c)                      # Implicit lookup
     10

Bypassing the *note __getattribute__(): 783. machinery in this fashion
provides significant scope for speed optimisations within the
interpreter, at the cost of some flexibility in the handling of special
methods (the special method `must' be set on the class object itself in
order to be consistently invoked by the interpreter).


File: python.info,  Node: Coroutines,  Prev: Special method names,  Up: Data model

4.3.4 Coroutines
----------------

* Menu:

* Awaitable Objects:: 
* Coroutine Objects:: 
* Asynchronous Iterators:: 
* Asynchronous Context Managers:: 


File: python.info,  Node: Awaitable Objects,  Next: Coroutine Objects,  Up: Coroutines

4.3.4.1 Awaitable Objects
.........................

An *note awaitable: 1ca. object generally implements an *note
__await__(): 1d0. method.  *note Coroutine: 2ad. objects returned from
*note async def: 1ce. functions are awaitable.

     Note: The *note generator iterator: 34e. objects returned from
     generators decorated with *note types.coroutine(): 34d. or *note
     asyncio.coroutine(): e4e. are also awaitable, but they do not
     implement *note __await__(): 1d0.

 -- Method: object.__await__ (self)

     Must return an *note iterator: e4f.  Should be used to implement
     *note awaitable: 1ca. objects.  For instance, *note asyncio.Future:
     e50. implements this method to be compatible with the *note await:
     1cf. expression.

New in version 3.5.

See also
........

PEP 492(1) for additional information about awaitable objects.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0492


File: python.info,  Node: Coroutine Objects,  Next: Asynchronous Iterators,  Prev: Awaitable Objects,  Up: Coroutines

4.3.4.2 Coroutine Objects
.........................

*note Coroutine: 2ad. objects are *note awaitable: 1ca. objects.  A
coroutine’s execution can be controlled by calling *note __await__():
1d0. and iterating over the result.  When the coroutine has finished
executing and returns, the iterator raises *note StopIteration: 191, and
the exception’s ‘value’ attribute holds the return value.  If the
coroutine raises an exception, it is propagated by the iterator.
Coroutines should not directly raise unhandled *note StopIteration: 191.
exceptions.

Coroutines also have the methods listed below, which are analogous to
those of generators (see *note Generator-iterator methods: e52.).
However, unlike generators, coroutines do not directly support
iteration.

Changed in version 3.5.2: It is a *note RuntimeError: 193. to await on a
coroutine more than once.

 -- Method: coroutine.send (value)

     Starts or resumes execution of the coroutine.  If `value' is
     ‘None’, this is equivalent to advancing the iterator returned by
     *note __await__(): 1d0.  If `value' is not ‘None’, this method
     delegates to the *note send(): e54. method of the iterator that
     caused the coroutine to suspend.  The result (return value, *note
     StopIteration: 191, or other exception) is the same as when
     iterating over the *note __await__(): 1d0. return value, described
     above.

 -- Method: coroutine.throw (type[, value[, traceback]])

     Raises the specified exception in the coroutine.  This method
     delegates to the *note throw(): e56. method of the iterator that
     caused the coroutine to suspend, if it has such a method.
     Otherwise, the exception is raised at the suspension point.  The
     result (return value, *note StopIteration: 191, or other exception)
     is the same as when iterating over the *note __await__(): 1d0.
     return value, described above.  If the exception is not caught in
     the coroutine, it propagates back to the caller.

 -- Method: coroutine.close ()

     Causes the coroutine to clean itself up and exit.  If the coroutine
     is suspended, this method first delegates to the *note close():
     e58. method of the iterator that caused the coroutine to suspend,
     if it has such a method.  Then it raises *note GeneratorExit: 9a6.
     at the suspension point, causing the coroutine to immediately clean
     itself up.  Finally, the coroutine is marked as having finished
     executing, even if it was never started.

     Coroutine objects are automatically closed using the above process
     when they are about to be destroyed.


File: python.info,  Node: Asynchronous Iterators,  Next: Asynchronous Context Managers,  Prev: Coroutine Objects,  Up: Coroutines

4.3.4.3 Asynchronous Iterators
..............................

An `asynchronous iterable' is able to call asynchronous code in its
‘__aiter__’ implementation, and an `asynchronous iterator' can call
asynchronous code in its ‘__anext__’ method.

Asynchronous iterators can be used in an *note async for: 1d1.
statement.

 -- Method: object.__aiter__ (self)

     Must return an `awaitable' resulting in an `asynchronous iterator'
     object.

 -- Method: object.__anext__ (self)

     Must return an `awaitable' resulting in a next value of the
     iterator.  Should raise a *note StopAsyncIteration: e5c. error when
     the iteration is over.

An example of an asynchronous iterable object:

     class Reader:
         async def readline(self):
             ...

         async def __aiter__(self):
             return self

         async def __anext__(self):
             val = await self.readline()
             if val == b'':
                 raise StopAsyncIteration
             return val

New in version 3.5.


File: python.info,  Node: Asynchronous Context Managers,  Prev: Asynchronous Iterators,  Up: Coroutines

4.3.4.4 Asynchronous Context Managers
.....................................

An `asynchronous context manager' is a `context manager' that is able to
suspend execution in its ‘__aenter__’ and ‘__aexit__’ methods.

Asynchronous context managers can be used in an *note async with: 1d2.
statement.

 -- Method: object.__aenter__ (self)

     This method is semantically similar to the *note __enter__(): 907,
     with only difference that it must return an `awaitable'.

 -- Method: object.__aexit__ (self, exc_type, exc_value, traceback)

     This method is semantically similar to the *note __exit__(): 908,
     with only difference that it must return an `awaitable'.

An example of an asynchronous context manager class:

     class AsyncContextManager:
         async def __aenter__(self):
             await log('entering context')

         async def __aexit__(self, exc_type, exc, tb):
             await log('exiting context')

New in version 3.5.


File: python.info,  Node: Execution model,  Next: The import system,  Prev: Data model,  Up: The Python Language Reference

4.4 Execution model
===================

* Menu:

* Structure of a program:: 
* Naming and binding:: 
* Exceptions: Exceptions<2>. 


File: python.info,  Node: Structure of a program,  Next: Naming and binding,  Up: Execution model

4.4.1 Structure of a program
----------------------------

A Python program is constructed from code blocks.  A `block' is a piece
of Python program text that is executed as a unit.  The following are
blocks: a module, a function body, and a class definition.  Each command
typed interactively is a block.  A script file (a file given as standard
input to the interpreter or specified as a command line argument to the
interpreter) is a code block.  A script command (a command specified on
the interpreter command line with the ’`-c'’ option) is a code block.
The string argument passed to the built-in functions *note eval(): 7e8.
and *note exec(): 8ac. is a code block.

A code block is executed in an `execution frame'.  A frame contains some
administrative information (used for debugging) and determines where and
how execution continues after the code block’s execution has completed.


File: python.info,  Node: Naming and binding,  Next: Exceptions<2>,  Prev: Structure of a program,  Up: Execution model

4.4.2 Naming and binding
------------------------

* Menu:

* Binding of names:: 
* Resolution of names:: 
* Builtins and restricted execution:: 
* Interaction with dynamic features:: 


File: python.info,  Node: Binding of names,  Next: Resolution of names,  Up: Naming and binding

4.4.2.1 Binding of names
........................

`Names' refer to objects.  Names are introduced by name binding
operations.

The following constructs bind names: formal parameters to functions,
*note import: 881. statements, class and function definitions (these
bind the class or function name in the defining block), and targets that
are identifiers if occurring in an assignment, *note for: 895. loop
header, or after *note as: 8aa. in a *note with: 29d. statement or *note
except: 785. clause.  The *note import: 881. statement of the form ‘from
... import *’ binds all names defined in the imported module, except
those beginning with an underscore.  This form may only be used at the
module level.

A target occurring in a *note del: c30. statement is also considered
bound for this purpose (though the actual semantics are to unbind the
name).

Each assignment or import statement occurs within a block defined by a
class or function definition or at the module level (the top-level code
block).

If a name is bound in a block, it is a local variable of that block,
unless declared as *note nonlocal: 8a6. or *note global: c0b.  If a name
is bound at the module level, it is a global variable.  (The variables
of the module code block are local and global.)  If a variable is used
in a code block but not defined there, it is a `free variable'.

Each occurrence of a name in the program text refers to the `binding' of
that name established by the following name resolution rules.


File: python.info,  Node: Resolution of names,  Next: Builtins and restricted execution,  Prev: Binding of names,  Up: Naming and binding

4.4.2.2 Resolution of names
...........................

A `scope' defines the visibility of a name within a block.  If a local
variable is defined in a block, its scope includes that block.  If the
definition occurs in a function block, the scope extends to any blocks
contained within the defining one, unless a contained block introduces a
different binding for the name.

When a name is used in a code block, it is resolved using the nearest
enclosing scope.  The set of all such scopes visible to a code block is
called the block’s `environment'.

When a name is not found at all, a *note NameError: 9f2. exception is
raised.  If the current scope is a function scope, and the name refers
to a local variable that has not yet been bound to a value at the point
where the name is used, an *note UnboundLocalError: afc. exception is
raised.  *note UnboundLocalError: afc. is a subclass of *note NameError:
9f2.

If a name binding operation occurs anywhere within a code block, all
uses of the name within the block are treated as references to the
current block.  This can lead to errors when a name is used within a
block before it is bound.  This rule is subtle.  Python lacks
declarations and allows name binding operations to occur anywhere within
a code block.  The local variables of a code block can be determined by
scanning the entire text of the block for name binding operations.

If the *note global: c0b. statement occurs within a block, all uses of
the name specified in the statement refer to the binding of that name in
the top-level namespace.  Names are resolved in the top-level namespace
by searching the global namespace, i.e.  the namespace of the module
containing the code block, and the builtins namespace, the namespace of
the module *note builtins: 13.  The global namespace is searched first.
If the name is not found there, the builtins namespace is searched.  The
*note global: c0b. statement must precede all uses of the name.

The *note global: c0b. statement has the same scope as a name binding
operation in the same block.  If the nearest enclosing scope for a free
variable contains a global statement, the free variable is treated as a
global.

The *note nonlocal: 8a6. statement causes corresponding names to refer
to previously bound variables in the nearest enclosing function scope.
*note SyntaxError: 3a6. is raised at compile time if the given name does
not exist in any enclosing function scope.

The namespace for a module is automatically created the first time a
module is imported.  The main module for a script is always called *note
__main__: 1.

Class definition blocks and arguments to *note exec(): 8ac. and *note
eval(): 7e8. are special in the context of name resolution.  A class
definition is an executable statement that may use and define names.
These references follow the normal rules for name resolution with an
exception that unbound local variables are looked up in the global
namespace.  The namespace of the class definition becomes the attribute
dictionary of the class.  The scope of names defined in a class block is
limited to the class block; it does not extend to the code blocks of
methods – this includes comprehensions and generator expressions since
they are implemented using a function scope.  This means that the
following will fail:

     class A:
         a = 42
         b = list(a + i for i in range(10))


File: python.info,  Node: Builtins and restricted execution,  Next: Interaction with dynamic features,  Prev: Resolution of names,  Up: Naming and binding

4.4.2.3 Builtins and restricted execution
.........................................

The builtins namespace associated with the execution of a code block is
actually found by looking up the name ‘__builtins__’ in its global
namespace; this should be a dictionary or a module (in the latter case
the module’s dictionary is used).  By default, when in the *note
__main__: 1. module, ‘__builtins__’ is the built-in module *note
builtins: 13.; when in any other module, ‘__builtins__’ is an alias for
the dictionary of the *note builtins: 13. module itself.  ‘__builtins__’
can be set to a user-created dictionary to create a weak form of
restricted execution.

`CPython implementation detail:' Users should not touch ‘__builtins__’;
it is strictly an implementation detail.  Users wanting to override
values in the builtins namespace should *note import: 881. the *note
builtins: 13. module and modify its attributes appropriately.


File: python.info,  Node: Interaction with dynamic features,  Prev: Builtins and restricted execution,  Up: Naming and binding

4.4.2.4 Interaction with dynamic features
.........................................

Name resolution of free variables occurs at runtime, not at compile
time.  This means that the following code will print 42:

     i = 10
     def f():
         print(i)
     i = 42
     f()

There are several cases where Python statements are illegal when used in
conjunction with nested scopes that contain free variables.

If a variable is referenced in an enclosing scope, it is illegal to
delete the name.  An error will be reported at compile time.

The *note eval(): 7e8. and *note exec(): 8ac. functions do not have
access to the full environment for resolving names.  Names may be
resolved in the local and global namespaces of the caller.  Free
variables are not resolved in the nearest enclosing namespace, but in
the global namespace.  (1) The *note exec(): 8ac. and *note eval(): 7e8.
functions have optional arguments to override the global and local
namespace.  If only one namespace is specified, it is used for both.

   ---------- Footnotes ----------

   (1) This limitation occurs because the code that is executed by these
operations is not available at the time the module is compiled.


File: python.info,  Node: Exceptions<2>,  Prev: Naming and binding,  Up: Execution model

4.4.3 Exceptions
----------------

Exceptions are a means of breaking out of the normal flow of control of
a code block in order to handle errors or other exceptional conditions.
An exception is `raised' at the point where the error is detected; it
may be `handled' by the surrounding code block or by any code block that
directly or indirectly invoked the code block where the error occurred.

The Python interpreter raises an exception when it detects a run-time
error (such as division by zero).  A Python program can also explicitly
raise an exception with the *note raise: 8a9. statement.  Exception
handlers are specified with the *note try: 9e9. ...  *note except: 785.
statement.  The *note finally: 526. clause of such a statement can be
used to specify cleanup code which does not handle the exception, but is
executed whether an exception occurred or not in the preceding code.

Python uses the "termination" model of error handling: an exception
handler can find out what happened and continue execution at an outer
level, but it cannot repair the cause of the error and retry the failing
operation (except by re-entering the offending piece of code from the
top).

When an exception is not handled at all, the interpreter terminates
execution of the program, or returns to its interactive main loop.  In
either case, it prints a stack backtrace, except when the exception is
*note SystemExit: 1a2.

Exceptions are identified by class instances.  The *note except: 785.
clause is selected depending on the class of the instance: it must
reference the class of the instance or a base class thereof.  The
instance can be received by the handler and can carry additional
information about the exceptional condition.

     Note: Exception messages are not part of the Python API. Their
     contents may change from one version of Python to the next without
     warning and should not be relied on by code which will run under
     multiple versions of the interpreter.

See also the description of the *note try: 9e9. statement in section
*note The try statement: 9e9. and *note raise: 8a9. statement in section
*note The raise statement: 8a9.


File: python.info,  Node: The import system,  Next: Expressions,  Prev: Execution model,  Up: The Python Language Reference

4.5 The import system
=====================

Python code in one *note module: e73. gains access to the code in
another module by the process of *note importing: e74. it.  The *note
import: 881. statement is the most common way of invoking the import
machinery, but it is not the only way.  Functions such as *note
importlib.import_module(): 754. and built-in *note __import__(): 5cd.
can also be used to invoke the import machinery.

The *note import: 881. statement combines two operations; it searches
for the named module, then it binds the results of that search to a name
in the local scope.  The search operation of the *note import: 881.
statement is defined as a call to the *note __import__(): 5cd. function,
with the appropriate arguments.  The return value of *note __import__():
5cd. is used to perform the name binding operation of the *note import:
881. statement.  See the *note import: 881. statement for the exact
details of that name binding operation.

A direct call to *note __import__(): 5cd. performs only the module
search and, if found, the module creation operation.  While certain
side-effects may occur, such as the importing of parent packages, and
the updating of various caches (including *note sys.modules: e75.), only
the *note import: 881. statement performs a name binding operation.

When calling *note __import__(): 5cd. as part of an import statement,
the standard builtin *note __import__(): 5cd. is called.  Other
mechanisms for invoking the import system (such as *note
importlib.import_module(): 754.) may choose to subvert *note
__import__(): 5cd. and use its own solution to implement import
semantics.

When a module is first imported, Python searches for the module and if
found, it creates a module object (1), initializing it.  If the named
module cannot be found, an *note ImportError: 19f. is raised.  Python
implements various strategies to search for the named module when the
import machinery is invoked.  These strategies can be modified and
extended by using various hooks described in the sections below.

Changed in version 3.3: The import system has been updated to fully
implement the second phase of PEP 302(2).  There is no longer any
implicit import machinery - the full import system is exposed through
*note sys.meta_path: 5dc.  In addition, native namespace package support
has been implemented (see PEP 420(3)).

* Menu:

* importlib: importlib<3>. 
* Packages: Packages<2>. 
* Searching:: 
* Loading:: 
* The Path Based Finder:: 
* Replacing the standard import system:: 
* Special considerations for __main__:: 
* Open issues:: 
* References:: 

   ---------- Footnotes ----------

   (1) See *note types.ModuleType: 2a6.

   (2) https://www.python.org/dev/peps/pep-0302

   (3) https://www.python.org/dev/peps/pep-0420


File: python.info,  Node: importlib<3>,  Next: Packages<2>,  Up: The import system

4.5.1 ‘importlib’
-----------------

The *note importlib: 9a. module provides a rich API for interacting with
the import system.  For example *note importlib.import_module(): 754.
provides a recommended, simpler API than built-in *note __import__():
5cd. for invoking the import machinery.  Refer to the *note importlib:
9a. library documentation for additional detail.


File: python.info,  Node: Packages<2>,  Next: Searching,  Prev: importlib<3>,  Up: The import system

4.5.2 Packages
--------------

Python has only one type of module object, and all modules are of this
type, regardless of whether the module is implemented in Python, C, or
something else.  To help organize modules and provide a naming
hierarchy, Python has a concept of *note packages: e78.

You can think of packages as the directories on a file system and
modules as files within directories, but don’t take this analogy too
literally since packages and modules need not originate from the file
system.  For the purposes of this documentation, we’ll use this
convenient analogy of directories and files.  Like file system
directories, packages are organized hierarchically, and packages may
themselves contain subpackages, as well as regular modules.

It’s important to keep in mind that all packages are modules, but not
all modules are packages.  Or put another way, packages are just a
special kind of module.  Specifically, any module that contains a
‘__path__’ attribute is considered a package.

All modules have a name.  Subpackage names are separated from their
parent package name by dots, akin to Python’s standard attribute access
syntax.  Thus you might have a module called *note sys: fb. and a
package called *note email: 67, which in turn has a subpackage called
*note email.mime: 71. and a module within that subpackage called
‘email.mime.text’.

* Menu:

* Regular packages:: 
* Namespace packages:: 


File: python.info,  Node: Regular packages,  Next: Namespace packages,  Up: Packages<2>

4.5.2.1 Regular packages
........................

Python defines two types of packages, *note regular packages: e7a. and
*note namespace packages: e7b.  Regular packages are traditional
packages as they existed in Python 3.2 and earlier.  A regular package
is typically implemented as a directory containing an ‘__init__.py’
file.  When a regular package is imported, this ‘__init__.py’ file is
implicitly executed, and the objects it defines are bound to names in
the package’s namespace.  The ‘__init__.py’ file can contain the same
Python code that any other module can contain, and Python will add some
additional attributes to the module when it is imported.

For example, the following file system layout defines a top level
‘parent’ package with three subpackages:

     parent/
         __init__.py
         one/
             __init__.py
         two/
             __init__.py
         three/
             __init__.py

Importing ‘parent.one’ will implicitly execute ‘parent/__init__.py’ and
‘parent/one/__init__.py’.  Subsequent imports of ‘parent.two’ or
‘parent.three’ will execute ‘parent/two/__init__.py’ and
‘parent/three/__init__.py’ respectively.


File: python.info,  Node: Namespace packages,  Prev: Regular packages,  Up: Packages<2>

4.5.2.2 Namespace packages
..........................

A namespace package is a composite of various *note portions: e7d, where
each portion contributes a subpackage to the parent package.  Portions
may reside in different locations on the file system.  Portions may also
be found in zip files, on the network, or anywhere else that Python
searches during import.  Namespace packages may or may not correspond
directly to objects on the file system; they may be virtual modules that
have no concrete representation.

Namespace packages do not use an ordinary list for their ‘__path__’
attribute.  They instead use a custom iterable type which will
automatically perform a new search for package portions on the next
import attempt within that package if the path of their parent package
(or *note sys.path: 16c. for a top level package) changes.

With namespace packages, there is no ‘parent/__init__.py’ file.  In
fact, there may be multiple ‘parent’ directories found during import
search, where each one is provided by a different portion.  Thus
‘parent/one’ may not be physically located next to ‘parent/two’.  In
this case, Python will create a namespace package for the top-level
‘parent’ package whenever it or one of its subpackages is imported.

See also PEP 420(1) for the namespace package specification.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0420


File: python.info,  Node: Searching,  Next: Loading,  Prev: Packages<2>,  Up: The import system

4.5.3 Searching
---------------

To begin the search, Python needs the *note fully qualified: dec. name
of the module (or package, but for the purposes of this discussion, the
difference is immaterial) being imported.  This name may come from
various arguments to the *note import: 881. statement, or from the
parameters to the *note importlib.import_module(): 754. or *note
__import__(): 5cd. functions.

This name will be used in various phases of the import search, and it
may be the dotted path to a submodule, e.g.  ‘foo.bar.baz’.  In this
case, Python first tries to import ‘foo’, then ‘foo.bar’, and finally
‘foo.bar.baz’.  If any of the intermediate imports fail, an *note
ImportError: 19f. is raised.

* Menu:

* The module cache:: 
* Finders and loaders:: 
* Import hooks:: 
* The meta path:: 


File: python.info,  Node: The module cache,  Next: Finders and loaders,  Up: Searching

4.5.3.1 The module cache
........................

The first place checked during import search is *note sys.modules: e75.
This mapping serves as a cache of all modules that have been previously
imported, including the intermediate paths.  So if ‘foo.bar.baz’ was
previously imported, *note sys.modules: e75. will contain entries for
‘foo’, ‘foo.bar’, and ‘foo.bar.baz’.  Each key will have as its value
the corresponding module object.

During import, the module name is looked up in *note sys.modules: e75.
and if present, the associated value is the module satisfying the
import, and the process completes.  However, if the value is ‘None’,
then an *note ImportError: 19f. is raised.  If the module name is
missing, Python will continue searching for the module.

*note sys.modules: e75. is writable.  Deleting a key may not destroy the
associated module (as other modules may hold references to it), but it
will invalidate the cache entry for the named module, causing Python to
search anew for the named module upon its next import.  The key can also
be assigned to ‘None’, forcing the next import of the module to result
in an *note ImportError: 19f.

Beware though, as if you keep a reference to the module object,
invalidate its cache entry in *note sys.modules: e75, and then re-import
the named module, the two module objects will `not' be the same.  By
contrast, *note importlib.reload(): 457. will reuse the `same' module
object, and simply reinitialise the module contents by rerunning the
module’s code.


File: python.info,  Node: Finders and loaders,  Next: Import hooks,  Prev: The module cache,  Up: Searching

4.5.3.2 Finders and loaders
...........................

If the named module is not found in *note sys.modules: e75, then
Python’s import protocol is invoked to find and load the module.  This
protocol consists of two conceptual objects, *note finders: e81. and
*note loaders: e82.  A finder’s job is to determine whether it can find
the named module using whatever strategy it knows about.  Objects that
implement both of these interfaces are referred to as *note importers:
e83. - they return themselves when they find that they can load the
requested module.

Python includes a number of default finders and importers.  The first
one knows how to locate built-in modules, and the second knows how to
locate frozen modules.  A third default finder searches an *note import
path: e84. for modules.  The *note import path: e84. is a list of
locations that may name file system paths or zip files.  It can also be
extended to search for any locatable resource, such as those identified
by URLs.

The import machinery is extensible, so new finders can be added to
extend the range and scope of module searching.

Finders do not actually load modules.  If they can find the named
module, they return a `module spec', an encapsulation of the module’s
import-related information, which the import machinery then uses when
loading the module.

The following sections describe the protocol for finders and loaders in
more detail, including how you can create and register new ones to
extend the import machinery.

Changed in version 3.4: In previous versions of Python, finders returned
*note loaders: e82. directly, whereas now they return module specs which
`contain' loaders.  Loaders are still used during import but have fewer
responsibilities.


File: python.info,  Node: Import hooks,  Next: The meta path,  Prev: Finders and loaders,  Up: Searching

4.5.3.3 Import hooks
....................

The import machinery is designed to be extensible; the primary mechanism
for this are the `import hooks'.  There are two types of import hooks:
`meta hooks' and `import path hooks'.

Meta hooks are called at the start of import processing, before any
other import processing has occurred, other than *note sys.modules: e75.
cache look up.  This allows meta hooks to override *note sys.path: 16c.
processing, frozen modules, or even built-in modules.  Meta hooks are
registered by adding new finder objects to *note sys.meta_path: 5dc, as
described below.

Import path hooks are called as part of *note sys.path: 16c. (or
‘package.__path__’) processing, at the point where their associated path
item is encountered.  Import path hooks are registered by adding new
callables to *note sys.path_hooks: 574. as described below.


File: python.info,  Node: The meta path,  Prev: Import hooks,  Up: Searching

4.5.3.4 The meta path
.....................

When the named module is not found in *note sys.modules: e75, Python
next searches *note sys.meta_path: 5dc, which contains a list of meta
path finder objects.  These finders are queried in order to see if they
know how to handle the named module.  Meta path finders must implement a
method called *note find_spec(): 544. which takes three arguments: a
name, an import path, and (optionally) a target module.  The meta path
finder can use any strategy it wants to determine whether it can handle
the named module or not.

If the meta path finder knows how to handle the named module, it returns
a spec object.  If it cannot handle the named module, it returns ‘None’.
If *note sys.meta_path: 5dc. processing reaches the end of its list
without returning a spec, then an *note ImportError: 19f. is raised.
Any other exceptions raised are simply propagated up, aborting the
import process.

The *note find_spec(): 544. method of meta path finders is called with
two or three arguments.  The first is the fully qualified name of the
module being imported, for example ‘foo.bar.baz’.  The second argument
is the path entries to use for the module search.  For top-level
modules, the second argument is ‘None’, but for submodules or
subpackages, the second argument is the value of the parent package’s
‘__path__’ attribute.  If the appropriate ‘__path__’ attribute cannot be
accessed, an *note ImportError: 19f. is raised.  The third argument is
an existing module object that will be the target of loading later.  The
import system passes in a target module only during reload.

The meta path may be traversed multiple times for a single import
request.  For example, assuming none of the modules involved has already
been cached, importing ‘foo.bar.baz’ will first perform a top level
import, calling ‘mpf.find_spec("foo", None, None)’ on each meta path
finder (‘mpf’).  After ‘foo’ has been imported, ‘foo.bar’ will be
imported by traversing the meta path a second time, calling
‘mpf.find_spec("foo.bar", foo.__path__, None)’.  Once ‘foo.bar’ has been
imported, the final traversal will call ‘mpf.find_spec("foo.bar.baz",
foo.bar.__path__, None)’.

Some meta path finders only support top level imports.  These importers
will always return ‘None’ when anything other than ‘None’ is passed as
the second argument.

Python’s default *note sys.meta_path: 5dc. has three meta path finders,
one that knows how to import built-in modules, one that knows how to
import frozen modules, and one that knows how to import modules from an
*note import path: e84. (i.e.  the *note path based finder: e87.).

Changed in version 3.4: The *note find_spec(): 544. method of meta path
finders replaced *note find_module(): 543, which is now deprecated.
While it will continue to work without change, the import machinery will
try it only if the finder does not implement ‘find_spec()’.


File: python.info,  Node: Loading,  Next: The Path Based Finder,  Prev: Searching,  Up: The import system

4.5.4 Loading
-------------

If and when a module spec is found, the import machinery will use it
(and the loader it contains) when loading the module.  Here is an
approximation of what happens during the loading portion of import:

     module = None
     if spec.loader is not None and hasattr(spec.loader, 'create_module'):
         # It is assumed 'exec_module' will also be defined on the loader.
         module = spec.loader.create_module(spec)
     if module is None:
         module = ModuleType(spec.name)
     # The import-related module attributes get set here:
     _init_module_attrs(spec, module)

     if spec.loader is None:
         if spec.submodule_search_locations is not None:
             # namespace package
             sys.modules[spec.name] = module
         else:
             # unsupported
             raise ImportError
     elif not hasattr(spec.loader, 'exec_module'):
         module = spec.loader.load_module(spec.name)
         # Set __loader__ and __package__ if missing.
     else:
         sys.modules[spec.name] = module
         try:
             spec.loader.exec_module(module)
         except BaseException:
             try:
                 del sys.modules[spec.name]
             except KeyError:
                 pass
             raise
     return sys.modules[spec.name]

Note the following details:

        * If there is an existing module object with the given name in
          *note sys.modules: e75, import will have already returned it.

        * The module will exist in *note sys.modules: e75. before the
          loader executes the module code.  This is crucial because the
          module code may (directly or indirectly) import itself; adding
          it to *note sys.modules: e75. beforehand prevents unbounded
          recursion in the worst case and multiple loading in the best.

        * If loading fails, the failing module – and only the failing
          module – gets removed from *note sys.modules: e75.  Any module
          already in the *note sys.modules: e75. cache, and any module
          that was successfully loaded as a side-effect, must remain in
          the cache.  This contrasts with reloading where even the
          failing module is left in *note sys.modules: e75.

        * After the module is created but before execution, the import
          machinery sets the import-related module attributes
          ("_init_module_attrs" in the pseudo-code example above), as
          summarized in a *note later section: e89.

        * Module execution is the key moment of loading in which the
          module’s namespace gets populated.  Execution is entirely
          delegated to the loader, which gets to decide what gets
          populated and how.

        * The module created during loading and passed to exec_module()
          may not be the one returned at the end of import (1).

Changed in version 3.4: The import system has taken over the boilerplate
responsibilities of loaders.  These were previously performed by the
*note importlib.abc.Loader.load_module(): 18b. method.

* Menu:

* Loaders:: 
* Submodules:: 
* Module spec:: 
* Import-related module attributes:: 
* module.__path__: module __path__. 
* Module reprs:: 

   ---------- Footnotes ----------

   (1) The importlib implementation avoids using the return value
directly.  Instead, it gets the module object by looking the module name
up in *note sys.modules: e75.  The indirect effect of this is that an
imported module may replace itself in *note sys.modules: e75.  This is
implementation-specific behavior that is not guaranteed to work in other
Python implementations.


File: python.info,  Node: Loaders,  Next: Submodules,  Up: Loading

4.5.4.1 Loaders
...............

Module loaders provide the critical function of loading: module
execution.  The import machinery calls the *note
importlib.abc.Loader.exec_module(): 18c. method with a single argument,
the module object to execute.  Any value returned from *note
exec_module(): 18c. is ignored.

Loaders must satisfy the following requirements:

        * If the module is a Python module (as opposed to a built-in
          module or a dynamically loaded extension), the loader should
          execute the module’s code in the module’s global name space
          (‘module.__dict__’).

        * If the loader cannot execute the module, it should raise an
          *note ImportError: 19f, although any other exception raised
          during *note exec_module(): 18c. will be propagated.

In many cases, the finder and loader can be the same object; in such
cases the *note find_spec(): 544. method would just return a spec with
the loader set to ‘self’.

Module loaders may opt in to creating the module object during loading
by implementing a *note create_module(): e8b. method.  It takes one
argument, the module spec, and returns the new module object to use
during loading.  ‘create_module()’ does not need to set any attributes
on the module object.  If the method returns ‘None’, the import
machinery will create the new module itself.

New in version 3.4: The create_module() method of loaders.

Changed in version 3.4: The *note load_module(): 18b. method was
replaced by *note exec_module(): 18c. and the import machinery assumed
all the boilerplate responsibilities of loading.

For compatibility with existing loaders, the import machinery will use
the ‘load_module()’ method of loaders if it exists and the loader does
not also implement ‘exec_module()’.  However, ‘load_module()’ has been
deprecated and loaders should implement ‘exec_module()’ instead.

The ‘load_module()’ method must implement all the boilerplate loading
functionality described above in addition to executing the module.  All
the same constraints apply, with some additional clarification:

        * If there is an existing module object with the given name in
          *note sys.modules: e75, the loader must use that existing
          module.  (Otherwise, *note importlib.reload(): 457. will not
          work correctly.)  If the named module does not exist in *note
          sys.modules: e75, the loader must create a new module object
          and add it to *note sys.modules: e75.

        * The module `must' exist in *note sys.modules: e75. before the
          loader executes the module code, to prevent unbounded
          recursion or multiple loading.

        * If loading fails, the loader must remove any modules it has
          inserted into *note sys.modules: e75, but it must remove
          `only' the failing module(s), and only if the loader itself
          has loaded the module(s) explicitly.

Changed in version 3.5: A *note DeprecationWarning: 192. is raised when
‘exec_module()’ is defined but ‘create_module()’ is not.  Starting in
Python 3.6 it will be an error to not define ‘create_module()’ on a
loader attached to a ModuleSpec.


File: python.info,  Node: Submodules,  Next: Module spec,  Prev: Loaders,  Up: Loading

4.5.4.2 Submodules
..................

When a submodule is loaded using any mechanism (e.g.  ‘importlib’ APIs,
the ‘import’ or ‘import-from’ statements, or built-in ‘__import__()’) a
binding is placed in the parent module’s namespace to the submodule
object.  For example, if package ‘spam’ has a submodule ‘foo’, after
importing ‘spam.foo’, ‘spam’ will have an attribute ‘foo’ which is bound
to the submodule.  Let’s say you have the following directory structure:

     spam/
         __init__.py
         foo.py
         bar.py

and ‘spam/__init__.py’ has the following lines in it:

     from .foo import Foo
     from .bar import Bar

then executing the following puts a name binding to ‘foo’ and ‘bar’ in
the ‘spam’ module:

     >>> import spam
     >>> spam.foo
     <module 'spam.foo' from '/tmp/imports/spam/foo.py'>
     >>> spam.bar
     <module 'spam.bar' from '/tmp/imports/spam/bar.py'>

Given Python’s familiar name binding rules this might seem surprising,
but it’s actually a fundamental feature of the import system.  The
invariant holding is that if you have ‘sys.modules['spam']’ and
‘sys.modules['spam.foo']’ (as you would after the above import), the
latter must appear as the ‘foo’ attribute of the former.


File: python.info,  Node: Module spec,  Next: Import-related module attributes,  Prev: Submodules,  Up: Loading

4.5.4.3 Module spec
...................

The import machinery uses a variety of information about each module
during import, especially before loading.  Most of the information is
common to all modules.  The purpose of a module’s spec is to encapsulate
this import-related information on a per-module basis.

Using a spec during import allows state to be transferred between import
system components, e.g.  between the finder that creates the module spec
and the loader that executes it.  Most importantly, it allows the import
machinery to perform the boilerplate operations of loading, whereas
without a module spec the loader had that responsibility.

See *note ModuleSpec: e8e. for more specifics on what information a
module’s spec may hold.

New in version 3.4.


File: python.info,  Node: Import-related module attributes,  Next: module __path__,  Prev: Module spec,  Up: Loading

4.5.4.4 Import-related module attributes
........................................

The import machinery fills in these attributes on each module object
during loading, based on the module’s spec, before the loader executes
the module.

 -- Attribute: __name__

     The ‘__name__’ attribute must be set to the fully-qualified name of
     the module.  This name is used to uniquely identify the module in
     the import system.

 -- Attribute: __loader__

     The ‘__loader__’ attribute must be set to the loader object that
     the import machinery used when loading the module.  This is mostly
     for introspection, but can be used for additional loader-specific
     functionality, for example getting data associated with a loader.

 -- Attribute: __package__

     The module’s ‘__package__’ attribute must be set.  Its value must
     be a string, but it can be the same value as its ‘__name__’.  When
     the module is a package, its ‘__package__’ value should be set to
     its ‘__name__’.  When the module is not a package, ‘__package__’
     should be set to the empty string for top-level modules, or for
     submodules, to the parent package’s name.  See PEP 366(1) for
     further details.

     This attribute is used instead of ‘__name__’ to calculate explicit
     relative imports for main modules, as defined in PEP 366(2).  It is
     expected to have the same value as ‘__spec__.parent’.

     Changed in version 3.6: The value of ‘__package__’ is expected to
     be the same as ‘__spec__.parent’.

 -- Attribute: __spec__

     The ‘__spec__’ attribute must be set to the module spec that was
     used when importing the module.  Setting ‘__spec__’ appropriately
     applies equally to *note modules initialized during interpreter
     startup: e91.  The one exception is ‘__main__’, where ‘__spec__’ is
     *note set to None in some cases: e92.

     When ‘__package__’ is not defined, ‘__spec__.parent’ is used as a
     fallback.

     New in version 3.4.

     Changed in version 3.6: ‘__spec__.parent’ is used as a fallback
     when ‘__package__’ is not defined.

 -- Attribute: __path__

     If the module is a package (either regular or namespace), the
     module object’s ‘__path__’ attribute must be set.  The value must
     be iterable, but may be empty if ‘__path__’ has no further
     significance.  If ‘__path__’ is not empty, it must produce strings
     when iterated over.  More details on the semantics of ‘__path__’
     are given *note below: e93.

     Non-package modules should not have a ‘__path__’ attribute.

 -- Attribute: __file__

 -- Attribute: __cached__

     ‘__file__’ is optional.  If set, this attribute’s value must be a
     string.  The import system may opt to leave ‘__file__’ unset if it
     has no semantic meaning (e.g.  a module loaded from a database).

     If ‘__file__’ is set, it may also be appropriate to set the
     ‘__cached__’ attribute which is the path to any compiled version of
     the code (e.g.  byte-compiled file).  The file does not need to
     exist to set this attribute; the path can simply point to where the
     compiled file would exist (see PEP 3147(3)).

     It is also appropriate to set ‘__cached__’ when ‘__file__’ is not
     set.  However, that scenario is quite atypical.  Ultimately, the
     loader is what makes use of ‘__file__’ and/or ‘__cached__’.  So if
     a loader can load from a cached module but otherwise does not load
     from a file, that atypical scenario may be appropriate.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0366

   (2) https://www.python.org/dev/peps/pep-0366

   (3) https://www.python.org/dev/peps/pep-3147


File: python.info,  Node: module __path__,  Next: Module reprs,  Prev: Import-related module attributes,  Up: Loading

4.5.4.5 module.__path__
.......................

By definition, if a module has an ‘__path__’ attribute, it is a package,
regardless of its value.

A package’s ‘__path__’ attribute is used during imports of its
subpackages.  Within the import machinery, it functions much the same as
*note sys.path: 16c, i.e.  providing a list of locations to search for
modules during import.  However, ‘__path__’ is typically much more
constrained than *note sys.path: 16c.

‘__path__’ must be an iterable of strings, but it may be empty.  The
same rules used for *note sys.path: 16c. also apply to a package’s
‘__path__’, and *note sys.path_hooks: 574. (described below) are
consulted when traversing a package’s ‘__path__’.

A package’s ‘__init__.py’ file may set or alter the package’s ‘__path__’
attribute, and this was typically the way namespace packages were
implemented prior to PEP 420(1).  With the adoption of PEP 420(2),
namespace packages no longer need to supply ‘__init__.py’ files
containing only ‘__path__’ manipulation code; the import machinery
automatically sets ‘__path__’ correctly for the namespace package.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0420

   (2) https://www.python.org/dev/peps/pep-0420


File: python.info,  Node: Module reprs,  Prev: module __path__,  Up: Loading

4.5.4.6 Module reprs
....................

By default, all modules have a usable repr, however depending on the
attributes set above, and in the module’s spec, you can more explicitly
control the repr of module objects.

If the module has a spec (‘__spec__’), the import machinery will try to
generate a repr from it.  If that fails or there is no spec, the import
system will craft a default repr using whatever information is available
on the module.  It will try to use the ‘module.__name__’,
‘module.__file__’, and ‘module.__loader__’ as input into the repr, with
defaults for whatever information is missing.

Here are the exact rules used:

        * If the module has a ‘__spec__’ attribute, the information in
          the spec is used to generate the repr.  The "name", "loader",
          "origin", and "has_location" attributes are consulted.

        * If the module has a ‘__file__’ attribute, this is used as part
          of the module’s repr.

        * If the module has no ‘__file__’ but does have a ‘__loader__’
          that is not ‘None’, then the loader’s repr is used as part of
          the module’s repr.

        * Otherwise, just use the module’s ‘__name__’ in the repr.

Changed in version 3.4: Use of *note loader.module_repr(): 54d. has been
deprecated and the module spec is now used by the import machinery to
generate a module repr.

For backward compatibility with Python 3.3, the module repr will be
generated by calling the loader’s *note module_repr(): 54d. method, if
defined, before trying either approach described above.  However, the
method is deprecated.


File: python.info,  Node: The Path Based Finder,  Next: Replacing the standard import system,  Prev: Loading,  Up: The import system

4.5.5 The Path Based Finder
---------------------------

As mentioned previously, Python comes with several default meta path
finders.  One of these, called the *note path based finder: e87. (*note
PathFinder: 573.), searches an *note import path: e84, which contains a
list of *note path entries: e97.  Each path entry names a location to
search for modules.

The path based finder itself doesn’t know how to import anything.
Instead, it traverses the individual path entries, associating each of
them with a path entry finder that knows how to handle that particular
kind of path.

The default set of path entry finders implement all the semantics for
finding modules on the file system, handling special file types such as
Python source code (‘.py’ files), Python byte code (‘.pyc’ files) and
shared libraries (e.g.  ‘.so’ files).  When supported by the *note
zipimport: 140. module in the standard library, the default path entry
finders also handle loading all of these file types (other than shared
libraries) from zipfiles.

Path entries need not be limited to file system locations.  They can
refer to URLs, database queries, or any other location that can be
specified as a string.

The path based finder provides additional hooks and protocols so that
you can extend and customize the types of searchable path entries.  For
example, if you wanted to support path entries as network URLs, you
could write a hook that implements HTTP semantics to find modules on the
web.  This hook (a callable) would return a *note path entry finder:
5d2. supporting the protocol described below, which was then used to get
a loader for the module from the web.

A word of warning: this section and the previous both use the term
`finder', distinguishing between them by using the terms *note meta path
finder: 5d1. and *note path entry finder: 5d2.  These two types of
finders are very similar, support similar protocols, and function in
similar ways during the import process, but it’s important to keep in
mind that they are subtly different.  In particular, meta path finders
operate at the beginning of the import process, as keyed off the *note
sys.meta_path: 5dc. traversal.

By contrast, path entry finders are in a sense an implementation detail
of the path based finder, and in fact, if the path based finder were to
be removed from *note sys.meta_path: 5dc, none of the path entry finder
semantics would be invoked.

* Menu:

* Path entry finders:: 
* Path entry finder protocol:: 


File: python.info,  Node: Path entry finders,  Next: Path entry finder protocol,  Up: The Path Based Finder

4.5.5.1 Path entry finders
..........................

The *note path based finder: e87. is responsible for finding and loading
Python modules and packages whose location is specified with a string
*note path entry: e97.  Most path entries name locations in the file
system, but they need not be limited to this.

As a meta path finder, the *note path based finder: e87. implements the
*note find_spec(): 544. protocol previously described, however it
exposes additional hooks that can be used to customize how modules are
found and loaded from the *note import path: e84.

Three variables are used by the *note path based finder: e87, *note
sys.path: 16c, *note sys.path_hooks: 574. and *note
sys.path_importer_cache: 3ac.  The ‘__path__’ attributes on package
objects are also used.  These provide additional ways that the import
machinery can be customized.

*note sys.path: 16c. contains a list of strings providing search
locations for modules and packages.  It is initialized from the
‘PYTHONPATH’ environment variable and various other installation- and
implementation-specific defaults.  Entries in *note sys.path: 16c. can
name directories on the file system, zip files, and potentially other
"locations" (see the *note site: e9. module) that should be searched for
modules, such as URLs, or database queries.  Only strings and bytes
should be present on *note sys.path: 16c.; all other data types are
ignored.  The encoding of bytes entries is determined by the individual
*note path entry finders: 5d2.

The *note path based finder: e87. is a *note meta path finder: 5d1, so
the import machinery begins the *note import path: e84. search by
calling the path based finder’s *note find_spec(): 542. method as
described previously.  When the ‘path’ argument to *note find_spec():
542. is given, it will be a list of string paths to traverse - typically
a package’s ‘__path__’ attribute for an import within that package.  If
the ‘path’ argument is ‘None’, this indicates a top level import and
*note sys.path: 16c. is used.

The path based finder iterates over every entry in the search path, and
for each of these, looks for an appropriate *note path entry finder:
5d2. (*note PathEntryFinder: 5d4.) for the path entry.  Because this can
be an expensive operation (e.g.  there may be ‘stat()’ call overheads
for this search), the path based finder maintains a cache mapping path
entries to path entry finders.  This cache is maintained in *note
sys.path_importer_cache: 3ac. (despite the name, this cache actually
stores finder objects rather than being limited to *note importer: e83.
objects).  In this way, the expensive search for a particular *note path
entry: e97. location’s *note path entry finder: 5d2. need only be done
once.  User code is free to remove cache entries from *note
sys.path_importer_cache: 3ac. forcing the path based finder to perform
the path entry search again (1).

If the path entry is not present in the cache, the path based finder
iterates over every callable in *note sys.path_hooks: 574.  Each of the
*note path entry hooks: e99. in this list is called with a single
argument, the path entry to be searched.  This callable may either
return a *note path entry finder: 5d2. that can handle the path entry,
or it may raise *note ImportError: 19f.  An *note ImportError: 19f. is
used by the path based finder to signal that the hook cannot find a
*note path entry finder: 5d2.  for that *note path entry: e97.  The
exception is ignored and *note import path: e84. iteration continues.
The hook should expect either a string or bytes object; the encoding of
bytes objects is up to the hook (e.g.  it may be a file system encoding,
UTF-8, or something else), and if the hook cannot decode the argument,
it should raise *note ImportError: 19f.

If *note sys.path_hooks: 574. iteration ends with no *note path entry
finder: 5d2. being returned, then the path based finder’s *note
find_spec(): 542. method will store ‘None’ in *note
sys.path_importer_cache: 3ac. (to indicate that there is no finder for
this path entry) and return ‘None’, indicating that this *note meta path
finder: 5d1. could not find the module.

If a *note path entry finder: 5d2. `is' returned by one of the *note
path entry hook: e99. callables on *note sys.path_hooks: 574, then the
following protocol is used to ask the finder for a module spec, which is
then used when loading the module.

The current working directory – denoted by an empty string – is handled
slightly differently from other entries on *note sys.path: 16c.  First,
if the current working directory is found to not exist, no value is
stored in *note sys.path_importer_cache: 3ac.  Second, the value for the
current working directory is looked up fresh for each module lookup.
Third, the path used for *note sys.path_importer_cache: 3ac. and
returned by *note importlib.machinery.PathFinder.find_spec(): 542. will
be the actual current working directory and not the empty string.

   ---------- Footnotes ----------

   (1) In legacy code, it is possible to find instances of *note
imp.NullImporter: 5dd. in the *note sys.path_importer_cache: 3ac.  It is
recommended that code be changed to use ‘None’ instead.  See *note
Porting Python code: 753. for more details.


File: python.info,  Node: Path entry finder protocol,  Prev: Path entry finders,  Up: The Path Based Finder

4.5.5.2 Path entry finder protocol
..................................

In order to support imports of modules and initialized packages and also
to contribute portions to namespace packages, path entry finders must
implement the *note find_spec(): 547. method.

*note find_spec(): 547. takes two argument, the fully qualified name of
the module being imported, and the (optional) target module.
‘find_spec()’ returns a fully populated spec for the module.  This spec
will always have "loader" set (with one exception).

To indicate to the import machinery that the spec represents a namespace
*note portion: e7d.  the path entry finder sets "loader" on the spec to
‘None’ and "submodule_search_locations" to a list containing the
portion.

Changed in version 3.4: *note find_spec(): 547. replaced *note
find_loader(): 545. and *note find_module(): 546, both of which are now
deprecated, but will be used if ‘find_spec()’ is not defined.

Older path entry finders may implement one of these two deprecated
methods instead of ‘find_spec()’.  The methods are still respected for
the sake of backward compatibility.  Howevever, if ‘find_spec()’ is
implemented on the path entry finder, the legacy methods are ignored.

*note find_loader(): 545. takes one argument, the fully qualified name
of the module being imported.  ‘find_loader()’ returns a 2-tuple where
the first item is the loader and the second item is a namespace *note
portion: e7d.  When the first item (i.e.  the loader) is ‘None’, this
means that while the path entry finder does not have a loader for the
named module, it knows that the path entry contributes to a namespace
portion for the named module.  This will almost always be the case where
Python is asked to import a namespace package that has no physical
presence on the file system.  When a path entry finder returns ‘None’
for the loader, the second item of the 2-tuple return value must be a
sequence, although it can be empty.

If ‘find_loader()’ returns a non-‘None’ loader value, the portion is
ignored and the loader is returned from the path based finder,
terminating the search through the path entries.

For backwards compatibility with other implementations of the import
protocol, many path entry finders also support the same, traditional
‘find_module()’ method that meta path finders support.  However path
entry finder ‘find_module()’ methods are never called with a ‘path’
argument (they are expected to record the appropriate path information
from the initial call to the path hook).

The ‘find_module()’ method on path entry finders is deprecated, as it
does not allow the path entry finder to contribute portions to namespace
packages.  If both ‘find_loader()’ and ‘find_module()’ exist on a path
entry finder, the import system will always call ‘find_loader()’ in
preference to ‘find_module()’.


File: python.info,  Node: Replacing the standard import system,  Next: Special considerations for __main__,  Prev: The Path Based Finder,  Up: The import system

4.5.6 Replacing the standard import system
------------------------------------------

The most reliable mechanism for replacing the entire import system is to
delete the default contents of *note sys.meta_path: 5dc, replacing them
entirely with a custom meta path hook.

If it is acceptable to only alter the behaviour of import statements
without affecting other APIs that access the import system, then
replacing the builtin *note __import__(): 5cd. function may be
sufficient.  This technique may also be employed at the module level to
only alter the behaviour of import statements within that module.

To selectively prevent import of some modules from a hook early on the
meta path (rather than disabling the standard import system entirely),
it is sufficient to raise *note ImportError: 19f. directly from *note
find_spec(): 544. instead of returning ‘None’.  The latter indicates
that the meta path search should continue, while raising an exception
terminates it immediately.


File: python.info,  Node: Special considerations for __main__,  Next: Open issues,  Prev: Replacing the standard import system,  Up: The import system

4.5.7 Special considerations for __main__
-----------------------------------------

The *note __main__: 1. module is a special case relative to Python’s
import system.  As noted *note elsewhere: e91, the ‘__main__’ module is
directly initialized at interpreter startup, much like *note sys: fb.
and *note builtins: 13.  However, unlike those two, it doesn’t strictly
qualify as a built-in module.  This is because the manner in which
‘__main__’ is initialized depends on the flags and other options with
which the interpreter is invoked.

* Menu:

* __main__.__spec__: __main__ __spec__. 


File: python.info,  Node: __main__ __spec__,  Up: Special considerations for __main__

4.5.7.1 __main__.__spec__
.........................

Depending on how *note __main__: 1. is initialized, ‘__main__.__spec__’
gets set appropriately or to ‘None’.

When Python is started with the *note -m: 8b4. option, ‘__spec__’ is set
to the module spec of the corresponding module or package.  ‘__spec__’
is also populated when the ‘__main__’ module is loaded as part of
executing a directory, zipfile or other *note sys.path: 16c. entry.

In *note the remaining cases: cfc. ‘__main__.__spec__’ is set to ‘None’,
as the code used to populate the *note __main__: 1. does not correspond
directly with an importable module:

   - interactive prompt

   - -c switch

   - running from stdin

   - running directly from a source or bytecode file

Note that ‘__main__.__spec__’ is always ‘None’ in the last case, `even
if' the file could technically be imported directly as a module instead.
Use the *note -m: 8b4. switch if valid module metadata is desired in
*note __main__: 1.

Note also that even when ‘__main__’ corresponds with an importable
module and ‘__main__.__spec__’ is set accordingly, they’re still
considered `distinct' modules.  This is due to the fact that blocks
guarded by ‘if __name__ == "__main__":’ checks only execute when the
module is used to populate the ‘__main__’ namespace, and not during
normal import.


File: python.info,  Node: Open issues,  Next: References,  Prev: Special considerations for __main__,  Up: The import system

4.5.8 Open issues
-----------------

XXX It would be really nice to have a diagram.

XXX * (import_machinery.rst) how about a section devoted just to the
attributes of modules and packages, perhaps expanding upon or
supplanting the related entries in the data model reference page?

XXX runpy, pkgutil, et al in the library manual should all get "See
Also" links at the top pointing to the new import system section.

XXX Add more explanation regarding the different ways in which
‘__main__’ is initialized?

XXX Add more info on ‘__main__’ quirks/pitfalls (i.e.  copy from PEP
395(1)).

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0395


File: python.info,  Node: References,  Prev: Open issues,  Up: The import system

4.5.9 References
----------------

The import machinery has evolved considerably since Python’s early days.
The original specification for packages(1) is still available to read,
although some details have changed since the writing of that document.

The original specification for *note sys.meta_path: 5dc. was PEP 302(2),
with subsequent extension in PEP 420(3).

PEP 420(4) introduced *note namespace packages: e7b. for Python 3.3.
PEP 420(5) also introduced the ‘find_loader()’ protocol as an
alternative to ‘find_module()’.

PEP 366(6) describes the addition of the ‘__package__’ attribute for
explicit relative imports in main modules.

PEP 328(7) introduced absolute and explicit relative imports and
initially proposed ‘__name__’ for semantics PEP 366(8) would eventually
specify for ‘__package__’.

PEP 338(9) defines executing modules as scripts.

PEP 451(10) adds the encapsulation of per-module import state in spec
objects.  It also off-loads most of the boilerplate responsibilities of
loaders back onto the import machinery.  These changes allow the
deprecation of several APIs in the import system and also addition of
new methods to finders and loaders.

   ---------- Footnotes ----------

   (1) http://legacy.python.org/doc/essays/packages.html

   (2) https://www.python.org/dev/peps/pep-0302

   (3) https://www.python.org/dev/peps/pep-0420

   (4) https://www.python.org/dev/peps/pep-0420

   (5) https://www.python.org/dev/peps/pep-0420

   (6) https://www.python.org/dev/peps/pep-0366

   (7) https://www.python.org/dev/peps/pep-0328

   (8) https://www.python.org/dev/peps/pep-0366

   (9) https://www.python.org/dev/peps/pep-0338

   (10) https://www.python.org/dev/peps/pep-0451


File: python.info,  Node: Expressions,  Next: Simple statements,  Prev: The import system,  Up: The Python Language Reference

4.6 Expressions
===============

This chapter explains the meaning of the elements of expressions in
Python.

`Syntax Notes:' In this and the following chapters, extended BNF
notation will be used to describe syntax, not lexical analysis.  When
(one alternative of) a syntax rule has the form

     name ::= othername

and no semantics are given, the semantics of this form of ‘name’ are the
same as for ‘othername’.

* Menu:

* Arithmetic conversions:: 
* Atoms:: 
* Primaries:: 
* Await expression:: 
* The power operator:: 
* Unary arithmetic and bitwise operations:: 
* Binary arithmetic operations:: 
* Shifting operations:: 
* Binary bitwise operations:: 
* Comparisons:: 
* Boolean operations:: 
* Conditional expressions:: 
* Lambdas:: 
* Expression lists:: 
* Evaluation order:: 
* Operator precedence:: 


File: python.info,  Node: Arithmetic conversions,  Next: Atoms,  Up: Expressions

4.6.1 Arithmetic conversions
----------------------------

When a description of an arithmetic operator below uses the phrase "the
numeric arguments are converted to a common type," this means that the
operator implementation for built-in types works as follows:

   * If either argument is a complex number, the other is converted to
     complex;

   * otherwise, if either argument is a floating point number, the other
     is converted to floating point;

   * otherwise, both must be integers and no conversion is necessary.

Some additional rules apply for certain operators (e.g., a string as a
left argument to the ’%’ operator).  Extensions must define their own
conversion behavior.


File: python.info,  Node: Atoms,  Next: Primaries,  Prev: Arithmetic conversions,  Up: Expressions

4.6.2 Atoms
-----------

Atoms are the most basic elements of expressions.  The simplest atoms
are identifiers or literals.  Forms enclosed in parentheses, brackets or
braces are also categorized syntactically as atoms.  The syntax for
atoms is:

     atom      ::= identifier | literal | enclosure
     enclosure ::= parenth_form | list_display | dict_display | set_display
                   | generator_expression | yield_atom

* Menu:

* Identifiers (Names): Identifiers Names. 
* Literals: Literals<2>. 
* Parenthesized forms:: 
* Displays for lists, sets and dictionaries: Displays for lists sets and dictionaries. 
* List displays:: 
* Set displays:: 
* Dictionary displays:: 
* Generator expressions:: 
* Yield expressions:: 


File: python.info,  Node: Identifiers Names,  Next: Literals<2>,  Up: Atoms

4.6.2.1 Identifiers (Names)
...........................

An identifier occurring as an atom is a name.  See section *note
Identifiers and keywords: d90. for lexical definition and section *note
Naming and binding: e66. for documentation of naming and binding.

When the name is bound to an object, evaluation of the atom yields that
object.  When a name is not bound, an attempt to evaluate it raises a
*note NameError: 9f2. exception.

`Private name mangling:' When an identifier that textually occurs in a
class definition begins with two or more underscore characters and does
not end in two or more underscores, it is considered a `private name' of
that class.  Private names are transformed to a longer form before code
is generated for them.  The transformation inserts the class name, with
leading underscores removed and a single underscore inserted, in front
of the name.  For example, the identifier ‘__spam’ occurring in a class
named ‘Ham’ will be transformed to ‘_Ham__spam’.  This transformation is
independent of the syntactical context in which the identifier is used.
If the transformed name is extremely long (longer than 255 characters),
implementation defined truncation may happen.  If the class name
consists only of underscores, no transformation is done.


File: python.info,  Node: Literals<2>,  Next: Parenthesized forms,  Prev: Identifiers Names,  Up: Atoms

4.6.2.2 Literals
................

Python supports string and bytes literals and various numeric literals:

     literal ::= stringliteral | bytesliteral
                 | integer | floatnumber | imagnumber

Evaluation of a literal yields an object of the given type (string,
bytes, integer, floating point number, complex number) with the given
value.  The value may be approximated in the case of floating point and
imaginary (complex) literals.  See section *note Literals: d9d. for
details.

All literals correspond to immutable data types, and hence the object’s
identity is less important than its value.  Multiple evaluations of
literals with the same value (either the same occurrence in the program
text or a different occurrence) may obtain the same object or a
different object with the same value.


File: python.info,  Node: Parenthesized forms,  Next: Displays for lists sets and dictionaries,  Prev: Literals<2>,  Up: Atoms

4.6.2.3 Parenthesized forms
...........................

A parenthesized form is an optional expression list enclosed in
parentheses:

     parenth_form ::= "(" [expression_list] ")"

A parenthesized expression list yields whatever that expression list
yields: if the list contains at least one comma, it yields a tuple;
otherwise, it yields the single expression that makes up the expression
list.

An empty pair of parentheses yields an empty tuple object.  Since tuples
are immutable, the rules for literals apply (i.e., two occurrences of
the empty tuple may or may not yield the same object).

Note that tuples are not formed by the parentheses, but rather by use of
the comma operator.  The exception is the empty tuple, for which
parentheses `are' required — allowing unparenthesized "nothing" in
expressions would cause ambiguities and allow common typos to pass
uncaught.


File: python.info,  Node: Displays for lists sets and dictionaries,  Next: List displays,  Prev: Parenthesized forms,  Up: Atoms

4.6.2.4 Displays for lists, sets and dictionaries
.................................................

For constructing a list, a set or a dictionary Python provides special
syntax called "displays", each of them in two flavors:

   * either the container contents are listed explicitly, or

   * they are computed via a set of looping and filtering instructions,
     called a `comprehension'.

Common syntax elements for comprehensions are:

     comprehension ::= expression comp_for
     comp_for      ::= "for" target_list "in" or_test [comp_iter]
     comp_iter     ::= comp_for | comp_if
     comp_if       ::= "if" expression_nocond [comp_iter]

The comprehension consists of a single expression followed by at least
one *note for: 895. clause and zero or more *note for: 895. or *note if:
a65. clauses.  In this case, the elements of the new container are those
that would be produced by considering each of the *note for: 895. or
*note if: a65. clauses a block, nesting from left to right, and
evaluating the expression to produce an element each time the innermost
block is reached.

Note that the comprehension is executed in a separate scope, so names
assigned to in the target list don’t "leak" into the enclosing scope.


File: python.info,  Node: List displays,  Next: Set displays,  Prev: Displays for lists sets and dictionaries,  Up: Atoms

4.6.2.5 List displays
.....................

A list display is a possibly empty series of expressions enclosed in
square brackets:

     list_display ::= "[" [expression_list | comprehension] "]"

A list display yields a new list object, the contents being specified by
either a list of expressions or a comprehension.  When a comma-separated
list of expressions is supplied, its elements are evaluated from left to
right and placed into the list object in that order.  When a
comprehension is supplied, the list is constructed from the elements
resulting from the comprehension.


File: python.info,  Node: Set displays,  Next: Dictionary displays,  Prev: List displays,  Up: Atoms

4.6.2.6 Set displays
....................

A set display is denoted by curly braces and distinguishable from
dictionary displays by the lack of colons separating keys and values:

     set_display ::= "{" (expression_list | comprehension) "}"

A set display yields a new mutable set object, the contents being
specified by either a sequence of expressions or a comprehension.  When
a comma-separated list of expressions is supplied, its elements are
evaluated from left to right and added to the set object.  When a
comprehension is supplied, the set is constructed from the elements
resulting from the comprehension.

An empty set cannot be constructed with ‘{}’; this literal constructs an
empty dictionary.


File: python.info,  Node: Dictionary displays,  Next: Generator expressions,  Prev: Set displays,  Up: Atoms

4.6.2.7 Dictionary displays
...........................

A dictionary display is a possibly empty series of key/datum pairs
enclosed in curly braces:

     dict_display       ::= "{" [key_datum_list | dict_comprehension] "}"
     key_datum_list     ::= key_datum ("," key_datum)* [","]
     key_datum          ::= expression ":" expression
     dict_comprehension ::= expression ":" expression comp_for

A dictionary display yields a new dictionary object.

If a comma-separated sequence of key/datum pairs is given, they are
evaluated from left to right to define the entries of the dictionary:
each key object is used as a key into the dictionary to store the
corresponding datum.  This means that you can specify the same key
multiple times in the key/datum list, and the final dictionary’s value
for that key will be the last one given.

A dict comprehension, in contrast to list and set comprehensions, needs
two expressions separated with a colon followed by the usual "for" and
"if" clauses.  When the comprehension is run, the resulting key and
value elements are inserted in the new dictionary in the order they are
produced.

Restrictions on the types of the key values are listed earlier in
section *note The standard type hierarchy: de0.  (To summarize, the key
type should be *note hashable: de9, which excludes all mutable objects.)
Clashes between duplicate keys are not detected; the last datum
(textually rightmost in the display) stored for a given key value
prevails.


File: python.info,  Node: Generator expressions,  Next: Yield expressions,  Prev: Dictionary displays,  Up: Atoms

4.6.2.8 Generator expressions
.............................

A generator expression is a compact generator notation in parentheses:

     generator_expression ::= "(" expression comp_for ")"

A generator expression yields a new generator object.  Its syntax is the
same as for comprehensions, except that it is enclosed in parentheses
instead of brackets or curly braces.

Variables used in the generator expression are evaluated lazily when the
*note __next__(): c99. method is called for the generator object (in the
same fashion as normal generators).  However, the leftmost *note for:
895. clause is immediately evaluated, so that an error produced by it
can be seen before any other possible error in the code that handles the
generator expression.  Subsequent *note for: 895. clauses cannot be
evaluated immediately since they may depend on the previous *note for:
895. loop.  For example: ‘(x*y for x in range(10) for y in bar(x))’.

The parentheses can be omitted on calls with only one argument.  See
section *note Calls: deb. for details.


File: python.info,  Node: Yield expressions,  Prev: Generator expressions,  Up: Atoms

4.6.2.9 Yield expressions
.........................

     yield_atom       ::= "(" yield_expression ")"
     yield_expression ::= "yield" [expression_list | "from" expression]

The yield expression is only used when defining a *note generator: 5c0.
function and thus can only be used in the body of a function definition.
Using a yield expression in a function’s body causes that function to be
a generator.

When a generator function is called, it returns an iterator known as a
generator.  That generator then controls the execution of the generator
function.  The execution starts when one of the generator’s methods is
called.  At that time, the execution proceeds to the first yield
expression, where it is suspended again, returning the value of *note
expression_list: ec9. to the generator’s caller.  By suspended, we mean
that all local state is retained, including the current bindings of
local variables, the instruction pointer, the internal evaluation stack,
and the state of any exception handling.  When the execution is resumed
by calling one of the generator’s methods, the function can proceed
exactly as if the yield expression were just another external call.  The
value of the yield expression after resuming depends on the method which
resumed the execution.  If *note __next__(): c99. is used (typically via
either a *note for: 895. or the *note next(): 218. builtin) then the
result is *note None: 19d.  Otherwise, if *note send(): e54. is used,
then the result will be the value passed in to that method.

All of this makes generator functions quite similar to coroutines; they
yield multiple times, they have more than one entry point and their
execution can be suspended.  The only difference is that a generator
function cannot control where the execution should continue after it
yields; the control is always transferred to the generator’s caller.

Yield expressions are allowed anywhere in a *note try: 9e9. construct.
If the generator is not resumed before it is finalized (by reaching a
zero reference count or by being garbage collected), the
generator-iterator’s *note close(): e58. method will be called, allowing
any pending *note finally: 526. clauses to execute.

When ‘yield from <expr>’ is used, it treats the supplied expression as a
subiterator.  All values produced by that subiterator are passed
directly to the caller of the current generator’s methods.  Any values
passed in with *note send(): e54. and any exceptions passed in with
*note throw(): e56. are passed to the underlying iterator if it has the
appropriate methods.  If this is not the case, then *note send(): e54.
will raise *note AttributeError: 356. or *note TypeError: 562, while
*note throw(): e56. will just raise the passed in exception immediately.

When the underlying iterator is complete, the ‘value’ attribute of the
raised *note StopIteration: 191. instance becomes the value of the yield
expression.  It can be either set explicitly when raising *note
StopIteration: 191, or automatically when the sub-iterator is a
generator (by returning a value from the sub-generator).

     Changed in version 3.3: Added ‘yield from <expr>’ to delegate
     control flow to a subiterator.

The parentheses may be omitted when the yield expression is the sole
expression on the right hand side of an assignment statement.

See also
........

PEP 255(1) - Simple Generators

     The proposal for adding generators and the *note yield: 480.
     statement to Python.

PEP 342(2) - Coroutines via Enhanced Generators

     The proposal to enhance the API and syntax of generators, making
     them usable as simple coroutines.

PEP 380(3) - Syntax for Delegating to a Subgenerator

     The proposal to introduce the ‘yield_from’ syntax, making
     delegation to sub-generators easy.

* Menu:

* Generator-iterator methods:: 
* Examples:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0255

   (2) https://www.python.org/dev/peps/pep-0342

   (3) https://www.python.org/dev/peps/pep-0380


File: python.info,  Node: Generator-iterator methods,  Next: Examples,  Up: Yield expressions

4.6.2.10 Generator-iterator methods
...................................

This subsection describes the methods of a generator iterator.  They can
be used to control the execution of a generator function.

Note that calling any of the generator methods below when the generator
is already executing raises a *note ValueError: 19c. exception.

 -- Method: generator.__next__ ()

     Starts the execution of a generator function or resumes it at the
     last executed yield expression.  When a generator function is
     resumed with a *note __next__(): c99. method, the current yield
     expression always evaluates to *note None: 19d.  The execution then
     continues to the next yield expression, where the generator is
     suspended again, and the value of the *note expression_list: ec9.
     is returned to *note __next__(): c99.’s caller.  If the generator
     exits without yielding another value, a *note StopIteration: 191.
     exception is raised.

     This method is normally called implicitly, e.g.  by a *note for:
     895. loop, or by the built-in *note next(): 218. function.

 -- Method: generator.send (value)

     Resumes the execution and "sends" a value into the generator
     function.  The `value' argument becomes the result of the current
     yield expression.  The *note send(): e54. method returns the next
     value yielded by the generator, or raises *note StopIteration: 191.
     if the generator exits without yielding another value.  When *note
     send(): e54. is called to start the generator, it must be called
     with *note None: 19d. as the argument, because there is no yield
     expression that could receive the value.

 -- Method: generator.throw (type[, value[, traceback]])

     Raises an exception of type ‘type’ at the point where the generator
     was paused, and returns the next value yielded by the generator
     function.  If the generator exits without yielding another value, a
     *note StopIteration: 191. exception is raised.  If the generator
     function does not catch the passed-in exception, or raises a
     different exception, then that exception propagates to the caller.

 -- Method: generator.close ()

     Raises a *note GeneratorExit: 9a6. at the point where the generator
     function was paused.  If the generator function then exits
     gracefully, is already closed, or raises *note GeneratorExit: 9a6.
     (by not catching the exception), close returns to its caller.  If
     the generator yields a value, a *note RuntimeError: 193. is raised.
     If the generator raises any other exception, it is propagated to
     the caller.  *note close(): e58. does nothing if the generator has
     already exited due to an exception or normal exit.


File: python.info,  Node: Examples,  Prev: Generator-iterator methods,  Up: Yield expressions

4.6.2.11 Examples
.................

Here is a simple example that demonstrates the behavior of generators
and generator functions:

     >>> def echo(value=None):
     ...     print("Execution starts when 'next()' is called for the first time.")
     ...     try:
     ...         while True:
     ...             try:
     ...                 value = (yield value)
     ...             except Exception as e:
     ...                 value = e
     ...     finally:
     ...         print("Don't forget to clean up when 'close()' is called.")
     ...
     >>> generator = echo(1)
     >>> print(next(generator))
     Execution starts when 'next()' is called for the first time.
     1
     >>> print(next(generator))
     None
     >>> print(generator.send(2))
     2
     >>> generator.throw(TypeError, "spam")
     TypeError('spam',)
     >>> generator.close()
     Don't forget to clean up when 'close()' is called.

For examples using ‘yield from’, see *note PEP 380; Syntax for
Delegating to a Subgenerator: 595. in "What’s New in Python."


File: python.info,  Node: Primaries,  Next: Await expression,  Prev: Atoms,  Up: Expressions

4.6.3 Primaries
---------------

Primaries represent the most tightly bound operations of the language.
Their syntax is:

     primary ::= atom | attributeref | subscription | slicing | call

* Menu:

* Attribute references:: 
* Subscriptions:: 
* Slicings:: 
* Calls:: 


File: python.info,  Node: Attribute references,  Next: Subscriptions,  Up: Primaries

4.6.3.1 Attribute references
............................

An attribute reference is a primary followed by a period and a name:

     attributeref ::= primary "." identifier

The primary must evaluate to an object of a type that supports attribute
references, which most objects do.  This object is then asked to produce
the attribute whose name is the identifier.  This production can be
customized by overriding the *note __getattr__(): 782. method.  If this
attribute is not available, the exception *note AttributeError: 356. is
raised.  Otherwise, the type and value of the object produced is
determined by the object.  Multiple evaluations of the same attribute
reference may yield different objects.


File: python.info,  Node: Subscriptions,  Next: Slicings,  Prev: Attribute references,  Up: Primaries

4.6.3.2 Subscriptions
.....................

A subscription selects an item of a sequence (string, tuple or list) or
mapping (dictionary) object:

     subscription ::= primary "[" expression_list "]"

The primary must evaluate to an object that supports subscription (lists
or dictionaries for example).  User-defined objects can support
subscription by defining a *note __getitem__(): a84. method.

For built-in objects, there are two types of objects that support
subscription:

If the primary is a mapping, the expression list must evaluate to an
object whose value is one of the keys of the mapping, and the
subscription selects the value in the mapping that corresponds to that
key.  (The expression list is a tuple except if it has exactly one
item.)

If the primary is a sequence, the expression (list) must evaluate to an
integer or a slice (as discussed in the following section).

The formal syntax makes no special provision for negative indices in
sequences; however, built-in sequences all provide a *note
__getitem__(): a84. method that interprets negative indices by adding
the length of the sequence to the index (so that ‘x[-1]’ selects the
last item of ‘x’).  The resulting value must be a nonnegative integer
less than the number of items in the sequence, and the subscription
selects the item whose index is that value (counting from zero).  Since
the support for negative indices and slicing occurs in the object’s
*note __getitem__(): a84. method, subclasses overriding this method will
need to explicitly add that support.

A string’s items are characters.  A character is not a separate data
type but a string of exactly one character.


File: python.info,  Node: Slicings,  Next: Calls,  Prev: Subscriptions,  Up: Primaries

4.6.3.3 Slicings
................

A slicing selects a range of items in a sequence object (e.g., a string,
tuple or list).  Slicings may be used as expressions or as targets in
assignment or *note del: c30. statements.  The syntax for a slicing:

     slicing      ::= primary "[" slice_list "]"
     slice_list   ::= slice_item ("," slice_item)* [","]
     slice_item   ::= expression | proper_slice
     proper_slice ::= [lower_bound] ":" [upper_bound] [ ":" [stride] ]
     lower_bound  ::= expression
     upper_bound  ::= expression
     stride       ::= expression

There is ambiguity in the formal syntax here: anything that looks like
an expression list also looks like a slice list, so any subscription can
be interpreted as a slicing.  Rather than further complicating the
syntax, this is disambiguated by defining that in this case the
interpretation as a subscription takes priority over the interpretation
as a slicing (this is the case if the slice list contains no proper
slice).

The semantics for a slicing are as follows.  The primary is indexed
(using the same *note __getitem__(): a84. method as normal subscription)
with a key that is constructed from the slice list, as follows.  If the
slice list contains at least one comma, the key is a tuple containing
the conversion of the slice items; otherwise, the conversion of the lone
slice item is the key.  The conversion of a slice item that is an
expression is that expression.  The conversion of a proper slice is a
slice object (see section *note The standard type hierarchy: de0.) whose
‘start’, ‘stop’ and ‘step’ attributes are the values of the expressions
given as lower bound, upper bound and stride, respectively, substituting
‘None’ for missing expressions.


File: python.info,  Node: Calls,  Prev: Slicings,  Up: Primaries

4.6.3.4 Calls
.............

A call calls a callable object (e.g., a *note function: edf.) with a
possibly empty series of *note arguments: ee0.:

     call                 ::= primary "(" [argument_list [","] | comprehension] ")"
     argument_list        ::= positional_arguments ["," keyword_arguments]
                                ["," "*" expression] ["," keyword_arguments]
                                ["," "**" expression]
                              | keyword_arguments ["," "*" expression]
                                ["," keyword_arguments] ["," "**" expression]
                              | "*" expression ["," keyword_arguments] ["," "**" expression]
                              | "**" expression
     positional_arguments ::= expression ("," expression)*
     keyword_arguments    ::= keyword_item ("," keyword_item)*
     keyword_item         ::= identifier "=" expression

An optional trailing comma may be present after the positional and
keyword arguments but does not affect the semantics.

The primary must evaluate to a callable object (user-defined functions,
built-in functions, methods of built-in objects, class objects, methods
of class instances, and all objects having a *note __call__(): dee.
method are callable).  All argument expressions are evaluated before the
call is attempted.  Please refer to section *note Function definitions:
c1e. for the syntax of formal *note parameter: ee6. lists.

If keyword arguments are present, they are first converted to positional
arguments, as follows.  First, a list of unfilled slots is created for
the formal parameters.  If there are N positional arguments, they are
placed in the first N slots.  Next, for each keyword argument, the
identifier is used to determine the corresponding slot (if the
identifier is the same as the first formal parameter name, the first
slot is used, and so on).  If the slot is already filled, a *note
TypeError: 562. exception is raised.  Otherwise, the value of the
argument is placed in the slot, filling it (even if the expression is
‘None’, it fills the slot).  When all arguments have been processed, the
slots that are still unfilled are filled with the corresponding default
value from the function definition.  (Default values are calculated,
once, when the function is defined; thus, a mutable object such as a
list or dictionary used as default value will be shared by all calls
that don’t specify an argument value for the corresponding slot; this
should usually be avoided.)  If there are any unfilled slots for which
no default value is specified, a *note TypeError: 562. exception is
raised.  Otherwise, the list of filled slots is used as the argument
list for the call.

`CPython implementation detail:' An implementation may provide built-in
functions whose positional parameters do not have names, even if they
are ’named’ for the purpose of documentation, and which therefore cannot
be supplied by keyword.  In CPython, this is the case for functions
implemented in C that use *note PyArg_ParseTuple(): 724. to parse their
arguments.

If there are more positional arguments than there are formal parameter
slots, a *note TypeError: 562. exception is raised, unless a formal
parameter using the syntax ‘*identifier’ is present; in this case, that
formal parameter receives a tuple containing the excess positional
arguments (or an empty tuple if there were no excess positional
arguments).

If any keyword argument does not correspond to a formal parameter name,
a *note TypeError: 562. exception is raised, unless a formal parameter
using the syntax ‘**identifier’ is present; in this case, that formal
parameter receives a dictionary containing the excess keyword arguments
(using the keywords as keys and the argument values as corresponding
values), or a (new) empty dictionary if there were no excess keyword
arguments.

If the syntax ‘*expression’ appears in the function call, ‘expression’
must evaluate to an iterable.  Elements from this iterable are treated
as if they were additional positional arguments; if there are positional
arguments `x1', ..., `xN', and ‘expression’ evaluates to a sequence
`y1', ..., `yM', this is equivalent to a call with M+N positional
arguments `x1', ..., `xN', `y1', ..., `yM'.

A consequence of this is that although the ‘*expression’ syntax may
appear `after' some keyword arguments, it is processed `before' the
keyword arguments (and the ‘**expression’ argument, if any – see below).
So:

     >>> def f(a, b):
     ...  print(a, b)
     ...
     >>> f(b=1, *(2,))
     2 1
     >>> f(a=1, *(2,))
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     TypeError: f() got multiple values for keyword argument 'a'
     >>> f(1, *(2,))
     1 2

It is unusual for both keyword arguments and the ‘*expression’ syntax to
be used in the same call, so in practice this confusion does not arise.

If the syntax ‘**expression’ appears in the function call, ‘expression’
must evaluate to a mapping, the contents of which are treated as
additional keyword arguments.  In the case of a keyword appearing in
both ‘expression’ and as an explicit keyword argument, a *note
TypeError: 562. exception is raised.

Formal parameters using the syntax ‘*identifier’ or ‘**identifier’
cannot be used as positional argument slots or as keyword argument
names.

A call always returns some value, possibly ‘None’, unless it raises an
exception.  How this value is computed depends on the type of the
callable object.

If it is—

a user-defined function:

     The code block for the function is executed, passing it the
     argument list.  The first thing the code block will do is bind the
     formal parameters to the arguments; this is described in section
     *note Function definitions: c1e.  When the code block executes a
     *note return: 981. statement, this specifies the return value of
     the function call.

a built-in function or method:

     The result is up to the interpreter; see *note Built-in Functions:
     854. for the descriptions of built-in functions and methods.

a class object:

     A new instance of that class is returned.

a class instance method:

     The corresponding user-defined function is called, with an argument
     list that is one longer than the argument list of the call: the
     instance becomes the first argument.

a class instance:

     The class must define a *note __call__(): dee. method; the effect
     is then the same as if that method was called.


File: python.info,  Node: Await expression,  Next: The power operator,  Prev: Primaries,  Up: Expressions

4.6.4 Await expression
----------------------

Suspend the execution of *note coroutine: 2ad. on an *note awaitable:
1ca. object.  Can only be used inside a *note coroutine function: 1cb.

     await ::= ["await"] primary

New in version 3.5.


File: python.info,  Node: The power operator,  Next: Unary arithmetic and bitwise operations,  Prev: Await expression,  Up: Expressions

4.6.5 The power operator
------------------------

The power operator binds more tightly than unary operators on its left;
it binds less tightly than unary operators on its right.  The syntax is:

     power ::= await ["**" u_expr]

Thus, in an unparenthesized sequence of power and unary operators, the
operators are evaluated from right to left (this does not constrain the
evaluation order for the operands): ‘-1**2’ results in ‘-1’.

The power operator has the same semantics as the built-in *note pow():
ad3. function, when called with two arguments: it yields its left
argument raised to the power of its right argument.  The numeric
arguments are first converted to a common type, and the result is of
that type.

For int operands, the result has the same type as the operands unless
the second argument is negative; in that case, all arguments are
converted to float and a float result is delivered.  For example,
‘10**2’ returns ‘100’, but ‘10**-2’ returns ‘0.01’.

Raising ‘0.0’ to a negative power results in a *note ZeroDivisionError:
c6a.  Raising a negative number to a fractional power results in a *note
complex: 579. number.  (In earlier versions it raised a *note
ValueError: 19c.)


File: python.info,  Node: Unary arithmetic and bitwise operations,  Next: Binary arithmetic operations,  Prev: The power operator,  Up: Expressions

4.6.6 Unary arithmetic and bitwise operations
---------------------------------------------

All unary arithmetic and bitwise operations have the same priority:

     u_expr ::= power | "-" u_expr | "+" u_expr | "~" u_expr

The unary ‘-’ (minus) operator yields the negation of its numeric
argument.

The unary ‘+’ (plus) operator yields its numeric argument unchanged.

The unary ‘~’ (invert) operator yields the bitwise inversion of its
integer argument.  The bitwise inversion of ‘x’ is defined as ‘-(x+1)’.
It only applies to integral numbers.

In all three cases, if the argument does not have the proper type, a
*note TypeError: 562. exception is raised.


File: python.info,  Node: Binary arithmetic operations,  Next: Shifting operations,  Prev: Unary arithmetic and bitwise operations,  Up: Expressions

4.6.7 Binary arithmetic operations
----------------------------------

The binary arithmetic operations have the conventional priority levels.
Note that some of these operations also apply to certain non-numeric
types.  Apart from the power operator, there are only two levels, one
for multiplicative operators and one for additive operators:

     m_expr ::= u_expr | m_expr "*" u_expr | m_expr "@" m_expr |
                m_expr "//" u_expr| m_expr "/" u_expr |
                m_expr "%" u_expr
     a_expr ::= m_expr | a_expr "+" m_expr | a_expr "-" m_expr

The ‘*’ (multiplication) operator yields the product of its arguments.
The arguments must either both be numbers, or one argument must be an
integer and the other must be a sequence.  In the former case, the
numbers are converted to a common type and then multiplied together.  In
the latter case, sequence repetition is performed; a negative repetition
factor yields an empty sequence.

The ‘@’ (at) operator is intended to be used for matrix multiplication.
No builtin Python types implement this operator.

New in version 3.5.

The ‘/’ (division) and ‘//’ (floor division) operators yield the
quotient of their arguments.  The numeric arguments are first converted
to a common type.  Division of integers yields a float, while floor
division of integers results in an integer; the result is that of
mathematical division with the ’floor’ function applied to the result.
Division by zero raises the *note ZeroDivisionError: c6a. exception.

The ‘%’ (modulo) operator yields the remainder from the division of the
first argument by the second.  The numeric arguments are first converted
to a common type.  A zero right argument raises the *note
ZeroDivisionError: c6a. exception.  The arguments may be floating point
numbers, e.g., ‘3.14%0.7’ equals ‘0.34’ (since ‘3.14’ equals ‘4*0.7 +
0.34’.)  The modulo operator always yields a result with the same sign
as its second operand (or zero); the absolute value of the result is
strictly smaller than the absolute value of the second operand (1).

The floor division and modulo operators are connected by the following
identity: ‘x == (x//y)*y + (x%y)’.  Floor division and modulo are also
connected with the built-in function *note divmod(): e2c.: ‘divmod(x, y)
== (x//y, x%y)’.  (2).

In addition to performing the modulo operation on numbers, the ‘%’
operator is also overloaded by string objects to perform old-style
string formatting (also known as interpolation).  The syntax for string
formatting is described in the Python Library Reference, section *note
printf-style String Formatting: bec.

The floor division operator, the modulo operator, and the *note
divmod(): e2c. function are not defined for complex numbers.  Instead,
convert to a floating point number using the *note abs(): c7c. function
if appropriate.

The ‘+’ (addition) operator yields the sum of its arguments.  The
arguments must either both be numbers or both be sequences of the same
type.  In the former case, the numbers are converted to a common type
and then added together.  In the latter case, the sequences are
concatenated.

The ‘-’ (subtraction) operator yields the difference of its arguments.
The numeric arguments are first converted to a common type.

   ---------- Footnotes ----------

   (1) While ‘abs(x%y) < abs(y)’ is true mathematically, for floats it
may not be true numerically due to roundoff.  For example, and assuming
a platform on which a Python float is an IEEE 754 double-precision
number, in order that ‘-1e-100 % 1e100’ have the same sign as ‘1e100’,
the computed result is ‘-1e-100 + 1e100’, which is numerically exactly
equal to ‘1e100’.  The function *note math.fmod(): ef3. returns a result
whose sign matches the sign of the first argument instead, and so
returns ‘-1e-100’ in this case.  Which approach is more appropriate
depends on the application.

   (2) If x is very close to an exact integer multiple of y, it’s
possible for ‘x//y’ to be one larger than ‘(x-x%y)//y’ due to rounding.
In such cases, Python returns the latter result, in order to preserve
that ‘divmod(x,y)[0] * y + x % y’ be very close to ‘x’.


File: python.info,  Node: Shifting operations,  Next: Binary bitwise operations,  Prev: Binary arithmetic operations,  Up: Expressions

4.6.8 Shifting operations
-------------------------

The shifting operations have lower priority than the arithmetic
operations:

     shift_expr ::= a_expr | shift_expr ( "<<" | ">>" ) a_expr

These operators accept integers as arguments.  They shift the first
argument to the left or right by the number of bits given by the second
argument.

A right shift by `n' bits is defined as floor division by ‘pow(2,n)’.  A
left shift by `n' bits is defined as multiplication with ‘pow(2,n)’.

     Note: In the current implementation, the right-hand operand is
     required to be at most *note sys.maxsize: 78c.  If the right-hand
     operand is larger than *note sys.maxsize: 78c. an *note
     OverflowError: 578. exception is raised.


File: python.info,  Node: Binary bitwise operations,  Next: Comparisons,  Prev: Shifting operations,  Up: Expressions

4.6.9 Binary bitwise operations
-------------------------------

Each of the three bitwise operations has a different priority level:

     and_expr ::= shift_expr | and_expr "&" shift_expr
     xor_expr ::= and_expr | xor_expr "^" and_expr
     or_expr  ::= xor_expr | or_expr "|" xor_expr

The ‘&’ operator yields the bitwise AND of its arguments, which must be
integers.

The ‘^’ operator yields the bitwise XOR (exclusive OR) of its arguments,
which must be integers.

The ‘|’ operator yields the bitwise (inclusive) OR of its arguments,
which must be integers.


File: python.info,  Node: Comparisons,  Next: Boolean operations,  Prev: Binary bitwise operations,  Up: Expressions

4.6.10 Comparisons
------------------

Unlike C, all comparison operations in Python have the same priority,
which is lower than that of any arithmetic, shifting or bitwise
operation.  Also unlike C, expressions like ‘a < b < c’ have the
interpretation that is conventional in mathematics:

     comparison    ::= or_expr ( comp_operator or_expr )*
     comp_operator ::= "<" | ">" | "==" | ">=" | "<=" | "!="
                       | "is" ["not"] | ["not"] "in"

Comparisons yield boolean values: ‘True’ or ‘False’.

Comparisons can be chained arbitrarily, e.g., ‘x < y <= z’ is equivalent
to ‘x < y and y <= z’, except that ‘y’ is evaluated only once (but in
both cases ‘z’ is not evaluated at all when ‘x < y’ is found to be
false).

Formally, if `a', `b', `c', ..., `y', `z' are expressions and `op1',
`op2', ..., `opN' are comparison operators, then ‘a op1 b op2 c ... y
opN z’ is equivalent to ‘a op1 b and b op2 c and ... y opN z’, except
that each expression is evaluated at most once.

Note that ‘a op1 b op2 c’ doesn’t imply any kind of comparison between
`a' and `c', so that, e.g., ‘x < y > z’ is perfectly legal (though
perhaps not pretty).

* Menu:

* Value comparisons:: 
* Membership test operations:: 
* Identity comparisons:: 


File: python.info,  Node: Value comparisons,  Next: Membership test operations,  Up: Comparisons

4.6.10.1 Value comparisons
..........................

The operators ‘<’, ‘>’, ‘==’, ‘>=’, ‘<=’, and ‘!=’ compare the values of
two objects.  The objects do not need to have the same type.

Chapter *note Objects, values and types: ddc. states that objects have a
value (in addition to type and identity).  The value of an object is a
rather abstract notion in Python: For example, there is no canonical
access method for an object’s value.  Also, there is no requirement that
the value of an object should be constructed in a particular way, e.g.
comprised of all its data attributes.  Comparison operators implement a
particular notion of what the value of an object is.  One can think of
them as defining the value of an object indirectly, by means of their
comparison implementation.

Because all types are (direct or indirect) subtypes of *note object:
5cb, they inherit the default comparison behavior from *note object:
5cb.  Types can customize their comparison behavior by implementing
`rich comparison methods' like *note __lt__(): 899, described in *note
Basic customization: dfa.

The default behavior for equality comparison (‘==’ and ‘!=’) is based on
the identity of the objects.  Hence, equality comparison of instances
with the same identity results in equality, and equality comparison of
instances with different identities results in inequality.  A motivation
for this default behavior is the desire that all objects should be
reflexive (i.e.  ‘x is y’ implies ‘x == y’).

A default order comparison (‘<’, ‘>’, ‘<=’, and ‘>=’) is not provided;
an attempt raises *note TypeError: 562.  A motivation for this default
behavior is the lack of a similar invariant as for equality.

The behavior of the default equality comparison, that instances with
different identities are always unequal, may be in contrast to what
types will need that have a sensible definition of object value and
value-based equality.  Such types will need to customize their
comparison behavior, and in fact, a number of built-in types have done
that.

The following list describes the comparison behavior of the most
important built-in types.

   * Numbers of built-in numeric types (*note Numeric Types — int,
     float, complex: be6.) and of the standard library types *note
     fractions.Fraction: 378. and *note decimal.Decimal: 618. can be
     compared within and across their types, with the restriction that
     complex numbers do not support order comparison.  Within the limits
     of the types involved, they compare mathematically
     (algorithmically) correct without loss of precision.

     The not-a-number values ‘float('NaN')’ and ‘Decimal('NaN')’ are
     special.  They are identical to themselves (‘x is x’ is true) but
     are not equal to themselves (‘x == x’ is false).  Additionally,
     comparing any number to a not-a-number value will return ‘False’.
     For example, both ‘3 < float('NaN')’ and ‘float('NaN') < 3’ will
     return ‘False’.

   * Binary sequences (instances of *note bytes: 1db. or *note
     bytearray: 1dc.) can be compared within and across their types.
     They compare lexicographically using the numeric values of their
     elements.

   * Strings (instances of *note str: 25a.) compare lexicographically
     using the numerical Unicode code points (the result of the built-in
     function *note ord(): de6.) of their characters.  (1)

     Strings and binary sequences cannot be directly compared.

   * Sequences (instances of *note tuple: 25c, *note list: 25d, or *note
     range: 5e0.) can be compared only within each of their types, with
     the restriction that ranges do not support order comparison.
     Equality comparison across these types results in unequality, and
     ordering comparison across these types raises *note TypeError: 562.

     Sequences compare lexicographically using comparison of
     corresponding elements, whereby reflexivity of the elements is
     enforced.

     In enforcing reflexivity of elements, the comparison of collections
     assumes that for a collection element ‘x’, ‘x == x’ is always true.
     Based on that assumption, element identity is compared first, and
     element comparison is performed only for distinct elements.  This
     approach yields the same result as a strict element comparison
     would, if the compared elements are reflexive.  For non-reflexive
     elements, the result is different than for strict element
     comparison, and may be surprising: The non-reflexive not-a-number
     values for example result in the following comparison behavior when
     used in a list:

          >>> nan = float('NaN')
          >>> nan is nan
          True
          >>> nan == nan
          False                 <-- the defined non-reflexive behavior of NaN
          >>> [nan] == [nan]
          True                  <-- list enforces reflexivity and tests identity first

     Lexicographical comparison between built-in collections works as
     follows:

        - For two collections to compare equal, they must be of the same
          type, have the same length, and each pair of corresponding
          elements must compare equal (for example, ‘[1,2] == (1,2)’ is
          false because the type is not the same).

        - Collections that support order comparison are ordered the same
          as their first unequal elements (for example, ‘[1,2,x] <=
          [1,2,y]’ has the same value as ‘x <= y’).  If a corresponding
          element does not exist, the shorter collection is ordered
          first (for example, ‘[1,2] < [1,2,3]’ is true).

   * Mappings (instances of *note dict: 3b0.) compare equal if and only
     if they have equal ‘(key, value)’ pairs.  Equality comparison of
     the keys and elements enforces reflexivity.

     Order comparisons (‘<’, ‘>’, ‘<=’, and ‘>=’) raise *note TypeError:
     562.

   * Sets (instances of *note set: 7be. or *note frozenset: 84c.) can be
     compared within and across their types.

     They define order comparison operators to mean subset and superset
     tests.  Those relations do not define total orderings (for example,
     the two sets ‘{1,2}’ and ‘{2,3}’ are not equal, nor subsets of one
     another, nor supersets of one another).  Accordingly, sets are not
     appropriate arguments for functions which depend on total ordering
     (for example, *note min(): 3f9, *note max(): 3fa, and *note
     sorted(): 84e. produce undefined results given a list of sets as
     inputs).

     Comparison of sets enforces reflexivity of its elements.

   * Most other built-in types have no comparison methods implemented,
     so they inherit the default comparison behavior.

User-defined classes that customize their comparison behavior should
follow some consistency rules, if possible:

   * Equality comparison should be reflexive.  In other words, identical
     objects should compare equal:

          ‘x is y’ implies ‘x == y’

   * Comparison should be symmetric.  In other words, the following
     expressions should have the same result:

          ‘x == y’ and ‘y == x’

          ‘x != y’ and ‘y != x’

          ‘x < y’ and ‘y > x’

          ‘x <= y’ and ‘y >= x’

   * Comparison should be transitive.  The following (non-exhaustive)
     examples illustrate that:

          ‘x > y and y > z’ implies ‘x > z’

          ‘x < y and y <= z’ implies ‘x < z’

   * Inverse comparison should result in the boolean negation.  In other
     words, the following expressions should have the same result:

          ‘x == y’ and ‘not x != y’

          ‘x < y’ and ‘not x >= y’ (for total ordering)

          ‘x > y’ and ‘not x <= y’ (for total ordering)

     The last two expressions apply to totally ordered collections (e.g.
     to sequences, but not to sets or mappings).  See also the *note
     total_ordering(): 440. decorator.

Python does not enforce these consistency rules.  In fact, the
not-a-number values are an example for not following these rules.

   ---------- Footnotes ----------

   (1) The Unicode standard distinguishes between `code points' (e.g.
U+0041) and `abstract characters' (e.g.  "LATIN CAPITAL LETTER A").
While most abstract characters in Unicode are only represented using one
code point, there is a number of abstract characters that can in
addition be represented using a sequence of more than one code point.
For example, the abstract character "LATIN CAPITAL LETTER C WITH
CEDILLA" can be represented as a single `precomposed character' at code
position U+00C7, or as a sequence of a `base character' at code position
U+0043 (LATIN CAPITAL LETTER C), followed by a `combining character' at
code position U+0327 (COMBINING CEDILLA).

The comparison operators on strings compare at the level of Unicode code
points.  This may be counter-intuitive to humans.  For example,
‘"\u00C7" == "\u0043\u0327"’ is ‘False’, even though both strings
represent the same abstract character "LATIN CAPITAL LETTER C WITH
CEDILLA".

To compare strings at the level of abstract characters (that is, in a
way intuitive to humans), use *note unicodedata.normalize(): f01.


File: python.info,  Node: Membership test operations,  Next: Identity comparisons,  Prev: Value comparisons,  Up: Comparisons

4.6.10.2 Membership test operations
...................................

The operators *note in: 37d. and *note not in: e20. test for membership.
‘x in s’ evaluates to true if `x' is a member of `s', and false
otherwise.  ‘x not in s’ returns the negation of ‘x in s’.  All built-in
sequences and set types support this as well as dictionary, for which
*note in: 37d. tests whether the dictionary has a given key.  For
container types such as list, tuple, set, frozenset, dict, or
collections.deque, the expression ‘x in y’ is equivalent to ‘any(x is e
or x == e for e in y)’.

For the string and bytes types, ‘x in y’ is true if and only if `x' is a
substring of `y'.  An equivalent test is ‘y.find(x) != -1’.  Empty
strings are always considered to be a substring of any other string, so
‘"" in "abc"’ will return ‘True’.

For user-defined classes which define the *note __contains__(): 99c.
method, ‘x in y’ is true if and only if ‘y.__contains__(x)’ is true.

For user-defined classes which do not define *note __contains__(): 99c.
but do define *note __iter__(): 99b, ‘x in y’ is true if some value ‘z’
with ‘x == z’ is produced while iterating over ‘y’.  If an exception is
raised during the iteration, it is as if *note in: 37d. raised that
exception.

Lastly, the old-style iteration protocol is tried: if a class defines
*note __getitem__(): a84, ‘x in y’ is true if and only if there is a
non-negative integer index `i' such that ‘x == y[i]’, and all lower
integer indices do not raise *note IndexError: afb. exception.  (If any
other exception is raised, it is as if *note in: 37d. raised that
exception).

The operator *note not in: e20. is defined to have the inverse true
value of *note in: 37d.


File: python.info,  Node: Identity comparisons,  Prev: Membership test operations,  Up: Comparisons

4.6.10.3 Identity comparisons
.............................

The operators *note is: dde. and *note is not: f03. test for object
identity: ‘x is y’ is true if and only if `x' and `y' are the same
object.  ‘x is not y’ yields the inverse truth value.  (1)

   ---------- Footnotes ----------

   (1) Due to automatic garbage-collection, free lists, and the dynamic
nature of descriptors, you may notice seemingly unusual behaviour in
certain uses of the *note is: dde. operator, like those involving
comparisons between instance methods, or constants.  Check their
documentation for more info.


File: python.info,  Node: Boolean operations,  Next: Conditional expressions,  Prev: Comparisons,  Up: Expressions

4.6.11 Boolean operations
-------------------------

     or_test  ::= and_test | or_test "or" and_test
     and_test ::= not_test | and_test "and" not_test
     not_test ::= comparison | "not" not_test

In the context of Boolean operations, and also when expressions are used
by control flow statements, the following values are interpreted as
false: ‘False’, ‘None’, numeric zero of all types, and empty strings and
containers (including strings, tuples, lists, dictionaries, sets and
frozensets).  All other values are interpreted as true.  User-defined
objects can customize their truth value by providing a *note __bool__():
8d4. method.

The operator *note not: f08. yields ‘True’ if its argument is false,
‘False’ otherwise.

The expression ‘x and y’ first evaluates `x'; if `x' is false, its value
is returned; otherwise, `y' is evaluated and the resulting value is
returned.

The expression ‘x or y’ first evaluates `x'; if `x' is true, its value
is returned; otherwise, `y' is evaluated and the resulting value is
returned.

(Note that neither *note and: f06. nor *note or: f07. restrict the value
and type they return to ‘False’ and ‘True’, but rather return the last
evaluated argument.  This is sometimes useful, e.g., if ‘s’ is a string
that should be replaced by a default value if it is empty, the
expression ‘s or 'foo'’ yields the desired value.  Because *note not:
f08. has to create a new value, it returns a boolean value regardless of
the type of its argument (for example, ‘not 'foo'’ produces ‘False’
rather than ‘''’.)


File: python.info,  Node: Conditional expressions,  Next: Lambdas,  Prev: Boolean operations,  Up: Expressions

4.6.12 Conditional expressions
------------------------------

     conditional_expression ::= or_test ["if" or_test "else" expression]
     expression             ::= conditional_expression | lambda_expr
     expression_nocond      ::= or_test | lambda_expr_nocond

Conditional expressions (sometimes called a "ternary operator") have the
lowest priority of all Python operations.

The expression ‘x if C else y’ first evaluates the condition, `C' rather
than `x'.  If `C' is true, `x' is evaluated and its value is returned;
otherwise, `y' is evaluated and its value is returned.

See PEP 308(1) for more details about conditional expressions.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0308


File: python.info,  Node: Lambdas,  Next: Expression lists,  Prev: Conditional expressions,  Up: Expressions

4.6.13 Lambdas
--------------

     lambda_expr        ::= "lambda" [parameter_list]: expression
     lambda_expr_nocond ::= "lambda" [parameter_list]: expression_nocond

Lambda expressions (sometimes called lambda forms) are used to create
anonymous functions.  The expression ‘lambda arguments: expression’
yields a function object.  The unnamed object behaves like a function
object defined with

     def <lambda>(arguments):
         return expression

See section *note Function definitions: c1e. for the syntax of parameter
lists.  Note that functions created with lambda expressions cannot
contain statements or annotations.


File: python.info,  Node: Expression lists,  Next: Evaluation order,  Prev: Lambdas,  Up: Expressions

4.6.14 Expression lists
-----------------------

     expression_list ::= expression ( "," expression )* [","]

An expression list containing at least one comma yields a tuple.  The
length of the tuple is the number of expressions in the list.  The
expressions are evaluated from left to right.

The trailing comma is required only to create a single tuple (a.k.a.  a
`singleton'); it is optional in all other cases.  A single expression
without a trailing comma doesn’t create a tuple, but rather yields the
value of that expression.  (To create an empty tuple, use an empty pair
of parentheses: ‘()’.)


File: python.info,  Node: Evaluation order,  Next: Operator precedence,  Prev: Expression lists,  Up: Expressions

4.6.15 Evaluation order
-----------------------

Python evaluates expressions from left to right.  Notice that while
evaluating an assignment, the right-hand side is evaluated before the
left-hand side.

In the following lines, expressions will be evaluated in the arithmetic
order of their suffixes:

     expr1, expr2, expr3, expr4
     (expr1, expr2, expr3, expr4)
     {expr1: expr2, expr3: expr4}
     expr1 + expr2 * (expr3 - expr4)
     expr1(expr2, expr3, *expr4, **expr5)
     expr3, expr4 = expr1, expr2


File: python.info,  Node: Operator precedence,  Prev: Evaluation order,  Up: Expressions

4.6.16 Operator precedence
--------------------------

The following table summarizes the operator precedence in Python, from
lowest precedence (least binding) to highest precedence (most binding).
Operators in the same box have the same precedence.  Unless the syntax
is explicitly given, operators are binary.  Operators in the same box
group left to right (except for exponentiation, which groups from right
to left).

Note that comparisons, membership tests, and identity tests, all have
the same precedence and have a left-to-right chaining feature as
described in the *note Comparisons: efc. section.

Operator                                            Description
                                                    
----------------------------------------------------------------------------------------------
                                                    
*note lambda: 894.                                  Lambda expression
                                                    
                                                    
*note if: a65. – *note else: bfa.                   Conditional expression
                                                    
                                                    
*note or: f07.                                      Boolean OR
                                                    
                                                    
*note and: f06.                                     Boolean AND
                                                    
                                                    
*note not: f08. ‘x’                                 Boolean NOT
                                                    
                                                    
*note in: 37d, *note not in: e20, *note is: dde,    Comparisons, including membership tests
*note is not: f03, ‘<’, ‘<=’, ‘>’, ‘>=’, ‘!=’,      and identity tests
‘==’                                                

‘|’                                                 Bitwise OR
                                                    
                                                    
‘^’                                                 Bitwise XOR
                                                    
                                                    
‘&’                                                 Bitwise AND
                                                    
                                                    
‘<<’, ‘>>’                                          Shifts
                                                    
                                                    
‘+’, ‘-’                                            Addition and subtraction
                                                    
                                                    
‘*’, ‘@’, ‘/’, ‘//’, ‘%’                            Multiplication, matrix multiplication
                                                    division, remainder (1)
                                                    
                                                    
‘+x’, ‘-x’, ‘~x’                                    Positive, negative, bitwise NOT
                                                    
                                                    
‘**’                                                Exponentiation (2)
                                                    
                                                    
‘await’ ‘x’                                         Await expression
                                                    
                                                    
‘x[index]’, ‘x[index:index]’, ‘x(arguments...)’,    Subscription, slicing, call, attribute
‘x.attribute’                                       reference
                                                    
                                                    
‘(expressions...)’, ‘[expressions...]’, ‘{key:      Binding or tuple display, list display,
value...}’, ‘{expressions...}’                      dictionary display, set display
                                                    

   ---------- Footnotes ----------

   (1) The ‘%’ operator is also used for string formatting; the same
precedence applies.

   (2) The power operator ‘**’ binds less tightly than an arithmetic or
bitwise unary operator on its right, that is, ‘2**-1’ is ‘0.5’.


File: python.info,  Node: Simple statements,  Next: Compound statements,  Prev: Expressions,  Up: The Python Language Reference

4.7 Simple statements
=====================

A simple statement is comprised within a single logical line.  Several
simple statements may occur on a single line separated by semicolons.
The syntax for simple statements is:

     simple_stmt ::= expression_stmt
                     | assert_stmt
                     | assignment_stmt
                     | augmented_assignment_stmt
                     | pass_stmt
                     | del_stmt
                     | return_stmt
                     | yield_stmt
                     | raise_stmt
                     | break_stmt
                     | continue_stmt
                     | import_stmt
                     | global_stmt
                     | nonlocal_stmt

* Menu:

* Expression statements:: 
* Assignment statements:: 
* The assert statement:: 
* The pass statement:: 
* The del statement: The del statement<2>. 
* The return statement:: 
* The yield statement:: 
* The raise statement:: 
* The break statement:: 
* The continue statement:: 
* The import statement:: 
* The global statement:: 
* The nonlocal statement:: 


File: python.info,  Node: Expression statements,  Next: Assignment statements,  Up: Simple statements

4.7.1 Expression statements
---------------------------

Expression statements are used (mostly interactively) to compute and
write a value, or (usually) to call a procedure (a function that returns
no meaningful result; in Python, procedures return the value ‘None’).
Other uses of expression statements are allowed and occasionally useful.
The syntax for an expression statement is:

     expression_stmt ::= expression_list

An expression statement evaluates the expression list (which may be a
single expression).

In interactive mode, if the value is not ‘None’, it is converted to a
string using the built-in *note repr(): 3bb. function and the resulting
string is written to standard output on a line by itself (except if the
result is ‘None’, so that procedure calls do not cause any output.)


File: python.info,  Node: Assignment statements,  Next: The assert statement,  Prev: Expression statements,  Up: Simple statements

4.7.2 Assignment statements
---------------------------

Assignment statements are used to (re)bind names to values and to modify
attributes or items of mutable objects:

     assignment_stmt ::= (target_list "=")+ (expression_list | yield_expression)
     target_list     ::= target ("," target)* [","]
     target          ::= identifier
                         | "(" target_list ")"
                         | "[" target_list "]"
                         | attributeref
                         | subscription
                         | slicing
                         | "*" target

(See section *note Primaries: ecc. for the syntax definitions for
`attributeref', `subscription', and `slicing'.)

An assignment statement evaluates the expression list (remember that
this can be a single expression or a comma-separated list, the latter
yielding a tuple) and assigns the single resulting object to each of the
target lists, from left to right.

Assignment is defined recursively depending on the form of the target
(list).  When a target is part of a mutable object (an attribute
reference, subscription or slicing), the mutable object must ultimately
perform the assignment and decide about its validity, and may raise an
exception if the assignment is unacceptable.  The rules observed by
various types and the exceptions raised are given with the definition of
the object types (see section *note The standard type hierarchy: de0.).

Assignment of an object to a target list, optionally enclosed in
parentheses or square brackets, is recursively defined as follows.

   * If the target list is a single target: The object is assigned to
     that target.

   * If the target list is a comma-separated list of targets: The object
     must be an iterable with the same number of items as there are
     targets in the target list, and the items are assigned, from left
     to right, to the corresponding targets.

        * If the target list contains one target prefixed with an
          asterisk, called a "starred" target: The object must be a
          sequence with at least as many items as there are targets in
          the target list, minus one.  The first items of the sequence
          are assigned, from left to right, to the targets before the
          starred target.  The final items of the sequence are assigned
          to the targets after the starred target.  A list of the
          remaining items in the sequence is then assigned to the
          starred target (the list can be empty).

        * Else: The object must be a sequence with the same number of
          items as there are targets in the target list, and the items
          are assigned, from left to right, to the corresponding
          targets.

Assignment of an object to a single target is recursively defined as
follows.

   * If the target is an identifier (name):

        * If the name does not occur in a *note global: c0b. or *note
          nonlocal: 8a6. statement in the current code block: the name
          is bound to the object in the current local namespace.

        * Otherwise: the name is bound to the object in the global
          namespace or the outer namespace determined by *note nonlocal:
          8a6, respectively.

     The name is rebound if it was already bound.  This may cause the
     reference count for the object previously bound to the name to
     reach zero, causing the object to be deallocated and its destructor
     (if it has one) to be called.

   * If the target is a target list enclosed in parentheses or in square
     brackets: The object must be an iterable with the same number of
     items as there are targets in the target list, and its items are
     assigned, from left to right, to the corresponding targets.

   * If the target is an attribute reference: The primary expression in
     the reference is evaluated.  It should yield an object with
     assignable attributes; if this is not the case, *note TypeError:
     562. is raised.  That object is then asked to assign the assigned
     object to the given attribute; if it cannot perform the assignment,
     it raises an exception (usually but not necessarily *note
     AttributeError: 356.).  Note: If the object is a class instance and
     the attribute reference occurs on both sides of the assignment
     operator, the RHS expression, ‘a.x’ can access either an instance
     attribute or (if no instance attribute exists) a class attribute.
     The LHS target ‘a.x’ is always set as an instance attribute,
     creating it if necessary.  Thus, the two occurrences of ‘a.x’ do
     not necessarily refer to the same attribute: if the RHS expression
     refers to a class attribute, the LHS creates a new instance
     attribute as the target of the assignment:

          class Cls:
              x = 3             # class variable
          inst = Cls()
          inst.x = inst.x + 1   # writes inst.x as 4 leaving Cls.x as 3

     This description does not necessarily apply to descriptor
     attributes, such as properties created with *note property(): 377.

   * If the target is a subscription: The primary expression in the
     reference is evaluated.  It should yield either a mutable sequence
     object (such as a list) or a mapping object (such as a dictionary).
     Next, the subscript expression is evaluated.

     If the primary is a mutable sequence object (such as a list), the
     subscript must yield an integer.  If it is negative, the sequence’s
     length is added to it.  The resulting value must be a nonnegative
     integer less than the sequence’s length, and the sequence is asked
     to assign the assigned object to its item with that index.  If the
     index is out of range, *note IndexError: afb. is raised (assignment
     to a subscripted sequence cannot add new items to a list).

     If the primary is a mapping object (such as a dictionary), the
     subscript must have a type compatible with the mapping’s key type,
     and the mapping is then asked to create a key/datum pair which maps
     the subscript to the assigned object.  This can either replace an
     existing key/value pair with the same key value, or insert a new
     key/value pair (if no key with the same value existed).

     For user-defined objects, the *note __setitem__(): 8cd. method is
     called with appropriate arguments.

   * If the target is a slicing: The primary expression in the reference
     is evaluated.  It should yield a mutable sequence object (such as a
     list).  The assigned object should be a sequence object of the same
     type.  Next, the lower and upper bound expressions are evaluated,
     insofar they are present; defaults are zero and the sequence’s
     length.  The bounds should evaluate to integers.  If either bound
     is negative, the sequence’s length is added to it.  The resulting
     bounds are clipped to lie between zero and the sequence’s length,
     inclusive.  Finally, the sequence object is asked to replace the
     slice with the items of the assigned sequence.  The length of the
     slice may be different from the length of the assigned sequence,
     thus changing the length of the target sequence, if the target
     sequence allows it.

`CPython implementation detail:' In the current implementation, the
syntax for targets is taken to be the same as for expressions, and
invalid syntax is rejected during the code generation phase, causing
less detailed error messages.

Although the definition of assignment implies that overlaps between the
left-hand side and the right-hand side are ’simultanenous’ (for example
‘a, b = b, a’ swaps two variables), overlaps `within' the collection of
assigned-to variables occur left-to-right, sometimes resulting in
confusion.  For instance, the following program prints ‘[0, 2]’:

     x = [0, 1]
     i = 0
     i, x[i] = 1, 2         # i is updated, then x[i] is updated
     print(x)

See also
........

PEP 3132(1) - Extended Iterable Unpacking

     The specification for the ‘*target’ feature.

* Menu:

* Augmented assignment statements:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3132


File: python.info,  Node: Augmented assignment statements,  Up: Assignment statements

4.7.2.1 Augmented assignment statements
.......................................

Augmented assignment is the combination, in a single statement, of a
binary operation and an assignment statement:

     augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)
     augtarget                 ::= identifier | attributeref | subscription | slicing
     augop                     ::= "+=" | "-=" | "*=" | "@=" | "/=" | "//=" | "%=" | "**="
                                   | ">>=" | "<<=" | "&=" | "^=" | "|="

(See section *note Primaries: ecc. for the syntax definitions of the
last three symbols.)

An augmented assignment evaluates the target (which, unlike normal
assignment statements, cannot be an unpacking) and the expression list,
performs the binary operation specific to the type of assignment on the
two operands, and assigns the result to the original target.  The target
is only evaluated once.

An augmented assignment expression like ‘x += 1’ can be rewritten as ‘x
= x + 1’ to achieve a similar, but not exactly equal effect.  In the
augmented version, ‘x’ is only evaluated once.  Also, when possible, the
actual operation is performed `in-place', meaning that rather than
creating a new object and assigning that to the target, the old object
is modified instead.

Unlike normal assignments, augmented assignments evaluate the left-hand
side `before' evaluating the right-hand side.  For example, ‘a[i] +=
f(x)’ first looks-up ‘a[i]’, then it evaluates ‘f(x)’ and performs the
addition, and lastly, it writes the result back to ‘a[i]’.

With the exception of assigning to tuples and multiple targets in a
single statement, the assignment done by augmented assignment statements
is handled the same way as normal assignments.  Similarly, with the
exception of the possible `in-place' behavior, the binary operation
performed by augmented assignment is the same as the normal binary
operations.

For targets which are attribute references, the same *note caveat about
class and instance attributes: f27. applies as for regular assignments.


File: python.info,  Node: The assert statement,  Next: The pass statement,  Prev: Assignment statements,  Up: Simple statements

4.7.3 The ‘assert’ statement
----------------------------

Assert statements are a convenient way to insert debugging assertions
into a program:

     assert_stmt ::= "assert" expression ["," expression]

The simple form, ‘assert expression’, is equivalent to

     if __debug__:
        if not expression: raise AssertionError

The extended form, ‘assert expression1, expression2’, is equivalent to

     if __debug__:
        if not expression1: raise AssertionError(expression2)

These equivalences assume that *note __debug__: f2f. and *note
AssertionError: f30. refer to the built-in variables with those names.
In the current implementation, the built-in variable *note __debug__:
f2f. is ‘True’ under normal circumstances, ‘False’ when optimization is
requested (command line option -O). The current code generator emits no
code for an assert statement when optimization is requested at compile
time.  Note that it is unnecessary to include the source code for the
expression that failed in the error message; it will be displayed as
part of the stack trace.

Assignments to *note __debug__: f2f. are illegal.  The value for the
built-in variable is determined when the interpreter starts.


File: python.info,  Node: The pass statement,  Next: The del statement<2>,  Prev: The assert statement,  Up: Simple statements

4.7.4 The ‘pass’ statement
--------------------------

     pass_stmt ::= "pass"

*note pass: c07. is a null operation — when it is executed, nothing
happens.  It is useful as a placeholder when a statement is required
syntactically, but no code needs to be executed, for example:

     def f(arg): pass    # a function that does nothing (yet)

     class C: pass       # a class with no methods (yet)


File: python.info,  Node: The del statement<2>,  Next: The return statement,  Prev: The pass statement,  Up: Simple statements

4.7.5 The ‘del’ statement
-------------------------

     del_stmt ::= "del" target_list

Deletion is recursively defined very similar to the way assignment is
defined.  Rather than spelling it out in full details, here are some
hints.

Deletion of a target list recursively deletes each target, from left to
right.

Deletion of a name removes the binding of that name from the local or
global namespace, depending on whether the name occurs in a *note
global: c0b. statement in the same code block.  If the name is unbound,
a *note NameError: 9f2. exception will be raised.

Deletion of attribute references, subscriptions and slicings is passed
to the primary object involved; deletion of a slicing is in general
equivalent to assignment of an empty slice of the right type (but even
this is determined by the sliced object).

Changed in version 3.2: Previously it was illegal to delete a name from
the local namespace if it occurs as a free variable in a nested block.


File: python.info,  Node: The return statement,  Next: The yield statement,  Prev: The del statement<2>,  Up: Simple statements

4.7.6 The ‘return’ statement
----------------------------

     return_stmt ::= "return" [expression_list]

*note return: 981. may only occur syntactically nested in a function
definition, not within a nested class definition.

If an expression list is present, it is evaluated, else ‘None’ is
substituted.

*note return: 981. leaves the current function call with the expression
list (or ‘None’) as return value.

When *note return: 981. passes control out of a *note try: 9e9.
statement with a *note finally: 526. clause, that *note finally: 526.
clause is executed before really leaving the function.

In a generator function, the *note return: 981. statement indicates that
the generator is done and will cause *note StopIteration: 191. to be
raised.  The returned value (if any) is used as an argument to construct
*note StopIteration: 191. and becomes the ‘StopIteration.value’
attribute.


File: python.info,  Node: The yield statement,  Next: The raise statement,  Prev: The return statement,  Up: Simple statements

4.7.7 The ‘yield’ statement
---------------------------

     yield_stmt ::= yield_expression

A *note yield: 480. statement is semantically equivalent to a *note
yield expression: ec6.  The yield statement can be used to omit the
parentheses that would otherwise be required in the equivalent yield
expression statement.  For example, the yield statements

     yield <expr>
     yield from <expr>

are equivalent to the yield expression statements

     (yield <expr>)
     (yield from <expr>)

Yield expressions and statements are only used when defining a *note
generator: 5c0. function, and are only used in the body of the generator
function.  Using yield in a function definition is sufficient to cause
that definition to create a generator function instead of a normal
function.

For full details of *note yield: 480. semantics, refer to the *note
Yield expressions: ec6. section.


File: python.info,  Node: The raise statement,  Next: The break statement,  Prev: The yield statement,  Up: Simple statements

4.7.8 The ‘raise’ statement
---------------------------

     raise_stmt ::= "raise" [expression ["from" expression]]

If no expressions are present, *note raise: 8a9. re-raises the last
exception that was active in the current scope.  If no exception is
active in the current scope, a *note RuntimeError: 193. exception is
raised indicating that this is an error.

Otherwise, *note raise: 8a9. evaluates the first expression as the
exception object.  It must be either a subclass or an instance of *note
BaseException: 8c9.  If it is a class, the exception instance will be
obtained when needed by instantiating the class with no arguments.

The `type' of the exception is the exception instance’s class, the
`value' is the instance itself.

A traceback object is normally created automatically when an exception
is raised and attached to it as the ‘__traceback__’ attribute, which is
writable.  You can create an exception and set your own traceback in one
step using the ‘with_traceback()’ exception method (which returns the
same exception instance, with its traceback set to its argument), like
so:

     raise Exception("foo occurred").with_traceback(tracebackobj)

The ‘from’ clause is used for exception chaining: if given, the second
`expression' must be another exception class or instance, which will
then be attached to the raised exception as the ‘__cause__’ attribute
(which is writable).  If the raised exception is not handled, both
exceptions will be printed:

     >>> try:
     ...     print(1 / 0)
     ... except Exception as exc:
     ...     raise RuntimeError("Something bad happened") from exc
     ...
     Traceback (most recent call last):
       File "<stdin>", line 2, in <module>
     ZeroDivisionError: int division or modulo by zero

     The above exception was the direct cause of the following exception:

     Traceback (most recent call last):
       File "<stdin>", line 4, in <module>
     RuntimeError: Something bad happened

A similar mechanism works implicitly if an exception is raised inside an
exception handler or a *note finally: 526. clause: the previous
exception is then attached as the new exception’s ‘__context__’
attribute:

     >>> try:
     ...     print(1 / 0)
     ... except:
     ...     raise RuntimeError("Something bad happened")
     ...
     Traceback (most recent call last):
       File "<stdin>", line 2, in <module>
     ZeroDivisionError: int division or modulo by zero

     During handling of the above exception, another exception occurred:

     Traceback (most recent call last):
       File "<stdin>", line 4, in <module>
     RuntimeError: Something bad happened

Additional information on exceptions can be found in section *note
Exceptions: e6f, and information about handling exceptions is in section
*note The try statement: 9e9.


File: python.info,  Node: The break statement,  Next: The continue statement,  Prev: The raise statement,  Up: Simple statements

4.7.9 The ‘break’ statement
---------------------------

     break_stmt ::= "break"

*note break: c02. may only occur syntactically nested in a *note for:
895. or *note while: bf3. loop, but not nested in a function or class
definition within that loop.

It terminates the nearest enclosing loop, skipping the optional *note
else: bfa. clause if the loop has one.

If a *note for: 895. loop is terminated by *note break: c02, the loop
control target keeps its current value.

When *note break: c02. passes control out of a *note try: 9e9. statement
with a *note finally: 526. clause, that *note finally: 526. clause is
executed before really leaving the loop.


File: python.info,  Node: The continue statement,  Next: The import statement,  Prev: The break statement,  Up: Simple statements

4.7.10 The ‘continue’ statement
-------------------------------

     continue_stmt ::= "continue"

*note continue: c04. may only occur syntactically nested in a *note for:
895. or *note while: bf3. loop, but not nested in a function or class
definition or *note finally: 526. clause within that loop.  It continues
with the next cycle of the nearest enclosing loop.

When *note continue: c04. passes control out of a *note try: 9e9.
statement with a *note finally: 526. clause, that *note finally: 526.
clause is executed before really starting the next loop cycle.


File: python.info,  Node: The import statement,  Next: The global statement,  Prev: The continue statement,  Up: Simple statements

4.7.11 The ‘import’ statement
-----------------------------

     import_stmt     ::= "import" module ["as" name] ( "," module ["as" name] )*
                         | "from" relative_module "import" identifier ["as" name]
                         ( "," identifier ["as" name] )*
                         | "from" relative_module "import" "(" identifier ["as" name]
                         ( "," identifier ["as" name] )* [","] ")"
                         | "from" module "import" "*"
     module          ::= (identifier ".")* identifier
     relative_module ::= "."* module | "."+
     name            ::= identifier

The basic import statement (no *note from: 8ad. clause) is executed in
two steps:

  1. find a module, loading and initializing it if necessary

  2. define a name or names in the local namespace for the scope where
     the *note import: 881. statement occurs.

When the statement contains multiple clauses (separated by commas) the
two steps are carried out separately for each clause, just as though the
clauses had been separated out into individiual import statements.

The details of the first step, finding and loading modules are described
in greater detail in the section on the *note import system: def, which
also describes the various types of packages and modules that can be
imported, as well as all the hooks that can be used to customize the
import system.  Note that failures in this step may indicate either that
the module could not be located, `or' that an error occurred while
initializing the module, which includes execution of the module’s code.

If the requested module is retrieved successfully, it will be made
available in the local namespace in one of three ways:

   * If the module name is followed by *note as: 8aa, then the name
     following *note as: 8aa. is bound directly to the imported module.

   * If no other name is specified, and the module being imported is a
     top level module, the module’s name is bound in the local namespace
     as a reference to the imported module

   * If the module being imported is `not' a top level module, then the
     name of the top level package that contains the module is bound in
     the local namespace as a reference to the top level package.  The
     imported module must be accessed using its full qualified name
     rather than directly

The *note from: 8ad. form uses a slightly more complex process:

  1. find the module specified in the *note from: 8ad. clause, loading
     and initializing it if necessary;

  2. for each of the identifiers specified in the *note import: 881.
     clauses:

       1. check if the imported module has an attribute by that name

       2. if not, attempt to import a submodule with that name and then
          check the imported module again for that attribute

       3. if the attribute is not found, *note ImportError: 19f. is
          raised.

       4. otherwise, a reference to that value is stored in the local
          namespace, using the name in the *note as: 8aa. clause if it
          is present, otherwise using the attribute name

Examples:

     import foo                 # foo imported and bound locally
     import foo.bar.baz         # foo.bar.baz imported, foo bound locally
     import foo.bar.baz as fbb  # foo.bar.baz imported and bound as fbb
     from foo.bar import baz    # foo.bar.baz imported and bound as baz
     from foo import attr       # foo imported and foo.attr bound as attr

If the list of identifiers is replaced by a star (‘'*'’), all public
names defined in the module are bound in the local namespace for the
scope where the *note import: 881. statement occurs.

The `public names' defined by a module are determined by checking the
module’s namespace for a variable named ‘__all__’; if defined, it must
be a sequence of strings which are names defined or imported by that
module.  The names given in ‘__all__’ are all considered public and are
required to exist.  If ‘__all__’ is not defined, the set of public names
includes all names found in the module’s namespace which do not begin
with an underscore character (‘'_'’).  ‘__all__’ should contain the
entire public API. It is intended to avoid accidentally exporting items
that are not part of the API (such as library modules which were
imported and used within the module).

The wild card form of import — ‘from module import *’ — is only allowed
at the module level.  Attempting to use it in class or function
definitions will raise a *note SyntaxError: 3a6.

When specifying what module to import you do not have to specify the
absolute name of the module.  When a module or package is contained
within another package it is possible to make a relative import within
the same top package without having to mention the package name.  By
using leading dots in the specified module or package after *note from:
8ad. you can specify how high to traverse up the current package
hierarchy without specifying exact names.  One leading dot means the
current package where the module making the import exists.  Two dots
means up one package level.  Three dots is up two levels, etc.  So if
you execute ‘from . import mod’ from a module in the ‘pkg’ package then
you will end up importing ‘pkg.mod’.  If you execute ‘from ..subpkg2
import mod’ from within ‘pkg.subpkg1’ you will import ‘pkg.subpkg2.mod’.
The specification for relative imports is contained within PEP 328(1).

*note importlib.import_module(): 754. is provided to support
applications that determine dynamically the modules to be loaded.

* Menu:

* Future statements:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0328

