This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: Mocking Unbound Methods,  Next: Checking multiple calls with mock,  Prev: Applying the same patch to every test method,  Up: Further Examples

5.26.6.17 Mocking Unbound Methods
.................................

Whilst writing tests today I needed to patch an `unbound method'
(patching the method on the class rather than on the instance).  I
needed self to be passed in as the first argument because I want to make
asserts about which objects were calling this particular method.  The
issue is that you can’t patch with a mock for this, because if you
replace an unbound method with a mock it doesn’t become a bound method
when fetched from the instance, and so it doesn’t get self passed in.
The workaround is to patch the unbound method with a real function
instead.  The *note patch(): 35b. decorator makes it so simple to patch
out methods with a mock that having to create a real function becomes a
nuisance.

If you pass ‘autospec=True’ to patch then it does the patching with a
`real' function object.  This function object has the same signature as
the one it is replacing, but delegates to a mock under the hood.  You
still get your mock auto-created in exactly the same way as before.
What it means though, is that if you use it to patch out an unbound
method on a class the mocked function will be turned into a bound method
if it is fetched from an instance.  It will have ‘self’ passed in as the
first argument, which is exactly what I wanted:

     >>> class Foo:
     ...   def foo(self):
     ...     pass
     ...
     >>> with patch.object(Foo, 'foo', autospec=True) as mock_foo:
     ...   mock_foo.return_value = 'foo'
     ...   foo = Foo()
     ...   foo.foo()
     ...
     'foo'
     >>> mock_foo.assert_called_once_with(foo)

If we don’t use ‘autospec=True’ then the unbound method is patched out
with a Mock instance instead, and isn’t called with ‘self’.


File: python.info,  Node: Checking multiple calls with mock,  Next: Coping with mutable arguments,  Prev: Mocking Unbound Methods,  Up: Further Examples

5.26.6.18 Checking multiple calls with mock
...........................................

mock has a nice API for making assertions about how your mock objects
are used.

     >>> mock = Mock()
     >>> mock.foo_bar.return_value = None
     >>> mock.foo_bar('baz', spam='eggs')
     >>> mock.foo_bar.assert_called_with('baz', spam='eggs')

If your mock is only being called once you can use the
‘assert_called_once_with()’ method that also asserts that the
‘call_count’ is one.

     >>> mock.foo_bar.assert_called_once_with('baz', spam='eggs')
     >>> mock.foo_bar()
     >>> mock.foo_bar.assert_called_once_with('baz', spam='eggs')
     Traceback (most recent call last):
         ...
     AssertionError: Expected to be called once. Called 2 times.

Both ‘assert_called_with’ and ‘assert_called_once_with’ make assertions
about the `most recent' call.  If your mock is going to be called
several times, and you want to make assertions about `all' those calls
you can use *note call_args_list: 2c20.:

     >>> mock = Mock(return_value=None)
     >>> mock(1, 2, 3)
     >>> mock(4, 5, 6)
     >>> mock()
     >>> mock.call_args_list
     [call(1, 2, 3), call(4, 5, 6), call()]

The *note call: 2c21. helper makes it easy to make assertions about
these calls.  You can build up a list of expected calls and compare it
to ‘call_args_list’.  This looks remarkably similar to the repr of the
‘call_args_list’:

     >>> expected = [call(1, 2, 3), call(4, 5, 6), call()]
     >>> mock.call_args_list == expected
     True


File: python.info,  Node: Coping with mutable arguments,  Next: Nesting Patches,  Prev: Checking multiple calls with mock,  Up: Further Examples

5.26.6.19 Coping with mutable arguments
.......................................

Another situation is rare, but can bite you, is when your mock is called
with mutable arguments.  ‘call_args’ and ‘call_args_list’ store
`references' to the arguments.  If the arguments are mutated by the code
under test then you can no longer make assertions about what the values
were when the mock was called.

Here’s some example code that shows the problem.  Imagine the following
functions defined in ’mymodule’:

     def frob(val):
         pass

     def grob(val):
         "First frob and then clear val"
         frob(val)
         val.clear()

When we try to test that ‘grob’ calls ‘frob’ with the correct argument
look what happens:

     >>> with patch('mymodule.frob') as mock_frob:
     ...     val = {6}
     ...     mymodule.grob(val)
     ...
     >>> val
     set()
     >>> mock_frob.assert_called_with({6})
     Traceback (most recent call last):
         ...
     AssertionError: Expected: (({6},), {})
     Called with: ((set(),), {})

One possibility would be for mock to copy the arguments you pass in.
This could then cause problems if you do assertions that rely on object
identity for equality.

Here’s one solution that uses the ‘side_effect’ functionality.  If you
provide a ‘side_effect’ function for a mock then ‘side_effect’ will be
called with the same args as the mock.  This gives us an opportunity to
copy the arguments and store them for later assertions.  In this example
I’m using `another' mock to store the arguments so that I can use the
mock methods for doing the assertion.  Again a helper function sets this
up for me.

     >>> from copy import deepcopy
     >>> from unittest.mock import Mock, patch, DEFAULT
     >>> def copy_call_args(mock):
     ...     new_mock = Mock()
     ...     def side_effect(*args, **kwargs):
     ...         args = deepcopy(args)
     ...         kwargs = deepcopy(kwargs)
     ...         new_mock(*args, **kwargs)
     ...         return DEFAULT
     ...     mock.side_effect = side_effect
     ...     return new_mock
     ...
     >>> with patch('mymodule.frob') as mock_frob:
     ...     new_mock = copy_call_args(mock_frob)
     ...     val = {6}
     ...     mymodule.grob(val)
     ...
     >>> new_mock.assert_called_with({6})
     >>> new_mock.call_args
     call({6})

‘copy_call_args’ is called with the mock that will be called.  It
returns a new mock that we do the assertion on.  The ‘side_effect’
function makes a copy of the args and calls our ‘new_mock’ with the
copy.

     Note: If your mock is only going to be used once there is an easier
     way of checking arguments at the point they are called.  You can
     simply do the checking inside a ‘side_effect’ function.

          >>> def side_effect(arg):
          ...     assert arg == {6}
          ...
          >>> mock = Mock(side_effect=side_effect)
          >>> mock({6})
          >>> mock(set())
          Traceback (most recent call last):
              ...
          AssertionError

An alternative approach is to create a subclass of *note Mock: 172. or
*note MagicMock: 358. that copies (using *note copy.deepcopy(): 90e.)
the arguments.  Here’s an example implementation:

     >>> from copy import deepcopy
     >>> class CopyingMock(MagicMock):
     ...     def __call__(self, *args, **kwargs):
     ...         args = deepcopy(args)
     ...         kwargs = deepcopy(kwargs)
     ...         return super(CopyingMock, self).__call__(*args, **kwargs)
     ...
     >>> c = CopyingMock(return_value=None)
     >>> arg = set()
     >>> c(arg)
     >>> arg.add(1)
     >>> c.assert_called_with(set())
     >>> c.assert_called_with(arg)
     Traceback (most recent call last):
         ...
     AssertionError: Expected call: mock({1})
     Actual call: mock(set())
     >>> c.foo
     <CopyingMock name='mock.foo' id='...'>

When you subclass ‘Mock’ or ‘MagicMock’ all dynamically created
attributes, and the ‘return_value’ will use your subclass automatically.
That means all children of a ‘CopyingMock’ will also have the type
‘CopyingMock’.


File: python.info,  Node: Nesting Patches,  Next: Mocking a dictionary with MagicMock,  Prev: Coping with mutable arguments,  Up: Further Examples

5.26.6.20 Nesting Patches
.........................

Using patch as a context manager is nice, but if you do multiple patches
you can end up with nested with statements indenting further and further
to the right:

     >>> class MyTest(TestCase):
     ...
     ...     def test_foo(self):
     ...         with patch('mymodule.Foo') as mock_foo:
     ...             with patch('mymodule.Bar') as mock_bar:
     ...                 with patch('mymodule.Spam') as mock_spam:
     ...                     assert mymodule.Foo is mock_foo
     ...                     assert mymodule.Bar is mock_bar
     ...                     assert mymodule.Spam is mock_spam
     ...
     >>> original = mymodule.Foo
     >>> MyTest('test_foo').test_foo()
     >>> assert mymodule.Foo is original

With unittest ‘cleanup’ functions and the *note patch methods; start and
stop: 2c32. we can achieve the same effect without the nested
indentation.  A simple helper method, ‘create_patch’, puts the patch in
place and returns the created mock for us:

     >>> class MyTest(TestCase):
     ...
     ...     def create_patch(self, name):
     ...         patcher = patch(name)
     ...         thing = patcher.start()
     ...         self.addCleanup(patcher.stop)
     ...         return thing
     ...
     ...     def test_foo(self):
     ...         mock_foo = self.create_patch('mymodule.Foo')
     ...         mock_bar = self.create_patch('mymodule.Bar')
     ...         mock_spam = self.create_patch('mymodule.Spam')
     ...
     ...         assert mymodule.Foo is mock_foo
     ...         assert mymodule.Bar is mock_bar
     ...         assert mymodule.Spam is mock_spam
     ...
     >>> original = mymodule.Foo
     >>> MyTest('test_foo').run()
     >>> assert mymodule.Foo is original


File: python.info,  Node: Mocking a dictionary with MagicMock,  Next: Mock subclasses and their attributes,  Prev: Nesting Patches,  Up: Further Examples

5.26.6.21 Mocking a dictionary with MagicMock
.............................................

You may want to mock a dictionary, or other container object, recording
all access to it whilst having it still behave like a dictionary.

We can do this with *note MagicMock: 358, which will behave like a
dictionary, and using *note side_effect: 2c0d. to delegate dictionary
access to a real underlying dictionary that is under our control.

When the *note __getitem__(): a84. and *note __setitem__(): 8cd. methods
of our ‘MagicMock’ are called (normal dictionary access) then
‘side_effect’ is called with the key (and in the case of ‘__setitem__’
the value too).  We can also control what is returned.

After the ‘MagicMock’ has been used we can use attributes like *note
call_args_list: 2c20. to assert about how the dictionary was used:

     >>> my_dict = {'a': 1, 'b': 2, 'c': 3}
     >>> def getitem(name):
     ...      return my_dict[name]
     ...
     >>> def setitem(name, val):
     ...     my_dict[name] = val
     ...
     >>> mock = MagicMock()
     >>> mock.__getitem__.side_effect = getitem
     >>> mock.__setitem__.side_effect = setitem

     Note: An alternative to using ‘MagicMock’ is to use ‘Mock’ and
     `only' provide the magic methods you specifically want:

          >>> mock = Mock()
          >>> mock.__getitem__ = Mock(side_effect=getitem)
          >>> mock.__setitem__ = Mock(side_effect=setitem)

     A `third' option is to use ‘MagicMock’ but passing in ‘dict’ as the
     `spec' (or `spec_set') argument so that the ‘MagicMock’ created
     only has dictionary magic methods available:

          >>> mock = MagicMock(spec_set=dict)
          >>> mock.__getitem__.side_effect = getitem
          >>> mock.__setitem__.side_effect = setitem

With these side effect functions in place, the ‘mock’ will behave like a
normal dictionary but recording the access.  It even raises a *note
KeyError: 1a7. if you try to access a key that doesn’t exist.

     >>> mock['a']
     1
     >>> mock['c']
     3
     >>> mock['d']
     Traceback (most recent call last):
         ...
     KeyError: 'd'
     >>> mock['b'] = 'fish'
     >>> mock['d'] = 'eggs'
     >>> mock['b']
     'fish'
     >>> mock['d']
     'eggs'

After it has been used you can make assertions about the access using
the normal mock methods and attributes:

     >>> mock.__getitem__.call_args_list
     [call('a'), call('c'), call('d'), call('b'), call('d')]
     >>> mock.__setitem__.call_args_list
     [call('b', 'fish'), call('d', 'eggs')]
     >>> my_dict
     {'a': 1, 'c': 3, 'b': 'fish', 'd': 'eggs'}


File: python.info,  Node: Mock subclasses and their attributes,  Next: Mocking imports with patch dict,  Prev: Mocking a dictionary with MagicMock,  Up: Further Examples

5.26.6.22 Mock subclasses and their attributes
..............................................

There are various reasons why you might want to subclass *note Mock:
172.  One reason might be to add helper methods.  Here’s a silly
example:

     >>> class MyMock(MagicMock):
     ...     def has_been_called(self):
     ...         return self.called
     ...
     >>> mymock = MyMock(return_value=None)
     >>> mymock
     <MyMock id='...'>
     >>> mymock.has_been_called()
     False
     >>> mymock()
     >>> mymock.has_been_called()
     True

The standard behaviour for ‘Mock’ instances is that attributes and the
return value mocks are of the same type as the mock they are accessed
on.  This ensures that ‘Mock’ attributes are ‘Mocks’ and ‘MagicMock’
attributes are ‘MagicMocks’ (1).  So if you’re subclassing to add helper
methods then they’ll also be available on the attributes and return
value mock of instances of your subclass.

     >>> mymock.foo
     <MyMock name='mock.foo' id='...'>
     >>> mymock.foo.has_been_called()
     False
     >>> mymock.foo()
     <MyMock name='mock.foo()' id='...'>
     >>> mymock.foo.has_been_called()
     True

Sometimes this is inconvenient.  For example, one user(2) is subclassing
mock to created a Twisted adaptor(3).  Having this applied to attributes
too actually causes errors.

‘Mock’ (in all its flavours) uses a method called ‘_get_child_mock’ to
create these "sub-mocks" for attributes and return values.  You can
prevent your subclass being used for attributes by overriding this
method.  The signature is that it takes arbitrary keyword arguments
(‘**kwargs’) which are then passed onto the mock constructor:

     >>> class Subclass(MagicMock):
     ...     def _get_child_mock(self, **kwargs):
     ...         return MagicMock(**kwargs)
     ...
     >>> mymock = Subclass()
     >>> mymock.foo
     <MagicMock name='mock.foo' id='...'>
     >>> assert isinstance(mymock, Subclass)
     >>> assert not isinstance(mymock.foo, Subclass)
     >>> assert not isinstance(mymock(), Subclass)

   ---------- Footnotes ----------

   (1) An exception to this rule are the non-callable mocks.  Attributes
use the callable variant because otherwise non-callable mocks couldn’t
have callable methods.

   (2) https://code.google.com/p/mock/issues/detail?id=105

   (3) 
http://twistedmatrix.com/documents/11.0.0/api/twisted.python.components.html


File: python.info,  Node: Mocking imports with patch dict,  Next: Tracking order of calls and less verbose call assertions,  Prev: Mock subclasses and their attributes,  Up: Further Examples

5.26.6.23 Mocking imports with patch.dict
.........................................

One situation where mocking can be hard is where you have a local import
inside a function.  These are harder to mock because they aren’t using
an object from the module namespace that we can patch out.

Generally local imports are to be avoided.  They are sometimes done to
prevent circular dependencies, for which there is `usually' a much
better way to solve the problem (refactor the code) or to prevent "up
front costs" by delaying the import.  This can also be solved in better
ways than an unconditional local import (store the module as a class or
module attribute and only do the import on first use).

That aside there is a way to use ‘mock’ to affect the results of an
import.  Importing fetches an `object' from the *note sys.modules: e75.
dictionary.  Note that it fetches an `object', which need not be a
module.  Importing a module for the first time results in a module
object being put in ‘sys.modules’, so usually when you import something
you get a module back.  This need not be the case however.

This means you can use *note patch.dict(): 2c06. to `temporarily' put a
mock in place in *note sys.modules: e75.  Any imports whilst this patch
is active will fetch the mock.  When the patch is complete (the
decorated function exits, the with statement body is complete or
‘patcher.stop()’ is called) then whatever was there previously will be
restored safely.

Here’s an example that mocks out the ’fooble’ module.

     >>> mock = Mock()
     >>> with patch.dict('sys.modules', {'fooble': mock}):
     ...    import fooble
     ...    fooble.blob()
     ...
     <Mock name='mock.blob()' id='...'>
     >>> assert 'fooble' not in sys.modules
     >>> mock.blob.assert_called_once_with()

As you can see the ‘import fooble’ succeeds, but on exit there is no
’fooble’ left in *note sys.modules: e75.

This also works for the ‘from module import name’ form:

     >>> mock = Mock()
     >>> with patch.dict('sys.modules', {'fooble': mock}):
     ...    from fooble import blob
     ...    blob.blip()
     ...
     <Mock name='mock.blob.blip()' id='...'>
     >>> mock.blob.blip.assert_called_once_with()

With slightly more work you can also mock package imports:

     >>> mock = Mock()
     >>> modules = {'package': mock, 'package.module': mock.module}
     >>> with patch.dict('sys.modules', modules):
     ...    from package.module import fooble
     ...    fooble()
     ...
     <Mock name='mock.module.fooble()' id='...'>
     >>> mock.module.fooble.assert_called_once_with()


File: python.info,  Node: Tracking order of calls and less verbose call assertions,  Next: More complex argument matching,  Prev: Mocking imports with patch dict,  Up: Further Examples

5.26.6.24 Tracking order of calls and less verbose call assertions
..................................................................

The *note Mock: 172. class allows you to track the `order' of method
calls on your mock objects through the *note method_calls: 2c19.
attribute.  This doesn’t allow you to track the order of calls between
separate mock objects, however we can use *note mock_calls: 2c15. to
achieve the same effect.

Because mocks track calls to child mocks in ‘mock_calls’, and accessing
an arbitrary attribute of a mock creates a child mock, we can create our
separate mocks from a parent one.  Calls to those child mock will then
all be recorded, in order, in the ‘mock_calls’ of the parent:

     >>> manager = Mock()
     >>> mock_foo = manager.foo
     >>> mock_bar = manager.bar

     >>> mock_foo.something()
     <Mock name='mock.foo.something()' id='...'>
     >>> mock_bar.other.thing()
     <Mock name='mock.bar.other.thing()' id='...'>

     >>> manager.mock_calls
     [call.foo.something(), call.bar.other.thing()]

We can then assert about the calls, including the order, by comparing
with the ‘mock_calls’ attribute on the manager mock:

     >>> expected_calls = [call.foo.something(), call.bar.other.thing()]
     >>> manager.mock_calls == expected_calls
     True

If ‘patch’ is creating, and putting in place, your mocks then you can
attach them to a manager mock using the *note attach_mock(): 2c18.
method.  After attaching calls will be recorded in ‘mock_calls’ of the
manager.

     >>> manager = MagicMock()
     >>> with patch('mymodule.Class1') as MockClass1:
     ...     with patch('mymodule.Class2') as MockClass2:
     ...         manager.attach_mock(MockClass1, 'MockClass1')
     ...         manager.attach_mock(MockClass2, 'MockClass2')
     ...         MockClass1().foo()
     ...         MockClass2().bar()
     ...
     <MagicMock name='mock.MockClass1().foo()' id='...'>
     <MagicMock name='mock.MockClass2().bar()' id='...'>
     >>> manager.mock_calls
     [call.MockClass1(),
      call.MockClass1().foo(),
      call.MockClass2(),
      call.MockClass2().bar()]

If many calls have been made, but you’re only interested in a particular
sequence of them then an alternative is to use the *note
assert_has_calls(): 2c14. method.  This takes a list of calls
(constructed with the *note call: 2c21. object).  If that sequence of
calls are in *note mock_calls: 2c15. then the assert succeeds.

     >>> m = MagicMock()
     >>> m().foo().bar().baz()
     <MagicMock name='mock().foo().bar().baz()' id='...'>
     >>> m.one().two().three()
     <MagicMock name='mock.one().two().three()' id='...'>
     >>> calls = call.one().two().three().call_list()
     >>> m.assert_has_calls(calls)

Even though the chained call ‘m.one().two().three()’ aren’t the only
calls that have been made to the mock, the assert still succeeds.

Sometimes a mock may have several calls made to it, and you are only
interested in asserting about `some' of those calls.  You may not even
care about the order.  In this case you can pass ‘any_order=True’ to
‘assert_has_calls’:

     >>> m = MagicMock()
     >>> m(1), m.two(2, 3), m.seven(7), m.fifty('50')
     (...)
     >>> calls = [call.fifty('50'), call(1), call.seven(7)]
     >>> m.assert_has_calls(calls, any_order=True)


File: python.info,  Node: More complex argument matching,  Prev: Tracking order of calls and less verbose call assertions,  Up: Further Examples

5.26.6.25 More complex argument matching
........................................

Using the same basic concept as *note ANY: 2c44. we can implement
matchers to do more complex assertions on objects used as arguments to
mocks.

Suppose we expect some object to be passed to a mock that by default
compares equal based on object identity (which is the Python default for
user defined classes).  To use *note assert_called_with(): 2c11. we
would need to pass in the exact same object.  If we are only interested
in some of the attributes of this object then we can create a matcher
that will check these attributes for us.

You can see in this example how a ’standard’ call to
‘assert_called_with’ isn’t sufficient:

     >>> class Foo:
     ...     def __init__(self, a, b):
     ...         self.a, self.b = a, b
     ...
     >>> mock = Mock(return_value=None)
     >>> mock(Foo(1, 2))
     >>> mock.assert_called_with(Foo(1, 2))
     Traceback (most recent call last):
         ...
     AssertionError: Expected: call(<__main__.Foo object at 0x...>)
     Actual call: call(<__main__.Foo object at 0x...>)

A comparison function for our ‘Foo’ class might look something like
this:

     >>> def compare(self, other):
     ...     if not type(self) == type(other):
     ...         return False
     ...     if self.a != other.a:
     ...         return False
     ...     if self.b != other.b:
     ...         return False
     ...     return True
     ...

And a matcher object that can use comparison functions like this for its
equality operation would look something like this:

     >>> class Matcher:
     ...     def __init__(self, compare, some_obj):
     ...         self.compare = compare
     ...         self.some_obj = some_obj
     ...     def __eq__(self, other):
     ...         return self.compare(self.some_obj, other)
     ...

Putting all this together:

     >>> match_foo = Matcher(compare, Foo(1, 2))
     >>> mock.assert_called_with(match_foo)

The ‘Matcher’ is instantiated with our compare function and the ‘Foo’
object we want to compare against.  In ‘assert_called_with’ the
‘Matcher’ equality method will be called, which compares the object the
mock was called with against the one we created our matcher with.  If
they match then ‘assert_called_with’ passes, and if they don’t an *note
AssertionError: f30. is raised:

     >>> match_wrong = Matcher(compare, Foo(3, 4))
     >>> mock.assert_called_with(match_wrong)
     Traceback (most recent call last):
         ...
     AssertionError: Expected: ((<Matcher object at 0x...>,), {})
     Called with: ((<Foo object at 0x...>,), {})

With a bit of tweaking you could have the comparison function raise the
*note AssertionError: f30. directly and provide a more useful failure
message.

As of version 1.5, the Python testing library PyHamcrest(1) provides
similar functionality, that may be useful here, in the form of its
equality matcher (hamcrest.library.integration.match_equality(2)).

   ---------- Footnotes ----------

   (1) https://pyhamcrest.readthedocs.org/

   (2) 
https://pyhamcrest.readthedocs.org/en/release-1.8/integration/#module-hamcrest.library.integration.match_equality


File: python.info,  Node: 2to3 - Automated Python 2 to 3 code translation,  Next: test --- Regression tests package for Python,  Prev: unittest mock --- getting started,  Up: Development Tools

5.26.7 2to3 - Automated Python 2 to 3 code translation
------------------------------------------------------

2to3 is a Python program that reads Python 2.x source code and applies a
series of `fixers' to transform it into valid Python 3.x code.  The
standard library contains a rich set of fixers that will handle almost
all code.  2to3 supporting library *note lib2to3: a5. is, however, a
flexible and generic library, so it is possible to write your own fixers
for 2to3.  *note lib2to3: a5. could also be adapted to custom
applications in which Python code needs to be edited automatically.

* Menu:

* Using 2to3:: 
* Fixers:: 
* lib2to3 - 2to3's library:: 


File: python.info,  Node: Using 2to3,  Next: Fixers,  Up: 2to3 - Automated Python 2 to 3 code translation

5.26.7.1 Using 2to3
...................

2to3 will usually be installed with the Python interpreter as a script.
It is also located in the ‘Tools/scripts’ directory of the Python root.

2to3’s basic arguments are a list of files or directories to transform.
The directories are recursively traversed for Python sources.

Here is a sample Python 2.x source file, ‘example.py’:

     def greet(name):
         print "Hello, {0}!".format(name)
     print "What's your name?"
     name = raw_input()
     greet(name)

It can be converted to Python 3.x code via 2to3 on the command line:

     $ 2to3 example.py

A diff against the original source file is printed.  2to3 can also write
the needed modifications right back to the source file.  (A backup of
the original file is made unless ‘-n’ is also given.)  Writing the
changes back is enabled with the ‘-w’ flag:

     $ 2to3 -w example.py

After transformation, ‘example.py’ looks like this:

     def greet(name):
         print("Hello, {0}!".format(name))
     print("What's your name?")
     name = input()
     greet(name)

Comments and exact indentation are preserved throughout the translation
process.

By default, 2to3 runs a set of *note predefined fixers: 2c6a.  The *note
-l: 1784. flag lists all available fixers.  An explicit set of fixers to
run can be given with ‘-f’.  Likewise the ‘-x’ explicitly disables a
fixer.  The following example runs only the ‘imports’ and ‘has_key’
fixers:

     $ 2to3 -f imports -f has_key example.py

This command runs every fixer except the ‘apply’ fixer:

     $ 2to3 -x apply example.py

Some fixers are `explicit', meaning they aren’t run by default and must
be listed on the command line to be run.  Here, in addition to the
default fixers, the ‘idioms’ fixer is run:

     $ 2to3 -f all -f idioms example.py

Notice how passing ‘all’ enables all default fixers.

Sometimes 2to3 will find a place in your source code that needs to be
changed, but 2to3 cannot fix automatically.  In this case, 2to3 will
print a warning beneath the diff for a file.  You should address the
warning in order to have compliant 3.x code.

2to3 can also refactor doctests.  To enable this mode, use the ‘-d’
flag.  Note that `only' doctests will be refactored.  This also doesn’t
require the module to be valid Python.  For example, doctest like
examples in a reST document could also be refactored with this option.

The ‘-v’ option enables output of more information on the translation
process.

Since some print statements can be parsed as function calls or
statements, 2to3 cannot always read files containing the print function.
When 2to3 detects the presence of the ‘from __future__ import
print_function’ compiler directive, it modifies its internal grammar to
interpret *note print(): 481. as a function.  This change can also be
enabled manually with the ‘-p’ flag.  Use ‘-p’ to run fixers on code
that already has had its print statements converted.

The ‘-o’ or ‘--output-dir’ option allows specification of an alternate
directory for processed output files to be written to.  The ‘-n’ flag is
required when using this as backup files do not make sense when not
overwriting the input files.

New in version 3.2.3: The ‘-o’ option was added.

The ‘-W’ or ‘--write-unchanged-files’ flag tells 2to3 to always write
output files even if no changes were required to the file.  This is most
useful with ‘-o’ so that an entire Python source tree is copied with
translation from one directory to another.  This option implies the ‘-w’
flag as it would not make sense otherwise.

New in version 3.2.3: The ‘-W’ flag was added.

The ‘--add-suffix’ option specifies a string to append to all output
filenames.  The ‘-n’ flag is required when specifying this as backups
are not necessary when writing to different filenames.  Example:

     $ 2to3 -n -W --add-suffix=3 example.py

Will cause a converted file named ‘example.py3’ to be written.

New in version 3.2.3: The ‘--add-suffix’ option was added.

To translate an entire project from one directory tree to another use:

     $ 2to3 --output-dir=python3-version/mycode -W -n python2-version/mycode


File: python.info,  Node: Fixers,  Next: lib2to3 - 2to3's library,  Prev: Using 2to3,  Up: 2to3 - Automated Python 2 to 3 code translation

5.26.7.2 Fixers
...............

Each step of transforming code is encapsulated in a fixer.  The command
‘2to3 -l’ lists them.  As *note documented above: 2c69, each can be
turned on and off individually.  They are described here in more detail.

 -- 2to3fixer: apply

     Removes usage of ‘apply()’.  For example ‘apply(function, *args,
     **kwargs)’ is converted to ‘function(*args, **kwargs)’.

 -- 2to3fixer: asserts

     Replaces deprecated *note unittest: 118. method names with the
     correct ones.

     From                                 To
                                          
     ------------------------------------------------------------------------------------
                                          
     ‘failUnlessEqual(a, b)’              *note assertEqual(a, b): 813.
                                          
                                          
     ‘assertEquals(a, b)’                 *note assertEqual(a, b): 813.
                                          
                                          
     ‘failIfEqual(a, b)’                  *note assertNotEqual(a, b): 814.
                                          
                                          
     ‘assertNotEquals(a, b)’              *note assertNotEqual(a, b): 814.
                                          
                                          
     ‘failUnless(a)’                      *note assertTrue(a): 812.
                                          
                                          
     ‘assert_(a)’                         *note assertTrue(a): 812.
                                          
                                          
     ‘failIf(a)’                          *note assertFalse(a): 93d.
                                          
                                          
     ‘failUnlessRaises(exc, cal)’         *note assertRaises(exc, cal): 6f6.
                                          
                                          
     ‘failUnlessAlmostEqual(a, b)’        *note assertAlmostEqual(a, b): 815.
                                          
                                          
     ‘assertAlmostEquals(a, b)’           *note assertAlmostEqual(a, b): 815.
                                          
                                          
     ‘failIfAlmostEqual(a, b)’            *note assertNotAlmostEqual(a, b): 816.
                                          
                                          
     ‘assertNotAlmostEquals(a, b)’        *note assertNotAlmostEqual(a, b): 816.
                                          

 -- 2to3fixer: basestring

     Converts ‘basestring’ to *note str: 25a.

 -- 2to3fixer: buffer

     Converts ‘buffer’ to *note memoryview: 1b7.  This fixer is optional
     because the *note memoryview: 1b7. API is similar but not exactly
     the same as that of ‘buffer’.

 -- 2to3fixer: callable

     Converts ‘callable(x)’ to ‘isinstance(x, collections.Callable)’,
     adding an import to *note collections: 1e. if needed.  Note
     ‘callable(x)’ has returned in Python 3.2, so if you do not intend
     to support Python 3.1, you can disable this fixer.

 -- 2to3fixer: dict

     Fixes dictionary iteration methods.  ‘dict.iteritems()’ is
     converted to *note dict.items(): 890, ‘dict.iterkeys()’ to *note
     dict.keys(): 88f, and ‘dict.itervalues()’ to *note dict.values():
     891.  Similarly, ‘dict.viewitems()’, ‘dict.viewkeys()’ and
     ‘dict.viewvalues()’ are converted respectively to *note
     dict.items(): 890, *note dict.keys(): 88f. and *note dict.values():
     891.  It also wraps existing usages of *note dict.items(): 890,
     *note dict.keys(): 88f, and *note dict.values(): 891. in a call to
     *note list: 25d.

 -- 2to3fixer: except

     Converts ‘except X, T’ to ‘except X as T’.

 -- 2to3fixer: exec

     Converts the ‘exec’ statement to the *note exec(): 8ac. function.

 -- 2to3fixer: execfile

     Removes usage of ‘execfile()’.  The argument to ‘execfile()’ is
     wrapped in calls to *note open(): 1e8, *note compile(): 903, and
     *note exec(): 8ac.

 -- 2to3fixer: exitfunc

     Changes assignment of ‘sys.exitfunc’ to use of the *note atexit: c.
     module.

 -- 2to3fixer: filter

     Wraps *note filter(): 893. usage in a *note list: 25d. call.

 -- 2to3fixer: funcattrs

     Fixes function attributes that have been renamed.  For example,
     ‘my_function.func_closure’ is converted to
     ‘my_function.__closure__’.

 -- 2to3fixer: future

     Removes ‘from __future__ import new_feature’ statements.

 -- 2to3fixer: getcwdu

     Renames ‘os.getcwdu()’ to *note os.getcwd(): 1568.

 -- 2to3fixer: has_key

     Changes ‘dict.has_key(key)’ to ‘key in dict’.

 -- 2to3fixer: idioms

     This optional fixer performs several transformations that make
     Python code more idiomatic.  Type comparisons like ‘type(x) is
     SomeClass’ and ‘type(x) == SomeClass’ are converted to
     ‘isinstance(x, SomeClass)’.  ‘while 1’ becomes ‘while True’.  This
     fixer also tries to make use of *note sorted(): 84e. in appropriate
     places.  For example, this block

          L = list(some_iterable)
          L.sort()

     is changed to

          L = sorted(some_iterable)

 -- 2to3fixer: import

     Detects sibling imports and converts them to relative imports.

 -- 2to3fixer: imports

     Handles module renames in the standard library.

 -- 2to3fixer: imports2

     Handles other modules renames in the standard library.  It is
     separate from the *note imports: 2c7d. fixer only because of
     technical limitations.

 -- 2to3fixer: input

     Converts ‘input(prompt)’ to ‘eval(input(prompt))’.

 -- 2to3fixer: intern

     Converts ‘intern()’ to *note sys.intern(): 8da.

 -- 2to3fixer: isinstance

     Fixes duplicate types in the second argument of *note isinstance():
     998.  For example, ‘isinstance(x, (int, int))’ is converted to
     ‘isinstance(x, (int))’.

 -- 2to3fixer: itertools_imports

     Removes imports of ‘itertools.ifilter()’, ‘itertools.izip()’, and
     ‘itertools.imap()’.  Imports of ‘itertools.ifilterfalse()’ are also
     changed to *note itertools.filterfalse(): fa3.

 -- 2to3fixer: itertools

     Changes usage of ‘itertools.ifilter()’, ‘itertools.izip()’, and
     ‘itertools.imap()’ to their built-in equivalents.
     ‘itertools.ifilterfalse()’ is changed to *note
     itertools.filterfalse(): fa3.

 -- 2to3fixer: long

     Renames ‘long’ to *note int: 227.

 -- 2to3fixer: map

     Wraps *note map(): 892. in a *note list: 25d. call.  It also
     changes ‘map(None, x)’ to ‘list(x)’.  Using ‘from future_builtins
     import map’ disables this fixer.

 -- 2to3fixer: metaclass

     Converts the old metaclass syntax (‘__metaclass__ = Meta’ in the
     class body) to the new (‘class X(metaclass=Meta)’).

 -- 2to3fixer: methodattrs

     Fixes old method attribute names.  For example, ‘meth.im_func’ is
     converted to ‘meth.__func__’.

 -- 2to3fixer: ne

     Converts the old not-equal syntax, ‘<>’, to ‘!=’.

 -- 2to3fixer: next

     Converts the use of iterator’s ‘next()’ methods to the *note
     next(): 218. function.  It also renames *note next(): 218. methods
     to *note __next__(): 8cf.

 -- 2to3fixer: nonzero

     Renames ‘__nonzero__()’ to *note __bool__(): 8d4.

 -- 2to3fixer: numliterals

     Converts octal literals into the new syntax.

 -- 2to3fixer: operator

     Converts calls to various functions in the *note operator: c0.
     module to other, but equivalent, function calls.  When needed, the
     appropriate ‘import’ statements are added, e.g.  ‘import
     collections’.  The following mapping are made:

     From                                   To
                                            
     --------------------------------------------------------------------------------------
                                            
     ‘operator.isCallable(obj)’             ‘hasattr(obj, '__call__')’
                                            
                                            
     ‘operator.sequenceIncludes(obj)’       ‘operator.contains(obj)’
                                            
                                            
     ‘operator.isSequenceType(obj)’         ‘isinstance(obj, collections.Sequence)’
                                            
                                            
     ‘operator.isMappingType(obj)’          ‘isinstance(obj, collections.Mapping)’
                                            
                                            
     ‘operator.isNumberType(obj)’           ‘isinstance(obj, numbers.Number)’
                                            
                                            
     ‘operator.repeat(obj, n)’              ‘operator.mul(obj, n)’
                                            
                                            
     ‘operator.irepeat(obj, n)’             ‘operator.imul(obj, n)’
                                            

 -- 2to3fixer: paren

     Add extra parenthesis where they are required in list
     comprehensions.  For example, ‘[x for x in 1, 2]’ becomes ‘[x for x
     in (1, 2)]’.

 -- 2to3fixer: print

     Converts the ‘print’ statement to the *note print(): 481. function.

 -- 2to3fixer: raise

     Converts ‘raise E, V’ to ‘raise E(V)’, and ‘raise E, V, T’ to
     ‘raise E(V).with_traceback(T)’.  If ‘E’ is a tuple, the translation
     will be incorrect because substituting tuples for exceptions has
     been removed in 3.0.

 -- 2to3fixer: raw_input

     Converts ‘raw_input()’ to *note input(): 8d7.

 -- 2to3fixer: reduce

     Handles the move of ‘reduce()’ to *note functools.reduce(): 8db.

 -- 2to3fixer: reload

     Converts ‘reload()’ to *note imp.reload(): 8dc.

 -- 2to3fixer: renames

     Changes ‘sys.maxint’ to *note sys.maxsize: 78c.

 -- 2to3fixer: repr

     Replaces backtick repr with the *note repr(): 3bb. function.

 -- 2to3fixer: set_literal

     Replaces use of the *note set: 7be. constructor with set literals.
     This fixer is optional.

 -- 2to3fixer: standarderror

     Renames ‘StandardError’ to *note Exception: 1a1.

 -- 2to3fixer: sys_exc

     Changes the deprecated ‘sys.exc_value’, ‘sys.exc_type’,
     ‘sys.exc_traceback’ to use *note sys.exc_info(): 8ca.

 -- 2to3fixer: throw

     Fixes the API change in generator’s ‘throw()’ method.

 -- 2to3fixer: tuple_params

     Removes implicit tuple parameter unpacking.  This fixer inserts
     temporary variables.

 -- 2to3fixer: types

     Fixes code broken from the removal of some members in the *note
     types: 115. module.

 -- 2to3fixer: unicode

     Renames ‘unicode’ to *note str: 25a.

 -- 2to3fixer: urllib

     Handles the rename of *note urllib: 11a. and ‘urllib2’ to the *note
     urllib: 11a. package.

 -- 2to3fixer: ws_comma

     Removes excess whitespace from comma separated items.  This fixer
     is optional.

 -- 2to3fixer: xrange

     Renames ‘xrange()’ to *note range(): 5e0. and wraps existing *note
     range(): 5e0. calls with *note list: 25d.

 -- 2to3fixer: xreadlines

     Changes ‘for x in file.xreadlines()’ to ‘for x in file’.

 -- 2to3fixer: zip

     Wraps *note zip(): 897. usage in a *note list: 25d. call.  This is
     disabled when ‘from future_builtins import zip’ appears.


File: python.info,  Node: lib2to3 - 2to3's library,  Prev: Fixers,  Up: 2to3 - Automated Python 2 to 3 code translation

5.26.7.3 ‘lib2to3’ - 2to3’s library
...................................

     Note: The *note lib2to3: a5. API should be considered unstable and
     may change drastically in the future.


File: python.info,  Node: test --- Regression tests package for Python,  Next: test support --- Utilities for the Python test suite,  Prev: 2to3 - Automated Python 2 to 3 code translation,  Up: Development Tools

5.26.8 ‘test’ — Regression tests package for Python
---------------------------------------------------

     Note: The *note test: 103. package is meant for internal use by
     Python only.  It is documented for the benefit of the core
     developers of Python.  Any use of this package outside of Python’s
     standard library is discouraged as code mentioned here can change
     or be removed without notice between releases of Python.

The *note test: 103. package contains all regression tests for Python as
well as the modules *note test.support: 104. and ‘test.regrtest’.  *note
test.support: 104. is used to enhance your tests while ‘test.regrtest’
drives the testing suite.

Each module in the *note test: 103. package whose name starts with
‘test_’ is a testing suite for a specific module or feature.  All new
tests should be written using the *note unittest: 118. or *note doctest:
65. module.  Some older tests are written using a "traditional" testing
style that compares output printed to ‘sys.stdout’; this style of test
is considered deprecated.

See also
........

Module *note unittest: 118.

     Writing PyUnit regression tests.

Module *note doctest: 65.

     Tests embedded in documentation strings.

* Menu:

* Writing Unit Tests for the test package:: 
* Running tests using the command-line interface:: 


File: python.info,  Node: Writing Unit Tests for the test package,  Next: Running tests using the command-line interface,  Up: test --- Regression tests package for Python

5.26.8.1 Writing Unit Tests for the ‘test’ package
..................................................

It is preferred that tests that use the *note unittest: 118. module
follow a few guidelines.  One is to name the test module by starting it
with ‘test_’ and end it with the name of the module being tested.  The
test methods in the test module should start with ‘test_’ and end with a
description of what the method is testing.  This is needed so that the
methods are recognized by the test driver as test methods.  Also, no
documentation string for the method should be included.  A comment (such
as ‘# Tests function returns only True or False’) should be used to
provide documentation for test methods.  This is done because
documentation strings get printed out if they exist and thus what test
is being run is not stated.

A basic boilerplate is often used:

     import unittest
     from test import support

     class MyTestCase1(unittest.TestCase):

         # Only use setUp() and tearDown() if necessary

         def setUp(self):
             ... code to execute in preparation for tests ...

         def tearDown(self):
             ... code to execute to clean up after tests ...

         def test_feature_one(self):
             # Test feature one.
             ... testing code ...

         def test_feature_two(self):
             # Test feature two.
             ... testing code ...

         ... more test methods ...

     class MyTestCase2(unittest.TestCase):
         ... same structure as MyTestCase1 ...

     ... more test classes ...

     if __name__ == '__main__':
         unittest.main()

This code pattern allows the testing suite to be run by ‘test.regrtest’,
on its own as a script that supports the *note unittest: 118. CLI, or
via the ‘python -m unittest’ CLI.

The goal for regression testing is to try to break code.  This leads to
a few guidelines to be followed:

   * The testing suite should exercise all classes, functions, and
     constants.  This includes not just the external API that is to be
     presented to the outside world but also "private" code.

   * Whitebox testing (examining the code being tested when the tests
     are being written) is preferred.  Blackbox testing (testing only
     the published user interface) is not complete enough to make sure
     all boundary and edge cases are tested.

   * Make sure all possible values are tested including invalid ones.
     This makes sure that not only all valid values are acceptable but
     also that improper values are handled correctly.

   * Exhaust as many code paths as possible.  Test where branching
     occurs and thus tailor input to make sure as many different paths
     through the code are taken.

   * Add an explicit test for any bugs discovered for the tested code.
     This will make sure that the error does not crop up again if the
     code is changed in the future.

   * Make sure to clean up after your tests (such as close and remove
     all temporary files).

   * If a test is dependent on a specific condition of the operating
     system then verify the condition already exists before attempting
     the test.

   * Import as few modules as possible and do it as soon as possible.
     This minimizes external dependencies of tests and also minimizes
     possible anomalous behavior from side-effects of importing a
     module.

   * Try to maximize code reuse.  On occasion, tests will vary by
     something as small as what type of input is used.  Minimize code
     duplication by subclassing a basic test class with a class that
     specifies the input:

          class TestFuncAcceptsSequencesMixin:

              func = mySuperWhammyFunction

              def test_func(self):
                  self.func(self.arg)

          class AcceptLists(TestFuncAcceptsSequencesMixin, unittest.TestCase):
              arg = [1, 2, 3]

          class AcceptStrings(TestFuncAcceptsSequencesMixin, unittest.TestCase):
              arg = 'abc'

          class AcceptTuples(TestFuncAcceptsSequencesMixin, unittest.TestCase):
              arg = (1, 2, 3)

     When using this pattern, remember that all classes that inherit
     from *note unittest.TestCase: 501. are run as tests.  The ‘Mixin’
     class in the example above does not have any data and so can’t be
     run by itself, thus it does not inherit from *note
     unittest.TestCase: 501.

See also
........

Test Driven Development

     A book by Kent Beck on writing tests before code.


File: python.info,  Node: Running tests using the command-line interface,  Prev: Writing Unit Tests for the test package,  Up: test --- Regression tests package for Python

5.26.8.2 Running tests using the command-line interface
.......................................................

The *note test: 103. package can be run as a script to drive Python’s
regression test suite, thanks to the *note -m: 8b4. option: ‘python -m
test’.  Under the hood, it uses ‘test.regrtest’; the call ‘python -m
test.regrtest’ used in previous Python versions still works.  Running
the script by itself automatically starts running all regression tests
in the *note test: 103. package.  It does this by finding all modules in
the package whose name starts with ‘test_’, importing them, and
executing the function ‘test_main()’ if present or loading the tests via
unittest.TestLoader.loadTestsFromModule if ‘test_main’ does not exist.
The names of tests to execute may also be passed to the script.
Specifying a single regression test (‘python -m test test_spam’) will
minimize output and only print whether the test passed or failed.

Running *note test: 103. directly allows what resources are available
for tests to use to be set.  You do this by using the ‘-u’ command-line
option.  Specifying ‘all’ as the value for the ‘-u’ option enables all
possible resources: ‘python -m test -uall’.  If all but one resource is
desired (a more common case), a comma-separated list of resources that
are not desired may be listed after ‘all’.  The command ‘python -m test
-uall,-audio,-largefile’ will run *note test: 103. with all resources
except the ‘audio’ and ‘largefile’ resources.  For a list of all
resources and more command-line options, run ‘python -m test -h’.

Some other ways to execute the regression tests depend on what platform
the tests are being executed on.  On Unix, you can run ‘make test’ at
the top-level directory where Python was built.  On Windows, executing
‘rt.bat’ from your ‘PCBuild’ directory will run all regression tests.


File: python.info,  Node: test support --- Utilities for the Python test suite,  Prev: test --- Regression tests package for Python,  Up: Development Tools

5.26.9 ‘test.support’ — Utilities for the Python test suite
-----------------------------------------------------------

The *note test.support: 104. module provides support for Python’s
regression test suite.

     Note: *note test.support: 104. is not a public module.  It is
     documented here to help Python developers write tests.  The API of
     this module is subject to change without backwards compatibility
     concerns between releases.

This module defines the following exceptions:

 -- Exception: test.support.TestFailed

     Exception to be raised when a test fails.  This is deprecated in
     favor of *note unittest: 118.-based tests and *note
     unittest.TestCase: 501.’s assertion methods.

 -- Exception: test.support.ResourceDenied

     Subclass of *note unittest.SkipTest: 505.  Raised when a resource
     (such as a network connection) is not available.  Raised by the
     *note requires(): 2caa. function.

The *note test.support: 104. module defines the following constants:

 -- Data: test.support.verbose

     ‘True’ when verbose output is enabled.  Should be checked when more
     detailed information is desired about a running test.  `verbose' is
     set by ‘test.regrtest’.

 -- Data: test.support.is_jython

     ‘True’ if the running interpreter is Jython.

 -- Data: test.support.TESTFN

     Set to a name that is safe to use as the name of a temporary file.
     Any temporary file that is created should be closed and unlinked
     (removed).

The *note test.support: 104. module defines the following functions:

 -- Function: test.support.forget (module_name)

     Remove the module named `module_name' from ‘sys.modules’ and delete
     any byte-compiled files of the module.

 -- Function: test.support.is_resource_enabled (resource)

     Return ‘True’ if `resource' is enabled and available.  The list of
     available resources is only set when ‘test.regrtest’ is executing
     the tests.

 -- Function: test.support.requires (resource, msg=None)

     Raise *note ResourceDenied: 2ca9. if `resource' is not available.
     `msg' is the argument to *note ResourceDenied: 2ca9. if it is
     raised.  Always returns ‘True’ if called by a function whose
     ‘__name__’ is ‘'__main__'’.  Used when tests are executed by
     ‘test.regrtest’.

 -- Function: test.support.findfile (filename, subdir=None)

     Return the path to the file named `filename'.  If no match is found
     `filename' is returned.  This does not equal a failure since it
     could be the path to the file.

          Setting `subdir' indicates a relative path to use to find the
          file rather than looking directly in the path directories.

 -- Function: test.support.run_unittest (*classes)

     Execute *note unittest.TestCase: 501. subclasses passed to the
     function.  The function scans the classes for methods starting with
     the prefix ‘test_’ and executes the tests individually.

     It is also legal to pass strings as parameters; these should be
     keys in ‘sys.modules’.  Each associated module will be scanned by
     ‘unittest.TestLoader.loadTestsFromModule()’.  This is usually seen
     in the following ‘test_main()’ function:

          def test_main():
              support.run_unittest(__name__)

     This will run all tests defined in the named module.

 -- Function: test.support.run_doctest (module, verbosity=None)

     Run *note doctest.testmod(): a4c. on the given `module'.  Return
     ‘(failure_count, test_count)’.

     If `verbosity' is ‘None’, *note doctest.testmod(): a4c. is run with
     verbosity set to *note verbose: 2cab.  Otherwise, it is run with
     verbosity set to ‘None’.

 -- Function: test.support.check_warnings (*filters, quiet=True)

     A convenience wrapper for *note warnings.catch_warnings(): 2cb4.
     that makes it easier to test that a warning was correctly raised.
     It is approximately equivalent to calling
     ‘warnings.catch_warnings(record=True)’ with *note
     warnings.simplefilter(): 2cb5. set to ‘always’ and with the option
     to automatically validate the results that are recorded.

     ‘check_warnings’ accepts 2-tuples of the form ‘("message regexp",
     WarningCategory)’ as positional arguments.  If one or more
     `filters' are provided, or if the optional keyword argument `quiet'
     is ‘False’, it checks to make sure the warnings are as expected:
     each specified filter must match at least one of the warnings
     raised by the enclosed code or the test fails, and if any warnings
     are raised that do not match any of the specified filters the test
     fails.  To disable the first of these checks, set `quiet' to
     ‘True’.

     If no arguments are specified, it defaults to:

          check_warnings(("", Warning), quiet=True)

     In this case all warnings are caught and no errors are raised.

     On entry to the context manager, a ‘WarningRecorder’ instance is
     returned.  The underlying warnings list from *note
     catch_warnings(): 2cb4. is available via the recorder object’s
     *note warnings: 123. attribute.  As a convenience, the attributes
     of the object representing the most recent warning can also be
     accessed directly through the recorder object (see example below).
     If no warning has been raised, then any of the attributes that
     would otherwise be expected on an object representing a warning
     will return ‘None’.

     The recorder object also has a ‘reset()’ method, which clears the
     warnings list.

     The context manager is designed to be used like this:

          with check_warnings(("assertion is always true", SyntaxWarning),
                              ("", UserWarning)):
              exec('assert(False, "Hey!")')
              warnings.warn(UserWarning("Hide me!"))

     In this case if either warning was not raised, or some other
     warning was raised, *note check_warnings(): 2cb3. would raise an
     error.

     When a test needs to look more deeply into the warnings, rather
     than just checking whether or not they occurred, code like this can
     be used:

          with check_warnings(quiet=True) as w:
              warnings.warn("foo")
              assert str(w.args[0]) == "foo"
              warnings.warn("bar")
              assert str(w.args[0]) == "bar"
              assert str(w.warnings[0].args[0]) == "foo"
              assert str(w.warnings[1].args[0]) == "bar"
              w.reset()
              assert len(w.warnings) == 0

     Here all warnings will be caught, and the test code tests the
     captured warnings directly.

     Changed in version 3.2: New optional arguments `filters' and
     `quiet'.

 -- Function: test.support.captured_stdin ()
 -- Function: test.support.captured_stdout ()
 -- Function: test.support.captured_stderr ()

     A context managers that temporarily replaces the named stream with
     *note io.StringIO: 41e. object.

     Example use with output streams:

          with captured_stdout() as stdout, captured_stderr() as stderr:
              print("hello")
              print("error", file=sys.stderr)
          assert stdout.getvalue() == "hello\n"
          assert stderr.getvalue() == "error\n"

     Example use with input stream:

          with captured_stdin() as stdin:
              stdin.write('hello\n')
              stdin.seek(0)
              # call test code that consumes from sys.stdin
              captured = input()
          self.assertEqual(captured, "hello")

 -- Function: test.support.temp_dir (path=None, quiet=False)

     A context manager that creates a temporary directory at `path' and
     yields the directory.

     If `path' is None, the temporary directory is created using *note
     tempfile.mkdtemp(): 160d.  If `quiet' is ‘False’, the context
     manager raises an exception on error.  Otherwise, if `path' is
     specified and cannot be created, only a warning is issued.

 -- Function: test.support.change_cwd (path, quiet=False)

     A context manager that temporarily changes the current working
     directory to `path' and yields the directory.

     If `quiet' is ‘False’, the context manager raises an exception on
     error.  Otherwise, it issues only a warning and keeps the current
     working directory the same.

 -- Function: test.support.temp_cwd (name='tempcwd', quiet=False)

     A context manager that temporarily creates a new directory and
     changes the current working directory (CWD).

     The context manager creates a temporary directory in the current
     directory with name `name' before temporarily changing the current
     working directory.  If `name' is None, the temporary directory is
     created using *note tempfile.mkdtemp(): 160d.

     If `quiet' is ‘False’ and it is not possible to create or change
     the CWD, an error is raised.  Otherwise, only a warning is raised
     and the original CWD is used.

 -- Function: test.support.temp_umask (umask)

     A context manager that temporarily sets the process umask.

 -- Function: test.support.can_symlink ()

     Return ‘True’ if the OS supports symbolic links, ‘False’ otherwise.

 -- Function: @test.support.skip_unless_symlink

     A decorator for running tests that require support for symbolic
     links.

 -- Function: @test.support.anticipate_failure (condition)

     A decorator to conditionally mark tests with *note
     unittest.expectedFailure(): 2bbd.  Any use of this decorator should
     have an associated comment identifying the relevant tracker issue.

 -- Function: @test.support.run_with_locale (catstr, *locales)

     A decorator for running a function in a different locale, correctly
     resetting it after it has finished.  `catstr' is the locale
     category as a string (for example ‘"LC_ALL"’).  The `locales'
     passed will be tried sequentially, and the first valid locale will
     be used.

 -- Function: test.support.make_bad_fd ()

     Create an invalid file descriptor by opening and closing a
     temporary file, and returning its descriptor.

 -- Function: test.support.import_module (name, deprecated=False)

     This function imports and returns the named module.  Unlike a
     normal import, this function raises *note unittest.SkipTest: 505.
     if the module cannot be imported.

     Module and package deprecation messages are suppressed during this
     import if `deprecated' is ‘True’.

     New in version 3.1.

 -- Function: test.support.import_fresh_module (name, fresh=(),
          blocked=(), deprecated=False)

     This function imports and returns a fresh copy of the named Python
     module by removing the named module from ‘sys.modules’ before doing
     the import.  Note that unlike ‘reload()’, the original module is
     not affected by this operation.

     `fresh' is an iterable of additional module names that are also
     removed from the ‘sys.modules’ cache before doing the import.

     `blocked' is an iterable of module names that are replaced with
     ‘None’ in the module cache during the import to ensure that
     attempts to import them raise *note ImportError: 19f.

     The named module and any modules named in the `fresh' and `blocked'
     parameters are saved before starting the import and then reinserted
     into ‘sys.modules’ when the fresh import is complete.

     Module and package deprecation messages are suppressed during this
     import if `deprecated' is ‘True’.

     This function will raise *note ImportError: 19f. if the named
     module cannot be imported.

     Example use:

          # Get copies of the warnings module for testing without affecting the
          # version being used by the rest of the test suite. One copy uses the
          # C implementation, the other is forced to use the pure Python fallback
          # implementation
          py_warnings = import_fresh_module('warnings', blocked=['_warnings'])
          c_warnings = import_fresh_module('warnings', fresh=['_warnings'])

     New in version 3.1.

 -- Function: test.support.bind_port (sock, host=HOST)

     Bind the socket to a free port and return the port number.  Relies
     on ephemeral ports in order to ensure we are using an unbound port.
     This is important as many tests may be running simultaneously,
     especially in a buildbot environment.  This method raises an
     exception if the ‘sock.family’ is *note AF_INET: 1e1a. and
     ‘sock.type’ is *note SOCK_STREAM: 8fb, and the socket has
     ‘SO_REUSEADDR’ or ‘SO_REUSEPORT’ set on it.  Tests should never set
     these socket options for TCP/IP sockets.  The only case for setting
     these options is testing multicasting via multiple UDP sockets.

     Additionally, if the ‘SO_EXCLUSIVEADDRUSE’ socket option is
     available (i.e.  on Windows), it will be set on the socket.  This
     will prevent anyone else from binding to our host/port for the
     duration of the test.

 -- Function: test.support.find_unused_port (family=socket.AF_INET,
          socktype=socket.SOCK_STREAM)

     Returns an unused port that should be suitable for binding.  This
     is achieved by creating a temporary socket with the same family and
     type as the ‘sock’ parameter (default is *note AF_INET: 1e1a, *note
     SOCK_STREAM: 8fb.), and binding it to the specified host address
     (defaults to ‘0.0.0.0’) with the port set to 0, eliciting an unused
     ephemeral port from the OS. The temporary socket is then closed and
     deleted, and the ephemeral port is returned.

     Either this method or *note bind_port(): 2cc3. should be used for
     any tests where a server socket needs to be bound to a particular
     port for the duration of the test.  Which one to use depends on
     whether the calling code is creating a python socket, or if an
     unused port needs to be provided in a constructor or passed to an
     external program (i.e.  the ‘-accept’ argument to openssl’s
     s_server mode).  Always prefer *note bind_port(): 2cc3. over *note
     find_unused_port(): 2cc4. where possible.  Using a hard coded port
     is discouraged since it can make multiple instances of the test
     impossible to run simultaneously, which is a problem for buildbots.

 -- Function: test.support.load_package_tests (pkg_dir, loader,
          standard_tests, pattern)

     Generic implementation of the *note unittest: 118. ‘load_tests’
     protocol for use in test packages.  `pkg_dir' is the root directory
     of the package; `loader', `standard_tests', and `pattern' are the
     arguments expected by ‘load_tests’.  In simple cases, the test
     package’s ‘__init__.py’ can be the following:

          import os
          from test.support import load_package_tests

          def load_tests(*args):
              return load_package_tests(os.path.dirname(__file__), *args)

 -- Function: detect_api_mismatch(ref_api, other_api, *, ignore=()):

     Returns the set of attributes, functions or methods of `ref_api'
     not found on `other_api', except for a defined list of items to be
     ignored in this check specified in `ignore'.

     By default this skips private attributes beginning with ’_’ but
     includes all magic methods, i.e.  those starting and ending in
     ’__’.

     New in version 3.5.

 -- Function: test.support.check__all__ (test_case, module,
          name_of_module=None, extra=(), blacklist=())

     Assert that the ‘__all__’ variable of `module' contains all public
     names.

     The module’s public names (its API) are detected automatically
     based on whether they match the public name convention and were
     defined in `module'.

     The `name_of_module' argument can specify (as a string or tuple
     thereof) what module(s) an API could be defined in in order to be
     detected as a public API. One case for this is when `module'
     imports part of its public API from other modules, possibly a C
     backend (like ‘csv’ and its ‘_csv’).

     The `extra' argument can be a set of names that wouldn’t otherwise
     be automatically detected as "public", like objects without a
     proper ‘__module__’ attribute.  If provided, it will be added to
     the automatically detected ones.

     The `blacklist' argument can be a set of names that must not be
     treated as part of the public API even though their names indicate
     otherwise.

     Example use:

          import bar
          import foo
          import unittest
          from test import support

          class MiscTestCase(unittest.TestCase):
              def test__all__(self):
                  support.check__all__(self, foo)

          class OtherTestCase(unittest.TestCase):
              def test__all__(self):
                  extra = {'BAR_CONST', 'FOO_CONST'}
                  blacklist = {'baz'}  # Undocumented name.
                  # bar imports part of its API from _bar.
                  support.check__all__(self, bar, ('bar', '_bar'),
                                       extra=extra, blacklist=blacklist)

     New in version 3.6.

The *note test.support: 104. module defines the following classes:

 -- Class: test.support.TransientResource (exc, **kwargs)

     Instances are a context manager that raises *note ResourceDenied:
     2ca9. if the specified exception type is raised.  Any keyword
     arguments are treated as attribute/value pairs to be compared
     against any exception raised within the *note with: 29d. statement.
     Only if all pairs match properly against attributes on the
     exception is *note ResourceDenied: 2ca9. raised.

 -- Class: test.support.EnvironmentVarGuard

     Class used to temporarily set or unset environment variables.
     Instances can be used as a context manager and have a complete
     dictionary interface for querying/modifying the underlying
     ‘os.environ’.  After exit from the context manager all changes to
     environment variables done through this instance will be rolled
     back.

     Changed in version 3.1: Added dictionary interface.

 -- Method: EnvironmentVarGuard.set (envvar, value)

     Temporarily set the environment variable ‘envvar’ to the value of
     ‘value’.

 -- Method: EnvironmentVarGuard.unset (envvar)

     Temporarily unset the environment variable ‘envvar’.

 -- Class: test.support.SuppressCrashReport

     A context manager used to try to prevent crash dialog popups on
     tests that are expected to crash a subprocess.

     On Windows, it disables Windows Error Reporting dialogs using
     SetErrorMode(1).

     On UNIX, *note resource.setrlimit(): 2ccc. is used to set *note
     resource.RLIMIT_CORE: 2ccd.’s soft limit to 0 to prevent coredump
     file creation.

     On both platforms, the old value is restored by *note __exit__():
     908.

 -- Class: test.support.WarningsRecorder

     Class used to record warnings for unit tests.  See documentation of
     *note check_warnings(): 2cb3. above for more details.

   ---------- Footnotes ----------

   (1) 
https://msdn.microsoft.com/en-us/library/windows/desktop/ms680621.aspx


File: python.info,  Node: Debugging and Profiling,  Next: Software Packaging and Distribution,  Prev: Development Tools,  Up: The Python Standard Library

5.27 Debugging and Profiling
============================

These libraries help you with Python development: the debugger enables
you to step through code, analyze stack frames and set breakpoints etc.,
and the profilers run code and give you a detailed breakdown of
execution times, allowing you to identify bottlenecks in your programs.

* Menu:

* bdb: bdb --- Debugger framework. Debugger framework
* faulthandler: faulthandler --- Dump the Python traceback. Dump the Python traceback
* pdb: pdb --- The Python Debugger. The Python Debugger
* The Python Profilers:: 
* timeit: timeit --- Measure execution time of small code snippets. Measure execution time of small code snippets
* trace: trace --- Trace or track Python statement execution. Trace or track Python statement execution
* tracemalloc: tracemalloc --- Trace memory allocations. Trace memory allocations


File: python.info,  Node: bdb --- Debugger framework,  Next: faulthandler --- Dump the Python traceback,  Up: Debugging and Profiling

5.27.1 ‘bdb’ — Debugger framework
---------------------------------

`Source code:' Lib/bdb.py(1)

__________________________________________________________________

The *note bdb: f. module handles basic debugger functions, like setting
breakpoints or managing execution via the debugger.

The following exception is defined:

 -- Exception: bdb.BdbQuit

     Exception raised by the *note Bdb: 90a. class for quitting the
     debugger.

The *note bdb: f. module also defines two classes:

 -- Class: bdb.Breakpoint (self, file, line, temporary=0, cond=None,
          funcname=None)

     This class implements temporary breakpoints, ignore counts,
     disabling and (re-)enabling, and conditionals.

     Breakpoints are indexed by number through a list called
     ‘bpbynumber’ and by ‘(file, line)’ pairs through ‘bplist’.  The
     former points to a single instance of class *note Breakpoint: 2cd4.
     The latter points to a list of such instances since there may be
     more than one breakpoint per line.

     When creating a breakpoint, its associated filename should be in
     canonical form.  If a `funcname' is defined, a breakpoint hit will
     be counted when the first line of that function is executed.  A
     conditional breakpoint always counts a hit.

     *note Breakpoint: 2cd4. instances have the following methods:

      -- Method: deleteMe ()

          Delete the breakpoint from the list associated to a file/line.
          If it is the last breakpoint in that position, it also deletes
          the entry for the file/line.

      -- Method: enable ()

          Mark the breakpoint as enabled.

      -- Method: disable ()

          Mark the breakpoint as disabled.

      -- Method: bpformat ()

          Return a string with all the information about the breakpoint,
          nicely formatted:

             * The breakpoint number.

             * If it is temporary or not.

             * Its file,line position.

             * The condition that causes a break.

             * If it must be ignored the next N times.

             * The breakpoint hit count.

          New in version 3.2.

      -- Method: bpprint (out=None)

          Print the output of *note bpformat(): 2cd8. to the file `out',
          or if it is ‘None’, to standard output.

 -- Class: bdb.Bdb (skip=None)

     The *note Bdb: 90a. class acts as a generic Python debugger base
     class.

     This class takes care of the details of the trace facility; a
     derived class should implement user interaction.  The standard
     debugger class (*note pdb.Pdb: 2cda.) is an example.

     The `skip' argument, if given, must be an iterable of glob-style
     module name patterns.  The debugger will not step into frames that
     originate in a module that matches one of these patterns.  Whether
     a frame is considered to originate in a certain module is
     determined by the ‘__name__’ in the frame globals.

     New in version 3.1: The `skip' argument.

     The following methods of *note Bdb: 90a. normally don’t need to be
     overridden.

      -- Method: canonic (filename)

          Auxiliary method for getting a filename in a canonical form,
          that is, as a case-normalized (on case-insensitive
          filesystems) absolute path, stripped of surrounding angle
          brackets.

      -- Method: reset ()

          Set the ‘botframe’, ‘stopframe’, ‘returnframe’ and ‘quitting’
          attributes with values ready to start debugging.

      -- Method: trace_dispatch (frame, event, arg)

          This function is installed as the trace function of debugged
          frames.  Its return value is the new trace function (in most
          cases, that is, itself).

          The default implementation decides how to dispatch a frame,
          depending on the type of event (passed as a string) that is
          about to be executed.  `event' can be one of the following:

             * ‘"line"’: A new line of code is going to be executed.

             * ‘"call"’: A function is about to be called, or another
               code block entered.

             * ‘"return"’: A function or other code block is about to
               return.

             * ‘"exception"’: An exception has occurred.

             * ‘"c_call"’: A C function is about to be called.

             * ‘"c_return"’: A C function has returned.

             * ‘"c_exception"’: A C function has raised an exception.

          For the Python events, specialized functions (see below) are
          called.  For the C events, no action is taken.

          The `arg' parameter depends on the previous event.

          See the documentation for *note sys.settrace(): ac0. for more
          information on the trace function.  For more information on
          code and frame objects, refer to *note The standard type
          hierarchy: de0.

      -- Method: dispatch_line (frame)

          If the debugger should stop on the current line, invoke the
          *note user_line(): 2cdf. method (which should be overridden in
          subclasses).  Raise a *note BdbQuit: 2cd3. exception if the
          ‘Bdb.quitting’ flag is set (which can be set from *note
          user_line(): 2cdf.).  Return a reference to the *note
          trace_dispatch(): 2cdd. method for further tracing in that
          scope.

      -- Method: dispatch_call (frame, arg)

          If the debugger should stop on this function call, invoke the
          *note user_call(): 2ce1. method (which should be overridden in
          subclasses).  Raise a *note BdbQuit: 2cd3. exception if the
          ‘Bdb.quitting’ flag is set (which can be set from *note
          user_call(): 2ce1.).  Return a reference to the *note
          trace_dispatch(): 2cdd. method for further tracing in that
          scope.

      -- Method: dispatch_return (frame, arg)

          If the debugger should stop on this function return, invoke
          the *note user_return(): 2ce3. method (which should be
          overridden in subclasses).  Raise a *note BdbQuit: 2cd3.
          exception if the ‘Bdb.quitting’ flag is set (which can be set
          from *note user_return(): 2ce3.).  Return a reference to the
          *note trace_dispatch(): 2cdd. method for further tracing in
          that scope.

      -- Method: dispatch_exception (frame, arg)

          If the debugger should stop at this exception, invokes the
          *note user_exception(): 2ce5. method (which should be
          overridden in subclasses).  Raise a *note BdbQuit: 2cd3.
          exception if the ‘Bdb.quitting’ flag is set (which can be set
          from *note user_exception(): 2ce5.).  Return a reference to
          the *note trace_dispatch(): 2cdd. method for further tracing
          in that scope.

     Normally derived classes don’t override the following methods, but
     they may if they want to redefine the definition of stopping and
     breakpoints.

      -- Method: stop_here (frame)

          This method checks if the `frame' is somewhere below
          ‘botframe’ in the call stack.  ‘botframe’ is the frame in
          which debugging started.

      -- Method: break_here (frame)

          This method checks if there is a breakpoint in the filename
          and line belonging to `frame' or, at least, in the current
          function.  If the breakpoint is a temporary one, this method
          deletes it.

      -- Method: break_anywhere (frame)

          This method checks if there is a breakpoint in the filename of
          the current frame.

     Derived classes should override these methods to gain control over
     debugger operation.

      -- Method: user_call (frame, argument_list)

          This method is called from *note dispatch_call(): 2ce0. when
          there is the possibility that a break might be necessary
          anywhere inside the called function.

      -- Method: user_line (frame)

          This method is called from *note dispatch_line(): 2cde. when
          either *note stop_here(): 2ce6. or *note break_here(): 2ce7.
          yields ‘True’.

      -- Method: user_return (frame, return_value)

          This method is called from *note dispatch_return(): 2ce2. when
          *note stop_here(): 2ce6. yields ‘True’.

      -- Method: user_exception (frame, exc_info)

          This method is called from *note dispatch_exception(): 2ce4.
          when *note stop_here(): 2ce6. yields ‘True’.

      -- Method: do_clear (arg)

          Handle how a breakpoint must be removed when it is a temporary
          one.

          This method must be implemented by derived classes.

     Derived classes and clients can call the following methods to
     affect the stepping state.

      -- Method: set_step ()

          Stop after one line of code.

      -- Method: set_next (frame)

          Stop on the next line in or below the given frame.

      -- Method: set_return (frame)

          Stop when returning from the given frame.

      -- Method: set_until (frame)

          Stop when the line with the line no greater than the current
          one is reached or when returning from current frame.

      -- Method: set_trace ([frame])

          Start debugging from `frame'.  If `frame' is not specified,
          debugging starts from caller’s frame.

      -- Method: set_continue ()

          Stop only at breakpoints or when finished.  If there are no
          breakpoints, set the system trace function to None.

      -- Method: set_quit ()

          Set the ‘quitting’ attribute to ‘True’.  This raises *note
          BdbQuit: 2cd3. in the next call to one of the ‘dispatch_*()’
          methods.

     Derived classes and clients can call the following methods to
     manipulate breakpoints.  These methods return a string containing
     an error message if something went wrong, or ‘None’ if all is well.

      -- Method: set_break (filename, lineno, temporary=0, cond,
               funcname)

          Set a new breakpoint.  If the `lineno' line doesn’t exist for
          the `filename' passed as argument, return an error message.
          The `filename' should be in canonical form, as described in
          the *note canonic(): 2cdb. method.

      -- Method: clear_break (filename, lineno)

          Delete the breakpoints in `filename' and `lineno'.  If none
          were set, an error message is returned.

      -- Method: clear_bpbynumber (arg)

          Delete the breakpoint which has the index `arg' in the
          ‘Breakpoint.bpbynumber’.  If `arg' is not numeric or out of
          range, return an error message.

      -- Method: clear_all_file_breaks (filename)

          Delete all breakpoints in `filename'.  If none were set, an
          error message is returned.

      -- Method: clear_all_breaks ()

          Delete all existing breakpoints.

      -- Method: get_bpbynumber (arg)

          Return a breakpoint specified by the given number.  If `arg'
          is a string, it will be converted to a number.  If `arg' is a
          non-numeric string, if the given breakpoint never existed or
          has been deleted, a *note ValueError: 19c. is raised.

          New in version 3.2.

      -- Method: get_break (filename, lineno)

          Check if there is a breakpoint for `lineno' of `filename'.

      -- Method: get_breaks (filename, lineno)

          Return all breakpoints for `lineno' in `filename', or an empty
          list if none are set.

      -- Method: get_file_breaks (filename)

          Return all breakpoints in `filename', or an empty list if none
          are set.

      -- Method: get_all_breaks ()

          Return all breakpoints that are set.

     Derived classes and clients can call the following methods to get a
     data structure representing a stack trace.

      -- Method: get_stack (f, t)

          Get a list of records for a frame and all higher (calling) and
          lower frames, and the size of the higher part.

      -- Method: format_stack_entry (frame_lineno, lprefix=': ')

          Return a string with information about a stack entry,
          identified by a ‘(frame, lineno)’ tuple:

             * The canonical form of the filename which contains the
               frame.

             * The function name, or ‘"<lambda>"’.

             * The input arguments.

             * The return value.

             * The line of code (if it exists).

     The following two methods can be called by clients to use a
     debugger to debug a *note statement: 1521, given as a string.

      -- Method: run (cmd, globals=None, locals=None)

          Debug a statement executed via the *note exec(): 8ac.
          function.  `globals' defaults to ‘__main__.__dict__’, `locals'
          defaults to `globals'.

      -- Method: runeval (expr, globals=None, locals=None)

          Debug an expression executed via the *note eval(): 7e8.
          function.  `globals' and `locals' have the same meaning as in
          *note run(): 2cfd.

      -- Method: runctx (cmd, globals, locals)

          For backwards compatibility.  Calls the *note run(): 2cfd.
          method.

      -- Method: runcall (func, *args, **kwds)

          Debug a single function call, and return its result.

Finally, the module defines the following functions:

 -- Function: bdb.checkfuncname (b, frame)

     Check whether we should break here, depending on the way the
     breakpoint `b' was set.

     If it was set via line number, it checks if ‘b.line’ is the same as
     the one in the frame also passed as argument.  If the breakpoint
     was set via function name, we have to check we are in the right
     frame (the right function) and if we are in its first executable
     line.

 -- Function: bdb.effective (file, line, frame)

     Determine if there is an effective (active) breakpoint at this line
     of code.  Return a tuple of the breakpoint and a boolean that
     indicates if it is ok to delete a temporary breakpoint.  Return
     ‘(None, None)’ if there is no matching breakpoint.

 -- Function: bdb.set_trace ()

     Start debugging with a *note Bdb: 90a. instance from caller’s
     frame.

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/bdb.py


File: python.info,  Node: faulthandler --- Dump the Python traceback,  Next: pdb --- The Python Debugger,  Prev: bdb --- Debugger framework,  Up: Debugging and Profiling

5.27.2 ‘faulthandler’ — Dump the Python traceback
-------------------------------------------------

New in version 3.3.

This module contains functions to dump Python tracebacks explicitly, on
a fault, after a timeout, or on a user signal.  Call *note
faulthandler.enable(): 161. to install fault handlers for the ‘SIGSEGV’,
‘SIGFPE’, ‘SIGABRT’, ‘SIGBUS’, and ‘SIGILL’ signals.  You can also
enable them at startup by setting the *note PYTHONFAULTHANDLER: 5eb.
environment variable or by using the *note -X: 5ec. ‘faulthandler’
command line option.

The fault handler is compatible with system fault handlers like Apport
or the Windows fault handler.  The module uses an alternative stack for
signal handlers if the ‘sigaltstack()’ function is available.  This
allows it to dump the traceback even on a stack overflow.

The fault handler is called on catastrophic cases and therefore can only
use signal-safe functions (e.g.  it cannot allocate memory on the heap).
Because of this limitation traceback dumping is minimal compared to
normal Python tracebacks:

   * Only ASCII is supported.  The ‘backslashreplace’ error handler is
     used on encoding.

   * Each string is limited to 500 characters.

   * Only the filename, the function name and the line number are
     displayed.  (no source code)

   * It is limited to 100 frames and 100 threads.

   * The order is reversed: the most recent call is shown first.

By default, the Python traceback is written to *note sys.stderr: 270.
To see tracebacks, applications must be run in the terminal.  A log file
can alternatively be passed to *note faulthandler.enable(): 161.

The module is implemented in C, so tracebacks can be dumped on a crash
or when Python is deadlocked.

* Menu:

* Dumping the traceback:: 
* Fault handler state:: 
* Dumping the tracebacks after a timeout:: 
* Dumping the traceback on a user signal:: 
* Issue with file descriptors:: 
* Example: Example<13>. 


File: python.info,  Node: Dumping the traceback,  Next: Fault handler state,  Up: faulthandler --- Dump the Python traceback

5.27.2.1 Dumping the traceback
..............................

 -- Function: faulthandler.dump_traceback (file=sys.stderr,
          all_threads=True)

     Dump the tracebacks of all threads into `file'.  If `all_threads'
     is ‘False’, dump only the current thread.

     Changed in version 3.5: Added support for passing file descriptor
     to this function.


File: python.info,  Node: Fault handler state,  Next: Dumping the tracebacks after a timeout,  Prev: Dumping the traceback,  Up: faulthandler --- Dump the Python traceback

5.27.2.2 Fault handler state
............................

 -- Function: faulthandler.enable (file=sys.stderr, all_threads=True)

     Enable the fault handler: install handlers for the ‘SIGSEGV’,
     ‘SIGFPE’, ‘SIGABRT’, ‘SIGBUS’ and ‘SIGILL’ signals to dump the
     Python traceback.  If `all_threads' is ‘True’, produce tracebacks
     for every running thread.  Otherwise, dump only the current thread.

     The `file' must be kept open until the fault handler is disabled:
     see *note issue with file descriptors: 2d08.

     Changed in version 3.5: Added support for passing file descriptor
     to this function.

     Changed in version 3.6: On Windows, a handler for Windows exception
     is also installed.

 -- Function: faulthandler.disable ()

     Disable the fault handler: uninstall the signal handlers installed
     by *note enable(): 161.

 -- Function: faulthandler.is_enabled ()

     Check if the fault handler is enabled.


File: python.info,  Node: Dumping the tracebacks after a timeout,  Next: Dumping the traceback on a user signal,  Prev: Fault handler state,  Up: faulthandler --- Dump the Python traceback

5.27.2.3 Dumping the tracebacks after a timeout
...............................................

 -- Function: faulthandler.dump_traceback_later (timeout, repeat=False,
          file=sys.stderr, exit=False)

     Dump the tracebacks of all threads, after a timeout of `timeout'
     seconds, or every `timeout' seconds if `repeat' is ‘True’.  If
     `exit' is ‘True’, call ‘_exit()’ with status=1 after dumping the
     tracebacks.  (Note ‘_exit()’ exits the process immediately, which
     means it doesn’t do any cleanup like flushing file buffers.)  If
     the function is called twice, the new call replaces previous
     parameters and resets the timeout.  The timer has a sub-second
     resolution.

     The `file' must be kept open until the traceback is dumped or *note
     cancel_dump_traceback_later(): 2d0c. is called: see *note issue
     with file descriptors: 2d08.

     This function is implemented using a watchdog thread and therefore
     is not available if Python is compiled with threads disabled.

     Changed in version 3.5: Added support for passing file descriptor
     to this function.

 -- Function: faulthandler.cancel_dump_traceback_later ()

     Cancel the last call to *note dump_traceback_later(): 28a.


File: python.info,  Node: Dumping the traceback on a user signal,  Next: Issue with file descriptors,  Prev: Dumping the tracebacks after a timeout,  Up: faulthandler --- Dump the Python traceback

5.27.2.4 Dumping the traceback on a user signal
...............................................

 -- Function: faulthandler.register (signum, file=sys.stderr,
          all_threads=True, chain=False)

     Register a user signal: install a handler for the `signum' signal
     to dump the traceback of all threads, or of the current thread if
     `all_threads' is ‘False’, into `file'.  Call the previous handler
     if chain is ‘True’.

     The `file' must be kept open until the signal is unregistered by
     *note unregister(): 2d0e.: see *note issue with file descriptors:
     2d08.

     Not available on Windows.

     Changed in version 3.5: Added support for passing file descriptor
     to this function.

 -- Function: faulthandler.unregister (signum)

     Unregister a user signal: uninstall the handler of the `signum'
     signal installed by *note register(): 288.  Return ‘True’ if the
     signal was registered, ‘False’ otherwise.

     Not available on Windows.


File: python.info,  Node: Issue with file descriptors,  Next: Example<13>,  Prev: Dumping the traceback on a user signal,  Up: faulthandler --- Dump the Python traceback

5.27.2.5 Issue with file descriptors
....................................

*note enable(): 161, *note dump_traceback_later(): 28a. and *note
register(): 288. keep the file descriptor of their `file' argument.  If
the file is closed and its file descriptor is reused by a new file, or
if *note os.dup2(): 204. is used to replace the file descriptor, the
traceback will be written into a different file.  Call these functions
again each time that the file is replaced.


File: python.info,  Node: Example<13>,  Prev: Issue with file descriptors,  Up: faulthandler --- Dump the Python traceback

5.27.2.6 Example
................

Example of a segmentation fault on Linux with and without enabling the
fault handler:

     $ python3 -c "import ctypes; ctypes.string_at(0)"
     Segmentation fault

     $ python3 -q -X faulthandler
     >>> import ctypes
     >>> ctypes.string_at(0)
     Fatal Python error: Segmentation fault

     Current thread 0x00007fb899f39700 (most recent call first):
       File "/home/python/cpython/Lib/ctypes/__init__.py", line 486 in string_at
       File "<stdin>", line 1 in <module>
     Segmentation fault


File: python.info,  Node: pdb --- The Python Debugger,  Next: The Python Profilers,  Prev: faulthandler --- Dump the Python traceback,  Up: Debugging and Profiling

5.27.3 ‘pdb’ — The Python Debugger
----------------------------------

`Source code:' Lib/pdb.py(1)

__________________________________________________________________

The module *note pdb: c7. defines an interactive source code debugger
for Python programs.  It supports setting (conditional) breakpoints and
single stepping at the source line level, inspection of stack frames,
source code listing, and evaluation of arbitrary Python code in the
context of any stack frame.  It also supports post-mortem debugging and
can be called under program control.

The debugger is extensible – it is actually defined as the class *note
Pdb: 2cda.  This is currently undocumented but easily understood by
reading the source.  The extension interface uses the modules *note bdb:
f. and *note cmd: 1a.

The debugger’s prompt is ‘(Pdb)’.  Typical usage to run a program under
control of the debugger is:

     >>> import pdb
     >>> import mymodule
     >>> pdb.run('mymodule.test()')
     > <string>(0)?()
     (Pdb) continue
     > <string>(1)?()
     (Pdb) continue
     NameError: 'spam'
     > <string>(1)?()
     (Pdb)

Changed in version 3.3: Tab-completion via the *note readline: dc.
module is available for commands and command arguments, e.g.  the
current global and local names are offered as arguments of the ‘p’
command.

‘pdb.py’ can also be invoked as a script to debug other scripts.  For
example:

     python3 -m pdb myscript.py

When invoked as a script, pdb will automatically enter post-mortem
debugging if the program being debugged exits abnormally.  After
post-mortem debugging (or after normal exit of the program), pdb will
restart the program.  Automatic restarting preserves pdb’s state (such
as breakpoints) and in most cases is more useful than quitting the
debugger upon program’s exit.

New in version 3.2: ‘pdb.py’ now accepts a ‘-c’ option that executes
commands as if given in a ‘.pdbrc’ file, see *note Debugger Commands:
2d14.

The typical usage to break into the debugger from a running program is
to insert

     import pdb; pdb.set_trace()

at the location you want to break into the debugger.  You can then step
through the code following this statement, and continue running without
the debugger using the *note continue: 2d15. command.

The typical usage to inspect a crashed program is:

     >>> import pdb
     >>> import mymodule
     >>> mymodule.test()
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
       File "./mymodule.py", line 4, in test
         test2()
       File "./mymodule.py", line 3, in test2
         print(spam)
     NameError: spam
     >>> pdb.pm()
     > ./mymodule.py(3)test2()
     -> print(spam)
     (Pdb)

The module defines the following functions; each enters the debugger in
a slightly different way:

 -- Function: pdb.run (statement, globals=None, locals=None)

     Execute the `statement' (given as a string or a code object) under
     debugger control.  The debugger prompt appears before any code is
     executed; you can set breakpoints and type *note continue: 2d15, or
     you can step through the statement using *note step: 2d16. or *note
     next: 2d17. (all these commands are explained below).  The optional
     `globals' and `locals' arguments specify the environment in which
     the code is executed; by default the dictionary of the module *note
     __main__: 1. is used.  (See the explanation of the built-in *note
     exec(): 8ac. or *note eval(): 7e8. functions.)

 -- Function: pdb.runeval (expression, globals=None, locals=None)

     Evaluate the `expression' (given as a string or a code object)
     under debugger control.  When *note runeval(): 2d18. returns, it
     returns the value of the expression.  Otherwise this function is
     similar to *note run(): 2b91.

 -- Function: pdb.runcall (function, *args, **kwds)

     Call the `function' (a function or method object, not a string)
     with the given arguments.  When *note runcall(): 2d19. returns, it
     returns whatever the function call returned.  The debugger prompt
     appears as soon as the function is entered.

 -- Function: pdb.set_trace ()

     Enter the debugger at the calling stack frame.  This is useful to
     hard-code a breakpoint at a given point in a program, even if the
     code is not otherwise being debugged (e.g.  when an assertion
     fails).

 -- Function: pdb.post_mortem (traceback=None)

     Enter post-mortem debugging of the given `traceback' object.  If no
     `traceback' is given, it uses the one of the exception that is
     currently being handled (an exception must be being handled if the
     default is to be used).

 -- Function: pdb.pm ()

     Enter post-mortem debugging of the traceback found in *note
     sys.last_traceback: 2d1b.

The ‘run*’ functions and *note set_trace(): 2b8e. are aliases for
instantiating the *note Pdb: 2cda. class and calling the method of the
same name.  If you want to access further features, you have to do this
yourself:

 -- Class: pdb.Pdb (completekey='tab', stdin=None, stdout=None,
          skip=None, nosigint=False)

     *note Pdb: 2cda. is the debugger class.

     The `completekey', `stdin' and `stdout' arguments are passed to the
     underlying *note cmd.Cmd: 29e7. class; see the description there.

     The `skip' argument, if given, must be an iterable of glob-style
     module name patterns.  The debugger will not step into frames that
     originate in a module that matches one of these patterns.  (2)

     By default, Pdb sets a handler for the SIGINT signal (which is sent
     when the user presses ‘Ctrl-C’ on the console) when you give a
     ‘continue’ command.  This allows you to break into the debugger
     again by pressing ‘Ctrl-C’.  If you want Pdb not to touch the
     SIGINT handler, set `nosigint' tot true.

     Example call to enable tracing with `skip':

          import pdb; pdb.Pdb(skip=['django.*']).set_trace()

     New in version 3.1: The `skip' argument.

     New in version 3.2: The `nosigint' argument.  Previously, a SIGINT
     handler was never set by Pdb.

      -- Method: run (statement, globals=None, locals=None)
      -- Method: runeval (expression, globals=None, locals=None)
      -- Method: runcall (function, *args, **kwds)
      -- Method: set_trace ()

          See the documentation for the functions explained above.

* Menu:

* Debugger Commands:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/pdb.py

   (2) Whether a frame is considered to originate in a certain module is
determined by the ‘__name__’ in the frame globals.


File: python.info,  Node: Debugger Commands,  Up: pdb --- The Python Debugger

5.27.3.1 Debugger Commands
..........................

The commands recognized by the debugger are listed below.  Most commands
can be abbreviated to one or two letters as indicated; e.g.  ‘h(elp)’
means that either ‘h’ or ‘help’ can be used to enter the help command
(but not ‘he’ or ‘hel’, nor ‘H’ or ‘Help’ or ‘HELP’).  Arguments to
commands must be separated by whitespace (spaces or tabs).  Optional
arguments are enclosed in square brackets (‘[]’) in the command syntax;
the square brackets must not be typed.  Alternatives in the command
syntax are separated by a vertical bar (‘|’).

Entering a blank line repeats the last command entered.  Exception: if
the last command was a *note list: 2d21. command, the next 11 lines are
listed.

Commands that the debugger doesn’t recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point (‘!’).  This is a powerful way to inspect the program being
debugged; it is even possible to change a variable or call a function.
When an exception occurs in such a statement, the exception name is
printed but the debugger’s state is not changed.

The debugger supports *note aliases: 2d22.  Aliases can have parameters
which allows one a certain level of adaptability to the context under
examination.

Multiple commands may be entered on a single line, separated by ‘;;’.
(A single ‘;’ is not used as it is the separator for multiple commands
in a line that is passed to the Python parser.)  No intelligence is
applied to separating the commands; the input is split at the first ‘;;’
pair, even if it is in the middle of a quoted string.

If a file ‘.pdbrc’ exists in the user’s home directory or in the current
directory, it is read in and executed as if it had been typed at the
debugger prompt.  This is particularly useful for aliases.  If both
files exist, the one in the home directory is read first and aliases
defined there can be overridden by the local file.

Changed in version 3.2: ‘.pdbrc’ can now contain commands that continue
debugging, such as *note continue: 2d15. or *note next: 2d17.
Previously, these commands had no effect.

 -- Pdbcommand: h(elp) [command]

     Without argument, print the list of available commands.  With a
     `command' as argument, print help about that command.  ‘help pdb’
     displays the full documentation (the docstring of the *note pdb:
     c7. module).  Since the `command' argument must be an identifier,
     ‘help exec’ must be entered to get help on the ‘!’ command.

 -- Pdbcommand: w(here)

     Print a stack trace, with the most recent frame at the bottom.  An
     arrow indicates the current frame, which determines the context of
     most commands.

 -- Pdbcommand: d(own) [count]

     Move the current frame `count' (default one) levels down in the
     stack trace (to a newer frame).

 -- Pdbcommand: u(p) [count]

     Move the current frame `count' (default one) levels up in the stack
     trace (to an older frame).

 -- Pdbcommand: b(reak) [([filename:]lineno | function) [, condition]]

     With a `lineno' argument, set a break there in the current file.
     With a `function' argument, set a break at the first executable
     statement within that function.  The line number may be prefixed
     with a filename and a colon, to specify a breakpoint in another
     file (probably one that hasn’t been loaded yet).  The file is
     searched on *note sys.path: 16c.  Note that each breakpoint is
     assigned a number to which all the other breakpoint commands refer.

     If a second argument is present, it is an expression which must
     evaluate to true before the breakpoint is honored.

     Without argument, list all breaks, including for each breakpoint,
     the number of times that breakpoint has been hit, the current
     ignore count, and the associated condition if any.

 -- Pdbcommand: tbreak [([filename:]lineno | function) [, condition]]

     Temporary breakpoint, which is removed automatically when it is
     first hit.  The arguments are the same as for *note break: 2d27.

 -- Pdbcommand: cl(ear) [filename:lineno | bpnumber [bpnumber ...]]

     With a `filename:lineno' argument, clear all the breakpoints at
     this line.  With a space separated list of breakpoint numbers,
     clear those breakpoints.  Without argument, clear all breaks (but
     first ask confirmation).

 -- Pdbcommand: disable [bpnumber [bpnumber ...]]

     Disable the breakpoints given as a space separated list of
     breakpoint numbers.  Disabling a breakpoint means it cannot cause
     the program to stop execution, but unlike clearing a breakpoint, it
     remains in the list of breakpoints and can be (re-)enabled.

 -- Pdbcommand: enable [bpnumber [bpnumber ...]]

     Enable the breakpoints specified.

 -- Pdbcommand: ignore bpnumber [count]

     Set the ignore count for the given breakpoint number.  If count is
     omitted, the ignore count is set to 0.  A breakpoint becomes active
     when the ignore count is zero.  When non-zero, the count is
     decremented each time the breakpoint is reached and the breakpoint
     is not disabled and any associated condition evaluates to true.

 -- Pdbcommand: condition bpnumber [condition]

     Set a new `condition' for the breakpoint, an expression which must
     evaluate to true before the breakpoint is honored.  If `condition'
     is absent, any existing condition is removed; i.e., the breakpoint
     is made unconditional.

 -- Pdbcommand: commands [bpnumber]

     Specify a list of commands for breakpoint number `bpnumber'.  The
     commands themselves appear on the following lines.  Type a line
     containing just ‘end’ to terminate the commands.  An example:

          (Pdb) commands 1
          (com) p some_variable
          (com) end
          (Pdb)

     To remove all commands from a breakpoint, type commands and follow
     it immediately with ‘end’; that is, give no commands.

     With no `bpnumber' argument, commands refers to the last breakpoint
     set.

     You can use breakpoint commands to start your program up again.
     Simply use the continue command, or step, or any other command that
     resumes execution.

     Specifying any command resuming execution (currently continue,
     step, next, return, jump, quit and their abbreviations) terminates
     the command list (as if that command was immediately followed by
     end).  This is because any time you resume execution (even with a
     simple next or step), you may encounter another breakpoint–which
     could have its own command list, leading to ambiguities about which
     list to execute.

     If you use the ’silent’ command in the command list, the usual
     message about stopping at a breakpoint is not printed.  This may be
     desirable for breakpoints that are to print a specific message and
     then continue.  If none of the other commands print anything, you
     see no sign that the breakpoint was reached.

 -- Pdbcommand: s(tep)

     Execute the current line, stop at the first possible occasion
     (either in a function that is called or on the next line in the
     current function).

 -- Pdbcommand: n(ext)

     Continue execution until the next line in the current function is
     reached or it returns.  (The difference between *note next: 2d17.
     and *note step: 2d16. is that *note step: 2d16. stops inside a
     called function, while *note next: 2d17. executes called functions
     at (nearly) full speed, only stopping at the next line in the
     current function.)

 -- Pdbcommand: unt(il) [lineno]

     Without argument, continue execution until the line with a number
     greater than the current one is reached.

     With a line number, continue execution until a line with a number
     greater or equal to that is reached.  In both cases, also stop when
     the current frame returns.

     Changed in version 3.2: Allow giving an explicit line number.

 -- Pdbcommand: r(eturn)

     Continue execution until the current function returns.

 -- Pdbcommand: c(ont(inue))

     Continue execution, only stop when a breakpoint is encountered.

 -- Pdbcommand: j(ump) lineno

     Set the next line that will be executed.  Only available in the
     bottom-most frame.  This lets you jump back and execute code again,
     or jump forward to skip code that you don’t want to run.

     It should be noted that not all jumps are allowed – for instance it
     is not possible to jump into the middle of a *note for: 895. loop
     or out of a *note finally: 526. clause.

 -- Pdbcommand: l(ist) [first[, last]]

     List source code for the current file.  Without arguments, list 11
     lines around the current line or continue the previous listing.
     With ‘.’ as argument, list 11 lines around the current line.  With
     one argument, list 11 lines around at that line.  With two
     arguments, list the given range; if the second argument is less
     than the first, it is interpreted as a count.

     The current line in the current frame is indicated by ‘->’.  If an
     exception is being debugged, the line where the exception was
     originally raised or propagated is indicated by ‘>>’, if it differs
     from the current line.

     New in version 3.2: The ‘>>’ marker.

 -- Pdbcommand: ll | longlist

     List all source code for the current function or frame.
     Interesting lines are marked as for *note list: 2d21.

     New in version 3.2.

 -- Pdbcommand: a(rgs)

     Print the argument list of the current function.

 -- Pdbcommand: p expression

     Evaluate the `expression' in the current context and print its
     value.

          Note: ‘print()’ can also be used, but is not a debugger
          command — this executes the Python *note print(): 481.
          function.

 -- Pdbcommand: pp expression

     Like the *note p: 482. command, except the value of the expression
     is pretty-printed using the *note pprint: d0. module.

 -- Pdbcommand: whatis expression

     Print the type of the `expression'.

 -- Pdbcommand: source expression

     Try to get source code for the given object and display it.

     New in version 3.2.

 -- Pdbcommand: display [expression]

     Display the value of the expression if it changed, each time
     execution stops in the current frame.

     Without expression, list all display expressions for the current
     frame.

     New in version 3.2.

 -- Pdbcommand: undisplay [expression]

     Do not display the expression any more in the current frame.
     Without expression, clear all display expressions for the current
     frame.

     New in version 3.2.

 -- Pdbcommand: interact

     Start an interative interpreter (using the *note code: 1b. module)
     whose global namespace contains all the (global and local) names
     found in the current scope.

     New in version 3.2.

 -- Pdbcommand: alias [name [command]]

     Create an alias called `name' that executes `command'.  The command
     must `not' be enclosed in quotes.  Replaceable parameters can be
     indicated by ‘%1’, ‘%2’, and so on, while ‘%*’ is replaced by all
     the parameters.  If no command is given, the current alias for
     `name' is shown.  If no arguments are given, all aliases are
     listed.

     Aliases may be nested and can contain anything that can be legally
     typed at the pdb prompt.  Note that internal pdb commands `can' be
     overridden by aliases.  Such a command is then hidden until the
     alias is removed.  Aliasing is recursively applied to the first
     word of the command line; all other words in the line are left
     alone.

     As an example, here are two useful aliases (especially when placed
     in the ‘.pdbrc’ file):

          # Print instance variables (usage "pi classInst")
          alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])
          # Print instance variables in self
          alias ps pi self

 -- Pdbcommand: unalias name

     Delete the specified alias.

 -- Pdbcommand: ! statement

     Execute the (one-line) `statement' in the context of the current
     stack frame.  The exclamation point can be omitted unless the first
     word of the statement resembles a debugger command.  To set a
     global variable, you can prefix the assignment command with a *note
     global: c0b. statement on the same line, e.g.:

          (Pdb) global list_options; list_options = ['-l']
          (Pdb)

 -- Pdbcommand: run [args ...]
 -- Pdbcommand: restart [args ...]

     Restart the debugged Python program.  If an argument is supplied,
     it is split with *note shlex: e6. and the result is used as the new
     *note sys.argv: 85c.  History, breakpoints, actions and debugger
     options are preserved.  *note restart: 2d3e. is an alias for *note
     run: 2d3d.

 -- Pdbcommand: q(uit)

     Quit from the debugger.  The program being executed is aborted.


File: python.info,  Node: The Python Profilers,  Next: timeit --- Measure execution time of small code snippets,  Prev: pdb --- The Python Debugger,  Up: Debugging and Profiling

5.27.4 The Python Profilers
---------------------------

`Source code:' Lib/profile.py(1) and Lib/pstats.py(2)

__________________________________________________________________

* Menu:

* Introduction to the profilers:: 
* Instant User's Manual:: 
* profile and cProfile Module Reference:: 
* The Stats Class:: 
* What Is Deterministic Profiling?:: 
* Limitations:: 
* Calibration:: 
* Using a custom timer:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/profile.py

   (2) https://hg.python.org/cpython/file/default/Lib/pstats.py


File: python.info,  Node: Introduction to the profilers,  Next: Instant User's Manual,  Up: The Python Profilers

5.27.4.1 Introduction to the profilers
......................................

*note cProfile: 27. and *note profile: d1. provide `deterministic
profiling' of Python programs.  A `profile' is a set of statistics that
describes how often and for how long various parts of the program
executed.  These statistics can be formatted into reports via the *note
pstats: d2. module.

The Python standard library provides two different implementations of
the same profiling interface:

  1. *note cProfile: 27. is recommended for most users; it’s a C
     extension with reasonable overhead that makes it suitable for
     profiling long-running programs.  Based on ‘lsprof’, contributed by
     Brett Rosen and Ted Czotter.

  2. *note profile: d1, a pure Python module whose interface is imitated
     by *note cProfile: 27, but which adds significant overhead to
     profiled programs.  If you’re trying to extend the profiler in some
     way, the task might be easier with this module.  Originally
     designed and written by Jim Roskind.

     Note: The profiler modules are designed to provide an execution
     profile for a given program, not for benchmarking purposes (for
     that, there is *note timeit: 108. for reasonably accurate results).
     This particularly applies to benchmarking Python code against C
     code: the profilers introduce overhead for Python code, but not for
     C-level functions, and so the C code would seem faster than any
     Python one.


File: python.info,  Node: Instant User's Manual,  Next: profile and cProfile Module Reference,  Prev: Introduction to the profilers,  Up: The Python Profilers

5.27.4.2 Instant User’s Manual
..............................

This section is provided for users that "don’t want to read the manual."
It provides a very brief overview, and allows a user to rapidly perform
profiling on an existing application.

To profile a function that takes a single argument, you can do:

     import cProfile
     import re
     cProfile.run('re.compile("foo|bar")')

(Use *note profile: d1. instead of *note cProfile: 27. if the latter is
not available on your system.)

The above action would run *note re.compile(): 110d. and print profile
results like the following:

           197 function calls (192 primitive calls) in 0.002 seconds

     Ordered by: standard name

     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
          1    0.000    0.000    0.001    0.001 <string>:1(<module>)
          1    0.000    0.000    0.001    0.001 re.py:212(compile)
          1    0.000    0.000    0.001    0.001 re.py:268(_compile)
          1    0.000    0.000    0.000    0.000 sre_compile.py:172(_compile_charset)
          1    0.000    0.000    0.000    0.000 sre_compile.py:201(_optimize_charset)
          4    0.000    0.000    0.000    0.000 sre_compile.py:25(_identityfunction)
        3/1    0.000    0.000    0.000    0.000 sre_compile.py:33(_compile)

The first line indicates that 197 calls were monitored.  Of those calls,
192 were `primitive', meaning that the call was not induced via
recursion.  The next line: ‘Ordered by: standard name’, indicates that
the text string in the far right column was used to sort the output.
The column headings include:

ncalls

     for the number of calls,

tottime

     for the total time spent in the given function (and excluding time
     made in calls to sub-functions)

percall

     is the quotient of ‘tottime’ divided by ‘ncalls’

cumtime

     is the cumulative time spent in this and all subfunctions (from
     invocation till exit).  This figure is accurate `even' for
     recursive functions.

percall

     is the quotient of ‘cumtime’ divided by primitive calls

filename:lineno(function)

     provides the respective data of each function

When there are two numbers in the first column (for example ‘3/1’), it
means that the function recursed.  The second value is the number of
primitive calls and the former is the total number of calls.  Note that
when the function does not recurse, these two values are the same, and
only the single figure is printed.

Instead of printing the output at the end of the profile run, you can
save the results to a file by specifying a filename to the ‘run()’
function:

     import cProfile
     import re
     cProfile.run('re.compile("foo|bar")', 'restats')

The *note pstats.Stats: 2d47. class reads profile results from a file
and formats them in various ways.

The file *note cProfile: 27. can also be invoked as a script to profile
another script.  For example:

     python -m cProfile [-o output_file] [-s sort_order] myscript.py

‘-o’ writes the profile results to a file instead of to stdout

‘-s’ specifies one of the *note sort_stats(): 2d48. sort values to sort
the output by.  This only applies when ‘-o’ is not supplied.

The *note pstats: d2. module’s *note Stats: 2d47. class has a variety of
methods for manipulating and printing the data saved into a profile
results file:

     import pstats
     p = pstats.Stats('restats')
     p.strip_dirs().sort_stats(-1).print_stats()

The *note strip_dirs(): 2d49. method removed the extraneous path from
all the module names.  The *note sort_stats(): 2d48. method sorted all
the entries according to the standard module/line/name string that is
printed.  The *note print_stats(): 2d4a. method printed out all the
statistics.  You might try the following sort calls:

     p.sort_stats('name')
     p.print_stats()

The first call will actually sort the list by function name, and the
second call will print out the statistics.  The following are some
interesting calls to experiment with:

     p.sort_stats('cumulative').print_stats(10)

This sorts the profile by cumulative time in a function, and then only
prints the ten most significant lines.  If you want to understand what
algorithms are taking time, the above line is what you would use.

If you were looking to see what functions were looping a lot, and taking
a lot of time, you would do:

     p.sort_stats('time').print_stats(10)

to sort according to time spent within each function, and then print the
statistics for the top ten functions.

You might also try:

     p.sort_stats('file').print_stats('__init__')

This will sort all the statistics by file name, and then print out
statistics for only the class init methods (since they are spelled with
‘__init__’ in them).  As one final example, you could try:

     p.sort_stats('time', 'cumulative').print_stats(.5, 'init')

This line sorts statistics with a primary key of time, and a secondary
key of cumulative time, and then prints out some of the statistics.  To
be specific, the list is first culled down to 50% (re: ‘.5’) of its
original size, then only lines containing ‘init’ are maintained, and
that sub-sub-list is printed.

If you wondered what functions called the above functions, you could now
(‘p’ is still sorted according to the last criteria) do:

     p.print_callers(.5, 'init')

and you would get a list of callers for each of the listed functions.

If you want more functionality, you’re going to have to read the manual,
or guess what the following functions do:

     p.print_callees()
     p.add('restats')

Invoked as a script, the *note pstats: d2. module is a statistics
browser for reading and examining profile dumps.  It has a simple
line-oriented interface (implemented using *note cmd: 1a.) and
interactive help.


File: python.info,  Node: profile and cProfile Module Reference,  Next: The Stats Class,  Prev: Instant User's Manual,  Up: The Python Profilers

5.27.4.3 ‘profile’ and ‘cProfile’ Module Reference
..................................................

Both the *note profile: d1. and *note cProfile: 27. modules provide the
following functions:

 -- Function: profile.run (command, filename=None, sort=-1)

     This function takes a single argument that can be passed to the
     *note exec(): 8ac. function, and an optional file name.  In all
     cases this routine executes:

          exec(command, __main__.__dict__, __main__.__dict__)

     and gathers profiling statistics from the execution.  If no file
     name is present, then this function automatically creates a *note
     Stats: 2d47. instance and prints a simple profiling report.  If the
     sort value is specified it is passed to this *note Stats: 2d47.
     instance to control how the results are sorted.

 -- Function: profile.runctx (command, globals, locals, filename=None)

     This function is similar to *note run(): 2d4c, with added arguments
     to supply the globals and locals dictionaries for the `command'
     string.  This routine executes:

          exec(command, globals, locals)

     and gathers profiling statistics as in the *note run(): 2d4c.
     function above.

 -- Class: profile.Profile (timer=None, timeunit=0.0, subcalls=True,
          builtins=True)

     This class is normally only used if more precise control over
     profiling is needed than what the ‘cProfile.run()’ function
     provides.

     A custom timer can be supplied for measuring how long code takes to
     run via the `timer' argument.  This must be a function that returns
     a single number representing the current time.  If the number is an
     integer, the `timeunit' specifies a multiplier that specifies the
     duration of each unit of time.  For example, if the timer returns
     times measured in thousands of seconds, the time unit would be
     ‘.001’.

     Directly using the *note Profile: 2d4e. class allows formatting
     profile results without writing the profile data to a file:

          import cProfile, pstats, io
          pr = cProfile.Profile()
          pr.enable()
          # ... do something ...
          pr.disable()
          s = io.StringIO()
          sortby = 'cumulative'
          ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
          ps.print_stats()
          print(s.getvalue())

      -- Method: enable ()

          Start collecting profiling data.

      -- Method: disable ()

          Stop collecting profiling data.

      -- Method: create_stats ()

          Stop collecting profiling data and record the results
          internally as the current profile.

      -- Method: print_stats (sort=-1)

          Create a *note Stats: 2d47. object based on the current
          profile and print the results to stdout.

      -- Method: dump_stats (filename)

          Write the results of the current profile to `filename'.

      -- Method: run (cmd)

          Profile the cmd via *note exec(): 8ac.

      -- Method: runctx (cmd, globals, locals)

          Profile the cmd via *note exec(): 8ac. with the specified
          global and local environment.

      -- Method: runcall (func, *args, **kwargs)

          Profile ‘func(*args, **kwargs)’


File: python.info,  Node: The Stats Class,  Next: What Is Deterministic Profiling?,  Prev: profile and cProfile Module Reference,  Up: The Python Profilers

5.27.4.4 The ‘Stats’ Class
..........................

Analysis of the profiler data is done using the *note Stats: 2d47.
class.

 -- Class: pstats.Stats (*filenames or profile, stream=sys.stdout)

     This class constructor creates an instance of a "statistics object"
     from a `filename' (or list of filenames) or from a ‘Profile’
     instance.  Output will be printed to the stream specified by
     `stream'.

     The file selected by the above constructor must have been created
     by the corresponding version of *note profile: d1. or *note
     cProfile: 27.  To be specific, there is `no' file compatibility
     guaranteed with future versions of this profiler, and there is no
     compatibility with files produced by other profilers.  If several
     files are provided, all the statistics for identical functions will
     be coalesced, so that an overall view of several processes can be
     considered in a single report.  If additional files need to be
     combined with data in an existing *note Stats: 2d47. object, the
     *note add(): 2d59. method can be used.

     Instead of reading the profile data from a file, a
     ‘cProfile.Profile’ or *note profile.Profile: 2d4e. object can be
     used as the profile data source.

     *note Stats: 2d47. objects have the following methods:

      -- Method: strip_dirs ()

          This method for the *note Stats: 2d47. class removes all
          leading path information from file names.  It is very useful
          in reducing the size of the printout to fit within (close to)
          80 columns.  This method modifies the object, and the stripped
          information is lost.  After performing a strip operation, the
          object is considered to have its entries in a "random" order,
          as it was just after object initialization and loading.  If
          *note strip_dirs(): 2d49. causes two function names to be
          indistinguishable (they are on the same line of the same
          filename, and have the same function name), then the
          statistics for these two entries are accumulated into a single
          entry.

      -- Method: add (*filenames)

          This method of the *note Stats: 2d47. class accumulates
          additional profiling information into the current profiling
          object.  Its arguments should refer to filenames created by
          the corresponding version of *note profile.run(): 2d4c. or
          ‘cProfile.run()’.  Statistics for identically named (re: file,
          line, name) functions are automatically accumulated into
          single function statistics.

      -- Method: dump_stats (filename)

          Save the data loaded into the *note Stats: 2d47. object to a
          file named `filename'.  The file is created if it does not
          exist, and is overwritten if it already exists.  This is
          equivalent to the method of the same name on the *note
          profile.Profile: 2d4e. and ‘cProfile.Profile’ classes.

      -- Method: sort_stats (*keys)

          This method modifies the *note Stats: 2d47. object by sorting
          it according to the supplied criteria.  The argument is
          typically a string identifying the basis of a sort (example:
          ‘'time'’ or ‘'name'’).

          When more than one key is provided, then additional keys are
          used as secondary criteria when there is equality in all keys
          selected before them.  For example, ‘sort_stats('name',
          'file')’ will sort all the entries according to their function
          name, and resolve all ties (identical function names) by
          sorting by file name.

          Abbreviations can be used for any key names, as long as the
          abbreviation is unambiguous.  The following are the keys
          currently defined:

          Valid Arg              Meaning
                                 
          --------------------------------------------------
                                 
          ‘'calls'’              call count
                                 
                                 
          ‘'cumulative'’         cumulative time
                                 
                                 
          ‘'cumtime'’            cumulative time
                                 
                                 
          ‘'file'’               file name
                                 
                                 
          ‘'filename'’           file name
                                 
                                 
          ‘'module'’             file name
                                 
                                 
          ‘'ncalls'’             call count
                                 
                                 
          ‘'pcalls'’             primitive call count
                                 
                                 
          ‘'line'’               line number
                                 
                                 
          ‘'name'’               function name
                                 
                                 
          ‘'nfl'’                name/file/line
                                 
                                 
          ‘'stdname'’            standard name
                                 
                                 
          ‘'time'’               internal time
                                 
                                 
          ‘'tottime'’            internal time
                                 

          Note that all sorts on statistics are in descending order
          (placing most time consuming items first), where as name,
          file, and line number searches are in ascending order
          (alphabetical).  The subtle distinction between ‘'nfl'’ and
          ‘'stdname'’ is that the standard name is a sort of the name as
          printed, which means that the embedded line numbers get
          compared in an odd way.  For example, lines 3, 20, and 40
          would (if the file names were the same) appear in the string
          order 20, 3 and 40.  In contrast, ‘'nfl'’ does a numeric
          compare of the line numbers.  In fact, ‘sort_stats('nfl')’ is
          the same as ‘sort_stats('name', 'file', 'line')’.

          For backward-compatibility reasons, the numeric arguments
          ‘-1’, ‘0’, ‘1’, and ‘2’ are permitted.  They are interpreted
          as ‘'stdname'’, ‘'calls'’, ‘'time'’, and ‘'cumulative'’
          respectively.  If this old style format (numeric) is used,
          only one sort key (the numeric key) will be used, and
          additional arguments will be silently ignored.

      -- Method: reverse_order ()

          This method for the *note Stats: 2d47. class reverses the
          ordering of the basic list within the object.  Note that by
          default ascending vs descending order is properly selected
          based on the sort key of choice.

      -- Method: print_stats (*restrictions)

          This method for the *note Stats: 2d47. class prints out a
          report as described in the *note profile.run(): 2d4c.
          definition.

          The order of the printing is based on the last *note
          sort_stats(): 2d48. operation done on the object (subject to
          caveats in *note add(): 2d59. and *note strip_dirs(): 2d49.).

          The arguments provided (if any) can be used to limit the list
          down to the significant entries.  Initially, the list is taken
          to be the complete set of profiled functions.  Each
          restriction is either an integer (to select a count of lines),
          or a decimal fraction between 0.0 and 1.0 inclusive (to select
          a percentage of lines), or a regular expression (to pattern
          match the standard name that is printed.  If several
          restrictions are provided, then they are applied sequentially.
          For example:

               print_stats(.1, 'foo:')

          would first limit the printing to first 10% of list, and then
          only print functions that were part of filename ‘.*foo:’.  In
          contrast, the command:

               print_stats('foo:', .1)

          would limit the list to all functions having file names
          ‘.*foo:’, and then proceed to only print the first 10% of
          them.

      -- Method: print_callers (*restrictions)

          This method for the *note Stats: 2d47. class prints a list of
          all functions that called each function in the profiled
          database.  The ordering is identical to that provided by *note
          print_stats(): 2d4a, and the definition of the restricting
          argument is also identical.  Each caller is reported on its
          own line.  The format differs slightly depending on the
          profiler that produced the stats:

             * With *note profile: d1, a number is shown in parentheses
               after each caller to show how many times this specific
               call was made.  For convenience, a second
               non-parenthesized number repeats the cumulative time
               spent in the function at the right.

             * With *note cProfile: 27, each caller is preceded by three
               numbers: the number of times this specific call was made,
               and the total and cumulative times spent in the current
               function while it was invoked by this specific caller.

      -- Method: print_callees (*restrictions)

          This method for the *note Stats: 2d47. class prints a list of
          all function that were called by the indicated function.
          Aside from this reversal of direction of calls (re: called vs
          was called by), the arguments and ordering are identical to
          the *note print_callers(): 2d5c. method.


File: python.info,  Node: What Is Deterministic Profiling?,  Next: Limitations,  Prev: The Stats Class,  Up: The Python Profilers

5.27.4.5 What Is Deterministic Profiling?
.........................................

`Deterministic profiling' is meant to reflect the fact that all
`function call', `function return', and `exception' events are
monitored, and precise timings are made for the intervals between these
events (during which time the user’s code is executing).  In contrast,
`statistical profiling' (which is not done by this module) randomly
samples the effective instruction pointer, and deduces where time is
being spent.  The latter technique traditionally involves less overhead
(as the code does not need to be instrumented), but provides only
relative indications of where time is being spent.

In Python, since there is an interpreter active during execution, the
presence of instrumented code is not required to do deterministic
profiling.  Python automatically provides a `hook' (optional callback)
for each event.  In addition, the interpreted nature of Python tends to
add so much overhead to execution, that deterministic profiling tends to
only add small processing overhead in typical applications.  The result
is that deterministic profiling is not that expensive, yet provides
extensive run time statistics about the execution of a Python program.

Call count statistics can be used to identify bugs in code (surprising
counts), and to identify possible inline-expansion points (high call
counts).  Internal time statistics can be used to identify "hot loops"
that should be carefully optimized.  Cumulative time statistics should
be used to identify high level errors in the selection of algorithms.
Note that the unusual handling of cumulative times in this profiler
allows statistics for recursive implementations of algorithms to be
directly compared to iterative implementations.


File: python.info,  Node: Limitations,  Next: Calibration,  Prev: What Is Deterministic Profiling?,  Up: The Python Profilers

5.27.4.6 Limitations
....................

One limitation has to do with accuracy of timing information.  There is
a fundamental problem with deterministic profilers involving accuracy.
The most obvious restriction is that the underlying "clock" is only
ticking at a rate (typically) of about .001 seconds.  Hence no
measurements will be more accurate than the underlying clock.  If enough
measurements are taken, then the "error" will tend to average out.
Unfortunately, removing this first error induces a second source of
error.

The second problem is that it "takes a while" from when an event is
dispatched until the profiler’s call to get the time actually `gets' the
state of the clock.  Similarly, there is a certain lag when exiting the
profiler event handler from the time that the clock’s value was obtained
(and then squirreled away), until the user’s code is once again
executing.  As a result, functions that are called many times, or call
many functions, will typically accumulate this error.  The error that
accumulates in this fashion is typically less than the accuracy of the
clock (less than one clock tick), but it `can' accumulate and become
very significant.

The problem is more important with *note profile: d1. than with the
lower-overhead *note cProfile: 27.  For this reason, *note profile: d1.
provides a means of calibrating itself for a given platform so that this
error can be probabilistically (on the average) removed.  After the
profiler is calibrated, it will be more accurate (in a least square
sense), but it will sometimes produce negative numbers (when call counts
are exceptionally low, and the gods of probability work against you :-).
)  Do `not' be alarmed by negative numbers in the profile.  They should
`only' appear if you have calibrated your profiler, and the results are
actually better than without calibration.


File: python.info,  Node: Calibration,  Next: Using a custom timer,  Prev: Limitations,  Up: The Python Profilers

5.27.4.7 Calibration
....................

The profiler of the *note profile: d1. module subtracts a constant from
each event handling time to compensate for the overhead of calling the
time function, and socking away the results.  By default, the constant
is 0.  The following procedure can be used to obtain a better constant
for a given platform (see *note Limitations: 2d60.).

     import profile
     pr = profile.Profile()
     for i in range(5):
         print(pr.calibrate(10000))

The method executes the number of Python calls given by the argument,
directly and again under the profiler, measuring the time for both.  It
then computes the hidden overhead per profiler event, and returns that
as a float.  For example, on a 1.8Ghz Intel Core i5 running Mac OS X,
and using Python’s time.clock() as the timer, the magical number is
about 4.04e-6.

The object of this exercise is to get a fairly consistent result.  If
your computer is `very' fast, or your timer function has poor
resolution, you might have to pass 100000, or even 1000000, to get
consistent results.

When you have a consistent answer, there are three ways you can use it:

     import profile

     # 1. Apply computed bias to all Profile instances created hereafter.
     profile.Profile.bias = your_computed_bias

     # 2. Apply computed bias to a specific Profile instance.
     pr = profile.Profile()
     pr.bias = your_computed_bias

     # 3. Specify computed bias in instance constructor.
     pr = profile.Profile(bias=your_computed_bias)

If you have a choice, you are better off choosing a smaller constant,
and then your results will "less often" show up as negative in profile
statistics.


File: python.info,  Node: Using a custom timer,  Prev: Calibration,  Up: The Python Profilers

5.27.4.8 Using a custom timer
.............................

If you want to change how current time is determined (for example, to
force use of wall-clock time or elapsed process time), pass the timing
function you want to the ‘Profile’ class constructor:

     pr = profile.Profile(your_time_func)

The resulting profiler will then call ‘your_time_func’.  Depending on
whether you are using *note profile.Profile: 2d4e. or
‘cProfile.Profile’, ‘your_time_func’’s return value will be interpreted
differently:

*note profile.Profile: 2d4e.

     ‘your_time_func’ should return a single number, or a list of
     numbers whose sum is the current time (like what *note os.times():
     691. returns).  If the function returns a single time number, or
     the list of returned numbers has length 2, then you will get an
     especially fast version of the dispatch routine.

     Be warned that you should calibrate the profiler class for the
     timer function that you choose (see *note Calibration: 2d63.).  For
     most machines, a timer that returns a lone integer value will
     provide the best results in terms of low overhead during profiling.
     (*note os.times(): 691. is `pretty' bad, as it returns a tuple of
     floating point values).  If you want to substitute a better timer
     in the cleanest fashion, derive a class and hardwire a replacement
     dispatch method that best handles your timer call, along with the
     appropriate calibration constant.

‘cProfile.Profile’

     ‘your_time_func’ should return a single number.  If it returns
     integers, you can also invoke the class constructor with a second
     argument specifying the real duration of one unit of time.  For
     example, if ‘your_integer_time_func’ returns times measured in
     thousands of seconds, you would construct the ‘Profile’ instance as
     follows:

          pr = cProfile.Profile(your_integer_time_func, 0.001)

     As the ‘cProfile.Profile’ class cannot be calibrated, custom timer
     functions should be used with care and should be as fast as
     possible.  For the best results with a custom timer, it might be
     necessary to hard-code it in the C source of the internal ‘_lsprof’
     module.

Python 3.3 adds several new functions in *note time: 107. that can be
used to make precise measurements of process or wall-clock time.  For
example, see *note time.perf_counter(): 6ec.


File: python.info,  Node: timeit --- Measure execution time of small code snippets,  Next: trace --- Trace or track Python statement execution,  Prev: The Python Profilers,  Up: Debugging and Profiling

5.27.5 ‘timeit’ — Measure execution time of small code snippets
---------------------------------------------------------------

`Source code:' Lib/timeit.py(1)

__________________________________________________________________

This module provides a simple way to time small bits of Python code.  It
has both a *note Command-Line Interface: 2d68. as well as a *note
callable: 2d69. one.  It avoids a number of common traps for measuring
execution times.  See also Tim Peters’ introduction to the "Algorithms"
chapter in the `Python Cookbook', published by O’Reilly.

* Menu:

* Basic Examples: Basic Examples<2>. 
* Python Interface:: 
* Command-Line Interface: Command-Line Interface<2>. 
* Examples: Examples<19>. 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/timeit.py


File: python.info,  Node: Basic Examples<2>,  Next: Python Interface,  Up: timeit --- Measure execution time of small code snippets

5.27.5.1 Basic Examples
.......................

The following example shows how the *note Command-Line Interface: 2d68.
can be used to compare three different expressions:

     $ python3 -m timeit '"-".join(str(n) for n in range(100))'
     10000 loops, best of 3: 30.2 usec per loop
     $ python3 -m timeit '"-".join([str(n) for n in range(100)])'
     10000 loops, best of 3: 27.5 usec per loop
     $ python3 -m timeit '"-".join(map(str, range(100)))'
     10000 loops, best of 3: 23.2 usec per loop

This can be achieved from the *note Python Interface: 2d69. with:

     >>> import timeit
     >>> timeit.timeit('"-".join(str(n) for n in range(100))', number=10000)
     0.3018611848820001
     >>> timeit.timeit('"-".join([str(n) for n in range(100)])', number=10000)
     0.2727368790656328
     >>> timeit.timeit('"-".join(map(str, range(100)))', number=10000)
     0.23702679807320237

Note however that *note timeit: 108. will automatically determine the
number of repetitions only when the command-line interface is used.  In
the *note Examples: 2d6b. section you can find more advanced examples.


File: python.info,  Node: Python Interface,  Next: Command-Line Interface<2>,  Prev: Basic Examples<2>,  Up: timeit --- Measure execution time of small code snippets

5.27.5.2 Python Interface
.........................

The module defines three convenience functions and a public class:

 -- Function: timeit.timeit (stmt='pass', setup='pass', timer=<default
          timer>, number=1000000, globals=None)

     Create a *note Timer: 2d6d. instance with the given statement,
     `setup' code and `timer' function and run its *note timeit(): 2d6e.
     method with `number' executions.  The optional `globals' argument
     specifies a namespace in which to execute the code.

     Changed in version 3.5: The optional `globals' parameter was added.

 -- Function: timeit.repeat (stmt='pass', setup='pass', timer=<default
          timer>, repeat=3, number=1000000, globals=None)

     Create a *note Timer: 2d6d. instance with the given statement,
     `setup' code and `timer' function and run its *note repeat(): 2d70.
     method with the given `repeat' count and `number' executions.  The
     optional `globals' argument specifies a namespace in which to
     execute the code.

     Changed in version 3.5: The optional `globals' parameter was added.

 -- Function: timeit.default_timer ()

     The default timer, which is always *note time.perf_counter(): 6ec.

     Changed in version 3.3: *note time.perf_counter(): 6ec. is now the
     default timer.

 -- Class: timeit.Timer (stmt='pass', setup='pass', timer=<timer
          function>, globals=None)

     Class for timing execution speed of small code snippets.

     The constructor takes a statement to be timed, an additional
     statement used for setup, and a timer function.  Both statements
     default to ‘'pass'’; the timer function is platform-dependent (see
     the module doc string).  `stmt' and `setup' may also contain
     multiple statements separated by ‘;’ or newlines, as long as they
     don’t contain multi-line string literals.  The statement will by
     default be executed within timeit’s namespace; this behavior can be
     controlled by passing a namespace to `globals'.

     To measure the execution time of the first statement, use the *note
     timeit(): 2d6e. method.  The *note repeat(): 2d70. method is a
     convenience to call *note timeit(): 2d6e. multiple times and return
     a list of results.

     The execution time of `setup' is excluded from the overall timed
     execution run.

     The `stmt' and `setup' parameters can also take objects that are
     callable without arguments.  This will embed calls to them in a
     timer function that will then be executed by *note timeit(): 2d6e.
     Note that the timing overhead is a little larger in this case
     because of the extra function calls.

     Changed in version 3.5: The optional `globals' parameter was added.

      -- Method: timeit (number=1000000)

          Time `number' executions of the main statement.  This executes
          the setup statement once, and then returns the time it takes
          to execute the main statement a number of times, measured in
          seconds as a float.  The argument is the number of times
          through the loop, defaulting to one million.  The main
          statement, the setup statement and the timer function to be
          used are passed to the constructor.

               Note: By default, *note timeit(): 2d6e. temporarily turns
               off *note garbage collection: cca. during the timing.
               The advantage of this approach is that it makes
               independent timings more comparable.  This disadvantage
               is that GC may be an important component of the
               performance of the function being measured.  If so, GC
               can be re-enabled as the first statement in the `setup'
               string.  For example:

                    timeit.Timer('for i in range(10): oct(i)', 'gc.enable()').timeit()

      -- Method: repeat (repeat=3, number=1000000)

          Call *note timeit(): 2d6e. a few times.

          This is a convenience function that calls the *note timeit():
          2d6e. repeatedly, returning a list of results.  The first
          argument specifies how many times to call *note timeit():
          2d6e.  The second argument specifies the `number' argument for
          *note timeit(): 2d6e.

               Note: It’s tempting to calculate mean and standard
               deviation from the result vector and report these.
               However, this is not very useful.  In a typical case, the
               lowest value gives a lower bound for how fast your
               machine can run the given code snippet; higher values in
               the result vector are typically not caused by variability
               in Python’s speed, but by other processes interfering
               with your timing accuracy.  So the *note min(): 3f9. of
               the result is probably the only number you should be
               interested in.  After that, you should look at the entire
               vector and apply common sense rather than statistics.

      -- Method: print_exc (file=None)

          Helper to print a traceback from the timed code.

          Typical use:

               t = Timer(...)       # outside the try/except
               try:
                   t.timeit(...)    # or t.repeat(...)
               except Exception:
                   t.print_exc()

          The advantage over the standard traceback is that source lines
          in the compiled template will be displayed.  The optional
          `file' argument directs where the traceback is sent; it
          defaults to *note sys.stderr: 270.


File: python.info,  Node: Command-Line Interface<2>,  Next: Examples<19>,  Prev: Python Interface,  Up: timeit --- Measure execution time of small code snippets

5.27.5.3 Command-Line Interface
...............................

When called as a program from the command line, the following form is
used:

     python -m timeit [-n N] [-r N] [-u U] [-s S] [-t] [-c] [-h] [statement ...]

Where the following options are understood:

 -- Program Option: -n N, --number=N

     how many times to execute ’statement’

 -- Program Option: -r N, --repeat=N

     how many times to repeat the timer (default 3)

 -- Program Option: -s S, --setup=S

     statement to be executed once initially (default ‘pass’)

 -- Program Option: -p, --process

     measure process time, not wallclock time, using *note
     time.process_time(): 6ed. instead of *note time.perf_counter():
     6ec, which is the default

     New in version 3.3.

 -- Program Option: -t, --time

     use *note time.time(): 6a5. (deprecated)

 -- Program Option: -u, --unit=U

          specify a time unit for timer output; can select usec, msec,
          or sec

     New in version 3.5.

 -- Program Option: -c, --clock

     use *note time.clock(): 72a. (deprecated)

 -- Program Option: -v, --verbose

     print raw timing results; repeat for more digits precision

 -- Program Option: -h, --help

     print a short usage message and exit

A multi-line statement may be given by specifying each line as a
separate statement argument; indented lines are possible by enclosing an
argument in quotes and using leading spaces.  Multiple *note -s: 2d78.
options are treated similarly.

If *note -n: 2d74. is not given, a suitable number of loops is
calculated by trying successive powers of 10 until the total time is at
least 0.2 seconds.

*note default_timer(): 2d71. measurements can be affected by other
programs running on the same machine, so the best thing to do when
accurate timing is necessary is to repeat the timing a few times and use
the best time.  The *note -r: 2d76. option is good for this; the default
of 3 repetitions is probably enough in most cases.  You can use *note
time.process_time(): 6ed. to measure CPU time.

     Note: There is a certain baseline overhead associated with
     executing a pass statement.  The code here doesn’t try to hide it,
     but you should be aware of it.  The baseline overhead can be
     measured by invoking the program without arguments, and it might
     differ between Python versions.


File: python.info,  Node: Examples<19>,  Prev: Command-Line Interface<2>,  Up: timeit --- Measure execution time of small code snippets

5.27.5.4 Examples
.................

It is possible to provide a setup statement that is executed only once
at the beginning:

     $ python -m timeit -s 'text = "sample string"; char = "g"'  'char in text'
     10000000 loops, best of 3: 0.0877 usec per loop
     $ python -m timeit -s 'text = "sample string"; char = "g"'  'text.find(char)'
     1000000 loops, best of 3: 0.342 usec per loop

     >>> import timeit
     >>> timeit.timeit('char in text', setup='text = "sample string"; char = "g"')
     0.41440500499993504
     >>> timeit.timeit('text.find(char)', setup='text = "sample string"; char = "g"')
     1.7246671520006203

The same can be done using the *note Timer: 2d6d. class and its methods:

     >>> import timeit
     >>> t = timeit.Timer('char in text', setup='text = "sample string"; char = "g"')
     >>> t.timeit()
     0.3955516149999312
     >>> t.repeat()
     [0.40193588800002544, 0.3960157959998014, 0.39594301399984033]

The following examples show how to time expressions that contain
multiple lines.  Here we compare the cost of using *note hasattr(): 780.
vs.  *note try: 9e9./*note except: 785. to test for missing and present
object attributes:

     $ python -m timeit 'try:' '  str.__bool__' 'except AttributeError:' '  pass'
     100000 loops, best of 3: 15.7 usec per loop
     $ python -m timeit 'if hasattr(str, "__bool__"): pass'
     100000 loops, best of 3: 4.26 usec per loop

     $ python -m timeit 'try:' '  int.__bool__' 'except AttributeError:' '  pass'
     1000000 loops, best of 3: 1.43 usec per loop
     $ python -m timeit 'if hasattr(int, "__bool__"): pass'
     100000 loops, best of 3: 2.23 usec per loop

     >>> import timeit
     >>> # attribute is missing
     >>> s = """\
     ... try:
     ...     str.__bool__
     ... except AttributeError:
     ...     pass
     ... """
     >>> timeit.timeit(stmt=s, number=100000)
     0.9138244460009446
     >>> s = "if hasattr(str, '__bool__'): pass"
     >>> timeit.timeit(stmt=s, number=100000)
     0.5829014980008651
     >>>
     >>> # attribute is present
     >>> s = """\
     ... try:
     ...     int.__bool__
     ... except AttributeError:
     ...     pass
     ... """
     >>> timeit.timeit(stmt=s, number=100000)
     0.04215312199994514
     >>> s = "if hasattr(int, '__bool__'): pass"
     >>> timeit.timeit(stmt=s, number=100000)
     0.08588060699912603

To give the *note timeit: 108. module access to functions you define,
you can pass a `setup' parameter which contains an import statement:

     def test():
         """Stupid test function"""
         L = [i for i in range(100)]

     if __name__ == '__main__':
         import timeit
         print(timeit.timeit("test()", setup="from __main__ import test"))

Another option is to pass *note globals(): f96. to the `globals'
parameter, which will cause the code to be executed within your current
global namespace.  This can be more convenient than individually
specifying imports:

     def f(x):
         return x**2
     def g(x):
         return x**4
     def h(x):
         return x**8

     import timeit
     print(timeit.timeit('[func(42) for func in (f,g,h)]', globals=globals()))


File: python.info,  Node: trace --- Trace or track Python statement execution,  Next: tracemalloc --- Trace memory allocations,  Prev: timeit --- Measure execution time of small code snippets,  Up: Debugging and Profiling

5.27.6 ‘trace’ — Trace or track Python statement execution
----------------------------------------------------------

`Source code:' Lib/trace.py(1)

__________________________________________________________________

The *note trace: 10f. module allows you to trace program execution,
generate annotated statement coverage listings, print caller/callee
relationships and list functions executed during a program run.  It can
be used in another program or from the command line.

* Menu:

* Command-Line Usage:: 
* Programmatic Interface:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/trace.py


File: python.info,  Node: Command-Line Usage,  Next: Programmatic Interface,  Up: trace --- Trace or track Python statement execution

5.27.6.1 Command-Line Usage
...........................

The *note trace: 10f. module can be invoked from the command line.  It
can be as simple as

     python -m trace --count -C . somefile.py ...

The above will execute ‘somefile.py’ and generate annotated listings of
all Python modules imported during the execution into the current
directory.

 -- Program Option: --help

     Display usage and exit.

 -- Program Option: --version

     Display the version of the module and exit.

* Menu:

* Main options:: 
* Modifiers:: 
* Filters:: 


File: python.info,  Node: Main options,  Next: Modifiers,  Up: Command-Line Usage

5.27.6.2 Main options
.....................

At least one of the following options must be specified when invoking
*note trace: 10f.  The *note –listfuncs: 2d8e. option is mutually
exclusive with the *note –trace: 2d8f. and *note –count: 2d90. options.
When *note –listfuncs: 2d8e. is provided, neither *note –count: 2d90.
nor *note –trace: 2d8f. are accepted, and vice versa.

 -- Program Option: -c, --count

     Produce a set of annotated listing files upon program completion
     that shows how many times each statement was executed.  See also
     *note –coverdir: 2d92, *note –file: 2d93. and *note –no-report:
     2d94. below.

 -- Program Option: -t, --trace

     Display lines as they are executed.

 -- Program Option: -l, --listfuncs

     Display the functions executed by running the program.

 -- Program Option: -r, --report

     Produce an annotated list from an earlier program run that used the
     *note –count: 2d90. and *note –file: 2d93. option.  This does not
     execute any code.

 -- Program Option: -T, --trackcalls

     Display the calling relationships exposed by running the program.


File: python.info,  Node: Modifiers,  Next: Filters,  Prev: Main options,  Up: Command-Line Usage

5.27.6.3 Modifiers
..................

 -- Program Option: -f, --file=<file>

     Name of a file to accumulate counts over several tracing runs.
     Should be used with the *note –count: 2d90. option.

 -- Program Option: -C, --coverdir=<dir>

     Directory where the report files go.  The coverage report for
     ‘package.module’ is written to file
     ‘`dir'/`package'/`module'.cover’.

 -- Program Option: -m, --missing

     When generating annotated listings, mark lines which were not
     executed with ‘>>>>>>’.

 -- Program Option: -s, --summary

     When using *note –count: 2d90. or *note –report: 2d97, write a
     brief summary to stdout for each file processed.

 -- Program Option: -R, --no-report

     Do not generate annotated listings.  This is useful if you intend
     to make several runs with *note –count: 2d90, and then produce a
     single set of annotated listings at the end.

 -- Program Option: -g, --timing

     Prefix each line with the time since the program started.  Only
     used while tracing.


File: python.info,  Node: Filters,  Prev: Modifiers,  Up: Command-Line Usage

5.27.6.4 Filters
................

These options may be repeated multiple times.

 -- Program Option: --ignore-module=<mod>

     Ignore each of the given module names and its submodules (if it is
     a package).  The argument can be a list of names separated by a
     comma.

 -- Program Option: --ignore-dir=<dir>

     Ignore all modules and packages in the named directory and
     subdirectories.  The argument can be a list of directories
     separated by *note os.pathsep: d15.


File: python.info,  Node: Programmatic Interface,  Prev: Command-Line Usage,  Up: trace --- Trace or track Python statement execution

5.27.6.5 Programmatic Interface
...............................

 -- Class: trace.Trace (count=1, trace=1, countfuncs=0, countcallers=0,
          ignoremods=(), ignoredirs=(), infile=None, outfile=None,
          timing=False)

     Create an object to trace execution of a single statement or
     expression.  All parameters are optional.  `count' enables counting
     of line numbers.  `trace' enables line execution tracing.
     `countfuncs' enables listing of the functions called during the
     run.  `countcallers' enables call relationship tracking.
     `ignoremods' is a list of modules or packages to ignore.
     `ignoredirs' is a list of directories whose modules or packages
     should be ignored.  `infile' is the name of the file from which to
     read stored count information.  `outfile' is the name of the file
     in which to write updated count information.  `timing' enables a
     timestamp relative to when tracing was started to be displayed.

           -- Method: run (cmd)

               Execute the command and gather statistics from the
               execution with the current tracing parameters.  `cmd'
               must be a string or code object, suitable for passing
               into *note exec(): 8ac.

           -- Method: runctx (cmd, globals=None, locals=None)

               Execute the command and gather statistics from the
               execution with the current tracing parameters, in the
               defined global and local environments.  If not defined,
               `globals' and `locals' default to empty dictionaries.

           -- Method: runfunc (func, *args, **kwds)

               Call `func' with the given arguments under control of the
               *note Trace: 2daa. object with the current tracing
               parameters.

           -- Method: results ()

               Return a *note CoverageResults: 2daf. object that
               contains the cumulative results of all previous calls to
               ‘run’, ‘runctx’ and ‘runfunc’ for the given *note Trace:
               2daa. instance.  Does not reset the accumulated trace
               results.

 -- Class: trace.CoverageResults

     A container for coverage results, created by *note Trace.results():
     2dae.  Should not be created directly by the user.

           -- Method: update (other)

               Merge in data from another *note CoverageResults: 2daf.
               object.

           -- Method: write_results (show_missing=True, summary=False,
                    coverdir=None)

               Write coverage results.  Set `show_missing' to show lines
               that had no hits.  Set `summary' to include in the output
               the coverage summary per module.  `coverdir' specifies
               the directory into which the coverage result files will
               be output.  If ‘None’, the results for each source file
               are placed in its directory.

A simple example demonstrating the use of the programmatic interface:

     import sys
     import trace

     # create a Trace object, telling it what to ignore, and whether to
     # do tracing or line-counting or both.
     tracer = trace.Trace(
         ignoredirs=[sys.prefix, sys.exec_prefix],
         trace=0,
         count=1)

     # run the new command using the given tracer
     tracer.run('main()')

     # make a report, placing output in the current directory
     r = tracer.results()
     r.write_results(show_missing=True, coverdir=".")


File: python.info,  Node: tracemalloc --- Trace memory allocations,  Prev: trace --- Trace or track Python statement execution,  Up: Debugging and Profiling

5.27.7 ‘tracemalloc’ — Trace memory allocations
-----------------------------------------------

New in version 3.4.

The tracemalloc module is a debug tool to trace memory blocks allocated
by Python.  It provides the following information:

   * Traceback where an object was allocated

   * Statistics on allocated memory blocks per filename and per line
     number: total size, number and average size of allocated memory
     blocks

   * Compute the differences between two snapshots to detect memory
     leaks

To trace most memory blocks allocated by Python, the module should be
started as early as possible by setting the *note PYTHONTRACEMALLOC:
d1b. environment variable to ‘1’, or by using *note -X: 5ec.
‘tracemalloc’ command line option.  The *note tracemalloc.start(): d10.
function can be called at runtime to start tracing Python memory
allocations.

By default, a trace of an allocated memory block only stores the most
recent frame (1 frame).  To store 25 frames at startup: set the *note
PYTHONTRACEMALLOC: d1b. environment variable to ‘25’, or use the *note
-X: 5ec. ‘tracemalloc=25’ command line option.

* Menu:

* Examples: Examples<20>. 
* API:: 


File: python.info,  Node: Examples<20>,  Next: API,  Up: tracemalloc --- Trace memory allocations

5.27.7.1 Examples
.................

* Menu:

* Display the top 10:: 
* Compute differences:: 
* Get the traceback of a memory block:: 
* Pretty top:: 


File: python.info,  Node: Display the top 10,  Next: Compute differences,  Up: Examples<20>

5.27.7.2 Display the top 10
...........................

Display the 10 files allocating the most memory:

     import tracemalloc

     tracemalloc.start()

     # ... run your application ...

     snapshot = tracemalloc.take_snapshot()
     top_stats = snapshot.statistics('lineno')

     print("[ Top 10 ]")
     for stat in top_stats[:10]:
         print(stat)

Example of output of the Python test suite:

     [ Top 10 ]
     <frozen importlib._bootstrap>:716: size=4855 KiB, count=39328, average=126 B
     <frozen importlib._bootstrap>:284: size=521 KiB, count=3199, average=167 B
     /usr/lib/python3.4/collections/__init__.py:368: size=244 KiB, count=2315, average=108 B
     /usr/lib/python3.4/unittest/case.py:381: size=185 KiB, count=779, average=243 B
     /usr/lib/python3.4/unittest/case.py:402: size=154 KiB, count=378, average=416 B
     /usr/lib/python3.4/abc.py:133: size=88.7 KiB, count=347, average=262 B
     <frozen importlib._bootstrap>:1446: size=70.4 KiB, count=911, average=79 B
     <frozen importlib._bootstrap>:1454: size=52.0 KiB, count=25, average=2131 B
     <string>:5: size=49.7 KiB, count=148, average=344 B
     /usr/lib/python3.4/sysconfig.py:411: size=48.0 KiB, count=1, average=48.0 KiB

We can see that Python loaded ‘4.8 MiB’ data (bytecode and constants)
from modules and that the *note collections: 1e. module allocated ‘244
KiB’ to build *note namedtuple: 229. types.

See *note Snapshot.statistics(): 2db6. for more options.


File: python.info,  Node: Compute differences,  Next: Get the traceback of a memory block,  Prev: Display the top 10,  Up: Examples<20>

5.27.7.3 Compute differences
............................

Take two snapshots and display the differences:

     import tracemalloc
     tracemalloc.start()
     # ... start your application ...

     snapshot1 = tracemalloc.take_snapshot()
     # ... call the function leaking memory ...
     snapshot2 = tracemalloc.take_snapshot()

     top_stats = snapshot2.compare_to(snapshot1, 'lineno')

     print("[ Top 10 differences ]")
     for stat in top_stats[:10]:
         print(stat)

Example of output before/after running some tests of the Python test
suite:

     [ Top 10 differences ]
     <frozen importlib._bootstrap>:716: size=8173 KiB (+4428 KiB), count=71332 (+39369), average=117 B
     /usr/lib/python3.4/linecache.py:127: size=940 KiB (+940 KiB), count=8106 (+8106), average=119 B
     /usr/lib/python3.4/unittest/case.py:571: size=298 KiB (+298 KiB), count=589 (+589), average=519 B
     <frozen importlib._bootstrap>:284: size=1005 KiB (+166 KiB), count=7423 (+1526), average=139 B
     /usr/lib/python3.4/mimetypes.py:217: size=112 KiB (+112 KiB), count=1334 (+1334), average=86 B
     /usr/lib/python3.4/http/server.py:848: size=96.0 KiB (+96.0 KiB), count=1 (+1), average=96.0 KiB
     /usr/lib/python3.4/inspect.py:1465: size=83.5 KiB (+83.5 KiB), count=109 (+109), average=784 B
     /usr/lib/python3.4/unittest/mock.py:491: size=77.7 KiB (+77.7 KiB), count=143 (+143), average=557 B
     /usr/lib/python3.4/urllib/parse.py:476: size=71.8 KiB (+71.8 KiB), count=969 (+969), average=76 B
     /usr/lib/python3.4/contextlib.py:38: size=67.2 KiB (+67.2 KiB), count=126 (+126), average=546 B

We can see that Python has loaded ‘8.2 MiB’ of module data (bytecode and
constants), and that this is ‘4.4 MiB’ more than had been loaded before
the tests, when the previous snapshot was taken.  Similarly, the *note
linecache: a6. module has cached ‘940 KiB’ of Python source code to
format tracebacks, all of it since the previous snapshot.

If the system has little free memory, snapshots can be written on disk
using the *note Snapshot.dump(): 2db8. method to analyze the snapshot
offline.  Then use the *note Snapshot.load(): 2db9. method reload the
snapshot.


File: python.info,  Node: Get the traceback of a memory block,  Next: Pretty top,  Prev: Compute differences,  Up: Examples<20>

5.27.7.4 Get the traceback of a memory block
............................................

Code to display the traceback of the biggest memory block:

     import tracemalloc

     # Store 25 frames
     tracemalloc.start(25)

     # ... run your application ...

     snapshot = tracemalloc.take_snapshot()
     top_stats = snapshot.statistics('traceback')

     # pick the biggest memory block
     stat = top_stats[0]
     print("%s memory blocks: %.1f KiB" % (stat.count, stat.size / 1024))
     for line in stat.traceback.format():
         print(line)

Example of output of the Python test suite (traceback limited to 25
frames):

     903 memory blocks: 870.1 KiB
       File "<frozen importlib._bootstrap>", line 716
       File "<frozen importlib._bootstrap>", line 1036
       File "<frozen importlib._bootstrap>", line 934
       File "<frozen importlib._bootstrap>", line 1068
       File "<frozen importlib._bootstrap>", line 619
       File "<frozen importlib._bootstrap>", line 1581
       File "<frozen importlib._bootstrap>", line 1614
       File "/usr/lib/python3.4/doctest.py", line 101
         import pdb
       File "<frozen importlib._bootstrap>", line 284
       File "<frozen importlib._bootstrap>", line 938
       File "<frozen importlib._bootstrap>", line 1068
       File "<frozen importlib._bootstrap>", line 619
       File "<frozen importlib._bootstrap>", line 1581
       File "<frozen importlib._bootstrap>", line 1614
       File "/usr/lib/python3.4/test/support/__init__.py", line 1728
         import doctest
       File "/usr/lib/python3.4/test/test_pickletools.py", line 21
         support.run_doctest(pickletools)
       File "/usr/lib/python3.4/test/regrtest.py", line 1276
         test_runner()
       File "/usr/lib/python3.4/test/regrtest.py", line 976
         display_failure=not verbose)
       File "/usr/lib/python3.4/test/regrtest.py", line 761
         match_tests=ns.match_tests)
       File "/usr/lib/python3.4/test/regrtest.py", line 1563
         main()
       File "/usr/lib/python3.4/test/__main__.py", line 3
         regrtest.main_in_temp_cwd()
       File "/usr/lib/python3.4/runpy.py", line 73
         exec(code, run_globals)
       File "/usr/lib/python3.4/runpy.py", line 160
         "__main__", fname, loader, pkg_name)

We can see that the most memory was allocated in the *note importlib:
9a. module to load data (bytecode and constants) from modules: ‘870
KiB’.  The traceback is where the *note importlib: 9a. loaded data most
recently: on the ‘import pdb’ line of the *note doctest: 65. module.
The traceback may change if a new module is loaded.


File: python.info,  Node: Pretty top,  Prev: Get the traceback of a memory block,  Up: Examples<20>

5.27.7.5 Pretty top
...................

Code to display the 10 lines allocating the most memory with a pretty
output, ignoring ‘<frozen importlib._bootstrap>’ and ‘<unknown>’ files:

     import linecache
     import os
     import tracemalloc

     def display_top(snapshot, group_by='lineno', limit=10):
         snapshot = snapshot.filter_traces((
             tracemalloc.Filter(False, "<frozen importlib._bootstrap>"),
             tracemalloc.Filter(False, "<unknown>"),
         ))
         top_stats = snapshot.statistics(group_by)

         print("Top %s lines" % limit)
         for index, stat in enumerate(top_stats[:limit], 1):
             frame = stat.traceback[0]
             # replace "/path/to/module/file.py" with "module/file.py"
             filename = os.sep.join(frame.filename.split(os.sep)[-2:])
             print("#%s: %s:%s: %.1f KiB"
                   % (index, filename, frame.lineno, stat.size / 1024))
             line = linecache.getline(frame.filename, frame.lineno).strip()
             if line:
                 print('    %s' % line)

         other = top_stats[limit:]
         if other:
             size = sum(stat.size for stat in other)
             print("%s other: %.1f KiB" % (len(other), size / 1024))
         total = sum(stat.size for stat in top_stats)
         print("Total allocated size: %.1f KiB" % (total / 1024))

     tracemalloc.start()

     # ... run your application ...

     snapshot = tracemalloc.take_snapshot()
     display_top(snapshot)

Example of output of the Python test suite:

     Top 10 lines
     #1: Lib/base64.py:414: 419.8 KiB
         _b85chars2 = [(a + b) for a in _b85chars for b in _b85chars]
     #2: Lib/base64.py:306: 419.8 KiB
         _a85chars2 = [(a + b) for a in _a85chars for b in _a85chars]
     #3: collections/__init__.py:368: 293.6 KiB
         exec(class_definition, namespace)
     #4: Lib/abc.py:133: 115.2 KiB
         cls = super().__new__(mcls, name, bases, namespace)
     #5: unittest/case.py:574: 103.1 KiB
         testMethod()
     #6: Lib/linecache.py:127: 95.4 KiB
         lines = fp.readlines()
     #7: urllib/parse.py:476: 71.8 KiB
         for a in _hexdig for b in _hexdig}
     #8: <string>:5: 62.0 KiB
     #9: Lib/_weakrefset.py:37: 60.0 KiB
         self.data = set()
     #10: Lib/base64.py:142: 59.8 KiB
         _b32tab2 = [a + b for a in _b32tab for b in _b32tab]
     6220 other: 3602.8 KiB
     Total allocated size: 5303.1 KiB

See *note Snapshot.statistics(): 2db6. for more options.


File: python.info,  Node: API,  Prev: Examples<20>,  Up: tracemalloc --- Trace memory allocations

5.27.7.6 API
............

* Menu:

* Functions: Functions<7>. 
* DomainFilter:: 
* Filter:: 
* Frame:: 
* Snapshot:: 
* Statistic:: 
* StatisticDiff:: 
* Trace:: 
* Traceback:: 


File: python.info,  Node: Functions<7>,  Next: DomainFilter,  Up: API

5.27.7.7 Functions
..................

 -- Function: tracemalloc.clear_traces ()

     Clear traces of memory blocks allocated by Python.

     See also *note stop(): 2dbf.

 -- Function: tracemalloc.get_object_traceback (obj)

     Get the traceback where the Python object `obj' was allocated.
     Return a *note Traceback: 2dc0. instance, or ‘None’ if the *note
     tracemalloc: 111. module is not tracing memory allocations or did
     not trace the allocation of the object.

     See also *note gc.get_referrers(): 2dc1. and *note sys.getsizeof():
     2dc2. functions.

 -- Function: tracemalloc.get_traceback_limit ()

     Get the maximum number of frames stored in the traceback of a
     trace.

     The *note tracemalloc: 111. module must be tracing memory
     allocations to get the limit, otherwise an exception is raised.

     The limit is set by the *note start(): d10. function.

 -- Function: tracemalloc.get_traced_memory ()

     Get the current size and peak size of memory blocks traced by the
     *note tracemalloc: 111. module as a tuple: ‘(current: int, peak:
     int)’.

 -- Function: tracemalloc.get_tracemalloc_memory ()

     Get the memory usage in bytes of the *note tracemalloc: 111. module
     used to store traces of memory blocks.  Return an *note int: 227.

 -- Function: tracemalloc.is_tracing ()

     ‘True’ if the *note tracemalloc: 111. module is tracing Python
     memory allocations, ‘False’ otherwise.

     See also *note start(): d10. and *note stop(): 2dbf. functions.

 -- Function: tracemalloc.start (nframe: int=1)

     Start tracing Python memory allocations: install hooks on Python
     memory allocators.  Collected tracebacks of traces will be limited
     to `nframe' frames.  By default, a trace of a memory block only
     stores the most recent frame: the limit is ‘1’.  `nframe' must be
     greater or equal to ‘1’.

     Storing more than ‘1’ frame is only useful to compute statistics
     grouped by ‘'traceback'’ or to compute cumulative statistics: see
     the *note Snapshot.compare_to(): 2dc7. and *note
     Snapshot.statistics(): 2db6. methods.

     Storing more frames increases the memory and CPU overhead of the
     *note tracemalloc: 111. module.  Use the *note
     get_tracemalloc_memory(): 2dc5. function to measure how much memory
     is used by the *note tracemalloc: 111. module.

     The *note PYTHONTRACEMALLOC: d1b. environment variable
     (‘PYTHONTRACEMALLOC=NFRAME’) and the *note -X: 5ec.
     ‘tracemalloc=NFRAME’ command line option can be used to start
     tracing at startup.

     See also *note stop(): 2dbf, *note is_tracing(): 2dc6. and *note
     get_traceback_limit(): 2dc3. functions.

 -- Function: tracemalloc.stop ()

     Stop tracing Python memory allocations: uninstall hooks on Python
     memory allocators.  Also clears all previously collected traces of
     memory blocks allocated by Python.

     Call *note take_snapshot(): 2dc8. function to take a snapshot of
     traces before clearing them.

     See also *note start(): d10, *note is_tracing(): 2dc6. and *note
     clear_traces(): 2dbe. functions.

 -- Function: tracemalloc.take_snapshot ()

     Take a snapshot of traces of memory blocks allocated by Python.
     Return a new *note Snapshot: 2dc9. instance.

     The snapshot does not include memory blocks allocated before the
     *note tracemalloc: 111. module started to trace memory allocations.

     Tracebacks of traces are limited to *note get_traceback_limit():
     2dc3. frames.  Use the `nframe' parameter of the *note start():
     d10. function to store more frames.

     The *note tracemalloc: 111. module must be tracing memory
     allocations to take a snapshot, see the *note start(): d10.
     function.

     See also the *note get_object_traceback(): b16. function.


File: python.info,  Node: DomainFilter,  Next: Filter,  Prev: Functions<7>,  Up: API

5.27.7.8 DomainFilter
.....................

 -- Class: tracemalloc.DomainFilter (inclusive: bool, domain: int)

     Filter traces of memory blocks by their address space (domain).

     New in version 3.6.

      -- Attribute: inclusive

          If `inclusive' is ‘True’ (include), match memory blocks
          allocated in the address space *note domain: 2dcd.

          If `inclusive' is ‘False’ (exclude), match memory blocks not
          allocated in the address space *note domain: 2dcd.

      -- Attribute: domain

          Address space of a memory block (‘int’).  Read-only property.


File: python.info,  Node: Filter,  Next: Frame,  Prev: DomainFilter,  Up: API

5.27.7.9 Filter
...............

 -- Class: tracemalloc.Filter (inclusive: bool, filename_pattern: str,
          lineno: int=None, all_frames: bool=False, domain: int=None)

     Filter on traces of memory blocks.

     See the *note fnmatch.fnmatch(): 161b. function for the syntax of
     `filename_pattern'.  The ‘'.pyc'’ file extension is replaced with
     ‘'.py'’.

     Examples:

        * ‘Filter(True, subprocess.__file__)’ only includes traces of
          the *note subprocess: f7. module

        * ‘Filter(False, tracemalloc.__file__)’ excludes traces of the
          *note tracemalloc: 111. module

        * ‘Filter(False, "<unknown>")’ excludes empty tracebacks

     Changed in version 3.5: The ‘'.pyo'’ file extension is no longer
     replaced with ‘'.py'’.

     Changed in version 3.6: Added the *note domain: 2dd0. attribute.

      -- Attribute: domain

          Address space of a memory block (‘int’ or ‘None’).

      -- Attribute: inclusive

          If `inclusive' is ‘True’ (include), only match memory blocks
          allocated in a file with a name matching *note
          filename_pattern: 2dd2. at line number *note lineno: 2dd3.

          If `inclusive' is ‘False’ (exclude), ignore memory blocks
          allocated in a file with a name matching *note
          filename_pattern: 2dd2. at line number *note lineno: 2dd3.

      -- Attribute: lineno

          Line number (‘int’) of the filter.  If `lineno' is ‘None’, the
          filter matches any line number.

      -- Attribute: filename_pattern

          Filename pattern of the filter (‘str’).  Read-only property.

      -- Attribute: all_frames

          If `all_frames' is ‘True’, all frames of the traceback are
          checked.  If `all_frames' is ‘False’, only the most recent
          frame is checked.

          This attribute has no effect if the traceback limit is ‘1’.
          See the *note get_traceback_limit(): 2dc3. function and *note
          Snapshot.traceback_limit: 2dd5. attribute.


File: python.info,  Node: Frame,  Next: Snapshot,  Prev: Filter,  Up: API

5.27.7.10 Frame
...............

 -- Class: tracemalloc.Frame

     Frame of a traceback.

     The *note Traceback: 2dc0. class is a sequence of *note Frame:
     2dd7. instances.

      -- Attribute: filename

          Filename (‘str’).

      -- Attribute: lineno

          Line number (‘int’).


File: python.info,  Node: Snapshot,  Next: Statistic,  Prev: Frame,  Up: API

5.27.7.11 Snapshot
..................

 -- Class: tracemalloc.Snapshot

     Snapshot of traces of memory blocks allocated by Python.

     The *note take_snapshot(): 2dc8. function creates a snapshot
     instance.

      -- Method: compare_to (old_snapshot: Snapshot, group_by: str,
               cumulative: bool=False)

          Compute the differences with an old snapshot.  Get statistics
          as a sorted list of *note StatisticDiff: 2ddb. instances
          grouped by `group_by'.

          See the *note Snapshot.statistics(): 2db6. method for
          `group_by' and `cumulative' parameters.

          The result is sorted from the biggest to the smallest by:
          absolute value of *note StatisticDiff.size_diff: 2ddc, *note
          StatisticDiff.size: 2ddd, absolute value of *note
          StatisticDiff.count_diff: 2dde, *note Statistic.count: 2ddf.
          and then by *note StatisticDiff.traceback: 2de0.

      -- Method: dump (filename)

          Write the snapshot into a file.

          Use *note load(): 2db9. to reload the snapshot.

      -- Method: filter_traces (filters)

          Create a new *note Snapshot: 2dc9. instance with a filtered
          *note traces: 2de2. sequence, `filters' is a list of *note
          DomainFilter: 2dcb. and *note Filter: 2dcf. instances.  If
          `filters' is an empty list, return a new *note Snapshot: 2dc9.
          instance with a copy of the traces.

          All inclusive filters are applied at once, a trace is ignored
          if no inclusive filters match it.  A trace is ignored if at
          least one exclusive filter matches it.

          Changed in version 3.6: *note DomainFilter: 2dcb. instances
          are now also accepted in `filters'.

      -- Class Method: load (filename)

          Load a snapshot from a file.

          See also *note dump(): 2db8.

      -- Method: statistics (group_by: str, cumulative: bool=False)

          Get statistics as a sorted list of *note Statistic: 2de3.
          instances grouped by `group_by':

          group_by                  description
                                    
          -------------------------------------------------------
                                    
          ‘'filename'’              filename
                                    
                                    
          ‘'lineno'’                filename and line number
                                    
                                    
          ‘'traceback'’             traceback
                                    

          If `cumulative' is ‘True’, cumulate size and count of memory
          blocks of all frames of the traceback of a trace, not only the
          most recent frame.  The cumulative mode can only be used with
          `group_by' equals to ‘'filename'’ and ‘'lineno'’.

          The result is sorted from the biggest to the smallest by:
          *note Statistic.size: 2de4, *note Statistic.count: 2ddf. and
          then by *note Statistic.traceback: 2de5.

      -- Attribute: traceback_limit

          Maximum number of frames stored in the traceback of *note
          traces: 2de2.: result of the *note get_traceback_limit():
          2dc3. when the snapshot was taken.

      -- Attribute: traces

          Traces of all memory blocks allocated by Python: sequence of
          *note Trace: 2de6. instances.

          The sequence has an undefined order.  Use the *note
          Snapshot.statistics(): 2db6. method to get a sorted list of
          statistics.


File: python.info,  Node: Statistic,  Next: StatisticDiff,  Prev: Snapshot,  Up: API

5.27.7.12 Statistic
...................

 -- Class: tracemalloc.Statistic

     Statistic on memory allocations.

     *note Snapshot.statistics(): 2db6. returns a list of *note
     Statistic: 2de3. instances.

     See also the *note StatisticDiff: 2ddb. class.

      -- Attribute: count

          Number of memory blocks (‘int’).

      -- Attribute: size

          Total size of memory blocks in bytes (‘int’).

      -- Attribute: traceback

          Traceback where the memory block was allocated, *note
          Traceback: 2dc0. instance.


File: python.info,  Node: StatisticDiff,  Next: Trace,  Prev: Statistic,  Up: API

5.27.7.13 StatisticDiff
.......................

 -- Class: tracemalloc.StatisticDiff

     Statistic difference on memory allocations between an old and a new
     *note Snapshot: 2dc9. instance.

     *note Snapshot.compare_to(): 2dc7. returns a list of *note
     StatisticDiff: 2ddb. instances.  See also the *note Statistic:
     2de3. class.

      -- Attribute: count

          Number of memory blocks in the new snapshot (‘int’): ‘0’ if
          the memory blocks have been released in the new snapshot.

      -- Attribute: count_diff

          Difference of number of memory blocks between the old and the
          new snapshots (‘int’): ‘0’ if the memory blocks have been
          allocated in the new snapshot.

      -- Attribute: size

          Total size of memory blocks in bytes in the new snapshot
          (‘int’): ‘0’ if the memory blocks have been released in the
          new snapshot.

      -- Attribute: size_diff

          Difference of total size of memory blocks in bytes between the
          old and the new snapshots (‘int’): ‘0’ if the memory blocks
          have been allocated in the new snapshot.

      -- Attribute: traceback

          Traceback where the memory blocks were allocated, *note
          Traceback: 2dc0. instance.


File: python.info,  Node: Trace,  Next: Traceback,  Prev: StatisticDiff,  Up: API

5.27.7.14 Trace
...............

 -- Class: tracemalloc.Trace

     Trace of a memory block.

     The *note Snapshot.traces: 2de2. attribute is a sequence of *note
     Trace: 2de6. instances.

      -- Attribute: size

          Size of the memory block in bytes (‘int’).

      -- Attribute: traceback

          Traceback where the memory block was allocated, *note
          Traceback: 2dc0. instance.


File: python.info,  Node: Traceback,  Prev: Trace,  Up: API

5.27.7.15 Traceback
...................

 -- Class: tracemalloc.Traceback

     Sequence of *note Frame: 2dd7. instances sorted from the most
     recent frame to the oldest frame.

     A traceback contains at least ‘1’ frame.  If the ‘tracemalloc’
     module failed to get a frame, the filename ‘"<unknown>"’ at line
     number ‘0’ is used.

     When a snapshot is taken, tracebacks of traces are limited to *note
     get_traceback_limit(): 2dc3. frames.  See the *note
     take_snapshot(): 2dc8. function.

     The *note Trace.traceback: 2dec. attribute is an instance of *note
     Traceback: 2dc0. instance.

      -- Method: format (limit=None)

          Format the traceback as a list of lines with newlines.  Use
          the *note linecache: a6. module to retrieve lines from the
          source code.  If `limit' is set, only format the `limit' most
          recent frames.

          Similar to the *note traceback.format_tb(): 2def. function,
          except that *note format(): 2dee. does not include newlines.

          Example:

               print("Traceback (most recent call first):")
               for line in traceback:
                   print(line)

          Output:

               Traceback (most recent call first):
                 File "test.py", line 9
                   obj = Object()
                 File "test.py", line 12
                   tb = tracemalloc.get_object_traceback(f())


File: python.info,  Node: Software Packaging and Distribution,  Next: Python Runtime Services,  Prev: Debugging and Profiling,  Up: The Python Standard Library

5.28 Software Packaging and Distribution
========================================

These libraries help you with publishing and installing Python software.
While these modules are designed to work in conjunction with the Python
Package Index(1), they can also be used with a local index server, or
without any index server at all.

* Menu:

* distutils: distutils --- Building and installing Python modules. Building and installing Python modules
* ensurepip: ensurepip --- Bootstrapping the pip installer. Bootstrapping the pip installer
* venv: venv --- Creation of virtual environments. Creation of virtual environments
* zipapp: zipapp --- Manage executable python zip archives. Manage executable python zip archives

   ---------- Footnotes ----------

   (1) https://pypi.python.org/pypi


File: python.info,  Node: distutils --- Building and installing Python modules,  Next: ensurepip --- Bootstrapping the pip installer,  Up: Software Packaging and Distribution

5.28.1 ‘distutils’ — Building and installing Python modules
-----------------------------------------------------------

The *note distutils: 37. package provides support for building and
installing additional modules into a Python installation.  The new
modules may be either 100%-pure Python, or may be extension modules
written in C, or may be collections of Python packages which include
modules coded in both Python and C.

Most Python users will `not' want to use this module directly, but
instead use the cross-version tools maintained by the Python Packaging
Authority.  In particular, setuptools(1) is an enhanced alternative to
*note distutils: 37. that provides:

   * support for declaring project dependencies

   * additional mechanisms for configuring which files to include in
     source releases (including plugins for integration with version
     control systems)

   * the ability to declare project "entry points", which can be used as
     the basis for application plugin systems

   * the ability to automatically generate Windows command line
     executables at installation time rather than needing to prebuild
     them

   * consistent behaviour across all supported Python versions

The recommended pip(2) installer runs all ‘setup.py’ scripts with
‘setuptools’, even if the script itself only imports ‘distutils’.  Refer
to the Python Packaging User Guide(3) for more information.

For the benefits of packaging tool authors and users seeking a deeper
understanding of the details of the current packaging and distribution
system, the legacy *note distutils: 37. based user documentation and API
reference remain available:

   * *note Installing Python Modules (Legacy version): 3e7.

   * *note Distributing Python Modules (Legacy version): 3e8.

   ---------- Footnotes ----------

   (1) https://setuptools.pypa.io/en/latest/setuptools.html

   (2) https://pip.pypa.io/

   (3) https://packaging.python.org


File: python.info,  Node: ensurepip --- Bootstrapping the pip installer,  Next: venv --- Creation of virtual environments,  Prev: distutils --- Building and installing Python modules,  Up: Software Packaging and Distribution

5.28.2 ‘ensurepip’ — Bootstrapping the ‘pip’ installer
------------------------------------------------------

New in version 3.4.

The *note ensurepip: 78. package provides support for bootstrapping the
‘pip’ installer into an existing Python installation or virtual
environment.  This bootstrapping approach reflects the fact that ‘pip’
is an independent project with its own release cycle, and the latest
available stable version is bundled with maintenance and feature
releases of the CPython reference interpreter.

In most cases, end users of Python shouldn’t need to invoke this module
directly (as ‘pip’ should be bootstrapped by default), but it may be
needed if installing ‘pip’ was skipped when installing Python (or when
creating a virtual environment) or after explicitly uninstalling ‘pip’.

     Note: This module `does not' access the internet.  All of the
     components needed to bootstrap ‘pip’ are included as internal parts
     of the package.

See also
........

*note Installing Python Modules: 3e5.

     The end user guide for installing Python packages

PEP 453(1): Explicit bootstrapping of pip in Python installations

     The original rationale and specification for this module.

* Menu:

* Command line interface:: 
* Module API:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0453


File: python.info,  Node: Command line interface,  Next: Module API,  Up: ensurepip --- Bootstrapping the pip installer

5.28.2.1 Command line interface
...............................

The command line interface is invoked using the interpreter’s ‘-m’
switch.

The simplest possible invocation is:

     python -m ensurepip

This invocation will install ‘pip’ if it is not already installed, but
otherwise does nothing.  To ensure the installed version of ‘pip’ is at
least as recent as the one bundled with ‘ensurepip’, pass the
‘--upgrade’ option:

     python -m ensurepip --upgrade

By default, ‘pip’ is installed into the current virtual environment (if
one is active) or into the system site packages (if there is no active
virtual environment).  The installation location can be controlled
through two additional command line options:

   * ‘--root <dir>’: Installs ‘pip’ relative to the given root directory
     rather than the root of the currently active virtual environment
     (if any) or the default root for the current Python installation.

   * ‘--user’: Installs ‘pip’ into the user site packages directory
     rather than globally for the current Python installation (this
     option is not permitted inside an active virtual environment).

By default, the scripts ‘pipX’ and ‘pipX.Y’ will be installed (where X.Y
stands for the version of Python used to invoke ‘ensurepip’).  The
scripts installed can be controlled through two additional command line
options:

   * ‘--altinstall’: if an alternate installation is requested, the
     ‘pipX’ script will `not' be installed.

   * 
     ‘--default-pip’: if a "default pip" installation is requested, the

          ‘pip’ script will be installed in addition to the two regular
          scripts.

Providing both of the script selection options will trigger an
exception.


File: python.info,  Node: Module API,  Prev: Command line interface,  Up: ensurepip --- Bootstrapping the pip installer

5.28.2.2 Module API
...................

*note ensurepip: 78. exposes two functions for programmatic use:

 -- Function: ensurepip.version ()

     Returns a string specifying the bundled version of pip that will be
     installed when bootstrapping an environment.

 -- Function: ensurepip.bootstrap (root=None, upgrade=False, user=False,
          altinstall=False, default_pip=False, verbosity=0)

     Bootstraps ‘pip’ into the current or designated environment.

     `root' specifies an alternative root directory to install relative
     to.  If `root' is None, then installation uses the default install
     location for the current environment.

     `upgrade' indicates whether or not to upgrade an existing
     installation of an earlier version of ‘pip’ to the bundled version.

     `user' indicates whether to use the user scheme rather than
     installing globally.

     By default, the scripts ‘pipX’ and ‘pipX.Y’ will be installed
     (where X.Y stands for the current version of Python).

     If `altinstall' is set, then ‘pipX’ will `not' be installed.

     If `default_pip' is set, then ‘pip’ will be installed in addition
     to the two regular scripts.

     Setting both `altinstall' and `default_pip' will trigger *note
     ValueError: 19c.

     `verbosity' controls the level of output to *note sys.stdout: 1ba.
     from the bootstrapping operation.

          Note: The bootstrapping process has side effects on both
          ‘sys.path’ and ‘os.environ’.  Invoking the command line
          interface in a subprocess instead allows these side effects to
          be avoided.

          Note: The bootstrapping process may install additional modules
          required by ‘pip’, but other software should not assume those
          dependencies will always be present by default (as the
          dependencies may be removed in a future version of ‘pip’).


File: python.info,  Node: venv --- Creation of virtual environments,  Next: zipapp --- Manage executable python zip archives,  Prev: ensurepip --- Bootstrapping the pip installer,  Up: Software Packaging and Distribution

5.28.3 ‘venv’ — Creation of virtual environments
------------------------------------------------

New in version 3.3.

`Source code:' Lib/venv(1)

__________________________________________________________________

The *note venv: 122. module provides support for creating lightweight
"virtual environments" with their own site directories, optionally
isolated from system site directories.  Each virtual environment has its
own Python binary (allowing creation of environments with various Python
versions) and can have its own independent set of installed Python
packages in its site directories.

See PEP 405(2) for more information about Python virtual environments.

* Menu:

* Creating virtual environments:: 
* API: API<2>. 
* An example of extending EnvBuilder:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/venv

   (2) https://www.python.org/dev/peps/pep-0405


File: python.info,  Node: Creating virtual environments,  Next: API<2>,  Up: venv --- Creation of virtual environments

5.28.3.1 Creating virtual environments
......................................

Creation of *note virtual environments: d6c. is done by executing the
‘pyvenv’ script:

     pyvenv /path/to/new/virtual/environment

Running this command creates the target directory (creating any parent
directories that don’t exist already) and places a ‘pyvenv.cfg’ file in
it with a ‘home’ key pointing to the Python installation the command was
run from.  It also creates a ‘bin’ (or ‘Scripts’ on Windows)
subdirectory containing a copy of the ‘python’ binary (or binaries, in
the case of Windows).  It also creates an (initially empty)
‘lib/pythonX.Y/site-packages’ subdirectory (on Windows, this is
‘Lib\site-packages’).

See also
........

Python Packaging User Guide: Creating and using virtual environments(1)

On Windows, you may have to invoke the ‘pyvenv’ script as follows, if
you don’t have the relevant PATH and PATHEXT settings:

     c:\Temp>c:\Python35\python c:\Python35\Tools\Scripts\pyvenv.py myenv

or equivalently:

     c:\Temp>c:\Python35\python -m venv myenv

The command, if run with ‘-h’, will show the available options:

     usage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]
                 [--upgrade] [--without-pip]
                 ENV_DIR [ENV_DIR ...]

     Creates virtual Python environments in one or more target directories.

     positional arguments:
       ENV_DIR             A directory to create the environment in.

     optional arguments:
       -h, --help             show this help message and exit
       --system-site-packages Give the virtual environment access to the system
                              site-packages dir.
       --symlinks             Try to use symlinks rather than copies, when symlinks
                              are not the default for the platform.
       --copies               Try to use copies rather than symlinks, even when
                              symlinks are the default for the platform.
       --clear                Delete the contents of the environment directory if it
                              already exists, before environment creation.
       --upgrade              Upgrade the environment directory to use this version
                              of Python, assuming Python has been upgraded in-place.
       --without-pip          Skips installing or upgrading pip in the virtual
                              environment (pip is bootstrapped by default)

Depending on how the ‘venv’ functionality has been invoked, the usage
message may vary slightly, e.g.  referencing ‘pyvenv’ rather than
‘venv’.

Changed in version 3.4: Installs pip by default, added the
‘--without-pip’ and ‘--copies’ options

Changed in version 3.4: In earlier versions, if the target directory
already existed, an error was raised, unless the ‘--clear’ or
‘--upgrade’ option was provided.  Now, if an existing directory is
specified, its contents are removed and the directory is processed as if
it had been newly created.

The created ‘pyvenv.cfg’ file also includes the
‘include-system-site-packages’ key, set to ‘true’ if ‘venv’ is run with
the ‘--system-site-packages’ option, ‘false’ otherwise.

Unless the ‘--without-pip’ option is given, *note ensurepip: 78. will be
invoked to bootstrap ‘pip’ into the virtual environment.

Multiple paths can be given to ‘pyvenv’, in which case an identical
virtualenv will be created, according to the given options, at each
provided path.

Once a venv has been created, it can be "activated" using a script in
the venv’s binary directory.  The invocation of the script is
platform-specific:

Platform          Shell                 Command to activate virtual environment
                                        
--------------------------------------------------------------------------------------
                                        
Posix             bash/zsh              $ source <venv>/bin/activate
                                        
                                        
                  fish                  $ .  <venv>/bin/activate.fish
                                        
                                        
                  csh/tcsh              $ source <venv>/bin/activate.csh
                                        
                                        
Windows           cmd.exe               C:> <venv>/Scripts/activate.bat
                                        
                                        
                  PowerShell            PS C:> <venv>/Scripts/Activate.ps1
                                        

You don’t specifically `need' to activate an environment; activation
just prepends the venv’s binary directory to your path, so that "python"
invokes the venv’s Python interpreter and you can run installed scripts
without having to use their full path.  However, all scripts installed
in a venv should be runnable without activating it, and run with the
venv’s Python automatically.

You can deactivate a venv by typing "deactivate" in your shell.  The
exact mechanism is platform-specific: for example, the Bash activation
script defines a "deactivate" function, whereas on Windows there are
separate scripts called ‘deactivate.bat’ and ‘Deactivate.ps1’ which are
installed when the venv is created.

New in version 3.4: ‘fish’ and ‘csh’ activation scripts.

     Note: A virtual environment (also called a ‘venv’) is a Python
     environment such that the Python interpreter, libraries and scripts
     installed into it are isolated from those installed in other
     virtual environments, and (by default) any libraries installed in a
     "system" Python, i.e.  one which is installed as part of your
     operating system.

     A venv is a directory tree which contains Python executable files
     and other files which indicate that it is a venv.

     Common installation tools such as ‘Setuptools’ and ‘pip’ work as
     expected with venvs - i.e.  when a venv is active, they install
     Python packages into the venv without needing to be told to do so
     explicitly.

     When a venv is active (i.e.  the venv’s Python interpreter is
     running), the attributes *note sys.prefix: 2dfd. and *note
     sys.exec_prefix: 2dfe. point to the base directory of the venv,
     whereas *note sys.base_prefix: 2dff. and *note
     sys.base_exec_prefix: 2e00. point to the non-venv Python
     installation which was used to create the venv.  If a venv is not
     active, then *note sys.prefix: 2dfd. is the same as *note
     sys.base_prefix: 2dff. and *note sys.exec_prefix: 2dfe. is the same
     as *note sys.base_exec_prefix: 2e00. (they all point to a non-venv
     Python installation).

     When a venv is active, any options that change the installation
     path will be ignored from all distutils configuration files to
     prevent projects being inadvertently installed outside of the
     virtual environment.

     When working in a command shell, users can make a venv active by
     running an ‘activate’ script in the venv’s executables directory
     (the precise filename is shell-dependent), which prepends the
     venv’s directory for executables to the ‘PATH’ environment variable
     for the running shell.  There should be no need in other
     circumstances to activate a venv – scripts installed into venvs
     have a shebang line which points to the venv’s Python interpreter.
     This means that the script will run with that interpreter
     regardless of the value of ‘PATH’.  On Windows, shebang line
     processing is supported if you have the Python Launcher for Windows
     installed (this was added to Python in 3.3 - see PEP 397(2) for
     more details).  Thus, double-clicking an installed script in a
     Windows Explorer window should run the script with the correct
     interpreter without there needing to be any reference to its venv
     in ‘PATH’.

   ---------- Footnotes ----------

   (1) 
https://packaging.python.org/en/latest/installing/#creating-virtual-environments

   (2) https://www.python.org/dev/peps/pep-0397


File: python.info,  Node: API<2>,  Next: An example of extending EnvBuilder,  Prev: Creating virtual environments,  Up: venv --- Creation of virtual environments

5.28.3.2 API
............

The high-level method described above makes use of a simple API which
provides mechanisms for third-party virtual environment creators to
customize environment creation according to their needs, the *note
EnvBuilder: 50a. class.

 -- Class: venv.EnvBuilder (system_site_packages=False, clear=False,
          symlinks=False, upgrade=False, with_pip=False)

     The *note EnvBuilder: 50a. class accepts the following keyword
     arguments on instantiation:

        * ‘system_site_packages’ – a Boolean value indicating that the
          system Python site-packages should be available to the
          environment (defaults to ‘False’).

        * ‘clear’ – a Boolean value which, if true, will delete the
          contents of any existing target directory, before creating the
          environment.

        * ‘symlinks’ – a Boolean value indicating whether to attempt to
          symlink the Python binary (and any necessary DLLs or other
          binaries, e.g.  ‘pythonw.exe’), rather than copying.  Defaults
          to ‘True’ on Linux and Unix systems, but ‘False’ on Windows.

        * ‘upgrade’ – a Boolean value which, if true, will upgrade an
          existing environment with the running Python - for use when
          that Python has been upgraded in-place (defaults to ‘False’).

        * ‘with_pip’ – a Boolean value which, if true, ensures pip is
          installed in the virtual environment.  This uses *note
          ensurepip: 78. with the ‘--default-pip’ option.

     Changed in version 3.4: Added the ‘with_pip’ parameter

     Creators of third-party virtual environment tools will be free to
     use the provided ‘EnvBuilder’ class as a base class.

     The returned env-builder is an object which has a method, ‘create’:

      -- Method: create (env_dir)

          This method takes as required argument the path (absolute or
          relative to the current directory) of the target directory
          which is to contain the virtual environment.  The ‘create’
          method will either create the environment in the specified
          directory, or raise an appropriate exception.

          The ‘create’ method of the ‘EnvBuilder’ class illustrates the
          hooks available for subclass customization:

               def create(self, env_dir):
                   """
                   Create a virtualized Python environment in a directory.
                   env_dir is the target directory to create an environment in.
                   """
                   env_dir = os.path.abspath(env_dir)
                   context = self.ensure_directories(env_dir)
                   self.create_configuration(context)
                   self.setup_python(context)
                   self.setup_scripts(context)
                   self.post_setup(context)

          Each of the methods *note ensure_directories(): 2e03, *note
          create_configuration(): 2e04, *note setup_python(): 2e05,
          *note setup_scripts(): 2e06. and *note post_setup(): 2e07. can
          be overridden.

      -- Method: ensure_directories (env_dir)

          Creates the environment directory and all necessary
          directories, and returns a context object.  This is just a
          holder for attributes (such as paths), for use by the other
          methods.  The directories are allowed to exist already, as
          long as either ‘clear’ or ‘upgrade’ were specified to allow
          operating on an existing environment directory.

      -- Method: create_configuration (context)

          Creates the ‘pyvenv.cfg’ configuration file in the
          environment.

      -- Method: setup_python (context)

          Creates a copy of the Python executable (and, under Windows,
          DLLs) in the environment.  On a POSIX system, if a specific
          executable ‘python3.x’ was used, symlinks to ‘python’ and
          ‘python3’ will be created pointing to that executable, unless
          files with those names already exist.

      -- Method: setup_scripts (context)

          Installs activation scripts appropriate to the platform into
          the virtual environment.

      -- Method: post_setup (context)

          A placeholder method which can be overridden in third party
          implementations to pre-install packages in the virtual
          environment or perform other post-creation steps.

     In addition, *note EnvBuilder: 50a. provides this utility method
     that can be called from *note setup_scripts(): 2e06. or *note
     post_setup(): 2e07. in subclasses to assist in installing custom
     scripts into the virtual environment.

      -- Method: install_scripts (context, path)

          `path' is the path to a directory that should contain
          subdirectories "common", "posix", "nt", each containing
          scripts destined for the bin directory in the environment.
          The contents of "common" and the directory corresponding to
          *note os.name: 184f. are copied after some text replacement of
          placeholders:

             * ‘__VENV_DIR__’ is replaced with the absolute path of the
               environment directory.

             * ‘__VENV_NAME__’ is replaced with the environment name
               (final path segment of environment directory).

             * ‘__VENV_PROMPT__’ is replaced with the prompt (the
               environment name surrounded by parentheses and with a
               following space)

             * ‘__VENV_BIN_NAME__’ is replaced with the name of the bin
               directory (either ‘bin’ or ‘Scripts’).

             * ‘__VENV_PYTHON__’ is replaced with the absolute path of
               the environment’s executable.

          The directories are allowed to exist (for when an existing
          environment is being upgraded).

There is also a module-level convenience function:

 -- Function: venv.create (env_dir, system_site_packages=False,
          clear=False, symlinks=False, with_pip=False)

     Create an *note EnvBuilder: 50a. with the given keyword arguments,
     and call its *note create(): 2e02. method with the `env_dir'
     argument.

     Changed in version 3.4: Added the ‘with_pip’ parameter


File: python.info,  Node: An example of extending EnvBuilder,  Prev: API<2>,  Up: venv --- Creation of virtual environments

5.28.3.3 An example of extending ‘EnvBuilder’
.............................................

The following script shows how to extend *note EnvBuilder: 50a. by
implementing a subclass which installs setuptools and pip into a created
venv:

     import os
     import os.path
     from subprocess import Popen, PIPE
     import sys
     from threading import Thread
     from urllib.parse import urlparse
     from urllib.request import urlretrieve
     import venv

     class ExtendedEnvBuilder(venv.EnvBuilder):
         """
         This builder installs setuptools and pip so that you can pip or
         easy_install other packages into the created environment.

         :param nodist: If True, setuptools and pip are not installed into the
                        created environment.
         :param nopip: If True, pip is not installed into the created
                       environment.
         :param progress: If setuptools or pip are installed, the progress of the
                          installation can be monitored by passing a progress
                          callable. If specified, it is called with two
                          arguments: a string indicating some progress, and a
                          context indicating where the string is coming from.
                          The context argument can have one of three values:
                          'main', indicating that it is called from virtualize()
                          itself, and 'stdout' and 'stderr', which are obtained
                          by reading lines from the output streams of a subprocess
                          which is used to install the app.

                          If a callable is not specified, default progress
                          information is output to sys.stderr.
         """

         def __init__(self, *args, **kwargs):
             self.nodist = kwargs.pop('nodist', False)
             self.nopip = kwargs.pop('nopip', False)
             self.progress = kwargs.pop('progress', None)
             self.verbose = kwargs.pop('verbose', False)
             super().__init__(*args, **kwargs)

         def post_setup(self, context):
             """
             Set up any packages which need to be pre-installed into the
             environment being created.

             :param context: The information for the environment creation request
                             being processed.
             """
             os.environ['VIRTUAL_ENV'] = context.env_dir
             if not self.nodist:
                 self.install_setuptools(context)
             # Can't install pip without setuptools
             if not self.nopip and not self.nodist:
                 self.install_pip(context)

         def reader(self, stream, context):
             """
             Read lines from a subprocess' output stream and either pass to a progress
             callable (if specified) or write progress information to sys.stderr.
             """
             progress = self.progress
             while True:
                 s = stream.readline()
                 if not s:
                     break
                 if progress is not None:
                     progress(s, context)
                 else:
                     if not self.verbose:
                         sys.stderr.write('.')
                     else:
                         sys.stderr.write(s.decode('utf-8'))
                     sys.stderr.flush()
             stream.close()

         def install_script(self, context, name, url):
             _, _, path, _, _, _ = urlparse(url)
             fn = os.path.split(path)[-1]
             binpath = context.bin_path
             distpath = os.path.join(binpath, fn)
             # Download script into the env's binaries folder
             urlretrieve(url, distpath)
             progress = self.progress
             if self.verbose:
                 term = '\n'
             else:
                 term = ''
             if progress is not None:
                 progress('Installing %s ...%s' % (name, term), 'main')
             else:
                 sys.stderr.write('Installing %s ...%s' % (name, term))
                 sys.stderr.flush()
             # Install in the env
             args = [context.env_exe, fn]
             p = Popen(args, stdout=PIPE, stderr=PIPE, cwd=binpath)
             t1 = Thread(target=self.reader, args=(p.stdout, 'stdout'))
             t1.start()
             t2 = Thread(target=self.reader, args=(p.stderr, 'stderr'))
             t2.start()
             p.wait()
             t1.join()
             t2.join()
             if progress is not None:
                 progress('done.', 'main')
             else:
                 sys.stderr.write('done.\n')
             # Clean up - no longer needed
             os.unlink(distpath)

         def install_setuptools(self, context):
             """
             Install setuptools in the environment.

             :param context: The information for the environment creation request
                             being processed.
             """
             url = 'https://bitbucket.org/pypa/setuptools/downloads/ez_setup.py'
             self.install_script(context, 'setuptools', url)
             # clear up the setuptools archive which gets downloaded
             pred = lambda o: o.startswith('setuptools-') and o.endswith('.tar.gz')
             files = filter(pred, os.listdir(context.bin_path))
             for f in files:
                 f = os.path.join(context.bin_path, f)
                 os.unlink(f)

         def install_pip(self, context):
             """
             Install pip in the environment.

             :param context: The information for the environment creation request
                             being processed.
             """
             url = 'https://raw.github.com/pypa/pip/master/contrib/get-pip.py'
             self.install_script(context, 'pip', url)

     def main(args=None):
         compatible = True
         if sys.version_info < (3, 3):
             compatible = False
         elif not hasattr(sys, 'base_prefix'):
             compatible = False
         if not compatible:
             raise ValueError('This script is only for use with '
                              'Python 3.3 or later')
         else:
             import argparse

             parser = argparse.ArgumentParser(prog=__name__,
                                              description='Creates virtual Python '
                                                          'environments in one or '
                                                          'more target '
                                                          'directories.')
             parser.add_argument('dirs', metavar='ENV_DIR', nargs='+',
                                 help='A directory to create the environment in.')
             parser.add_argument('--no-setuptools', default=False,
                                 action='store_true', dest='nodist',
                                 help="Don't install setuptools or pip in the "
                                      "virtual environment.")
             parser.add_argument('--no-pip', default=False,
                                 action='store_true', dest='nopip',
                                 help="Don't install pip in the virtual "
                                      "environment.")
             parser.add_argument('--system-site-packages', default=False,
                                 action='store_true', dest='system_site',
                                 help='Give the virtual environment access to the '
                                      'system site-packages dir.')
             if os.name == 'nt':
                 use_symlinks = False
             else:
                 use_symlinks = True
             parser.add_argument('--symlinks', default=use_symlinks,
                                 action='store_true', dest='symlinks',
                                 help='Try to use symlinks rather than copies, '
                                      'when symlinks are not the default for '
                                      'the platform.')
             parser.add_argument('--clear', default=False, action='store_true',
                                 dest='clear', help='Delete the contents of the '
                                                    'environment directory if it '
                                                    'already exists, before '
                                                    'environment creation.')
             parser.add_argument('--upgrade', default=False, action='store_true',
                                 dest='upgrade', help='Upgrade the environment '
                                                    'directory to use this version '
                                                    'of Python, assuming Python '
                                                    'has been upgraded in-place.')
             parser.add_argument('--verbose', default=False, action='store_true',
                                 dest='verbose', help='Display the output '
                                                    'from the scripts which '
                                                    'install setuptools and pip.')
             options = parser.parse_args(args)
             if options.upgrade and options.clear:
                 raise ValueError('you cannot supply --upgrade and --clear together.')
             builder = ExtendedEnvBuilder(system_site_packages=options.system_site,
                                            clear=options.clear,
                                            symlinks=options.symlinks,
                                            upgrade=options.upgrade,
                                            nodist=options.nodist,
                                            nopip=options.nopip,
                                            verbose=options.verbose)
             for d in options.dirs:
                 builder.create(d)

     if __name__ == '__main__':
         rc = 1
         try:
             main()
             rc = 0
         except Exception as e:
             print('Error: %s' % e, file=sys.stderr)
         sys.exit(rc)

This script is also available for download online(1).

   ---------- Footnotes ----------

   (1) https://gist.github.com/4673395


File: python.info,  Node: zipapp --- Manage executable python zip archives,  Prev: venv --- Creation of virtual environments,  Up: Software Packaging and Distribution

5.28.4 ‘zipapp’ — Manage executable python zip archives
-------------------------------------------------------

New in version 3.5.

`Source code:' Lib/zipapp.py(1)

__________________________________________________________________

This module provides tools to manage the creation of zip files
containing Python code, which can be *note executed directly by the
Python interpreter: cfc.  The module provides both a *note Command-Line
Interface: 2e0c. and a *note Python API: 2e0d.

* Menu:

* Basic Example:: 
* Command-Line Interface: Command-Line Interface<3>. 
* Python API:: 
* Examples: Examples<21>. 
* The Python Zip Application Archive Format:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/zipapp.py


File: python.info,  Node: Basic Example,  Next: Command-Line Interface<3>,  Up: zipapp --- Manage executable python zip archives

5.28.4.1 Basic Example
......................

The following example shows how the *note Command-Line Interface: 2e0c.
can be used to create an executable archive from a directory containing
Python code.  When run, the archive will execute the ‘main’ function
from the module ‘myapp’ in the archive.

     $ python -m zipapp myapp -m "myapp:main"
     $ python myapp.pyz
     <output from myapp>


File: python.info,  Node: Command-Line Interface<3>,  Next: Python API,  Prev: Basic Example,  Up: zipapp --- Manage executable python zip archives

5.28.4.2 Command-Line Interface
...............................

When called as a program from the command line, the following form is
used:

     $ python -m zipapp source [options]

If `source' is a directory, this will create an archive from the
contents of `source'.  If `source' is a file, it should be an archive,
and it will be copied to the target archive (or the contents of its
shebang line will be displayed if the –info option is specified).

The following options are understood:

 -- Program Option: -o <output>, --output=<output>

     Write the output to a file named `output'.  If this option is not
     specified, the output filename will be the same as the input
     `source', with the extension ‘.pyz’ added.  If an explicit filename
     is given, it is used as is (so a ‘.pyz’ extension should be
     included if required).

     An output filename must be specified if the `source' is an archive
     (and in that case, `output' must not be the same as `source').

 -- Program Option: -p <interpreter>, --python=<interpreter>

     Add a ‘#!’ line to the archive specifying `interpreter' as the
     command to run.  Also, on POSIX, make the archive executable.  The
     default is to write no ‘#!’ line, and not make the file executable.

 -- Program Option: -m <mainfn>, --main=<mainfn>

     Write a ‘__main__.py’ file to the archive that executes `mainfn'.
     The `mainfn' argument should have the form "pkg.mod:fn", where
     "pkg.mod" is a package/module in the archive, and "fn" is a
     callable in the given module.  The ‘__main__.py’ file will execute
     that callable.

     *note –main: 2e15. cannot be specified when copying an archive.

 -- Program Option: --info

     Display the interpreter embedded in the archive, for diagnostic
     purposes.  In this case, any other options are ignored and SOURCE
     must be an archive, not a directory.

 -- Program Option: -h, --help

     Print a short usage message and exit.


File: python.info,  Node: Python API,  Next: Examples<21>,  Prev: Command-Line Interface<3>,  Up: zipapp --- Manage executable python zip archives

5.28.4.3 Python API
...................

The module defines two convenience functions:

 -- Function: zipapp.create_archive (source, target=None,
          interpreter=None, main=None)

     Create an application archive from `source'.  The source can be any
     of the following:

        * The name of a directory, or a *note pathlib.Path: 2e8. object
          referring to a directory, in which case a new application
          archive will be created from the content of that directory.

        * The name of an existing application archive file, or a *note
          pathlib.Path: 2e8. object referring to such a file, in which
          case the file is copied to the target (modifying it to reflect
          the value given for the `interpreter' argument).  The file
          name should include the ‘.pyz’ extension, if required.

        * A file object open for reading in bytes mode.  The content of
          the file should be an application archive, and the file object
          is assumed to be positioned at the start of the archive.

     The `target' argument determines where the resulting archive will
     be written:

        * If it is the name of a file, or a ‘pathlb.Path’ object, the
          archive will be written to that file.

        * If it is an open file object, the archive will be written to
          that file object, which must be open for writing in bytes
          mode.

        * If the target is omitted (or None), the source must be a
          directory and the target will be a file with the same name as
          the source, with a ‘.pyz’ extension added.

     The `interpreter' argument specifies the name of the Python
     interpreter with which the archive will be executed.  It is written
     as a "shebang" line at the start of the archive.  On POSIX, this
     will be interpreted by the OS, and on Windows it will be handled by
     the Python launcher.  Omitting the `interpreter' results in no
     shebang line being written.  If an interpreter is specified, and
     the target is a filename, the executable bit of the target file
     will be set.

     The `main' argument specifies the name of a callable which will be
     used as the main program for the archive.  It can only be specified
     if the source is a directory, and the source does not already
     contain a ‘__main__.py’ file.  The `main' argument should take the
     form "pkg.module:callable" and the archive will be run by importing
     "pkg.module" and executing the given callable with no arguments.
     It is an error to omit `main' if the source is a directory and does
     not contain a ‘__main__.py’ file, as otherwise the resulting
     archive would not be executable.

     If a file object is specified for `source' or `target', it is the
     caller’s responsibility to close it after calling create_archive.

     When copying an existing archive, file objects supplied only need
     ‘read’ and ‘readline’, or ‘write’ methods.  When creating an
     archive from a directory, if the target is a file object it will be
     passed to the ‘zipfile.ZipFile’ class, and must supply the methods
     needed by that class.

 -- Function: zipapp.get_interpreter (archive)

     Return the interpreter specified in the ‘#!’ line at the start of
     the archive.  If there is no ‘#!’ line, return *note None: 19d.
     The `archive' argument can be a filename or a file-like object open
     for reading in bytes mode.  It is assumed to be at the start of the
     archive.


File: python.info,  Node: Examples<21>,  Next: The Python Zip Application Archive Format,  Prev: Python API,  Up: zipapp --- Manage executable python zip archives

5.28.4.4 Examples
.................

Pack up a directory into an archive, and run it.

     $ python -m zipapp myapp
     $ python myapp.pyz
     <output from myapp>

The same can be done using the *note create_archive(): 2e1a. functon:

     >>> import zipapp
     >>> zipapp.create_archive('myapp.pyz', 'myapp')

To make the application directly executable on POSIX, specify an
interpreter to use.

     $ python -m zipapp myapp -p "/usr/bin/env python"
     $ ./myapp.pyz
     <output from myapp>

To replace the shebang line on an existing archive, create a modified
archive using the *note create_archive(): 2e1a. function:

     >>> import zipapp
     >>> zipapp.create_archive('old_archive.pyz', 'new_archive.pyz', '/usr/bin/python3')

To update the file in place, do the replacement in memory using a
‘BytesIO’ object, and then overwrite the source afterwards.  Note that
there is a risk when overwriting a file in place that an error will
result in the loss of the original file.  This code does not protect
against such errors, but production code should do so.  Also, this
method will only work if the archive fits in memory:

     >>> import zipapp
     >>> import io
     >>> temp = io.BytesIO()
     >>> zipapp.create_archive('myapp.pyz', temp, '/usr/bin/python2')
     >>> with open('myapp.pyz', 'wb') as f:
     >>>     f.write(temp.getvalue())

Note that if you specify an interpreter and then distribute your
application archive, you need to ensure that the interpreter used is
portable.  The Python launcher for Windows supports most common forms of
POSIX ‘#!’ line, but there are other issues to consider:

   * If you use "/usr/bin/env python" (or other forms of the "python"
     command, such as "/usr/bin/python"), you need to consider that your
     users may have either Python 2 or Python 3 as their default, and
     write your code to work under both versions.

   * If you use an explicit version, for example "/usr/bin/env python3"
     your application will not work for users who do not have that
     version.  (This may be what you want if you have not made your code
     Python 2 compatible).

   * There is no way to say "python X.Y or later", so be careful of
     using an exact version like "/usr/bin/env python3.4" as you will
     need to change your shebang line for users of Python 3.5, for
     example.


File: python.info,  Node: The Python Zip Application Archive Format,  Prev: Examples<21>,  Up: zipapp --- Manage executable python zip archives

5.28.4.5 The Python Zip Application Archive Format
..................................................

Python has been able to execute zip files which contain a ‘__main__.py’
file since version 2.6.  In order to be executed by Python, an
application archive simply has to be a standard zip file containing a
‘__main__.py’ file which will be run as the entry point for the
application.  As usual for any Python script, the parent of the script
(in this case the zip file) will be placed on *note sys.path: 16c. and
thus further modules can be imported from the zip file.

The zip file format allows arbitrary data to be prepended to a zip file.
The zip application format uses this ability to prepend a standard POSIX
"shebang" line to the file (‘#!/path/to/interpreter’).

Formally, the Python zip application format is therefore:

  1. An optional shebang line, containing the characters ‘b'#!'’
     followed by an interpreter name, and then a newline (‘b'\n'’)
     character.  The interpreter name can be anything acceptable to the
     OS "shebang" processing, or the Python launcher on Windows.  The
     interpreter should be encoded in UTF-8 on Windows, and in *note
     sys.getfilesystemencoding(): 1758. on POSIX.

  2. Standard zipfile data, as generated by the *note zipfile: 13f.
     module.  The zipfile content `must' include a file called
     ‘__main__.py’ (which must be in the "root" of the zipfile - i.e.,
     it cannot be in a subdirectory).  The zipfile data can be
     compressed or uncompressed.

If an application archive has a shebang line, it may have the executable
bit set on POSIX systems, to allow it to be executed directly.

There is no requirement that the tools in this module are used to create
application archives - the module is a convenience, but archives in the
above format created by any means are acceptable to Python.


File: python.info,  Node: Python Runtime Services,  Next: Custom Python Interpreters,  Prev: Software Packaging and Distribution,  Up: The Python Standard Library

5.29 Python Runtime Services
============================

The modules described in this chapter provide a wide range of services
related to the Python interpreter and its interaction with its
environment.  Here’s an overview:

* Menu:

* sys: sys --- System-specific parameters and functions. System-specific parameters and functions
* sysconfig: sysconfig --- Provide access to Python's configuration information. Provide access to Python’s configuration information
* builtins: builtins --- Built-in objects. Built-in objects
* __main__: __main__ --- Top-level script environment. Top-level script environment
* warnings: warnings --- Warning control. Warning control
* contextlib: contextlib --- Utilities for with-statement contexts. Utilities for with-statement contexts
* abc: abc --- Abstract Base Classes. Abstract Base Classes
* atexit: atexit --- Exit handlers. Exit handlers
* traceback: traceback --- Print or retrieve a stack traceback. Print or retrieve a stack traceback
* __future__: __future__ --- Future statement definitions. Future statement definitions
* gc: gc --- Garbage Collector interface. Garbage Collector interface
* inspect: inspect --- Inspect live objects. Inspect live objects
* site: site --- Site-specific configuration hook. Site-specific configuration hook
* fpectl: fpectl --- Floating point exception control. Floating point exception control


File: python.info,  Node: sys --- System-specific parameters and functions,  Next: sysconfig --- Provide access to Python's configuration information,  Up: Python Runtime Services

5.29.1 ‘sys’ — System-specific parameters and functions
-------------------------------------------------------

This module provides access to some variables used or maintained by the
interpreter and to functions that interact strongly with the
interpreter.  It is always available.

 -- Data: sys.abiflags

     On POSIX systems where Python was built with the standard
     ‘configure’ script, this contains the ABI flags as specified by PEP
     3149(1).

     New in version 3.2.

 -- Data: sys.argv

     The list of command line arguments passed to a Python script.
     ‘argv[0]’ is the script name (it is operating system dependent
     whether this is a full pathname or not).  If the command was
     executed using the *note -c: bd2. command line option to the
     interpreter, ‘argv[0]’ is set to the string ‘'-c'’.  If no script
     name was passed to the Python interpreter, ‘argv[0]’ is the empty
     string.

     To loop over the standard input, or the list of files given on the
     command line, see the *note fileinput: 7e. module.

 -- Data: sys.base_exec_prefix

     Set during Python startup, before ‘site.py’ is run, to the same
     value as *note exec_prefix: 2dfe.  If not running in a *note
     virtual environment: d6c, the values will stay the same; if
     ‘site.py’ finds that a virtual environment is in use, the values of
     *note prefix: 2dfd. and *note exec_prefix: 2dfe. will be changed to
     point to the virtual environment, whereas *note base_prefix: 2dff.
     and *note base_exec_prefix: 2e00. will remain pointing to the base
     Python installation (the one which the virtual environment was
     created from).

     New in version 3.3.

 -- Data: sys.base_prefix

     Set during Python startup, before ‘site.py’ is run, to the same
     value as *note prefix: 2dfd.  If not running in a *note virtual
     environment: d6c, the values will stay the same; if ‘site.py’ finds
     that a virtual environment is in use, the values of *note prefix:
     2dfd. and *note exec_prefix: 2dfe. will be changed to point to the
     virtual environment, whereas *note base_prefix: 2dff. and *note
     base_exec_prefix: 2e00. will remain pointing to the base Python
     installation (the one which the virtual environment was created
     from).

     New in version 3.3.

 -- Data: sys.byteorder

     An indicator of the native byte order.  This will have the value
     ‘'big'’ on big-endian (most-significant byte first) platforms, and
     ‘'little'’ on little-endian (least-significant byte first)
     platforms.

 -- Data: sys.builtin_module_names

     A tuple of strings giving the names of all modules that are
     compiled into this Python interpreter.  (This information is not
     available in any other way — ‘modules.keys()’ only lists the
     imported modules.)

 -- Function: sys.call_tracing (func, args)

     Call ‘func(*args)’, while tracing is enabled.  The tracing state is
     saved, and restored afterwards.  This is intended to be called from
     a debugger from a checkpoint, to recursively debug some other code.

 -- Data: sys.copyright

     A string containing the copyright pertaining to the Python
     interpreter.

 -- Function: sys._clear_type_cache ()

     Clear the internal type cache.  The type cache is used to speed up
     attribute and method lookups.  Use the function `only' to drop
     unnecessary references during reference leak debugging.

     This function should be used for internal and specialized purposes
     only.

 -- Function: sys._current_frames ()

     Return a dictionary mapping each thread’s identifier to the topmost
     stack frame currently active in that thread at the time the
     function is called.  Note that functions in the *note traceback:
     110. module can build the call stack given such a frame.

     This is most useful for debugging deadlock: this function does not
     require the deadlocked threads’ cooperation, and such threads’ call
     stacks are frozen for as long as they remain deadlocked.  The frame
     returned for a non-deadlocked thread may bear no relationship to
     that thread’s current activity by the time calling code examines
     the frame.

     This function should be used for internal and specialized purposes
     only.

 -- Function: sys._debugmallocstats ()

     Print low-level information to stderr about the state of CPython’s
     memory allocator.

     If Python is configured –with-pydebug, it also performs some
     expensive internal consistency checks.

     New in version 3.3.

     `CPython implementation detail:' This function is specific to
     CPython.  The exact output format is not defined here, and may
     change.

 -- Data: sys.dllhandle

     Integer specifying the handle of the Python DLL. Availability:
     Windows.

 -- Function: sys.displayhook (value)

     If `value' is not ‘None’, this function prints ‘repr(value)’ to
     ‘sys.stdout’, and saves `value' in ‘builtins._’.  If ‘repr(value)’
     is not encodable to ‘sys.stdout.encoding’ with ‘sys.stdout.errors’
     error handler (which is probably ‘'strict'’), encode it to
     ‘sys.stdout.encoding’ with ‘'backslashreplace'’ error handler.

     ‘sys.displayhook’ is called on the result of evaluating an *note
     expression: 2e2b. entered in an interactive Python session.  The
     display of these values can be customized by assigning another
     one-argument function to ‘sys.displayhook’.

     Pseudo-code:

          def displayhook(value):
              if value is None:
                  return
              # Set '_' to None to avoid recursion
              builtins._ = None
              text = repr(value)
              try:
                  sys.stdout.write(text)
              except UnicodeEncodeError:
                  bytes = text.encode(sys.stdout.encoding, 'backslashreplace')
                  if hasattr(sys.stdout, 'buffer'):
                      sys.stdout.buffer.write(bytes)
                  else:
                      text = bytes.decode(sys.stdout.encoding, 'strict')
                      sys.stdout.write(text)
              sys.stdout.write("\n")
              builtins._ = value

     Changed in version 3.2: Use ‘'backslashreplace'’ error handler on
     *note UnicodeEncodeError: 852.

 -- Data: sys.dont_write_bytecode

     If this is true, Python won’t try to write ‘.pyc’ files on the
     import of source modules.  This value is initially set to ‘True’ or
     ‘False’ depending on the *note -B: 9ad. command line option and the
     *note PYTHONDONTWRITEBYTECODE: 9ae. environment variable, but you
     can set it yourself to control bytecode file generation.

 -- Function: sys.excepthook (type, value, traceback)

     This function prints out a given traceback and exception to
     ‘sys.stderr’.

     When an exception is raised and uncaught, the interpreter calls
     ‘sys.excepthook’ with three arguments, the exception class,
     exception instance, and a traceback object.  In an interactive
     session this happens just before control is returned to the prompt;
     in a Python program this happens just before the program exits.
     The handling of such top-level exceptions can be customized by
     assigning another three-argument function to ‘sys.excepthook’.

 -- Data: sys.__displayhook__
 -- Data: sys.__excepthook__

     These objects contain the original values of ‘displayhook’ and
     ‘excepthook’ at the start of the program.  They are saved so that
     ‘displayhook’ and ‘excepthook’ can be restored in case they happen
     to get replaced with broken objects.

 -- Function: sys.exc_info ()

     This function returns a tuple of three values that give information
     about the exception that is currently being handled.  The
     information returned is specific both to the current thread and to
     the current stack frame.  If the current stack frame is not
     handling an exception, the information is taken from the calling
     stack frame, or its caller, and so on until a stack frame is found
     that is handling an exception.  Here, "handling an exception" is
     defined as "executing an except clause."  For any stack frame, only
     information about the exception being currently handled is
     accessible.

     If no exception is being handled anywhere on the stack, a tuple
     containing three ‘None’ values is returned.  Otherwise, the values
     returned are ‘(type, value, traceback)’.  Their meaning is: `type'
     gets the type of the exception being handled (a subclass of *note
     BaseException: 8c9.); `value' gets the exception instance (an
     instance of the exception type); `traceback' gets a traceback
     object (see the Reference Manual) which encapsulates the call stack
     at the point where the exception originally occurred.

 -- Data: sys.exec_prefix

     A string giving the site-specific directory prefix where the
     platform-dependent Python files are installed; by default, this is
     also ‘'/usr/local'’.  This can be set at build time with the
     ‘--exec-prefix’ argument to the ‘configure’ script.  Specifically,
     all configuration files (e.g.  the ‘pyconfig.h’ header file) are
     installed in the directory ‘`exec_prefix'/lib/python`X.Y'/config’,
     and shared library modules are installed in
     ‘`exec_prefix'/lib/python`X.Y'/lib-dynload’, where `X.Y' is the
     version number of Python, for example ‘3.2’.

          Note: If a *note virtual environment: d6c. is in effect, this
          value will be changed in ‘site.py’ to point to the virtual
          environment.  The value for the Python installation will still
          be available, via *note base_exec_prefix: 2e00.

 -- Data: sys.executable

     A string giving the absolute path of the executable binary for the
     Python interpreter, on systems where this makes sense.  If Python
     is unable to retrieve the real path to its executable, *note
     sys.executable: 1d34. will be an empty string or ‘None’.

 -- Function: sys.exit ([arg])

     Exit from Python.  This is implemented by raising the *note
     SystemExit: 1a2. exception, so cleanup actions specified by finally
     clauses of *note try: 9e9. statements are honored, and it is
     possible to intercept the exit attempt at an outer level.

     The optional argument `arg' can be an integer giving the exit
     status (defaulting to zero), or another type of object.  If it is
     an integer, zero is considered "successful termination" and any
     nonzero value is considered "abnormal termination" by shells and
     the like.  Most systems require it to be in the range 0–127, and
     produce undefined results otherwise.  Some systems have a
     convention for assigning specific meanings to specific exit codes,
     but these are generally underdeveloped; Unix programs generally use
     2 for command line syntax errors and 1 for all other kind of
     errors.  If another type of object is passed, ‘None’ is equivalent
     to passing zero, and any other object is printed to *note stderr:
     270. and results in an exit code of 1.  In particular,
     ‘sys.exit("some error message")’ is a quick way to exit a program
     when an error occurs.

     Since *note exit(): fc5. ultimately "only" raises an exception, it
     will only exit the process when called from the main thread, and
     the exception is not intercepted.

     Changed in version 3.6: If an error occurs in the cleanup after the
     Python interpreter has caught *note SystemExit: 1a2. (such as an
     error flushing buffered data in the standard streams), the exit
     status is changed to 120.

 -- Data: sys.flags

     The *note struct sequence: 6dd. `flags' exposes the status of
     command line flags.  The attributes are read only.

     attribute                         flag
                                       
     --------------------------------------------------------------------
                                       
     ‘debug’                           *note -d: d01.
                                       
                                       
     *note inspect: 9e.                *note -i: aa1.
                                       
                                       
     ‘interactive’                     *note -i: aa1.
                                       
                                       
     ‘optimize’                        *note -O: 221. or
                                       *note -OO: 222.
                                       
                                       
     *note dont_write_bytecode: 2e2c.  *note -B: 9ad.
                                       
                                       
     ‘no_user_site’                    *note -s: 986.
                                       
                                       
     ‘no_site’                         *note -S: 766.
                                       
                                       
     ‘ignore_environment’              *note -E: d03.
                                       
                                       
     ‘verbose’                         *note -v: a02.
                                       
                                       
     ‘bytes_warning’                   *note -b: 226.
                                       
                                       
     ‘quiet’                           *note -q: d08.
                                       
                                       
     ‘hash_randomization’              *note -R: d09.
                                       

     Changed in version 3.2: Added ‘quiet’ attribute for the new *note
     -q: d08. flag.

     New in version 3.2.3: The ‘hash_randomization’ attribute.

     Changed in version 3.3: Removed obsolete ‘division_warning’
     attribute.

 -- Data: sys.float_info

     A *note struct sequence: 6dd. holding information about the float
     type.  It contains low level information about the precision and
     internal representation.  The values correspond to the various
     floating-point constants defined in the standard header file
     ‘float.h’ for the ’C’ programming language; see section 5.2.4.2.2
     of the 1999 ISO/IEC C standard *note [C99]: 2e2f, ’Characteristics
     of floating types’, for details.

     attribute                 float.h macro        explanation
                                                    
     ------------------------------------------------------------------------------------------------------
                                                    
     ‘epsilon’                 DBL_EPSILON          difference between 1 and the least value greater
                                                    than 1 that is representable as a float
                                                    
                                                    
     ‘dig’                     DBL_DIG              maximum number of decimal digits that can be
                                                    faithfully represented in a float; see below
                                                    
                                                    
     ‘mant_dig’                DBL_MANT_DIG         float precision: the number of base-‘radix’ digits
                                                    in the significand of a float
                                                    
                                                    
     *note max: 3fa.           DBL_MAX              maximum representable finite float
                                                    
                                                    
     ‘max_exp’                 DBL_MAX_EXP          maximum integer e such that ‘radix**(e-1)’ is a
                                                    representable finite float
                                                    
                                                    
     ‘max_10_exp’              DBL_MAX_10_EXP       maximum integer e such that ‘10**e’ is in the range
                                                    of representable finite floats
                                                    
                                                    
     *note min: 3f9.           DBL_MIN              minimum positive normalized float
                                                    
                                                    
     ‘min_exp’                 DBL_MIN_EXP          minimum integer e such that ‘radix**(e-1)’ is a
                                                    normalized float
                                                    
                                                    
     ‘min_10_exp’              DBL_MIN_10_EXP       minimum integer e such that ‘10**e’ is a normalized
                                                    float
                                                    
                                                    
     ‘radix’                   FLT_RADIX            radix of exponent representation
                                                    
                                                    
     ‘rounds’                  FLT_ROUNDS           integer constant representing the rounding mode used
                                                    for arithmetic operations.  This reflects the value
                                                    of the system FLT_ROUNDS macro at interpreter
                                                    startup time.  See section 5.2.4.2.2 of the C99
                                                    standard for an explanation of the possible values
                                                    and their meanings.
                                                    

     The attribute ‘sys.float_info.dig’ needs further explanation.  If
     ‘s’ is any string representing a decimal number with at most
     ‘sys.float_info.dig’ significant digits, then converting ‘s’ to a
     float and back again will recover a string representing the same
     decimal value:

          >>> import sys
          >>> sys.float_info.dig
          15
          >>> s = '3.14159265358979'    # decimal string with 15 significant digits
          >>> format(float(s), '.15g')  # convert to float and back -> same value
          '3.14159265358979'

     But for strings with more than ‘sys.float_info.dig’ significant
     digits, this isn’t always true:

          >>> s = '9876543211234567'    # 16 significant digits is too many!
          >>> format(float(s), '.16g')  # conversion changes value
          '9876543211234568'

 -- Data: sys.float_repr_style

     A string indicating how the *note repr(): 3bb. function behaves for
     floats.  If the string has value ‘'short'’ then for a finite float
     ‘x’, ‘repr(x)’ aims to produce a short string with the property
     that ‘float(repr(x)) == x’.  This is the usual behaviour in Python
     3.1 and later.  Otherwise, ‘float_repr_style’ has value ‘'legacy'’
     and ‘repr(x)’ behaves in the same way as it did in versions of
     Python prior to 3.1.

     New in version 3.1.

 -- Function: sys.getallocatedblocks ()

     Return the number of memory blocks currently allocated by the
     interpreter, regardless of their size.  This function is mainly
     useful for tracking and debugging memory leaks.  Because of the
     interpreter’s internal caches, the result can vary from call to
     call; you may have to call *note _clear_type_cache(): 2e28. and
     *note gc.collect(): a0c. to get more predictable results.

     If a Python build or implementation cannot reasonably compute this
     information, *note getallocatedblocks(): 4e3. is allowed to return
     0 instead.

     New in version 3.4.

 -- Function: sys.getcheckinterval ()

     Return the interpreter’s "check interval"; see *note
     setcheckinterval(): 2e30.

     Deprecated since version 3.2: Use *note getswitchinterval(): 2e31.
     instead.

 -- Function: sys.getdefaultencoding ()

     Return the name of the current default string encoding used by the
     Unicode implementation.

 -- Function: sys.getdlopenflags ()

     Return the current value of the flags that are used for ‘dlopen()’
     calls.  Symbolic names for the flag values can be found in the
     *note os: c2. module (‘RTLD_xxx’ constants, e.g.  *note
     os.RTLD_LAZY: 694.).  Availability: Unix.

 -- Function: sys.getfilesystemencoding ()

     Return the name of the encoding used to convert Unicode filenames
     into system file names.  The result value depends on the operating
     system:

        * On Mac OS X, the encoding is ‘'utf-8'’.

        * On Unix, the encoding is the user’s preference according to
          the result of nl_langinfo(CODESET).

        * On Windows NT+, file names are Unicode natively, so no
          conversion is performed.  *note getfilesystemencoding(): 1758.
          still returns ‘'mbcs'’, as this is the encoding that
          applications should use when they explicitly want to convert
          Unicode strings to byte strings that are equivalent when used
          as file names.

        * On Windows 9x, the encoding is ‘'mbcs'’.

     Changed in version 3.2: *note getfilesystemencoding(): 1758. result
     cannot be ‘None’ anymore.

 -- Function: sys.getrefcount (object)

     Return the reference count of the `object'.  The count returned is
     generally one higher than you might expect, because it includes the
     (temporary) reference as an argument to *note getrefcount(): 2e33.

 -- Function: sys.getrecursionlimit ()

     Return the current value of the recursion limit, the maximum depth
     of the Python interpreter stack.  This limit prevents infinite
     recursion from causing an overflow of the C stack and crashing
     Python.  It can be set by *note setrecursionlimit(): b01.

 -- Function: sys.getsizeof (object[, default])

     Return the size of an object in bytes.  The object can be any type
     of object.  All built-in objects will return correct results, but
     this does not have to hold true for third-party extensions as it is
     implementation specific.

     Only the memory consumption directly attributed to the object is
     accounted for, not the memory consumption of objects it refers to.

     If given, `default' will be returned if the object does not provide
     means to retrieve the size.  Otherwise a *note TypeError: 562. will
     be raised.

     *note getsizeof(): 2dc2. calls the object’s ‘__sizeof__’ method and
     adds an additional garbage collector overhead if the object is
     managed by the garbage collector.

     See recursive sizeof recipe(2) for an example of using *note
     getsizeof(): 2dc2. recursively to find the size of containers and
     all their contents.

 -- Function: sys.getswitchinterval ()

     Return the interpreter’s "thread switch interval"; see *note
     setswitchinterval(): 849.

     New in version 3.2.

 -- Function: sys._getframe ([depth])

     Return a frame object from the call stack.  If optional integer
     `depth' is given, return the frame object that many calls below the
     top of the stack.  If that is deeper than the call stack, *note
     ValueError: 19c. is raised.  The default for `depth' is zero,
     returning the frame at the top of the call stack.

     `CPython implementation detail:' This function should be used for
     internal and specialized purposes only.  It is not guaranteed to
     exist in all implementations of Python.

 -- Function: sys.getprofile ()

     Get the profiler function as set by *note setprofile(): abf.

 -- Function: sys.gettrace ()

     Get the trace function as set by *note settrace(): ac0.

     `CPython implementation detail:' The *note gettrace(): 9be.
     function is intended only for implementing debuggers, profilers,
     coverage tools and the like.  Its behavior is part of the
     implementation platform, rather than part of the language
     definition, and thus may not be available in all Python
     implementations.

 -- Function: sys.getwindowsversion ()

     Return a named tuple describing the Windows version currently
     running.  The named elements are `major', `minor', `build',
     `platform', `service_pack', `service_pack_minor',
     `service_pack_major', `suite_mask', and `product_type'.
     `service_pack' contains a string while all other values are
     integers.  The components can also be accessed by name, so
     ‘sys.getwindowsversion()[0]’ is equivalent to
     ‘sys.getwindowsversion().major’.  For compatibility with prior
     versions, only the first 5 elements are retrievable by indexing.

     `platform' may be one of the following values:

     Constant                                      Platform
                                                   
     ----------------------------------------------------------------------------
                                                   
     ‘0 (VER_PLATFORM_WIN32s)’                     Win32s on Windows 3.1
                                                   
                                                   
     ‘1 (VER_PLATFORM_WIN32_WINDOWS)’              Windows 95/98/ME
                                                   
                                                   
     ‘2 (VER_PLATFORM_WIN32_NT)’                   Windows NT/2000/XP/x64
                                                   
                                                   
     ‘3 (VER_PLATFORM_WIN32_CE)’                   Windows CE
                                                   

     `product_type' may be one of the following values:

     Constant                                    Meaning
                                                 
     ----------------------------------------------------------------------------------
                                                 
     ‘1 (VER_NT_WORKSTATION)’                    The system is a workstation.
                                                 
                                                 
     ‘2 (VER_NT_DOMAIN_CONTROLLER)’              The system is a domain controller.
                                                 
                                                 
     ‘3 (VER_NT_SERVER)’                         The system is a server, but not a
                                                 domain controller.
                                                 

     This function wraps the Win32 ‘GetVersionEx()’ function; see the
     Microsoft documentation on ‘OSVERSIONINFOEX()’ for more information
     about these fields.

     Availability: Windows.

     Changed in version 3.2: Changed to a named tuple and added
     `service_pack_minor', `service_pack_major', `suite_mask', and
     `product_type'.

 -- Function: sys.get_coroutine_wrapper ()

     Returns ‘None’, or a wrapper set by *note set_coroutine_wrapper():
     331.

     New in version 3.5: See PEP 492(3) for more details.

          Note: This function has been added on a provisional basis (see
          PEP 411(4) for details.)  Use it only for debugging purposes.

 -- Data: sys.hash_info

     A *note struct sequence: 6dd. giving parameters of the numeric hash
     implementation.  For more details about hashing of numeric types,
     see *note Hashing of numeric types: fdd.

     attribute                 explanation
                               
     ---------------------------------------------------------------------------------
                               
     ‘width’                   width in bits used for hash values
                               
                               
     ‘modulus’                 prime modulus P used for numeric hash scheme
                               
                               
     ‘inf’                     hash value returned for a positive infinity
                               
                               
     ‘nan’                     hash value returned for a nan
                               
                               
     ‘imag’                    multiplier used for the imaginary part of a complex
                               number
                               
                               
     ‘algorithm’               name of the algorithm for hashing of str, bytes, and
                               memoryview
                               
                               
     ‘hash_bits’               internal output size of the hash algorithm
                               
                               
     ‘seed_bits’               size of the seed key of the hash algorithm
                               

     New in version 3.2.

     Changed in version 3.4: Added `algorithm', `hash_bits' and
     `seed_bits'

 -- Data: sys.hexversion

     The version number encoded as a single integer.  This is guaranteed
     to increase with each version, including proper support for
     non-production releases.  For example, to test that the Python
     interpreter is at least version 1.5.2, use:

          if sys.hexversion >= 0x010502F0:
              # use some advanced feature
              ...
          else:
              # use an alternative implementation or warn the user
              ...

     This is called ‘hexversion’ since it only really looks meaningful
     when viewed as the result of passing it to the built-in *note
     hex(): 8d1. function.  The *note struct sequence: 6dd. *note
     sys.version_info: 75c. may be used for a more human-friendly
     encoding of the same information.

     More details of ‘hexversion’ can be found at *note API and ABI
     Versioning: 2e35.

 -- Data: sys.implementation

     An object containing information about the implementation of the
     currently running Python interpreter.  The following attributes are
     required to exist in all Python implementations.

     `name' is the implementation’s identifier, e.g.  ‘'cpython'’.  The
     actual string is defined by the Python implementation, but it is
     guaranteed to be lower case.

     `version' is a named tuple, in the same format as *note
     sys.version_info: 75c.  It represents the version of the Python
     `implementation'.  This has a distinct meaning from the specific
     version of the Python `language' to which the currently running
     interpreter conforms, which ‘sys.version_info’ represents.  For
     example, for PyPy 1.8 ‘sys.implementation.version’ might be
     ‘sys.version_info(1, 8, 0, 'final', 0)’, whereas ‘sys.version_info’
     would be ‘sys.version_info(2, 7, 2, 'final', 0)’.  For CPython they
     are the same value, since it is the reference implementation.

     `hexversion' is the implementation version in hexadecimal format,
     like *note sys.hexversion: 2e34.

     `cache_tag' is the tag used by the import machinery in the
     filenames of cached modules.  By convention, it would be a
     composite of the implementation’s name and version, like
     ‘'cpython-33'’.  However, a Python implementation may use some
     other value if appropriate.  If ‘cache_tag’ is set to ‘None’, it
     indicates that module caching should be disabled.

     *note sys.implementation: 5c8. may contain additional attributes
     specific to the Python implementation.  These non-standard
     attributes must start with an underscore, and are not described
     here.  Regardless of its contents, *note sys.implementation: 5c8.
     will not change during a run of the interpreter, nor between
     implementation versions.  (It may change between Python language
     versions, however.)  See PEP 421(5) for more information.

     New in version 3.3.

 -- Data: sys.int_info

     A *note struct sequence: 6dd. that holds information about Python’s
     internal representation of integers.  The attributes are read only.

     Attribute                     Explanation
                                   
     ---------------------------------------------------------------------------------
                                   
     ‘bits_per_digit’              number of bits held in each digit.  Python
                                   integers are stored internally in base
                                   ‘2**int_info.bits_per_digit’
                                   
                                   
     ‘sizeof_digit’                size in bytes of the C type used to represent a
                                   digit
                                   

     New in version 3.1.

 -- Data: sys.__interactivehook__

     When this attribute exists, its value is automatically called (with
     no arguments) when the interpreter is launched in *note interactive
     mode: 4e4.  This is done after the *note PYTHONSTARTUP: 4e6. file
     is read, so that you can set this hook there.  The *note site: e9.
     module *note sets this: 4e7.

     New in version 3.4.

 -- Function: sys.intern (string)

     Enter `string' in the table of "interned" strings and return the
     interned string – which is `string' itself or a copy.  Interning
     strings is useful to gain a little performance on dictionary lookup
     – if the keys in a dictionary are interned, and the lookup key is
     interned, the key comparisons (after hashing) can be done by a
     pointer compare instead of a string compare.  Normally, the names
     used in Python programs are automatically interned, and the
     dictionaries used to hold module, class or instance attributes have
     interned keys.

     Interned strings are not immortal; you must keep a reference to the
     return value of *note intern(): 8da. around to benefit from it.

 -- Function: sys.is_finalizing ()

     Return *note True: 9ff. if the Python interpreter is *note shutting
     down: 334, *note False: 60d. otherwise.

     New in version 3.5.

 -- Data: sys.last_type
 -- Data: sys.last_value
 -- Data: sys.last_traceback

     These three variables are not always defined; they are set when an
     exception is not handled and the interpreter prints an error
     message and a stack traceback.  Their intended use is to allow an
     interactive user to import a debugger module and engage in
     post-mortem debugging without having to re-execute the command that
     caused the error.  (Typical use is ‘import pdb; pdb.pm()’ to enter
     the post-mortem debugger; see *note pdb: c7. module for more
     information.)

     The meaning of the variables is the same as that of the return
     values from *note exc_info(): 8ca. above.

 -- Data: sys.maxsize

     An integer giving the maximum value a variable of type ‘Py_ssize_t’
     can take.  It’s usually ‘2**31 - 1’ on a 32-bit platform and ‘2**63
     - 1’ on a 64-bit platform.

 -- Data: sys.maxunicode

     An integer giving the value of the largest Unicode code point, i.e.
     ‘1114111’ (‘0x10FFFF’ in hexadecimal).

     Changed in version 3.3: Before PEP 393(6), ‘sys.maxunicode’ used to
     be either ‘0xFFFF’ or ‘0x10FFFF’, depending on the configuration
     option that specified whether Unicode characters were stored as
     UCS-2 or UCS-4.

 -- Data: sys.meta_path

     A list of *note meta path finder: 5d1. objects that have their
     *note find_spec(): 544. methods called to see if one of the objects
     can find the module to be imported.  The *note find_spec(): 544.
     method is called with at least the absolute name of the module
     being imported.  If the module to be imported is contained in a
     package, then the parent package’s *note __path__: c50. attribute
     is passed in as a second argument.  The method returns a *note
     module spec: 2e37, or ‘None’ if the module cannot be found.

     See also
     ........

     *note importlib.abc.MetaPathFinder: 5d3.

          The abstract base class defining the interface of finder
          objects on *note meta_path: 5dc.

     *note importlib.machinery.ModuleSpec: e8e.

          The concrete class which *note find_spec(): 544. should return
          instances of.

     Changed in version 3.4: *note Module specs: 2e37. were introduced
     in Python 3.4, by PEP 451(7).  Earlier versions of Python looked
     for a method called *note find_module(): 543.  This is still called
     as a fallback if a *note meta_path: 5dc. entry doesn’t have a *note
     find_spec(): 544. method.

 -- Data: sys.modules

     This is a dictionary that maps module names to modules which have
     already been loaded.  This can be manipulated to force reloading of
     modules and other tricks.  However, replacing the dictionary will
     not necessarily work as expected and deleting essential items from
     the dictionary may cause Python to fail.

 -- Data: sys.path

     A list of strings that specifies the search path for modules.
     Initialized from the environment variable *note PYTHONPATH: 567,
     plus an installation-dependent default.

     As initialized upon program startup, the first item of this list,
     ‘path[0]’, is the directory containing the script that was used to
     invoke the Python interpreter.  If the script directory is not
     available (e.g.  if the interpreter is invoked interactively or if
     the script is read from standard input), ‘path[0]’ is the empty
     string, which directs Python to search modules in the current
     directory first.  Notice that the script directory is inserted
     `before' the entries inserted as a result of *note PYTHONPATH: 567.

     A program is free to modify this list for its own purposes.  Only
     strings and bytes should be added to *note sys.path: 16c.; all
     other data types are ignored during import.

     See also
     ........

     Module *note site: e9. This describes how to use .pth files to
     extend *note sys.path: 16c.

 -- Data: sys.path_hooks

     A list of callables that take a path argument to try to create a
     *note finder: e81. for the path.  If a finder can be created, it is
     to be returned by the callable, else raise *note ImportError: 19f.

     Originally specified in PEP 302(8).

 -- Data: sys.path_importer_cache

     A dictionary acting as a cache for *note finder: e81. objects.  The
     keys are paths that have been passed to *note sys.path_hooks: 574.
     and the values are the finders that are found.  If a path is a
     valid file system path but no finder is found on *note
     sys.path_hooks: 574. then ‘None’ is stored.

     Originally specified in PEP 302(9).

     Changed in version 3.3: ‘None’ is stored instead of *note
     imp.NullImporter: 5dd. when no finder is found.

 -- Data: sys.platform

     This string contains a platform identifier that can be used to
     append platform-specific components to *note sys.path: 16c, for
     instance.

     For Unix systems, except on Linux, this is the lowercased OS name
     as returned by ‘uname -s’ with the first part of the version as
     returned by ‘uname -r’ appended, e.g.  ‘'sunos5'’ or ‘'freebsd8'’,
     `at the time when Python was built'.  Unless you want to test for a
     specific system version, it is therefore recommended to use the
     following idiom:

          if sys.platform.startswith('freebsd'):
              # FreeBSD-specific code here...
          elif sys.platform.startswith('linux'):
              # Linux-specific code here...

     For other systems, the values are:

     System               ‘platform’ value
                          
     -----------------------------------------------------
                          
     Linux                ‘'linux'’
                          
                          
     Windows              ‘'win32'’
                          
                          
     Windows/Cygwin       ‘'cygwin'’
                          
                          
     Mac OS X             ‘'darwin'’
                          

     Changed in version 3.3: On Linux, *note sys.platform: 1850. doesn’t
     contain the major version anymore.  It is always ‘'linux'’, instead
     of ‘'linux2'’ or ‘'linux3'’.  Since older Python versions include
     the version number, it is recommended to always use the
     ‘startswith’ idiom presented above.

     See also
     ........

     *note os.name: 184f. has a coarser granularity.  *note os.uname():
     692. gives system-dependent version information.

     The *note platform: cc. module provides detailed checks for the
     system’s identity.

 -- Data: sys.prefix

     A string giving the site-specific directory prefix where the
     platform independent Python files are installed; by default, this
     is the string ‘'/usr/local'’.  This can be set at build time with
     the ‘--prefix’ argument to the ‘configure’ script.  The main
     collection of Python library modules is installed in the directory
     ‘`prefix'/lib/python`X.Y'’ while the platform independent header
     files (all except ‘pyconfig.h’) are stored in
     ‘`prefix'/include/python`X.Y'’, where `X.Y' is the version number
     of Python, for example ‘3.2’.

          Note: If a *note virtual environment: d6c. is in effect, this
          value will be changed in ‘site.py’ to point to the virtual
          environment.  The value for the Python installation will still
          be available, via *note base_prefix: 2dff.

 -- Data: sys.ps1
 -- Data: sys.ps2

     Strings specifying the primary and secondary prompt of the
     interpreter.  These are only defined if the interpreter is in
     interactive mode.  Their initial values in this case are ‘'>>> '’
     and ‘'... '’.  If a non-string object is assigned to either
     variable, its *note str(): 25a. is re-evaluated each time the
     interpreter prepares to read a new interactive command; this can be
     used to implement a dynamic prompt.

 -- Function: sys.setcheckinterval (interval)

     Set the interpreter’s "check interval".  This integer value
     determines how often the interpreter checks for periodic things
     such as thread switches and signal handlers.  The default is ‘100’,
     meaning the check is performed every 100 Python virtual
     instructions.  Setting it to a larger value may increase
     performance for programs using threads.  Setting it to a value ‘<=’
     0 checks every virtual instruction, maximizing responsiveness as
     well as overhead.

     Deprecated since version 3.2: This function doesn’t have an effect
     anymore, as the internal logic for thread switching and
     asynchronous tasks has been rewritten.  Use *note
     setswitchinterval(): 849. instead.

 -- Function: sys.setdlopenflags (n)

     Set the flags used by the interpreter for ‘dlopen()’ calls, such as
     when the interpreter loads extension modules.  Among other things,
     this will enable a lazy resolving of symbols when importing a
     module, if called as ‘sys.setdlopenflags(0)’.  To share symbols
     across extension modules, call as
     ‘sys.setdlopenflags(os.RTLD_GLOBAL)’.  Symbolic names for the flag
     values can be found in the *note os: c2. module (‘RTLD_xxx’
     constants, e.g.  *note os.RTLD_LAZY: 694.).

     Availability: Unix.

 -- Function: sys.setprofile (profilefunc)

     Set the system’s profile function, which allows you to implement a
     Python source code profiler in Python.  See chapter *note The
     Python Profilers: 2d41. for more information on the Python
     profiler.  The system’s profile function is called similarly to the
     system’s trace function (see *note settrace(): ac0.), but it isn’t
     called for each executed line of code (only on call and return, but
     the return event is reported even when an exception has been set).
     The function is thread-specific, but there is no way for the
     profiler to know about context switches between threads, so it does
     not make sense to use this in the presence of multiple threads.
     Also, its return value is not used, so it can simply return ‘None’.

 -- Function: sys.setrecursionlimit (limit)

     Set the maximum depth of the Python interpreter stack to `limit'.
     This limit prevents infinite recursion from causing an overflow of
     the C stack and crashing Python.

     The highest possible limit is platform-dependent.  A user may need
     to set the limit higher when they have a program that requires deep
     recursion and a platform that supports a higher limit.  This should
     be done with care, because a too-high limit can lead to a crash.

     If the new limit is too low at the current recursion depth, a *note
     RecursionError: 1b8. exception is raised.

     Changed in version 3.5.1: A *note RecursionError: 1b8. exception is
     now raised if the new limit is too low at the current recursion
     depth.

 -- Function: sys.setswitchinterval (interval)

     Set the interpreter’s thread switch interval (in seconds).  This
     floating-point value determines the ideal duration of the
     "timeslices" allocated to concurrently running Python threads.
     Please note that the actual value can be higher, especially if
     long-running internal functions or methods are used.  Also, which
     thread becomes scheduled at the end of the interval is the
     operating system’s decision.  The interpreter doesn’t have its own
     scheduler.

     New in version 3.2.

 -- Function: sys.settrace (tracefunc)

     Set the system’s trace function, which allows you to implement a
     Python source code debugger in Python.  The function is
     thread-specific; for a debugger to support multiple threads, it
     must be registered using *note settrace(): ac0. for each thread
     being debugged.

     Trace functions should have three arguments: `frame', `event', and
     `arg'.  `frame' is the current stack frame.  `event' is a string:
     ‘'call'’, ‘'line'’, ‘'return'’, ‘'exception'’, ‘'c_call'’,
     ‘'c_return'’, or ‘'c_exception'’.  `arg' depends on the event type.

     The trace function is invoked (with `event' set to ‘'call'’)
     whenever a new local scope is entered; it should return a reference
     to a local trace function to be used that scope, or ‘None’ if the
     scope shouldn’t be traced.

     The local trace function should return a reference to itself (or to
     another function for further tracing in that scope), or ‘None’ to
     turn off tracing in that scope.

     The events have the following meaning:

     ‘'call'’

          A function is called (or some other code block entered).  The
          global trace function is called; `arg' is ‘None’; the return
          value specifies the local trace function.

     ‘'line'’

          The interpreter is about to execute a new line of code or
          re-execute the condition of a loop.  The local trace function
          is called; `arg' is ‘None’; the return value specifies the new
          local trace function.  See ‘Objects/lnotab_notes.txt’ for a
          detailed explanation of how this works.

     ‘'return'’

          A function (or other code block) is about to return.  The
          local trace function is called; `arg' is the value that will
          be returned, or ‘None’ if the event is caused by an exception
          being raised.  The trace function’s return value is ignored.

     ‘'exception'’

          An exception has occurred.  The local trace function is
          called; `arg' is a tuple ‘(exception, value, traceback)’; the
          return value specifies the new local trace function.

     ‘'c_call'’

          A C function is about to be called.  This may be an extension
          function or a built-in.  `arg' is the C function object.

     ‘'c_return'’

          A C function has returned.  `arg' is the C function object.

     ‘'c_exception'’

          A C function has raised an exception.  `arg' is the C function
          object.

     Note that as an exception is propagated down the chain of callers,
     an ‘'exception'’ event is generated at each level.

     For more information on code and frame objects, refer to *note The
     standard type hierarchy: de0.

     `CPython implementation detail:' The *note settrace(): ac0.
     function is intended only for implementing debuggers, profilers,
     coverage tools and the like.  Its behavior is part of the
     implementation platform, rather than part of the language
     definition, and thus may not be available in all Python
     implementations.

 -- Function: sys.settscdump (on_flag)

     Activate dumping of VM measurements using the Pentium timestamp
     counter, if `on_flag' is true.  Deactivate these dumps if `on_flag'
     is off.  The function is available only if Python was compiled with
     ‘--with-tsc’.  To understand the output of this dump, read
     ‘Python/ceval.c’ in the Python sources.

     `CPython implementation detail:' This function is intimately bound
     to CPython implementation details and thus not likely to be
     implemented elsewhere.

 -- Function: sys.set_coroutine_wrapper (wrapper)

     Allows intercepting creation of *note coroutine: 2ad. objects (only
     ones that are created by an *note async def: 1ce. function;
     generators decorated with *note types.coroutine(): 34d. or *note
     asyncio.coroutine(): e4e. will not be intercepted).

     The `wrapper' argument must be either:

        * a callable that accepts one argument (a coroutine object);

        * ‘None’, to reset the wrapper.

     If called twice, the new wrapper replaces the previous one.  The
     function is thread-specific.

     The `wrapper' callable cannot define new coroutines directly or
     indirectly:

          def wrapper(coro):
              async def wrap(coro):
                  return await coro
              return wrap(coro)
          sys.set_coroutine_wrapper(wrapper)

          async def foo():
              pass

          # The following line will fail with a RuntimeError, because
          # ``wrapper`` creates a ``wrap(coro)`` coroutine:
          foo()

     See also *note get_coroutine_wrapper(): 332.

     New in version 3.5: See PEP 492(10) for more details.

          Note: This function has been added on a provisional basis (see
          PEP 411(11) for details.)  Use it only for debugging purposes.

 -- Data: sys.stdin
 -- Data: sys.stdout
 -- Data: sys.stderr

     *note File objects: 78b. used by the interpreter for standard
     input, output and errors:

        * ‘stdin’ is used for all interactive input (including calls to
          *note input(): 8d7.);

        * ‘stdout’ is used for the output of *note print(): 481. and
          *note expression: 2e2b. statements and for the prompts of
          *note input(): 8d7.;

        * The interpreter’s own prompts and its error messages go to
          ‘stderr’.

     These streams are regular *note text files: c62. like those
     returned by the *note open(): 1e8. function.  Their parameters are
     chosen as follows:

        * The character encoding is platform-dependent.  Under Windows,
          if the stream is interactive (that is, if its ‘isatty()’
          method returns ‘True’), the console codepage is used,
          otherwise the ANSI code page.  Under other platforms, the
          locale encoding is used (see *note
          locale.getpreferredencoding(): fb0.).

          Under all platforms though, you can override this value by
          setting the *note PYTHONIOENCODING: 537. environment variable
          before starting Python.

        * When interactive, standard streams are line-buffered.
          Otherwise, they are block-buffered like regular text files.
          You can override this value with the *note -u: d0c.
          command-line option.

          Note: To write or read binary data from/to the standard
          streams, use the underlying binary *note buffer: 8a0. object.
          For example, to write bytes to *note stdout: 1ba, use
          ‘sys.stdout.buffer.write(b'abc')’.

          However, if you are writing a library (and do not control in
          which context its code will be executed), be aware that the
          standard streams may be replaced with file-like objects like
          *note io.StringIO: 41e. which do not support the ‘buffer’
          attribute.

 -- Data: sys.__stdin__
 -- Data: sys.__stdout__
 -- Data: sys.__stderr__

     These objects contain the original values of ‘stdin’, ‘stderr’ and
     ‘stdout’ at the start of the program.  They are used during
     finalization, and could be useful to print to the actual standard
     stream no matter if the ‘sys.std*’ object has been redirected.

     It can also be used to restore the actual files to known working
     file objects in case they have been overwritten with a broken
     object.  However, the preferred way to do this is to explicitly
     save the previous stream before replacing it, and restore the saved
     object.

          Note: Under some conditions ‘stdin’, ‘stdout’ and ‘stderr’ as
          well as the original values ‘__stdin__’, ‘__stdout__’ and
          ‘__stderr__’ can be None.  It is usually the case for Windows
          GUI apps that aren’t connected to a console and Python apps
          started with ‘pythonw’.

 -- Data: sys.thread_info

     A *note struct sequence: 6dd. holding information about the thread
     implementation.

     Attribute              Explanation
                            
     -------------------------------------------------------------------------------------
                            
     ‘name’                 Name of the thread implementation:
                            
                                    * ‘'nt'’: Windows threads
                            
                                    * ‘'pthread'’: POSIX threads
                            
                                    * ‘'solaris'’: Solaris threads
                            
                            
     ‘lock’                 Name of the lock implementation:
                            
                                    * ‘'semaphore'’: a lock uses a semaphore
                            
                                    * ‘'mutex+cond'’: a lock uses a mutex and a
                                      condition variable
                            
                                    * ‘None’ if this information is unknown
                            
                            
     *note version: 2e3b.   Name and version of the thread library.  It is a string, or
                            ‘None’ if these informations are unknown.
                            

     New in version 3.3.

 -- Data: sys.tracebacklimit

     When this variable is set to an integer value, it determines the
     maximum number of levels of traceback information printed when an
     unhandled exception occurs.  The default is ‘1000’.  When set to
     ‘0’ or less, all traceback information is suppressed and only the
     exception type and value are printed.

 -- Data: sys.version

     A string containing the version number of the Python interpreter
     plus additional information on the build number and compiler used.
     This string is displayed when the interactive interpreter is
     started.  Do not extract version information out of it, rather, use
     *note version_info: 75c. and the functions provided by the *note
     platform: cc. module.

 -- Data: sys.api_version

     The C API version for this interpreter.  Programmers may find this
     useful when debugging version conflicts between Python and
     extension modules.

 -- Data: sys.version_info

     A tuple containing the five components of the version number:
     `major', `minor', `micro', `releaselevel', and `serial'.  All
     values except `releaselevel' are integers; the release level is
     ‘'alpha'’, ‘'beta'’, ‘'candidate'’, or ‘'final'’.  The
     ‘version_info’ value corresponding to the Python version 2.0 is
     ‘(2, 0, 0, 'final', 0)’.  The components can also be accessed by
     name, so ‘sys.version_info[0]’ is equivalent to
     ‘sys.version_info.major’ and so on.

     Changed in version 3.1: Added named component attributes.

 -- Data: sys.warnoptions

     This is an implementation detail of the warnings framework; do not
     modify this value.  Refer to the *note warnings: 123. module for
     more information on the warnings framework.

 -- Data: sys.winver

     The version number used to form registry keys on Windows platforms.
     This is stored as string resource 1000 in the Python DLL. The value
     is normally the first three characters of *note version: 2e3b.  It
     is provided in the *note sys: fb. module for informational
     purposes; modifying this value has no effect on the registry keys
     used by Python.  Availability: Windows.

 -- Data: sys._xoptions

     A dictionary of the various implementation-specific flags passed
     through the *note -X: 5ec. command-line option.  Option names are
     either mapped to their values, if given explicitly, or to *note
     True: 9ff.  Example:

          $ ./python -Xa=b -Xc
          Python 3.2a3+ (py3k, Oct 16 2010, 20:14:50)
          [GCC 4.4.3] on linux2
          Type "help", "copyright", "credits" or "license" for more information.
          >>> import sys
          >>> sys._xoptions
          {'a': 'b', 'c': True}

     `CPython implementation detail:' This is a CPython-specific way of
     accessing options passed through *note -X: 5ec.  Other
     implementations may export them through other means, or not at all.

     New in version 3.2.

Citations
.........

(C99) ISO/IEC 9899:1999.  "Programming languages – C." A public draft of
this standard is available at
‘http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf’.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3149

   (2) http://code.activestate.com/recipes/577504

   (3) https://www.python.org/dev/peps/pep-0492

   (4) https://www.python.org/dev/peps/pep-0411

   (5) https://www.python.org/dev/peps/pep-0421

   (6) https://www.python.org/dev/peps/pep-0393

   (7) https://www.python.org/dev/peps/pep-0451

   (8) https://www.python.org/dev/peps/pep-0302

   (9) https://www.python.org/dev/peps/pep-0302

   (10) https://www.python.org/dev/peps/pep-0492

   (11) https://www.python.org/dev/peps/pep-0411

