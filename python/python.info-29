This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: Defining a callback option,  Next: How callbacks are called,  Up: Option Callbacks

5.36.1.29 Defining a callback option
....................................

As always, the easiest way to define a callback option is by using the
*note OptionParser.add_option(): 19c9. method.  Apart from *note action:
326d, the only option attribute you must specify is ‘callback’, the
function to call:

     parser.add_option("-c", action="callback", callback=my_callback)

‘callback’ is a function (or other callable object), so you must have
already defined ‘my_callback()’ when you create this callback option.
In this simple case, *note optparse: c1. doesn’t even know if ‘-c’ takes
any arguments, which usually means that the option takes no
arguments—the mere presence of ‘-c’ on the command-line is all it needs
to know.  In some circumstances, though, you might want your callback to
consume an arbitrary number of command-line arguments.  This is where
writing callbacks gets tricky; it’s covered later in this section.

*note optparse: c1. always passes four particular arguments to your
callback, and it will only pass additional arguments if you specify them
via *note callback_args: 329e. and *note callback_kwargs: 329f.  Thus,
the minimal callback function signature is:

     def my_callback(option, opt, value, parser):

The four arguments to a callback are described below.

There are several other option attributes that you can supply when you
define a callback option:

*note type: 326e.

     has its usual meaning: as with the ‘"store"’ or ‘"append"’ actions,
     it instructs *note optparse: c1. to consume one argument and
     convert it to *note type: 326e.  Rather than storing the converted
     value(s) anywhere, though, *note optparse: c1. passes it to your
     callback function.

*note nargs: 329a.

     also has its usual meaning: if it is supplied and > 1, *note
     optparse: c1. will consume *note nargs: 329a. arguments, each of
     which must be convertible to *note type: 326e.  It then passes a
     tuple of converted values to your callback.

*note callback_args: 329e.

     a tuple of extra positional arguments to pass to the callback

*note callback_kwargs: 329f.

     a dictionary of extra keyword arguments to pass to the callback


File: python.info,  Node: How callbacks are called,  Next: Raising errors in a callback,  Prev: Defining a callback option,  Up: Option Callbacks

5.36.1.30 How callbacks are called
..................................

All callbacks are called as follows:

     func(option, opt_str, value, parser, *args, **kwargs)

where

‘option’

     is the Option instance that’s calling the callback

‘opt_str’

     is the option string seen on the command-line that’s triggering the
     callback.  (If an abbreviated long option was used, ‘opt_str’ will
     be the full, canonical option string—e.g.  if the user puts ‘--foo’
     on the command-line as an abbreviation for ‘--foobar’, then
     ‘opt_str’ will be ‘"--foobar"’.)

‘value’

     is the argument to this option seen on the command-line.  *note
     optparse: c1. will only expect an argument if *note type: 326e. is
     set; the type of ‘value’ will be the type implied by the option’s
     type.  If *note type: 326e. for this option is ‘None’ (no argument
     expected), then ‘value’ will be ‘None’.  If *note nargs: 329a. > 1,
     ‘value’ will be a tuple of values of the appropriate type.

‘parser’

     is the OptionParser instance driving the whole thing, mainly useful
     because you can access some other interesting data through its
     instance attributes:

     ‘parser.largs’

          the current list of leftover arguments, ie.  arguments that
          have been consumed but are neither options nor option
          arguments.  Feel free to modify ‘parser.largs’, e.g.  by
          adding more arguments to it.  (This list will become ‘args’,
          the second return value of ‘parse_args()’.)

     ‘parser.rargs’

          the current list of remaining arguments, ie.  with ‘opt_str’
          and ‘value’ (if applicable) removed, and only the arguments
          following them still there.  Feel free to modify
          ‘parser.rargs’, e.g.  by consuming more arguments.

     ‘parser.values’

          the object where option values are by default stored (an
          instance of optparse.OptionValues).  This lets callbacks use
          the same mechanism as the rest of *note optparse: c1. for
          storing option values; you don’t need to mess around with
          globals or closures.  You can also access or modify the
          value(s) of any options already encountered on the
          command-line.

‘args’

     is a tuple of arbitrary positional arguments supplied via the *note
     callback_args: 329e. option attribute.

‘kwargs’

     is a dictionary of arbitrary keyword arguments supplied via *note
     callback_kwargs: 329f.


File: python.info,  Node: Raising errors in a callback,  Next: Callback example 1 trivial callback,  Prev: How callbacks are called,  Up: Option Callbacks

5.36.1.31 Raising errors in a callback
......................................

The callback function should raise ‘OptionValueError’ if there are any
problems with the option or its argument(s).  *note optparse: c1.
catches this and terminates the program, printing the error message you
supply to stderr.  Your message should be clear, concise, accurate, and
mention the option at fault.  Otherwise, the user will have a hard time
figuring out what he did wrong.


File: python.info,  Node: Callback example 1 trivial callback,  Next: Callback example 2 check option order,  Prev: Raising errors in a callback,  Up: Option Callbacks

5.36.1.32 Callback example 1: trivial callback
..............................................

Here’s an example of a callback option that takes no arguments, and
simply records that the option was seen:

     def record_foo_seen(option, opt_str, value, parser):
         parser.values.saw_foo = True

     parser.add_option("--foo", action="callback", callback=record_foo_seen)

Of course, you could do that with the ‘"store_true"’ action.


File: python.info,  Node: Callback example 2 check option order,  Next: Callback example 3 check option order generalized,  Prev: Callback example 1 trivial callback,  Up: Option Callbacks

5.36.1.33 Callback example 2: check option order
................................................

Here’s a slightly more interesting example: record the fact that ‘-a’ is
seen, but blow up if it comes after ‘-b’ in the command-line.

     def check_order(option, opt_str, value, parser):
         if parser.values.b:
             raise OptionValueError("can't use -a after -b")
         parser.values.a = 1
     [...]
     parser.add_option("-a", action="callback", callback=check_order)
     parser.add_option("-b", action="store_true", dest="b")


File: python.info,  Node: Callback example 3 check option order generalized,  Next: Callback example 4 check arbitrary condition,  Prev: Callback example 2 check option order,  Up: Option Callbacks

5.36.1.34 Callback example 3: check option order (generalized)
..............................................................

If you want to re-use this callback for several similar options (set a
flag, but blow up if ‘-b’ has already been seen), it needs a bit of
work: the error message and the flag that it sets must be generalized.

     def check_order(option, opt_str, value, parser):
         if parser.values.b:
             raise OptionValueError("can't use %s after -b" % opt_str)
         setattr(parser.values, option.dest, 1)
     [...]
     parser.add_option("-a", action="callback", callback=check_order, dest='a')
     parser.add_option("-b", action="store_true", dest="b")
     parser.add_option("-c", action="callback", callback=check_order, dest='c')


File: python.info,  Node: Callback example 4 check arbitrary condition,  Next: Callback example 5 fixed arguments,  Prev: Callback example 3 check option order generalized,  Up: Option Callbacks

5.36.1.35 Callback example 4: check arbitrary condition
.......................................................

Of course, you could put any condition in there—you’re not limited to
checking the values of already-defined options.  For example, if you
have options that should not be called when the moon is full, all you
have to do is this:

     def check_moon(option, opt_str, value, parser):
         if is_moon_full():
             raise OptionValueError("%s option invalid when moon is full"
                                    % opt_str)
         setattr(parser.values, option.dest, 1)
     [...]
     parser.add_option("--foo",
                       action="callback", callback=check_moon, dest="foo")

(The definition of ‘is_moon_full()’ is left as an exercise for the
reader.)


File: python.info,  Node: Callback example 5 fixed arguments,  Next: Callback example 6 variable arguments,  Prev: Callback example 4 check arbitrary condition,  Up: Option Callbacks

5.36.1.36 Callback example 5: fixed arguments
.............................................

Things get slightly more interesting when you define callback options
that take a fixed number of arguments.  Specifying that a callback
option takes arguments is similar to defining a ‘"store"’ or ‘"append"’
option: if you define *note type: 326e, then the option takes one
argument that must be convertible to that type; if you further define
*note nargs: 329a, then the option takes *note nargs: 329a. arguments.

Here’s an example that just emulates the standard ‘"store"’ action:

     def store_value(option, opt_str, value, parser):
         setattr(parser.values, option.dest, value)
     [...]
     parser.add_option("--foo",
                       action="callback", callback=store_value,
                       type="int", nargs=3, dest="foo")

Note that *note optparse: c1. takes care of consuming 3 arguments and
converting them to integers for you; all you have to do is store them.
(Or whatever; obviously you don’t need a callback for this example.)


File: python.info,  Node: Callback example 6 variable arguments,  Prev: Callback example 5 fixed arguments,  Up: Option Callbacks

5.36.1.37 Callback example 6: variable arguments
................................................

Things get hairy when you want an option to take a variable number of
arguments.  For this case, you must write a callback, as *note optparse:
c1. doesn’t provide any built-in capabilities for it.  And you have to
deal with certain intricacies of conventional Unix command-line parsing
that *note optparse: c1. normally handles for you.  In particular,
callbacks should implement the conventional rules for bare ‘--’ and ‘-’
arguments:

   * either ‘--’ or ‘-’ can be option arguments

   * bare ‘--’ (if not the argument to some option): halt command-line
     processing and discard the ‘--’

   * bare ‘-’ (if not the argument to some option): halt command-line
     processing but keep the ‘-’ (append it to ‘parser.largs’)

If you want an option that takes a variable number of arguments, there
are several subtle, tricky issues to worry about.  The exact
implementation you choose will be based on which trade-offs you’re
willing to make for your application (which is why *note optparse: c1.
doesn’t support this sort of thing directly).

Nevertheless, here’s a stab at a callback for an option with variable
arguments:

      def vararg_callback(option, opt_str, value, parser):
          assert value is None
          value = []

          def floatable(str):
              try:
                  float(str)
                  return True
              except ValueError:
                  return False

          for arg in parser.rargs:
              # stop on --foo like options
              if arg[:2] == "--" and len(arg) > 2:
                  break
              # stop on -a, but not on -3 or -3.0
              if arg[:1] == "-" and len(arg) > 1 and not floatable(arg):
                  break
              value.append(arg)

          del parser.rargs[:len(value)]
          setattr(parser.values, option.dest, value)

     [...]
     parser.add_option("-c", "--callback", dest="vararg_attr",
                       action="callback", callback=vararg_callback)


File: python.info,  Node: Extending optparse,  Prev: Option Callbacks,  Up: optparse --- Parser for command line options

5.36.1.38 Extending ‘optparse’
..............................

Since the two major controlling factors in how *note optparse: c1.
interprets command-line options are the action and type of each option,
the most likely direction of extension is to add new actions and new
types.

* Menu:

* Adding new types:: 
* Adding new actions:: 


File: python.info,  Node: Adding new types,  Next: Adding new actions,  Up: Extending optparse

5.36.1.39 Adding new types
..........................

To add new types, you need to define your own subclass of *note
optparse: c1.’s ‘Option’ class.  This class has a couple of attributes
that define *note optparse: c1.’s types: *note TYPES: 32c9. and *note
TYPE_CHECKER: 32ca.

 -- Attribute: Option.TYPES

     A tuple of type names; in your subclass, simply define a new tuple
     *note TYPES: 32c9. that builds on the standard one.

 -- Attribute: Option.TYPE_CHECKER

     A dictionary mapping type names to type-checking functions.  A
     type-checking function has the following signature:

          def check_mytype(option, opt, value)

     where ‘option’ is an ‘Option’ instance, ‘opt’ is an option string
     (e.g., ‘-f’), and ‘value’ is the string from the command line that
     must be checked and converted to your desired type.
     ‘check_mytype()’ should return an object of the hypothetical type
     ‘mytype’.  The value returned by a type-checking function will wind
     up in the OptionValues instance returned by
     ‘OptionParser.parse_args()’, or be passed to a callback as the
     ‘value’ parameter.

     Your type-checking function should raise ‘OptionValueError’ if it
     encounters any problems.  ‘OptionValueError’ takes a single string
     argument, which is passed as-is to *note OptionParser: 3262.’s
     ‘error()’ method, which in turn prepends the program name and the
     string ‘"error:"’ and prints everything to stderr before
     terminating the process.

Here’s a silly example that demonstrates adding a ‘"complex"’ option
type to parse Python-style complex numbers on the command line.  (This
is even sillier than it used to be, because *note optparse: c1. 1.3
added built-in support for complex numbers, but never mind.)

First, the necessary imports:

     from copy import copy
     from optparse import Option, OptionValueError

You need to define your type-checker first, since it’s referred to later
(in the *note TYPE_CHECKER: 32ca. class attribute of your Option
subclass):

     def check_complex(option, opt, value):
         try:
             return complex(value)
         except ValueError:
             raise OptionValueError(
                 "option %s: invalid complex value: %r" % (opt, value))

Finally, the Option subclass:

     class MyOption (Option):
         TYPES = Option.TYPES + ("complex",)
         TYPE_CHECKER = copy(Option.TYPE_CHECKER)
         TYPE_CHECKER["complex"] = check_complex

(If we didn’t make a *note copy(): 25. of *note Option.TYPE_CHECKER:
32ca, we would end up modifying the *note TYPE_CHECKER: 32ca. attribute
of *note optparse: c1.’s Option class.  This being Python, nothing stops
you from doing that except good manners and common sense.)

That’s it!  Now you can write a script that uses the new option type
just like any other *note optparse: c1.-based script, except you have to
instruct your OptionParser to use MyOption instead of Option:

     parser = OptionParser(option_class=MyOption)
     parser.add_option("-c", type="complex")

Alternately, you can build your own option list and pass it to
OptionParser; if you don’t use ‘add_option()’ in the above way, you
don’t need to tell OptionParser which option class to use:

     option_list = [MyOption("-c", action="store", type="complex", dest="c")]
     parser = OptionParser(option_list=option_list)


File: python.info,  Node: Adding new actions,  Prev: Adding new types,  Up: Extending optparse

5.36.1.40 Adding new actions
............................

Adding new actions is a bit trickier, because you have to understand
that *note optparse: c1. has a couple of classifications for actions:

"store" actions

     actions that result in *note optparse: c1. storing a value to an
     attribute of the current OptionValues instance; these options
     require a *note dest: 326f. attribute to be supplied to the Option
     constructor.

"typed" actions

     actions that take a value from the command line and expect it to be
     of a certain type; or rather, a string that can be converted to a
     certain type.  These options require a *note type: 326e. attribute
     to the Option constructor.

These are overlapping sets: some default "store" actions are ‘"store"’,
‘"store_const"’, ‘"append"’, and ‘"count"’, while the default "typed"
actions are ‘"store"’, ‘"append"’, and ‘"callback"’.

When you add an action, you need to categorize it by listing it in at
least one of the following class attributes of Option (all are lists of
strings):

 -- Attribute: Option.ACTIONS

     All actions must be listed in ACTIONS.

 -- Attribute: Option.STORE_ACTIONS

     "store" actions are additionally listed here.

 -- Attribute: Option.TYPED_ACTIONS

     "typed" actions are additionally listed here.

 -- Attribute: Option.ALWAYS_TYPED_ACTIONS

     Actions that always take a type (i.e.  whose options always take a
     value) are additionally listed here.  The only effect of this is
     that *note optparse: c1. assigns the default type, ‘"string"’, to
     options with no explicit type whose action is listed in *note
     ALWAYS_TYPED_ACTIONS: 32d0.

In order to actually implement your new action, you must override
Option’s ‘take_action()’ method and add a case that recognizes your
action.

For example, let’s add an ‘"extend"’ action.  This is similar to the
standard ‘"append"’ action, but instead of taking a single value from
the command-line and appending it to an existing list, ‘"extend"’ will
take multiple values in a single comma-delimited string, and extend an
existing list with them.  That is, if ‘--names’ is an ‘"extend"’ option
of type ‘"string"’, the command line

     --names=foo,bar --names blah --names ding,dong

would result in a list

     ["foo", "bar", "blah", "ding", "dong"]

Again we define a subclass of Option:

     class MyOption(Option):

         ACTIONS = Option.ACTIONS + ("extend",)
         STORE_ACTIONS = Option.STORE_ACTIONS + ("extend",)
         TYPED_ACTIONS = Option.TYPED_ACTIONS + ("extend",)
         ALWAYS_TYPED_ACTIONS = Option.ALWAYS_TYPED_ACTIONS + ("extend",)

         def take_action(self, action, dest, opt, value, values, parser):
             if action == "extend":
                 lvalue = value.split(",")
                 values.ensure_value(dest, []).extend(lvalue)
             else:
                 Option.take_action(
                     self, action, dest, opt, value, values, parser)

Features of note:

   * ‘"extend"’ both expects a value on the command-line and stores that
     value somewhere, so it goes in both *note STORE_ACTIONS: 32ce. and
     *note TYPED_ACTIONS: 32cf.

   * to ensure that *note optparse: c1. assigns the default type of
     ‘"string"’ to ‘"extend"’ actions, we put the ‘"extend"’ action in
     *note ALWAYS_TYPED_ACTIONS: 32d0. as well.

   * ‘MyOption.take_action()’ implements just this one new action, and
     passes control back to ‘Option.take_action()’ for the standard
     *note optparse: c1. actions.

   * ‘values’ is an instance of the optparse_parser.Values class, which
     provides the very useful ‘ensure_value()’ method.  ‘ensure_value()’
     is essentially *note getattr(): 781. with a safety valve; it is
     called as

          values.ensure_value(attr, value)

     If the ‘attr’ attribute of ‘values’ doesn’t exist or is None, then
     ensure_value() first sets it to ‘value’, and then returns ’value.
     This is very handy for actions like ‘"extend"’, ‘"append"’, and
     ‘"count"’, all of which accumulate data in a variable and expect
     that variable to be of a certain type (a list for the first two, an
     integer for the latter).  Using ‘ensure_value()’ means that scripts
     using your action don’t have to worry about setting a default value
     for the option destinations in question; they can just leave the
     default as None and ‘ensure_value()’ will take care of getting it
     right when it’s needed.


File: python.info,  Node: imp --- Access the import internals,  Prev: optparse --- Parser for command line options,  Up: Superseded Modules

5.36.2 ‘imp’ — Access the import internals
------------------------------------------

Deprecated since version 3.4: The *note imp: 99. package is pending
deprecation in favor of *note importlib: 9a.

This module provides an interface to the mechanisms used to implement
the *note import: 881. statement.  It defines the following constants
and functions:

 -- Function: imp.get_magic ()

     Return the magic string value used to recognize byte-compiled code
     files (‘.pyc’ files).  (This value may be different for each Python
     version.)

     Deprecated since version 3.4: Use *note
     importlib.util.MAGIC_NUMBER: 458. instead.

 -- Function: imp.get_suffixes ()

     Return a list of 3-element tuples, each describing a particular
     type of module.  Each triple has the form ‘(suffix, mode, type)’,
     where `suffix' is a string to be appended to the module name to
     form the filename to search for, `mode' is the mode string to pass
     to the built-in *note open(): 1e8. function to open the file (this
     can be ‘'r'’ for text files or ‘'rb'’ for binary files), and `type'
     is the file type, which has one of the values *note PY_SOURCE:
     32d4, *note PY_COMPILED: 32d5, or *note C_EXTENSION: 32d6,
     described below.

     Deprecated since version 3.3: Use the constants defined on *note
     importlib.machinery: 9c. instead.

 -- Function: imp.find_module (name[, path])

     Try to find the module `name'.  If `path' is omitted or ‘None’, the
     list of directory names given by ‘sys.path’ is searched, but first
     a few special places are searched: the function tries to find a
     built-in module with the given name (*note C_BUILTIN: 32d8.), then
     a frozen module (*note PY_FROZEN: 32d9.), and on some systems some
     other places are looked in as well (on Windows, it looks in the
     registry which may point to a specific file).

     Otherwise, `path' must be a list of directory names; each directory
     is searched for files with any of the suffixes returned by *note
     get_suffixes(): 32d3. above.  Invalid names in the list are
     silently ignored (but all list items must be strings).

     If search is successful, the return value is a 3-element tuple
     ‘(file, pathname, description)’:

     `file' is an open *note file object: 78b. positioned at the
     beginning, `pathname' is the pathname of the file found, and
     `description' is a 3-element tuple as contained in the list
     returned by *note get_suffixes(): 32d3. describing the kind of
     module found.

     If the module does not live in a file, the returned `file' is
     ‘None’, `pathname' is the empty string, and the `description' tuple
     contains empty strings for its suffix and mode; the module type is
     indicated as given in parentheses above.  If the search is
     unsuccessful, *note ImportError: 19f. is raised.  Other exceptions
     indicate problems with the arguments or environment.

     If the module is a package, `file' is ‘None’, `pathname' is the
     package path and the last item in the `description' tuple is *note
     PKG_DIRECTORY: 32da.

     This function does not handle hierarchical module names (names
     containing dots).  In order to find `P.M', that is, submodule `M'
     of package `P', use *note find_module(): 32d7. and *note
     load_module(): 32db. to find and load package `P', and then use
     *note find_module(): 32d7. with the `path' argument set to
     ‘P.__path__’.  When `P' itself has a dotted name, apply this recipe
     recursively.

     Deprecated since version 3.3: Use *note importlib.util.find_spec():
     540. instead unless Python 3.3 compatibility is required, in which
     case use *note importlib.find_loader(): 53f.  For example usage of
     the former case, see the *note Examples: 2f7e. section of the *note
     importlib: 9a. documentation.

 -- Function: imp.load_module (name, file, pathname, description)

     Load a module that was previously found by *note find_module():
     32d7. (or by an otherwise conducted search yielding compatible
     results).  This function does more than importing the module: if
     the module was already imported, it will reload the module!  The
     `name' argument indicates the full module name (including the
     package name, if this is a submodule of a package).  The `file'
     argument is an open file, and `pathname' is the corresponding file
     name; these can be ‘None’ and ‘''’, respectively, when the module
     is a package or not being loaded from a file.  The `description'
     argument is a tuple, as would be returned by *note get_suffixes():
     32d3, describing what kind of module must be loaded.

     If the load is successful, the return value is the module object;
     otherwise, an exception (usually *note ImportError: 19f.) is
     raised.

     `Important:' the caller is responsible for closing the `file'
     argument, if it was not ‘None’, even when an exception is raised.
     This is best done using a *note try: 9e9. ...  *note finally: 526.
     statement.

     Deprecated since version 3.3: If previously used in conjunction
     with *note imp.find_module(): 32d7. then consider using *note
     importlib.import_module(): 754, otherwise use the loader returned
     by the replacement you chose for *note imp.find_module(): 32d7.  If
     you called *note imp.load_module(): 32db. and related functions
     directly with file path arguments then use a combination of *note
     importlib.util.spec_from_file_location(): 2f7c. and *note
     importlib.util.module_from_spec(): 2a5.  See the *note Examples:
     2f7e. section of the *note importlib: 9a. documentation for details
     of the various approaches.

 -- Function: imp.new_module (name)

     Return a new empty module object called `name'.  This object is
     `not' inserted in ‘sys.modules’.

     Deprecated since version 3.4: Use *note
     importlib.util.module_from_spec(): 2a5. instead.

 -- Function: imp.reload (module)

     Reload a previously imported `module'.  The argument must be a
     module object, so it must have been successfully imported before.
     This is useful if you have edited the module source file using an
     external editor and want to try out the new version without leaving
     the Python interpreter.  The return value is the module object (the
     same as the `module' argument).

     When ‘reload(module)’ is executed:

        * Python modules’ code is recompiled and the module-level code
          reexecuted, defining a new set of objects which are bound to
          names in the module’s dictionary.  The ‘init’ function of
          extension modules is not called a second time.

        * As with all other objects in Python the old objects are only
          reclaimed after their reference counts drop to zero.

        * The names in the module namespace are updated to point to any
          new or changed objects.

        * Other references to the old objects (such as names external to
          the module) are not rebound to refer to the new objects and
          must be updated in each namespace where they occur if that is
          desired.

     There are a number of other caveats:

     When a module is reloaded, its dictionary (containing the module’s
     global variables) is retained.  Redefinitions of names will
     override the old definitions, so this is generally not a problem.
     If the new version of a module does not define a name that was
     defined by the old version, the old definition remains.  This
     feature can be used to the module’s advantage if it maintains a
     global table or cache of objects — with a *note try: 9e9. statement
     it can test for the table’s presence and skip its initialization if
     desired:

          try:
              cache
          except NameError:
              cache = {}

     It is legal though generally not very useful to reload built-in or
     dynamically loaded modules, except for *note sys: fb, *note
     __main__: 1. and *note builtins: 13.  In many cases, however,
     extension modules are not designed to be initialized more than
     once, and may fail in arbitrary ways when reloaded.

     If a module imports objects from another module using *note from:
     8ad. ...  *note import: 881. ..., calling *note reload(): 8dc. for
     the other module does not redefine the objects imported from it —
     one way around this is to re-execute the *note from: 8ad.
     statement, another is to use *note import: 881. and qualified names
     (`module'.*name*) instead.

     If a module instantiates instances of a class, reloading the module
     that defines the class does not affect the method definitions of
     the instances — they continue to use the old class definition.  The
     same is true for derived classes.

     Changed in version 3.3: Relies on both ‘__name__’ and ‘__loader__’
     being defined on the module being reloaded instead of just
     ‘__name__’.

     Deprecated since version 3.4: Use *note importlib.reload(): 457.
     instead.

The following functions are conveniences for handling PEP 3147(1)
byte-compiled file paths.

New in version 3.2.

 -- Function: imp.cache_from_source (path, debug_override=None)

     Return the PEP 3147(2) path to the byte-compiled file associated
     with the source `path'.  For example, if `path' is
     ‘/foo/bar/baz.py’ the return value would be
     ‘/foo/bar/__pycache__/baz.cpython-32.pyc’ for Python 3.2.  The
     ‘cpython-32’ string comes from the current magic tag (see *note
     get_tag(): 32de.; if ‘sys.implementation.cache_tag’ is not defined
     then *note NotImplementedError: 569. will be raised).  By passing
     in ‘True’ or ‘False’ for `debug_override' you can override the
     system’s value for ‘__debug__’, leading to optimized bytecode.

     `path' need not exist.

     Changed in version 3.3: If ‘sys.implementation.cache_tag’ is
     ‘None’, then *note NotImplementedError: 569. is raised.

     Deprecated since version 3.4: Use *note
     importlib.util.cache_from_source(): 223. instead.

     Changed in version 3.5: The `debug_override' parameter no longer
     creates a ‘.pyo’ file.

 -- Function: imp.source_from_cache (path)

     Given the `path' to a PEP 3147(3) file name, return the associated
     source code file path.  For example, if `path' is
     ‘/foo/bar/__pycache__/baz.cpython-32.pyc’ the returned path would
     be ‘/foo/bar/baz.py’.  `path' need not exist, however if it does
     not conform to PEP 3147(4) format, a ‘ValueError’ is raised.  If
     ‘sys.implementation.cache_tag’ is not defined, *note
     NotImplementedError: 569. is raised.

     Changed in version 3.3: Raise *note NotImplementedError: 569. when
     ‘sys.implementation.cache_tag’ is not defined.

     Deprecated since version 3.4: Use *note
     importlib.util.source_from_cache(): 45a. instead.

 -- Function: imp.get_tag ()

     Return the PEP 3147(5) magic tag string matching this version of
     Python’s magic number, as returned by *note get_magic(): 459.

     Deprecated since version 3.4: Use ‘sys.implementation.cache_tag’
     directly starting in Python 3.3.

The following functions help interact with the import system’s internal
locking mechanism.  Locking semantics of imports are an implementation
detail which may vary from release to release.  However, Python ensures
that circular imports work without any deadlocks.

 -- Function: imp.lock_held ()

     Return ‘True’ if the global import lock is currently held, else
     ‘False’.  On platforms without threads, always return ‘False’.

     On platforms with threads, a thread executing an import first holds
     a global import lock, then sets up a per-module lock for the rest
     of the import.  This blocks other threads from importing the same
     module until the original import completes, preventing other
     threads from seeing incomplete module objects constructed by the
     original thread.  An exception is made for circular imports, which
     by construction have to expose an incomplete module object at some
     point.

     Changed in version 3.3: The locking scheme has changed to
     per-module locks for the most part.  A global import lock is kept
     for some critical tasks, such as initializing the per-module locks.

     Deprecated since version 3.4.

 -- Function: imp.acquire_lock ()

     Acquire the interpreter’s global import lock for the current
     thread.  This lock should be used by import hooks to ensure
     thread-safety when importing modules.

     Once a thread has acquired the import lock, the same thread may
     acquire it again without blocking; the thread must release it once
     for each time it has acquired it.

     On platforms without threads, this function does nothing.

     Changed in version 3.3: The locking scheme has changed to
     per-module locks for the most part.  A global import lock is kept
     for some critical tasks, such as initializing the per-module locks.

     Deprecated since version 3.4.

 -- Function: imp.release_lock ()

     Release the interpreter’s global import lock.  On platforms without
     threads, this function does nothing.

     Changed in version 3.3: The locking scheme has changed to
     per-module locks for the most part.  A global import lock is kept
     for some critical tasks, such as initializing the per-module locks.

     Deprecated since version 3.4.

The following constants with integer values, defined in this module, are
used to indicate the search result of *note find_module(): 32d7.

 -- Data: imp.PY_SOURCE

     The module was found as a source file.

     Deprecated since version 3.3.

 -- Data: imp.PY_COMPILED

     The module was found as a compiled code object file.

     Deprecated since version 3.3.

 -- Data: imp.C_EXTENSION

     The module was found as dynamically loadable shared library.

     Deprecated since version 3.3.

 -- Data: imp.PKG_DIRECTORY

     The module was found as a package directory.

     Deprecated since version 3.3.

 -- Data: imp.C_BUILTIN

     The module was found as a built-in module.

     Deprecated since version 3.3.

 -- Data: imp.PY_FROZEN

     The module was found as a frozen module.

     Deprecated since version 3.3.

 -- Class: imp.NullImporter (path_string)

     The *note NullImporter: 5dd. type is a PEP 302(6) import hook that
     handles non-directory path strings by failing to find any modules.
     Calling this type with an existing directory or empty string raises
     *note ImportError: 19f.  Otherwise, a *note NullImporter: 5dd.
     instance is returned.

     Instances have only one method:

      -- Method: find_module (fullname[, path])

          This method always returns ‘None’, indicating that the
          requested module could not be found.

     Changed in version 3.3: ‘None’ is inserted into
     ‘sys.path_importer_cache’ instead of an instance of *note
     NullImporter: 5dd.

     Deprecated since version 3.4: Insert ‘None’ into
     ‘sys.path_importer_cache’ instead.

* Menu:

* Examples: Examples<27>. 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3147

   (2) https://www.python.org/dev/peps/pep-3147

   (3) https://www.python.org/dev/peps/pep-3147

   (4) https://www.python.org/dev/peps/pep-3147

   (5) https://www.python.org/dev/peps/pep-3147

   (6) https://www.python.org/dev/peps/pep-0302


File: python.info,  Node: Examples<27>,  Up: imp --- Access the import internals

5.36.2.1 Examples
.................

The following function emulates what was the standard import statement
up to Python 1.4 (no hierarchical module names).  (This `implementation'
wouldn’t work in that version, since *note find_module(): 32d7. has been
extended and *note load_module(): 32db. has been added in 1.4.)

     import imp
     import sys

     def __import__(name, globals=None, locals=None, fromlist=None):
         # Fast path: see if the module has already been imported.
         try:
             return sys.modules[name]
         except KeyError:
             pass

         # If any of the following calls raises an exception,
         # there's a problem we can't handle -- let the caller handle it.

         fp, pathname, description = imp.find_module(name)

         try:
             return imp.load_module(name, fp, pathname, description)
         finally:
             # Since we may exit via an exception, close fp explicitly.
             if fp:
                 fp.close()


File: python.info,  Node: Undocumented Modules,  Prev: Superseded Modules,  Up: The Python Standard Library

5.37 Undocumented Modules
=========================

Here’s a quick listing of modules that are currently undocumented, but
that should be documented.  Feel free to contribute documentation for
them!  (Send via email to <docs@python.org>.)

The idea and original contents for this chapter were taken from a
posting by Fredrik Lundh; the specific contents of this chapter have
been substantially revised.

* Menu:

* Platform specific modules:: 


File: python.info,  Node: Platform specific modules,  Up: Undocumented Modules

5.37.1 Platform specific modules
--------------------------------

These modules are used to implement the *note os.path: c3. module, and
are not documented beyond this mention.  There’s little need to document
these.

‘ntpath’

     — Implementation of *note os.path: c3. on Win32, Win64, and WinCE
     platforms.

‘posixpath’

     — Implementation of *note os.path: c3. on POSIX.


File: python.info,  Node: Extending and Embedding the Python Interpreter,  Next: Python/C API Reference Manual,  Prev: The Python Standard Library,  Up: Top

6 Extending and Embedding the Python Interpreter
************************************************

This document describes how to write modules in C or C++ to extend the
Python interpreter with new modules.  Those modules can not only define
new functions but also new object types and their methods.  The document
also describes how to embed the Python interpreter in another
application, for use as an extension language.  Finally, it shows how to
compile and link extension modules so that they can be loaded
dynamically (at run time) into the interpreter, if the underlying
operating system supports this feature.

This document assumes basic knowledge about Python.  For an informal
introduction to the language, see *note The Python Tutorial: bc4.  *note
The Python Language Reference: bc6. gives a more formal definition of
the language.  *note The Python Standard Library: bc5. documents the
existing object types, functions and modules (both built-in and written
in Python) that give the language its wide application range.

For a detailed description of the whole Python/C API, see the separate
*note Python/C API Reference Manual: bc8.

* Menu:

* Recommended third party tools:: 
* Creating extensions without third party tools:: 
* Embedding the CPython runtime in a larger application:: 


File: python.info,  Node: Recommended third party tools,  Next: Creating extensions without third party tools,  Up: Extending and Embedding the Python Interpreter

6.1 Recommended third party tools
=================================

This guide only covers the basic tools for creating extensions provided
as part of this version of CPython.  Third party tools like Cython,
‘cffi’, SWIG and Numba offer both simpler and more sophisticated
approaches to creating C and C++ extensions for Python.

See also
........

Python Packaging User Guide: Binary Extensions(1)

     The Python Packaging User Guide not only covers several available
     tools that simplify the creation of binary extensions, but also
     discusses the various reasons why creating an extension module may
     be desirable in the first place.

   ---------- Footnotes ----------

   (1) https://packaging.python.org/en/latest/extensions/


File: python.info,  Node: Creating extensions without third party tools,  Next: Embedding the CPython runtime in a larger application,  Prev: Recommended third party tools,  Up: Extending and Embedding the Python Interpreter

6.2 Creating extensions without third party tools
=================================================

This section of the guide covers creating C and C++ extensions without
assistance from third party tools.  It is intended primarily for
creators of those tools, rather than being a recommended way to create
your own C extensions.

* Menu:

* Extending Python with C or C++:: 
* Defining New Types:: 
* Building C and C++ Extensions:: 
* Building C and C++ Extensions on Windows:: 


File: python.info,  Node: Extending Python with C or C++,  Next: Defining New Types,  Up: Creating extensions without third party tools

6.2.1 Extending Python with C or C++
------------------------------------

It is quite easy to add new built-in modules to Python, if you know how
to program in C. Such `extension modules' can do two things that can’t
be done directly in Python: they can implement new built-in object
types, and they can call C library functions and system calls.

To support extensions, the Python API (Application Programmers
Interface) defines a set of functions, macros and variables that provide
access to most aspects of the Python run-time system.  The Python API is
incorporated in a C source file by including the header ‘"Python.h"’.

The compilation of an extension module depends on its intended use as
well as on your system setup; details are given in later chapters.

     Note: The C extension interface is specific to CPython, and
     extension modules do not work on other Python implementations.  In
     many cases, it is possible to avoid writing C extensions and
     preserve portability to other implementations.  For example, if
     your use case is calling C library functions or system calls, you
     should consider using the *note ctypes: 2a. module or the cffi(1)
     library rather than writing custom C code.  These modules let you
     write Python code to interface with C code and are more portable
     between implementations of Python than writing and compiling a C
     extension module.

* Menu:

* A Simple Example:: 
* Intermezzo; Errors and Exceptions: Intermezzo Errors and Exceptions. 
* Back to the Example:: 
* The Module's Method Table and Initialization Function:: 
* Compilation and Linkage:: 
* Calling Python Functions from C:: 
* Extracting Parameters in Extension Functions:: 
* Keyword Parameters for Extension Functions:: 
* Building Arbitrary Values:: 
* Reference Counts:: 
* Writing Extensions in C++:: 
* Providing a C API for an Extension Module:: 

   ---------- Footnotes ----------

   (1) https://cffi.readthedocs.org


File: python.info,  Node: A Simple Example,  Next: Intermezzo Errors and Exceptions,  Up: Extending Python with C or C++

6.2.1.1 A Simple Example
........................

Let’s create an extension module called ‘spam’ (the favorite food of
Monty Python fans...)  and let’s say we want to create a Python
interface to the C library function ‘system()’.  (1) This function takes
a null-terminated character string as argument and returns an integer.
We want this function to be callable from Python as follows:

     >>> import spam
     >>> status = spam.system("ls -l")

Begin by creating a file ‘spammodule.c’.  (Historically, if a module is
called ‘spam’, the C file containing its implementation is called
‘spammodule.c’; if the module name is very long, like ‘spammify’, the
module name can be just ‘spammify.c’.)

The first line of our file can be:

     #include <Python.h>

which pulls in the Python API (you can add a comment describing the
purpose of the module and a copyright notice if you like).

     Note: Since Python may define some pre-processor definitions which
     affect the standard headers on some systems, you `must' include
     ‘Python.h’ before any standard headers are included.

All user-visible symbols defined by ‘Python.h’ have a prefix of ‘Py’ or
‘PY’, except those defined in standard header files.  For convenience,
and since they are used extensively by the Python interpreter,
‘"Python.h"’ includes a few standard header files: ‘<stdio.h>’,
‘<string.h>’, ‘<errno.h>’, and ‘<stdlib.h>’.  If the latter header file
does not exist on your system, it declares the functions ‘malloc()’,
‘free()’ and ‘realloc()’ directly.

The next thing we add to our module file is the C function that will be
called when the Python expression ‘spam.system(string)’ is evaluated
(we’ll see shortly how it ends up being called):

     static PyObject *
     spam_system(PyObject *self, PyObject *args)
     {
         const char *command;
         int sts;

         if (!PyArg_ParseTuple(args, "s", &command))
             return NULL;
         sts = system(command);
         return PyLong_FromLong(sts);
     }

There is a straightforward translation from the argument list in Python
(for example, the single expression ‘"ls -l"’) to the arguments passed
to the C function.  The C function always has two arguments,
conventionally named `self' and `args'.

The `self' argument points to the module object for module-level
functions; for a method it would point to the object instance.

The `args' argument will be a pointer to a Python tuple object
containing the arguments.  Each item of the tuple corresponds to an
argument in the call’s argument list.  The arguments are Python objects
— in order to do anything with them in our C function we have to convert
them to C values.  The function *note PyArg_ParseTuple(): 724. in the
Python API checks the argument types and converts them to C values.  It
uses a template string to determine the required types of the arguments
as well as the types of the C variables into which to store the
converted values.  More about this later.

*note PyArg_ParseTuple(): 724. returns true (nonzero) if all arguments
have the right type and its components have been stored in the variables
whose addresses are passed.  It returns false (zero) if an invalid
argument list was passed.  In the latter case it also raises an
appropriate exception so the calling function can return `NULL'
immediately (as we saw in the example).

   ---------- Footnotes ----------

   (1) An interface for this function already exists in the standard
module *note os: c2. — it was chosen as a simple and straightforward
example.


File: python.info,  Node: Intermezzo Errors and Exceptions,  Next: Back to the Example,  Prev: A Simple Example,  Up: Extending Python with C or C++

6.2.1.2 Intermezzo: Errors and Exceptions
.........................................

An important convention throughout the Python interpreter is the
following: when a function fails, it should set an exception condition
and return an error value (usually a `NULL' pointer).  Exceptions are
stored in a static global variable inside the interpreter; if this
variable is `NULL' no exception has occurred.  A second global variable
stores the "associated value" of the exception (the second argument to
*note raise: 8a9.).  A third variable contains the stack traceback in
case the error originated in Python code.  These three variables are the
C equivalents of the result in Python of *note sys.exc_info(): 8ca. (see
the section on module *note sys: fb. in the Python Library Reference).
It is important to know about them to understand how errors are passed
around.

The Python API defines a number of functions to set various types of
exceptions.

The most common one is *note PyErr_SetString(): 32f5.  Its arguments are
an exception object and a C string.  The exception object is usually a
predefined object like ‘PyExc_ZeroDivisionError’.  The C string
indicates the cause of the error and is converted to a Python string
object and stored as the "associated value" of the exception.

Another useful function is *note PyErr_SetFromErrno(): 32f6, which only
takes an exception argument and constructs the associated value by
inspection of the global variable ‘errno’.  The most general function is
*note PyErr_SetObject(): 32f7, which takes two object arguments, the
exception and its associated value.  You don’t need to *note
Py_INCREF(): 32f8. the objects passed to any of these functions.

You can test non-destructively whether an exception has been set with
*note PyErr_Occurred(): 32f9.  This returns the current exception
object, or `NULL' if no exception has occurred.  You normally don’t need
to call *note PyErr_Occurred(): 32f9. to see whether an error occurred
in a function call, since you should be able to tell from the return
value.

When a function `f' that calls another function `g' detects that the
latter fails, `f' should itself return an error value (usually `NULL' or
‘-1’).  It should `not' call one of the ‘PyErr_*()’ functions — one has
already been called by `g'.  `f'’s caller is then supposed to also
return an error indication to `its' caller, again `without' calling
‘PyErr_*()’, and so on — the most detailed cause of the error was
already reported by the function that first detected it.  Once the error
reaches the Python interpreter’s main loop, this aborts the currently
executing Python code and tries to find an exception handler specified
by the Python programmer.

(There are situations where a module can actually give a more detailed
error message by calling another ‘PyErr_*()’ function, and in such cases
it is fine to do so.  As a general rule, however, this is not necessary,
and can cause information about the cause of the error to be lost: most
operations can fail for a variety of reasons.)

To ignore an exception set by a function call that failed, the exception
condition must be cleared explicitly by calling *note PyErr_Clear():
588.  The only time C code should call *note PyErr_Clear(): 588. is if
it doesn’t want to pass the error on to the interpreter but wants to
handle it completely by itself (possibly by trying something else, or
pretending nothing went wrong).

Every failing ‘malloc()’ call must be turned into an exception — the
direct caller of ‘malloc()’ (or ‘realloc()’) must call *note
PyErr_NoMemory(): 32fa. and return a failure indicator itself.  All the
object-creating functions (for example, *note PyLong_FromLong(): 32fb.)
already do this, so this note is only relevant to those who call
‘malloc()’ directly.

Also note that, with the important exception of *note
PyArg_ParseTuple(): 724. and friends, functions that return an integer
status usually return a positive value or zero for success and ‘-1’ for
failure, like Unix system calls.

Finally, be careful to clean up garbage (by making *note Py_XDECREF():
32fc. or *note Py_DECREF(): 32fd. calls for objects you have already
created) when you return an error indicator!

The choice of which exception to raise is entirely yours.  There are
predeclared C objects corresponding to all built-in Python exceptions,
such as ‘PyExc_ZeroDivisionError’, which you can use directly.  Of
course, you should choose exceptions wisely — don’t use
‘PyExc_TypeError’ to mean that a file couldn’t be opened (that should
probably be ‘PyExc_IOError’).  If something’s wrong with the argument
list, the *note PyArg_ParseTuple(): 724. function usually raises
‘PyExc_TypeError’.  If you have an argument whose value must be in a
particular range or must satisfy other conditions, ‘PyExc_ValueError’ is
appropriate.

You can also define a new exception that is unique to your module.  For
this, you usually declare a static object variable at the beginning of
your file:

     static PyObject *SpamError;

and initialize it in your module’s initialization function
(‘PyInit_spam()’) with an exception object (leaving out the error
checking for now):

     PyMODINIT_FUNC
     PyInit_spam(void)
     {
         PyObject *m;

         m = PyModule_Create(&spammodule);
         if (m == NULL)
             return NULL;

         SpamError = PyErr_NewException("spam.error", NULL, NULL);
         Py_INCREF(SpamError);
         PyModule_AddObject(m, "error", SpamError);
         return m;
     }

Note that the Python name for the exception object is ‘spam.error’.  The
*note PyErr_NewException(): 861. function may create a class with the
base class being *note Exception: 1a1. (unless another class is passed
in instead of `NULL'), described in *note Built-in Exceptions: c6b.

Note also that the ‘SpamError’ variable retains a reference to the newly
created exception class; this is intentional!  Since the exception could
be removed from the module by external code, an owned reference to the
class is needed to ensure that it will not be discarded, causing
‘SpamError’ to become a dangling pointer.  Should it become a dangling
pointer, C code which raises the exception could cause a core dump or
other unintended side effects.

We discuss the use of ‘PyMODINIT_FUNC’ as a function return type later
in this sample.

The ‘spam.error’ exception can be raised in your extension module using
a call to *note PyErr_SetString(): 32f5. as shown below:

     static PyObject *
     spam_system(PyObject *self, PyObject *args)
     {
         const char *command;
         int sts;

         if (!PyArg_ParseTuple(args, "s", &command))
             return NULL;
         sts = system(command);
         if (sts < 0) {
             PyErr_SetString(SpamError, "System command failed");
             return NULL;
         }
         return PyLong_FromLong(sts);
     }


File: python.info,  Node: Back to the Example,  Next: The Module's Method Table and Initialization Function,  Prev: Intermezzo Errors and Exceptions,  Up: Extending Python with C or C++

6.2.1.3 Back to the Example
...........................

Going back to our example function, you should now be able to understand
this statement:

     if (!PyArg_ParseTuple(args, "s", &command))
         return NULL;

It returns `NULL' (the error indicator for functions returning object
pointers) if an error is detected in the argument list, relying on the
exception set by *note PyArg_ParseTuple(): 724.  Otherwise the string
value of the argument has been copied to the local variable ‘command’.
This is a pointer assignment and you are not supposed to modify the
string to which it points (so in Standard C, the variable ‘command’
should properly be declared as ‘const char *command’).

The next statement is a call to the Unix function ‘system()’, passing it
the string we just got from *note PyArg_ParseTuple(): 724.:

     sts = system(command);

Our ‘spam.system()’ function must return the value of ‘sts’ as a Python
object.  This is done using the function *note PyLong_FromLong(): 32fb.

     return PyLong_FromLong(sts);

In this case, it will return an integer object.  (Yes, even integers are
objects on the heap in Python!)

If you have a C function that returns no useful argument (a function
returning ‘void’), the corresponding Python function must return ‘None’.
You need this idiom to do so (which is implemented by the *note
Py_RETURN_NONE: a52. macro):

     Py_INCREF(Py_None);
     return Py_None;

*note Py_None: 3300. is the C name for the special Python object ‘None’.
It is a genuine Python object rather than a `NULL' pointer, which means
"error" in most contexts, as we have seen.


File: python.info,  Node: The Module's Method Table and Initialization Function,  Next: Compilation and Linkage,  Prev: Back to the Example,  Up: Extending Python with C or C++

6.2.1.4 The Module’s Method Table and Initialization Function
.............................................................

I promised to show how ‘spam_system()’ is called from Python programs.
First, we need to list its name and address in a "method table":

     static PyMethodDef SpamMethods[] = {
         ...
         {"system",  spam_system, METH_VARARGS,
          "Execute a shell command."},
         ...
         {NULL, NULL, 0, NULL}        /* Sentinel */
     };

Note the third entry (‘METH_VARARGS’).  This is a flag telling the
interpreter the calling convention to be used for the C function.  It
should normally always be ‘METH_VARARGS’ or ‘METH_VARARGS |
METH_KEYWORDS’; a value of ‘0’ means that an obsolete variant of *note
PyArg_ParseTuple(): 724. is used.

When using only ‘METH_VARARGS’, the function should expect the
Python-level parameters to be passed in as a tuple acceptable for
parsing via *note PyArg_ParseTuple(): 724.; more information on this
function is provided below.

The *note METH_KEYWORDS: 3303. bit may be set in the third field if
keyword arguments should be passed to the function.  In this case, the C
function should accept a third ‘PyObject *’ parameter which will be a
dictionary of keywords.  Use *note PyArg_ParseTupleAndKeywords(): a57.
to parse the arguments to such a function.

The method table must be referenced in the module definition structure:

     static struct PyModuleDef spammodule = {
        PyModuleDef_HEAD_INIT,
        "spam",   /* name of module */
        spam_doc, /* module documentation, may be NULL */
        -1,       /* size of per-interpreter state of the module,
                     or -1 if the module keeps state in global variables. */
        SpamMethods
     };

This structure, in turn, must be passed to the interpreter in the
module’s initialization function.  The initialization function must be
named ‘PyInit_name()’, where `name' is the name of the module, and
should be the only non-‘static’ item defined in the module file:

     PyMODINIT_FUNC
     PyInit_spam(void)
     {
         return PyModule_Create(&spammodule);
     }

Note that PyMODINIT_FUNC declares the function as ‘PyObject *’ return
type, declares any special linkage declarations required by the
platform, and for C++ declares the function as ‘extern "C"’.

When the Python program imports module ‘spam’ for the first time,
‘PyInit_spam()’ is called.  (See below for comments about embedding
Python.)  It calls *note PyModule_Create(): 3304, which returns a module
object, and inserts built-in function objects into the newly created
module based upon the table (an array of *note PyMethodDef: a9d.
structures) found in the module definition.  *note PyModule_Create():
3304. returns a pointer to the module object that it creates.  It may
abort with a fatal error for certain errors, or return `NULL' if the
module could not be initialized satisfactorily.  The init function must
return the module object to its caller, so that it then gets inserted
into ‘sys.modules’.

When embedding Python, the ‘PyInit_spam()’ function is not called
automatically unless there’s an entry in the ‘PyImport_Inittab’ table.
To add the module to the initialization table, use *note
PyImport_AppendInittab(): 3305, optionally followed by an import of the
module:

     int
     main(int argc, char *argv[])
     {
         wchar_t *program = Py_DecodeLocale(argv[0], NULL);
         if (program == NULL) {
             fprintf(stderr, "Fatal error: cannot decode argv[0]\n");
             exit(1);
         }

         /* Add a built-in module, before Py_Initialize */
         PyImport_AppendInittab("spam", PyInit_spam);

         /* Pass argv[0] to the Python interpreter */
         Py_SetProgramName(program);

         /* Initialize the Python interpreter.  Required. */
         Py_Initialize();

         /* Optionally import the module; alternatively,
            import can be deferred until the embedded script
            imports it. */
         PyImport_ImportModule("spam");

         ...

         PyMem_RawFree(program);
         return 0;
     }

     Note: Removing entries from ‘sys.modules’ or importing compiled
     modules into multiple interpreters within a process (or following a
     ‘fork()’ without an intervening ‘exec()’) can create problems for
     some extension modules.  Extension module authors should exercise
     caution when initializing internal data structures.

A more substantial example module is included in the Python source
distribution as ‘Modules/xxmodule.c’.  This file may be used as a
template or simply read as an example.

     Note: Unlike our ‘spam’ example, ‘xxmodule’ uses `multi-phase
     initialization' (new in Python 3.5), where a PyModuleDef structure
     is returned from ‘PyInit_spam’, and creation of the module is left
     to the import machinery.  For details on multi-phase
     initialization, see PEP 489(1).

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0489


File: python.info,  Node: Compilation and Linkage,  Next: Calling Python Functions from C,  Prev: The Module's Method Table and Initialization Function,  Up: Extending Python with C or C++

6.2.1.5 Compilation and Linkage
...............................

There are two more things to do before you can use your new extension:
compiling and linking it with the Python system.  If you use dynamic
loading, the details may depend on the style of dynamic loading your
system uses; see the chapters about building extension modules (chapter
*note Building C and C++ Extensions: 3308.) and additional information
that pertains only to building on Windows (chapter *note Building C and
C++ Extensions on Windows: d53.) for more information about this.

If you can’t use dynamic loading, or if you want to make your module a
permanent part of the Python interpreter, you will have to change the
configuration setup and rebuild the interpreter.  Luckily, this is very
simple on Unix: just place your file (‘spammodule.c’ for example) in the
‘Modules/’ directory of an unpacked source distribution, add a line to
the file ‘Modules/Setup.local’ describing your file:

     spam spammodule.o

and rebuild the interpreter by running ‘make’ in the toplevel directory.
You can also run ‘make’ in the ‘Modules/’ subdirectory, but then you
must first rebuild ‘Makefile’ there by running ’‘make’ Makefile’.  (This
is necessary each time you change the ‘Setup’ file.)

If your module requires additional libraries to link with, these can be
listed on the line in the configuration file as well, for instance:

     spam spammodule.o -lX11


File: python.info,  Node: Calling Python Functions from C,  Next: Extracting Parameters in Extension Functions,  Prev: Compilation and Linkage,  Up: Extending Python with C or C++

6.2.1.6 Calling Python Functions from C
.......................................

So far we have concentrated on making C functions callable from Python.
The reverse is also useful: calling Python functions from C. This is
especially the case for libraries that support so-called "callback"
functions.  If a C interface makes use of callbacks, the equivalent
Python often needs to provide a callback mechanism to the Python
programmer; the implementation will require calling the Python callback
functions from a C callback.  Other uses are also imaginable.

Fortunately, the Python interpreter is easily called recursively, and
there is a standard interface to call a Python function.  (I won’t dwell
on how to call the Python parser with a particular string as input — if
you’re interested, have a look at the implementation of the *note -c:
bd2. command line option in ‘Modules/main.c’ from the Python source
code.)

Calling a Python function is easy.  First, the Python program must
somehow pass you the Python function object.  You should provide a
function (or some other interface) to do this.  When this function is
called, save a pointer to the Python function object (be careful to
*note Py_INCREF(): 32f8. it!)  in a global variable — or wherever you
see fit.  For example, the following function might be part of a module
definition:

     static PyObject *my_callback = NULL;

     static PyObject *
     my_set_callback(PyObject *dummy, PyObject *args)
     {
         PyObject *result = NULL;
         PyObject *temp;

         if (PyArg_ParseTuple(args, "O:set_callback", &temp)) {
             if (!PyCallable_Check(temp)) {
                 PyErr_SetString(PyExc_TypeError, "parameter must be callable");
                 return NULL;
             }
             Py_XINCREF(temp);         /* Add a reference to new callback */
             Py_XDECREF(my_callback);  /* Dispose of previous callback */
             my_callback = temp;       /* Remember new callback */
             /* Boilerplate to return "None" */
             Py_INCREF(Py_None);
             result = Py_None;
         }
         return result;
     }

This function must be registered with the interpreter using the *note
METH_VARARGS: acc. flag; this is described in section *note The Module’s
Method Table and Initialization Function: 3301.  The *note
PyArg_ParseTuple(): 724. function and its arguments are documented in
section *note Extracting Parameters in Extension Functions: 330b.

The macros *note Py_XINCREF(): 330c. and *note Py_XDECREF(): 32fc.
increment/decrement the reference count of an object and are safe in the
presence of `NULL' pointers (but note that `temp' will not be `NULL' in
this context).  More info on them in section *note Reference Counts:
330d.

Later, when it is time to call the function, you call the C function
*note PyObject_CallObject(): 330e.  This function has two arguments,
both pointers to arbitrary Python objects: the Python function, and the
argument list.  The argument list must always be a tuple object, whose
length is the number of arguments.  To call the Python function with no
arguments, pass in NULL, or an empty tuple; to call it with one
argument, pass a singleton tuple.  *note Py_BuildValue(): 9f7. returns a
tuple when its format string consists of zero or more format codes
between parentheses.  For example:

     int arg;
     PyObject *arglist;
     PyObject *result;
     ...
     arg = 123;
     ...
     /* Time to call the callback */
     arglist = Py_BuildValue("(i)", arg);
     result = PyObject_CallObject(my_callback, arglist);
     Py_DECREF(arglist);

*note PyObject_CallObject(): 330e. returns a Python object pointer: this
is the return value of the Python function.  *note
PyObject_CallObject(): 330e. is "reference-count-neutral" with respect
to its arguments.  In the example a new tuple was created to serve as
the argument list, which is *note Py_DECREF(): 32fd.-ed immediately
after the *note PyObject_CallObject(): 330e. call.

The return value of *note PyObject_CallObject(): 330e. is "new": either
it is a brand new object, or it is an existing object whose reference
count has been incremented.  So, unless you want to save it in a global
variable, you should somehow *note Py_DECREF(): 32fd. the result, even
(especially!)  if you are not interested in its value.

Before you do this, however, it is important to check that the return
value isn’t `NULL'. If it is, the Python function terminated by raising
an exception.  If the C code that called *note PyObject_CallObject():
330e. is called from Python, it should now return an error indication to
its Python caller, so the interpreter can print a stack trace, or the
calling Python code can handle the exception.  If this is not possible
or desirable, the exception should be cleared by calling *note
PyErr_Clear(): 588.  For example:

     if (result == NULL)
         return NULL; /* Pass error back */
     ...use result...
     Py_DECREF(result);

Depending on the desired interface to the Python callback function, you
may also have to provide an argument list to *note
PyObject_CallObject(): 330e.  In some cases the argument list is also
provided by the Python program, through the same interface that
specified the callback function.  It can then be saved and used in the
same manner as the function object.  In other cases, you may have to
construct a new tuple to pass as the argument list.  The simplest way to
do this is to call *note Py_BuildValue(): 9f7.  For example, if you want
to pass an integral event code, you might use the following code:

     PyObject *arglist;
     ...
     arglist = Py_BuildValue("(l)", eventcode);
     result = PyObject_CallObject(my_callback, arglist);
     Py_DECREF(arglist);
     if (result == NULL)
         return NULL; /* Pass error back */
     /* Here maybe use the result */
     Py_DECREF(result);

Note the placement of ‘Py_DECREF(arglist)’ immediately after the call,
before the error check!  Also note that strictly speaking this code is
not complete: *note Py_BuildValue(): 9f7. may run out of memory, and
this should be checked.

You may also call a function with keyword arguments by using *note
PyObject_Call(): 330f, which supports arguments and keyword arguments.
As in the above example, we use *note Py_BuildValue(): 9f7. to construct
the dictionary.

     PyObject *dict;
     ...
     dict = Py_BuildValue("{s:i}", "name", val);
     result = PyObject_Call(my_callback, NULL, dict);
     Py_DECREF(dict);
     if (result == NULL)
         return NULL; /* Pass error back */
     /* Here maybe use the result */
     Py_DECREF(result);


File: python.info,  Node: Extracting Parameters in Extension Functions,  Next: Keyword Parameters for Extension Functions,  Prev: Calling Python Functions from C,  Up: Extending Python with C or C++

6.2.1.7 Extracting Parameters in Extension Functions
....................................................

The *note PyArg_ParseTuple(): 724. function is declared as follows:

     int PyArg_ParseTuple(PyObject *arg, const char *format, ...);

The `arg' argument must be a tuple object containing an argument list
passed from Python to a C function.  The `format' argument must be a
format string, whose syntax is explained in *note Parsing arguments and
building values: 3311. in the Python/C API Reference Manual.  The
remaining arguments must be addresses of variables whose type is
determined by the format string.

Note that while *note PyArg_ParseTuple(): 724. checks that the Python
arguments have the required types, it cannot check the validity of the
addresses of C variables passed to the call: if you make mistakes there,
your code will probably crash or at least overwrite random bits in
memory.  So be careful!

Note that any Python object references which are provided to the caller
are `borrowed' references; do not decrement their reference count!

Some example calls:

     #define PY_SSIZE_T_CLEAN  /* Make "s#" use Py_ssize_t rather than int. */
     #include <Python.h>

     int ok;
     int i, j;
     long k, l;
     const char *s;
     Py_ssize_t size;

     ok = PyArg_ParseTuple(args, ""); /* No arguments */
         /* Python call: f() */

     ok = PyArg_ParseTuple(args, "s", &s); /* A string */
         /* Possible Python call: f('whoops!') */

     ok = PyArg_ParseTuple(args, "lls", &k, &l, &s); /* Two longs and a string */
         /* Possible Python call: f(1, 2, 'three') */

     ok = PyArg_ParseTuple(args, "(ii)s#", &i, &j, &s, &size);
         /* A pair of ints and a string, whose size is also returned */
         /* Possible Python call: f((1, 2), 'three') */

     {
         const char *file;
         const char *mode = "r";
         int bufsize = 0;
         ok = PyArg_ParseTuple(args, "s|si", &file, &mode, &bufsize);
         /* A string, and optionally another string and an integer */
         /* Possible Python calls:
            f('spam')
            f('spam', 'w')
            f('spam', 'wb', 100000) */
     }

     {
         int left, top, right, bottom, h, v;
         ok = PyArg_ParseTuple(args, "((ii)(ii))(ii)",
                  &left, &top, &right, &bottom, &h, &v);
         /* A rectangle and a point */
         /* Possible Python call:
            f(((0, 0), (400, 300)), (10, 10)) */
     }

     {
         Py_complex c;
         ok = PyArg_ParseTuple(args, "D:myfunction", &c);
         /* a complex, also providing a function name for errors */
         /* Possible Python call: myfunction(1+2j) */
     }


File: python.info,  Node: Keyword Parameters for Extension Functions,  Next: Building Arbitrary Values,  Prev: Extracting Parameters in Extension Functions,  Up: Extending Python with C or C++

6.2.1.8 Keyword Parameters for Extension Functions
..................................................

The *note PyArg_ParseTupleAndKeywords(): a57. function is declared as
follows:

     int PyArg_ParseTupleAndKeywords(PyObject *arg, PyObject *kwdict,
                                     const char *format, char *kwlist[], ...);

The `arg' and `format' parameters are identical to those of the *note
PyArg_ParseTuple(): 724. function.  The `kwdict' parameter is the
dictionary of keywords received as the third parameter from the Python
runtime.  The `kwlist' parameter is a `NULL'-terminated list of strings
which identify the parameters; the names are matched with the type
information from `format' from left to right.  On success, *note
PyArg_ParseTupleAndKeywords(): a57. returns true, otherwise it returns
false and raises an appropriate exception.

     Note: Nested tuples cannot be parsed when using keyword arguments!
     Keyword parameters passed in which are not present in the `kwlist'
     will cause *note TypeError: 562. to be raised.

Here is an example module which uses keywords, based on an example by
Geoff Philbrick (<philbrick@hks.com>):

     #include "Python.h"

     static PyObject *
     keywdarg_parrot(PyObject *self, PyObject *args, PyObject *keywds)
     {
         int voltage;
         char *state = "a stiff";
         char *action = "voom";
         char *type = "Norwegian Blue";

         static char *kwlist[] = {"voltage", "state", "action", "type", NULL};

         if (!PyArg_ParseTupleAndKeywords(args, keywds, "i|sss", kwlist,
                                          &voltage, &state, &action, &type))
             return NULL;

         printf("-- This parrot wouldn't %s if you put %i Volts through it.\n",
                action, voltage);
         printf("-- Lovely plumage, the %s -- It's %s!\n", type, state);

         Py_RETURN_NONE;
     }

     static PyMethodDef keywdarg_methods[] = {
         /* The cast of the function is necessary since PyCFunction values
          * only take two PyObject* parameters, and keywdarg_parrot() takes
          * three.
          */
         {"parrot", (PyCFunction)keywdarg_parrot, METH_VARARGS | METH_KEYWORDS,
          "Print a lovely skit to standard output."},
         {NULL, NULL, 0, NULL}   /* sentinel */
     };

     static struct PyModuleDef keywdargmodule = {
         PyModuleDef_HEAD_INIT,
         "keywdarg",
         NULL,
         -1,
         keywdarg_methods
     };

     PyMODINIT_FUNC
     PyInit_keywdarg(void)
     {
         return PyModule_Create(&keywdargmodule);
     }


File: python.info,  Node: Building Arbitrary Values,  Next: Reference Counts,  Prev: Keyword Parameters for Extension Functions,  Up: Extending Python with C or C++

6.2.1.9 Building Arbitrary Values
.................................

This function is the counterpart to *note PyArg_ParseTuple(): 724.  It
is declared as follows:

     PyObject *Py_BuildValue(const char *format, ...);

It recognizes a set of format units similar to the ones recognized by
*note PyArg_ParseTuple(): 724, but the arguments (which are input to the
function, not output) must not be pointers, just values.  It returns a
new Python object, suitable for returning from a C function called from
Python.

One difference with *note PyArg_ParseTuple(): 724.: while the latter
requires its first argument to be a tuple (since Python argument lists
are always represented as tuples internally), *note Py_BuildValue():
9f7. does not always build a tuple.  It builds a tuple only if its
format string contains two or more format units.  If the format string
is empty, it returns ‘None’; if it contains exactly one format unit, it
returns whatever object is described by that format unit.  To force it
to return a tuple of size 0 or one, parenthesize the format string.

Examples (to the left the call, to the right the resulting Python
value):

     Py_BuildValue("")                        None
     Py_BuildValue("i", 123)                  123
     Py_BuildValue("iii", 123, 456, 789)      (123, 456, 789)
     Py_BuildValue("s", "hello")              'hello'
     Py_BuildValue("y", "hello")              b'hello'
     Py_BuildValue("ss", "hello", "world")    ('hello', 'world')
     Py_BuildValue("s#", "hello", 4)          'hell'
     Py_BuildValue("y#", "hello", 4)          b'hell'
     Py_BuildValue("()")                      ()
     Py_BuildValue("(i)", 123)                (123,)
     Py_BuildValue("(ii)", 123, 456)          (123, 456)
     Py_BuildValue("(i,i)", 123, 456)         (123, 456)
     Py_BuildValue("[i,i]", 123, 456)         [123, 456]
     Py_BuildValue("{s:i,s:i}",
                   "abc", 123, "def", 456)    {'abc': 123, 'def': 456}
     Py_BuildValue("((ii)(ii)) (ii)",
                   1, 2, 3, 4, 5, 6)          (((1, 2), (3, 4)), (5, 6))


File: python.info,  Node: Reference Counts,  Next: Writing Extensions in C++,  Prev: Building Arbitrary Values,  Up: Extending Python with C or C++

6.2.1.10 Reference Counts
.........................

In languages like C or C++, the programmer is responsible for dynamic
allocation and deallocation of memory on the heap.  In C, this is done
using the functions ‘malloc()’ and ‘free()’.  In C++, the operators
‘new’ and ‘delete’ are used with essentially the same meaning and we’ll
restrict the following discussion to the C case.

Every block of memory allocated with ‘malloc()’ should eventually be
returned to the pool of available memory by exactly one call to
‘free()’.  It is important to call ‘free()’ at the right time.  If a
block’s address is forgotten but ‘free()’ is not called for it, the
memory it occupies cannot be reused until the program terminates.  This
is called a `memory leak'.  On the other hand, if a program calls
‘free()’ for a block and then continues to use the block, it creates a
conflict with re-use of the block through another ‘malloc()’ call.  This
is called `using freed memory'.  It has the same bad consequences as
referencing uninitialized data — core dumps, wrong results, mysterious
crashes.

Common causes of memory leaks are unusual paths through the code.  For
instance, a function may allocate a block of memory, do some
calculation, and then free the block again.  Now a change in the
requirements for the function may add a test to the calculation that
detects an error condition and can return prematurely from the function.
It’s easy to forget to free the allocated memory block when taking this
premature exit, especially when it is added later to the code.  Such
leaks, once introduced, often go undetected for a long time: the error
exit is taken only in a small fraction of all calls, and most modern
machines have plenty of virtual memory, so the leak only becomes
apparent in a long-running process that uses the leaking function
frequently.  Therefore, it’s important to prevent leaks from happening
by having a coding convention or strategy that minimizes this kind of
errors.

Since Python makes heavy use of ‘malloc()’ and ‘free()’, it needs a
strategy to avoid memory leaks as well as the use of freed memory.  The
chosen method is called `reference counting'.  The principle is simple:
every object contains a counter, which is incremented when a reference
to the object is stored somewhere, and which is decremented when a
reference to it is deleted.  When the counter reaches zero, the last
reference to the object has been deleted and the object is freed.

An alternative strategy is called `automatic garbage collection'.
(Sometimes, reference counting is also referred to as a garbage
collection strategy, hence my use of "automatic" to distinguish the
two.)  The big advantage of automatic garbage collection is that the
user doesn’t need to call ‘free()’ explicitly.  (Another claimed
advantage is an improvement in speed or memory usage — this is no hard
fact however.)  The disadvantage is that for C, there is no truly
portable automatic garbage collector, while reference counting can be
implemented portably (as long as the functions ‘malloc()’ and ‘free()’
are available — which the C Standard guarantees).  Maybe some day a
sufficiently portable automatic garbage collector will be available for
C. Until then, we’ll have to live with reference counts.

While Python uses the traditional reference counting implementation, it
also offers a cycle detector that works to detect reference cycles.
This allows applications to not worry about creating direct or indirect
circular references; these are the weakness of garbage collection
implemented using only reference counting.  Reference cycles consist of
objects which contain (possibly indirect) references to themselves, so
that each object in the cycle has a reference count which is non-zero.
Typical reference counting implementations are not able to reclaim the
memory belonging to any objects in a reference cycle, or referenced from
the objects in the cycle, even though there are no further references to
the cycle itself.

The cycle detector is able to detect garbage cycles and can reclaim
them.  The *note gc: 85. module exposes a way to run the detector (the
*note collect(): a0c. function), as well as configuration interfaces and
the ability to disable the detector at runtime.  The cycle detector is
considered an optional component; though it is included by default, it
can be disabled at build time using the ‘--without-cycle-gc’ option to
the ‘configure’ script on Unix platforms (including Mac OS X). If the
cycle detector is disabled in this way, the *note gc: 85. module will
not be available.

* Menu:

* Reference Counting in Python:: 
* Ownership Rules:: 
* Thin Ice:: 
* NULL Pointers:: 


File: python.info,  Node: Reference Counting in Python,  Next: Ownership Rules,  Up: Reference Counts

6.2.1.11 Reference Counting in Python
.....................................

There are two macros, ‘Py_INCREF(x)’ and ‘Py_DECREF(x)’, which handle
the incrementing and decrementing of the reference count.  *note
Py_DECREF(): 32fd. also frees the object when the count reaches zero.
For flexibility, it doesn’t call ‘free()’ directly — rather, it makes a
call through a function pointer in the object’s `type object'.  For this
purpose (and others), every object also contains a pointer to its type
object.

The big question now remains: when to use ‘Py_INCREF(x)’ and
‘Py_DECREF(x)’?  Let’s first introduce some terms.  Nobody "owns" an
object; however, you can `own a reference' to an object.  An object’s
reference count is now defined as the number of owned references to it.
The owner of a reference is responsible for calling *note Py_DECREF():
32fd. when the reference is no longer needed.  Ownership of a reference
can be transferred.  There are three ways to dispose of an owned
reference: pass it on, store it, or call *note Py_DECREF(): 32fd.
Forgetting to dispose of an owned reference creates a memory leak.

It is also possible to `borrow' (1) a reference to an object.  The
borrower of a reference should not call *note Py_DECREF(): 32fd.  The
borrower must not hold on to the object longer than the owner from which
it was borrowed.  Using a borrowed reference after the owner has
disposed of it risks using freed memory and should be avoided
completely.  (2)

The advantage of borrowing over owning a reference is that you don’t
need to take care of disposing of the reference on all possible paths
through the code — in other words, with a borrowed reference you don’t
run the risk of leaking when a premature exit is taken.  The
disadvantage of borrowing over owning is that there are some subtle
situations where in seemingly correct code a borrowed reference can be
used after the owner from which it was borrowed has in fact disposed of
it.

A borrowed reference can be changed into an owned reference by calling
*note Py_INCREF(): 32f8.  This does not affect the status of the owner
from which the reference was borrowed — it creates a new owned
reference, and gives full owner responsibilities (the new owner must
dispose of the reference properly, as well as the previous owner).

   ---------- Footnotes ----------

   (1) The metaphor of "borrowing" a reference is not completely
correct: the owner still has a copy of the reference.

   (2) Checking that the reference count is at least 1 `does not work' —
the reference count itself could be in freed memory and may thus be
reused for another object!


File: python.info,  Node: Ownership Rules,  Next: Thin Ice,  Prev: Reference Counting in Python,  Up: Reference Counts

6.2.1.12 Ownership Rules
........................

Whenever an object reference is passed into or out of a function, it is
part of the function’s interface specification whether ownership is
transferred with the reference or not.

Most functions that return a reference to an object pass on ownership
with the reference.  In particular, all functions whose function it is
to create a new object, such as *note PyLong_FromLong(): 32fb. and *note
Py_BuildValue(): 9f7, pass ownership to the receiver.  Even if the
object is not actually new, you still receive ownership of a new
reference to that object.  For instance, *note PyLong_FromLong(): 32fb.
maintains a cache of popular values and can return a reference to a
cached item.

Many functions that extract objects from other objects also transfer
ownership with the reference, for instance *note
PyObject_GetAttrString(): 331b.  The picture is less clear, here,
however, since a few common routines are exceptions: *note
PyTuple_GetItem(): 331c, *note PyList_GetItem(): 331d, *note
PyDict_GetItem(): 331e, and *note PyDict_GetItemString(): 331f. all
return references that you borrow from the tuple, list or dictionary.

The function *note PyImport_AddModule(): 3320. also returns a borrowed
reference, even though it may actually create the object it returns:
this is possible because an owned reference to the object is stored in
‘sys.modules’.

When you pass an object reference into another function, in general, the
function borrows the reference from you — if it needs to store it, it
will use *note Py_INCREF(): 32f8. to become an independent owner.  There
are exactly two important exceptions to this rule: *note
PyTuple_SetItem(): 3321. and *note PyList_SetItem(): 3322.  These
functions take over ownership of the item passed to them — even if they
fail!  (Note that *note PyDict_SetItem(): 3323. and friends don’t take
over ownership — they are "normal.")

When a C function is called from Python, it borrows references to its
arguments from the caller.  The caller owns a reference to the object,
so the borrowed reference’s lifetime is guaranteed until the function
returns.  Only when such a borrowed reference must be stored or passed
on, it must be turned into an owned reference by calling *note
Py_INCREF(): 32f8.

The object reference returned from a C function that is called from
Python must be an owned reference — ownership is transferred from the
function to its caller.


File: python.info,  Node: Thin Ice,  Next: NULL Pointers,  Prev: Ownership Rules,  Up: Reference Counts

6.2.1.13 Thin Ice
.................

There are a few situations where seemingly harmless use of a borrowed
reference can lead to problems.  These all have to do with implicit
invocations of the interpreter, which can cause the owner of a reference
to dispose of it.

The first and most important case to know about is using *note
Py_DECREF(): 32fd. on an unrelated object while borrowing a reference to
a list item.  For instance:

     void
     bug(PyObject *list)
     {
         PyObject *item = PyList_GetItem(list, 0);

         PyList_SetItem(list, 1, PyLong_FromLong(0L));
         PyObject_Print(item, stdout, 0); /* BUG! */
     }

This function first borrows a reference to ‘list[0]’, then replaces
‘list[1]’ with the value ‘0’, and finally prints the borrowed reference.
Looks harmless, right?  But it’s not!

Let’s follow the control flow into *note PyList_SetItem(): 3322.  The
list owns references to all its items, so when item 1 is replaced, it
has to dispose of the original item 1.  Now let’s suppose the original
item 1 was an instance of a user-defined class, and let’s further
suppose that the class defined a *note __del__(): 525. method.  If this
class instance has a reference count of 1, disposing of it will call its
*note __del__(): 525. method.

Since it is written in Python, the *note __del__(): 525. method can
execute arbitrary Python code.  Could it perhaps do something to
invalidate the reference to ‘item’ in ‘bug()’?  You bet!  Assuming that
the list passed into ‘bug()’ is accessible to the *note __del__(): 525.
method, it could execute a statement to the effect of ‘del list[0]’, and
assuming this was the last reference to that object, it would free the
memory associated with it, thereby invalidating ‘item’.

The solution, once you know the source of the problem, is easy:
temporarily increment the reference count.  The correct version of the
function reads:

     void
     no_bug(PyObject *list)
     {
         PyObject *item = PyList_GetItem(list, 0);

         Py_INCREF(item);
         PyList_SetItem(list, 1, PyLong_FromLong(0L));
         PyObject_Print(item, stdout, 0);
         Py_DECREF(item);
     }

This is a true story.  An older version of Python contained variants of
this bug and someone spent a considerable amount of time in a C debugger
to figure out why his *note __del__(): 525. methods would fail...

The second case of problems with a borrowed reference is a variant
involving threads.  Normally, multiple threads in the Python interpreter
can’t get in each other’s way, because there is a global lock protecting
Python’s entire object space.  However, it is possible to temporarily
release this lock using the macro *note Py_BEGIN_ALLOW_THREADS: 3326,
and to re-acquire it using *note Py_END_ALLOW_THREADS: 3327.  This is
common around blocking I/O calls, to let other threads use the processor
while waiting for the I/O to complete.  Obviously, the following
function has the same problem as the previous one:

     void
     bug(PyObject *list)
     {
         PyObject *item = PyList_GetItem(list, 0);
         Py_BEGIN_ALLOW_THREADS
         ...some blocking I/O call...
         Py_END_ALLOW_THREADS
         PyObject_Print(item, stdout, 0); /* BUG! */
     }


File: python.info,  Node: NULL Pointers,  Prev: Thin Ice,  Up: Reference Counts

6.2.1.14 NULL Pointers
......................

In general, functions that take object references as arguments do not
expect you to pass them `NULL' pointers, and will dump core (or cause
later core dumps) if you do so.  Functions that return object references
generally return `NULL' only to indicate that an exception occurred.
The reason for not testing for `NULL' arguments is that functions often
pass the objects they receive on to other function — if each function
were to test for `NULL', there would be a lot of redundant tests and the
code would run more slowly.

It is better to test for `NULL' only at the "source:" when a pointer
that may be `NULL' is received, for example, from ‘malloc()’ or from a
function that may raise an exception.

The macros *note Py_INCREF(): 32f8. and *note Py_DECREF(): 32fd. do not
check for `NULL' pointers — however, their variants *note Py_XINCREF():
330c. and *note Py_XDECREF(): 32fc. do.

The macros for checking for a particular object type (‘Pytype_Check()’)
don’t check for `NULL' pointers — again, there is much code that calls
several of these in a row to test an object against various different
expected types, and this would generate redundant tests.  There are no
variants with `NULL' checking.

The C function calling mechanism guarantees that the argument list
passed to C functions (‘args’ in the examples) is never `NULL' — in fact
it guarantees that it is always a tuple.  (1)

It is a severe error to ever let a `NULL' pointer "escape" to the Python
user.

   ---------- Footnotes ----------

   (1) These guarantees don’t hold when you use the "old" style calling
convention — this is still found in much existing code.


File: python.info,  Node: Writing Extensions in C++,  Next: Providing a C API for an Extension Module,  Prev: Reference Counts,  Up: Extending Python with C or C++

6.2.1.15 Writing Extensions in C++
..................................

It is possible to write extension modules in C++.  Some restrictions
apply.  If the main program (the Python interpreter) is compiled and
linked by the C compiler, global or static objects with constructors
cannot be used.  This is not a problem if the main program is linked by
the C++ compiler.  Functions that will be called by the Python
interpreter (in particular, module initialization functions) have to be
declared using ‘extern "C"’.  It is unnecessary to enclose the Python
header files in ‘extern "C" {...}’ — they use this form already if the
symbol ‘__cplusplus’ is defined (all recent C++ compilers define this
symbol).


File: python.info,  Node: Providing a C API for an Extension Module,  Prev: Writing Extensions in C++,  Up: Extending Python with C or C++

6.2.1.16 Providing a C API for an Extension Module
..................................................

Many extension modules just provide new functions and types to be used
from Python, but sometimes the code in an extension module can be useful
for other extension modules.  For example, an extension module could
implement a type "collection" which works like lists without order.
Just like the standard Python list type has a C API which permits
extension modules to create and manipulate lists, this new collection
type should have a set of C functions for direct manipulation from other
extension modules.

At first sight this seems easy: just write the functions (without
declaring them ‘static’, of course), provide an appropriate header file,
and document the C API. And in fact this would work if all extension
modules were always linked statically with the Python interpreter.  When
modules are used as shared libraries, however, the symbols defined in
one module may not be visible to another module.  The details of
visibility depend on the operating system; some systems use one global
namespace for the Python interpreter and all extension modules (Windows,
for example), whereas others require an explicit list of imported
symbols at module link time (AIX is one example), or offer a choice of
different strategies (most Unices).  And even if symbols are globally
visible, the module whose functions one wishes to call might not have
been loaded yet!

Portability therefore requires not to make any assumptions about symbol
visibility.  This means that all symbols in extension modules should be
declared ‘static’, except for the module’s initialization function, in
order to avoid name clashes with other extension modules (as discussed
in section *note The Module’s Method Table and Initialization Function:
3301.).  And it means that symbols that `should' be accessible from
other extension modules must be exported in a different way.

Python provides a special mechanism to pass C-level information
(pointers) from one extension module to another one: Capsules.  A
Capsule is a Python data type which stores a pointer (‘void *’).
Capsules can only be created and accessed via their C API, but they can
be passed around like any other Python object.  In particular, they can
be assigned to a name in an extension module’s namespace.  Other
extension modules can then import this module, retrieve the value of
this name, and then retrieve the pointer from the Capsule.

There are many ways in which Capsules can be used to export the C API of
an extension module.  Each function could get its own Capsule, or all C
API pointers could be stored in an array whose address is published in a
Capsule.  And the various tasks of storing and retrieving the pointers
can be distributed in different ways between the module providing the
code and the client modules.

Whichever method you choose, it’s important to name your Capsules
properly.  The function *note PyCapsule_New(): 332d. takes a name
parameter (‘const char *’); you’re permitted to pass in a `NULL' name,
but we strongly encourage you to specify a name.  Properly named
Capsules provide a degree of runtime type-safety; there is no feasible
way to tell one unnamed Capsule from another.

In particular, Capsules used to expose C APIs should be given a name
following this convention:

     modulename.attributename

The convenience function *note PyCapsule_Import(): 332e. makes it easy
to load a C API provided via a Capsule, but only if the Capsule’s name
matches this convention.  This behavior gives C API users a high degree
of certainty that the Capsule they load contains the correct C API.

The following example demonstrates an approach that puts most of the
burden on the writer of the exporting module, which is appropriate for
commonly used library modules.  It stores all C API pointers (just one
in the example!)  in an array of ‘void’ pointers which becomes the value
of a Capsule.  The header file corresponding to the module provides a
macro that takes care of importing the module and retrieving its C API
pointers; client modules only have to call this macro before accessing
the C API.

The exporting module is a modification of the ‘spam’ module from section
*note A Simple Example: 32f2.  The function ‘spam.system()’ does not
call the C library function ‘system()’ directly, but a function
‘PySpam_System()’, which would of course do something more complicated
in reality (such as adding "spam" to every command).  This function
‘PySpam_System()’ is also exported to other extension modules.

The function ‘PySpam_System()’ is a plain C function, declared ‘static’
like everything else:

     static int
     PySpam_System(const char *command)
     {
         return system(command);
     }

The function ‘spam_system()’ is modified in a trivial way:

     static PyObject *
     spam_system(PyObject *self, PyObject *args)
     {
         const char *command;
         int sts;

         if (!PyArg_ParseTuple(args, "s", &command))
             return NULL;
         sts = PySpam_System(command);
         return PyLong_FromLong(sts);
     }

In the beginning of the module, right after the line

     #include "Python.h"

two more lines must be added:

     #define SPAM_MODULE
     #include "spammodule.h"

The ‘#define’ is used to tell the header file that it is being included
in the exporting module, not a client module.  Finally, the module’s
initialization function must take care of initializing the C API pointer
array:

     PyMODINIT_FUNC
     PyInit_spam(void)
     {
         PyObject *m;
         static void *PySpam_API[PySpam_API_pointers];
         PyObject *c_api_object;

         m = PyModule_Create(&spammodule);
         if (m == NULL)
             return NULL;

         /* Initialize the C API pointer array */
         PySpam_API[PySpam_System_NUM] = (void *)PySpam_System;

         /* Create a Capsule containing the API pointer array's address */
         c_api_object = PyCapsule_New((void *)PySpam_API, "spam._C_API", NULL);

         if (c_api_object != NULL)
             PyModule_AddObject(m, "_C_API", c_api_object);
         return m;
     }

Note that ‘PySpam_API’ is declared ‘static’; otherwise the pointer array
would disappear when ‘PyInit_spam()’ terminates!

The bulk of the work is in the header file ‘spammodule.h’, which looks
like this:

     #ifndef Py_SPAMMODULE_H
     #define Py_SPAMMODULE_H
     #ifdef __cplusplus
     extern "C" {
     #endif

     /* Header file for spammodule */

     /* C API functions */
     #define PySpam_System_NUM 0
     #define PySpam_System_RETURN int
     #define PySpam_System_PROTO (const char *command)

     /* Total number of C API pointers */
     #define PySpam_API_pointers 1


     #ifdef SPAM_MODULE
     /* This section is used when compiling spammodule.c */

     static PySpam_System_RETURN PySpam_System PySpam_System_PROTO;

     #else
     /* This section is used in modules that use spammodule's API */

     static void **PySpam_API;

     #define PySpam_System \
      (*(PySpam_System_RETURN (*)PySpam_System_PROTO) PySpam_API[PySpam_System_NUM])

     /* Return -1 on error, 0 on success.
      * PyCapsule_Import will set an exception if there's an error.
      */
     static int
     import_spam(void)
     {
         PySpam_API = (void **)PyCapsule_Import("spam._C_API", 0);
         return (PySpam_API != NULL) ? 0 : -1;
     }

     #endif

     #ifdef __cplusplus
     }
     #endif

     #endif /* !defined(Py_SPAMMODULE_H) */

All that a client module must do in order to have access to the function
‘PySpam_System()’ is to call the function (or rather macro)
‘import_spam()’ in its initialization function:

     PyMODINIT_FUNC
     PyInit_client(void)
     {
         PyObject *m;

         m = PyModule_Create(&clientmodule);
         if (m == NULL)
             return NULL;
         if (import_spam() < 0)
             return NULL;
         /* additional initialization can happen here */
         return m;
     }

The main disadvantage of this approach is that the file ‘spammodule.h’
is rather complicated.  However, the basic structure is the same for
each function that is exported, so it has to be learned only once.

Finally it should be mentioned that Capsules offer additional
functionality, which is especially useful for memory allocation and
deallocation of the pointer stored in a Capsule.  The details are
described in the Python/C API Reference Manual in the section *note
Capsules: 332f. and in the implementation of Capsules (files
‘Include/pycapsule.h’ and ‘Objects/pycapsule.c’ in the Python source
code distribution).


File: python.info,  Node: Defining New Types,  Next: Building C and C++ Extensions,  Prev: Extending Python with C or C++,  Up: Creating extensions without third party tools

6.2.2 Defining New Types
------------------------

As mentioned in the last chapter, Python allows the writer of an
extension module to define new types that can be manipulated from Python
code, much like strings and lists in core Python.

This is not hard; the code for all extension types follows a pattern,
but there are some details that you need to understand before you can
get started.

* Menu:

* The Basics:: 
* Type Methods:: 


File: python.info,  Node: The Basics,  Next: Type Methods,  Up: Defining New Types

6.2.2.1 The Basics
..................

The Python runtime sees all Python objects as variables of type *note
PyObject*: 9f5, which serves as a "base type" for all Python objects.
*note PyObject: 9f5. itself only contains the refcount and a pointer to
the object’s "type object".  This is where the action is; the type
object determines which (C) functions get called when, for instance, an
attribute gets looked up on an object or it is multiplied by another
object.  These C functions are called "type methods".

So, if you want to define a new object type, you need to create a new
type object.

This sort of thing can only be explained by example, so here’s a
minimal, but complete, module that defines a new type:

     #include <Python.h>

     typedef struct {
         PyObject_HEAD
         /* Type-specific fields go here. */
     } noddy_NoddyObject;

     static PyTypeObject noddy_NoddyType = {
         PyVarObject_HEAD_INIT(NULL, 0)
         "noddy.Noddy",             /* tp_name */
         sizeof(noddy_NoddyObject), /* tp_basicsize */
         0,                         /* tp_itemsize */
         0,                         /* tp_dealloc */
         0,                         /* tp_print */
         0,                         /* tp_getattr */
         0,                         /* tp_setattr */
         0,                         /* tp_reserved */
         0,                         /* tp_repr */
         0,                         /* tp_as_number */
         0,                         /* tp_as_sequence */
         0,                         /* tp_as_mapping */
         0,                         /* tp_hash  */
         0,                         /* tp_call */
         0,                         /* tp_str */
         0,                         /* tp_getattro */
         0,                         /* tp_setattro */
         0,                         /* tp_as_buffer */
         Py_TPFLAGS_DEFAULT,        /* tp_flags */
         "Noddy objects",           /* tp_doc */
     };

     static PyModuleDef noddymodule = {
         PyModuleDef_HEAD_INIT,
         "noddy",
         "Example module that creates an extension type.",
         -1,
         NULL, NULL, NULL, NULL, NULL
     };

     PyMODINIT_FUNC
     PyInit_noddy(void)
     {
         PyObject* m;

         noddy_NoddyType.tp_new = PyType_GenericNew;
         if (PyType_Ready(&noddy_NoddyType) < 0)
             return NULL;

         m = PyModule_Create(&noddymodule);
         if (m == NULL)
             return NULL;

         Py_INCREF(&noddy_NoddyType);
         PyModule_AddObject(m, "Noddy", (PyObject *)&noddy_NoddyType);
         return m;
     }

Now that’s quite a bit to take in at once, but hopefully bits will seem
familiar from the last chapter.

The first bit that will be new is:

     typedef struct {
         PyObject_HEAD
     } noddy_NoddyObject;

This is what a Noddy object will contain—in this case, nothing more than
what every Python object contains—a refcount and a pointer to a type
object.  These are the fields the ‘PyObject_HEAD’ macro brings in.  The
reason for the macro is to standardize the layout and to enable special
debugging fields in debug builds.  Note that there is no semicolon after
the ‘PyObject_HEAD’ macro; one is included in the macro definition.  Be
wary of adding one by accident; it’s easy to do from habit, and your
compiler might not complain, but someone else’s probably will!  (On
Windows, MSVC is known to call this an error and refuse to compile the
code.)

For contrast, let’s take a look at the corresponding definition for
standard Python floats:

     typedef struct {
         PyObject_HEAD
         double ob_fval;
     } PyFloatObject;

Moving on, we come to the crunch — the type object.

     static PyTypeObject noddy_NoddyType = {
         PyVarObject_HEAD_INIT(NULL, 0)
         "noddy.Noddy",             /* tp_name */
         sizeof(noddy_NoddyObject), /* tp_basicsize */
         0,                         /* tp_itemsize */
         0,                         /* tp_dealloc */
         0,                         /* tp_print */
         0,                         /* tp_getattr */
         0,                         /* tp_setattr */
         0,                         /* tp_as_async */
         0,                         /* tp_repr */
         0,                         /* tp_as_number */
         0,                         /* tp_as_sequence */
         0,                         /* tp_as_mapping */
         0,                         /* tp_hash  */
         0,                         /* tp_call */
         0,                         /* tp_str */
         0,                         /* tp_getattro */
         0,                         /* tp_setattro */
         0,                         /* tp_as_buffer */
         Py_TPFLAGS_DEFAULT,        /* tp_flags */
         "Noddy objects",           /* tp_doc */
     };

Now if you go and look up the definition of *note PyTypeObject: 3bc. in
‘object.h’ you’ll see that it has many more fields that the definition
above.  The remaining fields will be filled with zeros by the C
compiler, and it’s common practice to not specify them explicitly unless
you need them.

This is so important that we’re going to pick the top of it apart still
further:

     PyVarObject_HEAD_INIT(NULL, 0)

This line is a bit of a wart; what we’d like to write is:

     PyVarObject_HEAD_INIT(&PyType_Type, 0)

as the type of a type object is "type", but this isn’t strictly
conforming C and some compilers complain.  Fortunately, this member will
be filled in for us by *note PyType_Ready(): 3335.

     "noddy.Noddy",              /* tp_name */

The name of our type.  This will appear in the default textual
representation of our objects and in some error messages, for example:

     >>> "" + noddy.new_noddy()
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     TypeError: cannot add type "noddy.Noddy" to string

Note that the name is a dotted name that includes both the module name
and the name of the type within the module.  The module in this case is
‘noddy’ and the type is ‘Noddy’, so we set the type name to
‘noddy.Noddy’.

     sizeof(noddy_NoddyObject),  /* tp_basicsize */

This is so that Python knows how much memory to allocate when you call
*note PyObject_New(): a96.

     Note: If you want your type to be subclassable from Python, and
     your type has the same *note tp_basicsize: 3336. as its base type,
     you may have problems with multiple inheritance.  A Python subclass
     of your type will have to list your type first in its *note
     __bases__: df2, or else it will not be able to call your type’s
     *note __new__(): 484. method without getting an error.  You can
     avoid this problem by ensuring that your type has a larger value
     for *note tp_basicsize: 3336. than its base type does.  Most of the
     time, this will be true anyway, because either your base type will
     be *note object: 5cb, or else you will be adding data members to
     your base type, and therefore increasing its size.

     0,                          /* tp_itemsize */

This has to do with variable length objects like lists and strings.
Ignore this for now.

Skipping a number of type methods that we don’t provide, we set the
class flags to *note Py_TPFLAGS_DEFAULT: 3337.

     Py_TPFLAGS_DEFAULT,        /* tp_flags */

All types should include this constant in their flags.  It enables all
of the members defined until at least Python 3.3.  If you need further
members, you will need to OR the corresponding flags.

We provide a doc string for the type in *note tp_doc: 3338.

     "Noddy objects",           /* tp_doc */

Now we get into the type methods, the things that make your objects
different from the others.  We aren’t going to implement any of these in
this version of the module.  We’ll expand this example later to have
more interesting behavior.

For now, all we want to be able to do is to create new ‘Noddy’ objects.
To enable object creation, we have to provide a *note tp_new: 3339.
implementation.  In this case, we can just use the default
implementation provided by the API function *note PyType_GenericNew():
333a.  We’d like to just assign this to the *note tp_new: 3339. slot,
but we can’t, for portability sake, On some platforms or compilers, we
can’t statically initialize a structure member with a function defined
in another C module, so, instead, we’ll assign the *note tp_new: 3339.
slot in the module initialization function just before calling *note
PyType_Ready(): 3335.:

     noddy_NoddyType.tp_new = PyType_GenericNew;
     if (PyType_Ready(&noddy_NoddyType) < 0)
         return;

All the other type methods are `NULL', so we’ll go over them later —
that’s for a later section!

Everything else in the file should be familiar, except for some code in
‘PyInit_noddy()’:

     if (PyType_Ready(&noddy_NoddyType) < 0)
         return;

This initializes the ‘Noddy’ type, filing in a number of members,
including ‘ob_type’ that we initially set to `NULL'.

     PyModule_AddObject(m, "Noddy", (PyObject *)&noddy_NoddyType);

This adds the type to the module dictionary.  This allows us to create
‘Noddy’ instances by calling the ‘Noddy’ class:

     >>> import noddy
     >>> mynoddy = noddy.Noddy()

That’s it!  All that remains is to build it; put the above code in a
file called ‘noddy.c’ and

     from distutils.core import setup, Extension
     setup(name="noddy", version="1.0",
           ext_modules=[Extension("noddy", ["noddy.c"])])

in a file called ‘setup.py’; then typing

     $ python setup.py build

at a shell should produce a file ‘noddy.so’ in a subdirectory; move to
that directory and fire up Python — you should be able to ‘import noddy’
and play around with Noddy objects.

That wasn’t so hard, was it?

Of course, the current Noddy type is pretty uninteresting.  It has no
data and doesn’t do anything.  It can’t even be subclassed.

* Menu:

* Adding data and methods to the Basic example:: 
* Providing finer control over data attributes:: 
* Supporting cyclic garbage collection:: 
* Subclassing other types:: 


File: python.info,  Node: Adding data and methods to the Basic example,  Next: Providing finer control over data attributes,  Up: The Basics

6.2.2.2 Adding data and methods to the Basic example
....................................................

Let’s extend the basic example to add some data and methods.  Let’s also
make the type usable as a base class.  We’ll create a new module,
‘noddy2’ that adds these capabilities:

     #include <Python.h>
     #include "structmember.h"

     typedef struct {
         PyObject_HEAD
         PyObject *first; /* first name */
         PyObject *last;  /* last name */
         int number;
     } Noddy;

     static void
     Noddy_dealloc(Noddy* self)
     {
         Py_XDECREF(self->first);
         Py_XDECREF(self->last);
         Py_TYPE(self)->tp_free((PyObject*)self);
     }

     static PyObject *
     Noddy_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
     {
         Noddy *self;

         self = (Noddy *)type->tp_alloc(type, 0);
         if (self != NULL) {
             self->first = PyUnicode_FromString("");
             if (self->first == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->last = PyUnicode_FromString("");
             if (self->last == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->number = 0;
         }

         return (PyObject *)self;
     }

     static int
     Noddy_init(Noddy *self, PyObject *args, PyObject *kwds)
     {
         PyObject *first=NULL, *last=NULL, *tmp;

         static char *kwlist[] = {"first", "last", "number", NULL};

         if (! PyArg_ParseTupleAndKeywords(args, kwds, "|OOi", kwlist,
                                           &first, &last,
                                           &self->number))
             return -1;

         if (first) {
             tmp = self->first;
             Py_INCREF(first);
             self->first = first;
             Py_XDECREF(tmp);
         }

         if (last) {
             tmp = self->last;
             Py_INCREF(last);
             self->last = last;
             Py_XDECREF(tmp);
         }

         return 0;
     }


     static PyMemberDef Noddy_members[] = {
         {"first", T_OBJECT_EX, offsetof(Noddy, first), 0,
          "first name"},
         {"last", T_OBJECT_EX, offsetof(Noddy, last), 0,
          "last name"},
         {"number", T_INT, offsetof(Noddy, number), 0,
          "noddy number"},
         {NULL}  /* Sentinel */
     };

     static PyObject *
     Noddy_name(Noddy* self)
     {
         if (self->first == NULL) {
             PyErr_SetString(PyExc_AttributeError, "first");
             return NULL;
         }

         if (self->last == NULL) {
             PyErr_SetString(PyExc_AttributeError, "last");
             return NULL;
         }

         return PyUnicode_FromFormat("%S %S", self->first, self->last);
     }

     static PyMethodDef Noddy_methods[] = {
         {"name", (PyCFunction)Noddy_name, METH_NOARGS,
          "Return the name, combining the first and last name"
         },
         {NULL}  /* Sentinel */
     };

     static PyTypeObject NoddyType = {
         PyVarObject_HEAD_INIT(NULL, 0)
         "noddy.Noddy",             /* tp_name */
         sizeof(Noddy),             /* tp_basicsize */
         0,                         /* tp_itemsize */
         (destructor)Noddy_dealloc, /* tp_dealloc */
         0,                         /* tp_print */
         0,                         /* tp_getattr */
         0,                         /* tp_setattr */
         0,                         /* tp_reserved */
         0,                         /* tp_repr */
         0,                         /* tp_as_number */
         0,                         /* tp_as_sequence */
         0,                         /* tp_as_mapping */
         0,                         /* tp_hash  */
         0,                         /* tp_call */
         0,                         /* tp_str */
         0,                         /* tp_getattro */
         0,                         /* tp_setattro */
         0,                         /* tp_as_buffer */
         Py_TPFLAGS_DEFAULT |
             Py_TPFLAGS_BASETYPE,   /* tp_flags */
         "Noddy objects",           /* tp_doc */
         0,                         /* tp_traverse */
         0,                         /* tp_clear */
         0,                         /* tp_richcompare */
         0,                         /* tp_weaklistoffset */
         0,                         /* tp_iter */
         0,                         /* tp_iternext */
         Noddy_methods,             /* tp_methods */
         Noddy_members,             /* tp_members */
         0,                         /* tp_getset */
         0,                         /* tp_base */
         0,                         /* tp_dict */
         0,                         /* tp_descr_get */
         0,                         /* tp_descr_set */
         0,                         /* tp_dictoffset */
         (initproc)Noddy_init,      /* tp_init */
         0,                         /* tp_alloc */
         Noddy_new,                 /* tp_new */
     };

     static PyModuleDef noddy2module = {
         PyModuleDef_HEAD_INIT,
         "noddy2",
         "Example module that creates an extension type.",
         -1,
         NULL, NULL, NULL, NULL, NULL
     };

     PyMODINIT_FUNC
     PyInit_noddy2(void)
     {
         PyObject* m;

         if (PyType_Ready(&NoddyType) < 0)
             return NULL;

         m = PyModule_Create(&noddy2module);
         if (m == NULL)
             return NULL;

         Py_INCREF(&NoddyType);
         PyModule_AddObject(m, "Noddy", (PyObject *)&NoddyType);
         return m;
     }

This version of the module has a number of changes.

We’ve added an extra include:

     #include <structmember.h>

This include provides declarations that we use to handle attributes, as
described a bit later.

The name of the ‘Noddy’ object structure has been shortened to ‘Noddy’.
The type object name has been shortened to ‘NoddyType’.

The ‘Noddy’ type now has three data attributes, `first', `last', and
`number'.  The `first' and `last' variables are Python strings
containing first and last names.  The `number' attribute is an integer.

The object structure is updated accordingly:

     typedef struct {
         PyObject_HEAD
         PyObject *first;
         PyObject *last;
         int number;
     } Noddy;

Because we now have data to manage, we have to be more careful about
object allocation and deallocation.  At a minimum, we need a
deallocation method:

     static void
     Noddy_dealloc(Noddy* self)
     {
         Py_XDECREF(self->first);
         Py_XDECREF(self->last);
         Py_TYPE(self)->tp_free((PyObject*)self);
     }

which is assigned to the *note tp_dealloc: 333c. member:

     (destructor)Noddy_dealloc, /*tp_dealloc*/

This method decrements the reference counts of the two Python
attributes.  We use *note Py_XDECREF(): 32fc. here because the ‘first’
and ‘last’ members could be `NULL'. It then calls the *note tp_free:
333d. member of the object’s type to free the object’s memory.  Note
that the object’s type might not be ‘NoddyType’, because the object may
be an instance of a subclass.

We want to make sure that the first and last names are initialized to
empty strings, so we provide a new method:

     static PyObject *
     Noddy_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
     {
         Noddy *self;

         self = (Noddy *)type->tp_alloc(type, 0);
         if (self != NULL) {
             self->first = PyUnicode_FromString("");
             if (self->first == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->last = PyUnicode_FromString("");
             if (self->last == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->number = 0;
         }

         return (PyObject *)self;
     }

and install it in the *note tp_new: 3339. member:

     Noddy_new,                 /* tp_new */

The new member is responsible for creating (as opposed to initializing)
objects of the type.  It is exposed in Python as the *note __new__():
484. method.  See the paper titled "Unifying types and classes in
Python" for a detailed discussion of the *note __new__(): 484. method.
One reason to implement a new method is to assure the initial values of
instance variables.  In this case, we use the new method to make sure
that the initial values of the members ‘first’ and ‘last’ are not
`NULL'. If we didn’t care whether the initial values were `NULL', we
could have used *note PyType_GenericNew(): 333a. as our new method, as
we did before.  *note PyType_GenericNew(): 333a. initializes all of the
instance variable members to `NULL'.

The new method is a static method that is passed the type being
instantiated and any arguments passed when the type was called, and that
returns the new object created.  New methods always accept positional
and keyword arguments, but they often ignore the arguments, leaving the
argument handling to initializer methods.  Note that if the type
supports subclassing, the type passed may not be the type being defined.
The new method calls the *note tp_alloc: 333e. slot to allocate memory.
We don’t fill the *note tp_alloc: 333e. slot ourselves.  Rather *note
PyType_Ready(): 3335. fills it for us by inheriting it from our base
class, which is *note object: 5cb. by default.  Most types use the
default allocation.

     Note: If you are creating a co-operative *note tp_new: 3339. (one
     that calls a base type’s *note tp_new: 3339. or *note __new__():
     484.), you must `not' try to determine what method to call using
     method resolution order at runtime.  Always statically determine
     what type you are going to call, and call its *note tp_new: 3339.
     directly, or via ‘type->tp_base->tp_new’.  If you do not do this,
     Python subclasses of your type that also inherit from other
     Python-defined classes may not work correctly.  (Specifically, you
     may not be able to create instances of such subclasses without
     getting a *note TypeError: 562.)

We provide an initialization function:

     static int
     Noddy_init(Noddy *self, PyObject *args, PyObject *kwds)
     {
         PyObject *first=NULL, *last=NULL, *tmp;

         static char *kwlist[] = {"first", "last", "number", NULL};

         if (! PyArg_ParseTupleAndKeywords(args, kwds, "|OOi", kwlist,
                                           &first, &last,
                                           &self->number))
             return -1;

         if (first) {
             tmp = self->first;
             Py_INCREF(first);
             self->first = first;
             Py_XDECREF(tmp);
         }

         if (last) {
             tmp = self->last;
             Py_INCREF(last);
             self->last = last;
             Py_XDECREF(tmp);
         }

         return 0;
     }

by filling the *note tp_init: 333f. slot.

     (initproc)Noddy_init,         /* tp_init */

The *note tp_init: 333f. slot is exposed in Python as the *note
__init__(): 9d5. method.  It is used to initialize an object after it’s
created.  Unlike the new method, we can’t guarantee that the initializer
is called.  The initializer isn’t called when unpickling objects and it
can be overridden.  Our initializer accepts arguments to provide initial
values for our instance.  Initializers always accept positional and
keyword arguments.  Initializers should return either 0 on success or -1
on error.

Initializers can be called multiple times.  Anyone can call the *note
__init__(): 9d5. method on our objects.  For this reason, we have to be
extra careful when assigning the new values.  We might be tempted, for
example to assign the ‘first’ member like this:

     if (first) {
         Py_XDECREF(self->first);
         Py_INCREF(first);
         self->first = first;
     }

But this would be risky.  Our type doesn’t restrict the type of the
‘first’ member, so it could be any kind of object.  It could have a
destructor that causes code to be executed that tries to access the
‘first’ member.  To be paranoid and protect ourselves against this
possibility, we almost always reassign members before decrementing their
reference counts.  When don’t we have to do this?

   * when we absolutely know that the reference count is greater than 1

   * when we know that deallocation of the object (1) will not cause any
     calls back into our type’s code

   * when decrementing a reference count in a *note tp_dealloc: 333c.
     handler when garbage-collections is not supported (2)

We want to expose our instance variables as attributes.  There are a
number of ways to do that.  The simplest way is to define member
definitions:

     static PyMemberDef Noddy_members[] = {
         {"first", T_OBJECT_EX, offsetof(Noddy, first), 0,
          "first name"},
         {"last", T_OBJECT_EX, offsetof(Noddy, last), 0,
          "last name"},
         {"number", T_INT, offsetof(Noddy, number), 0,
          "noddy number"},
         {NULL}  /* Sentinel */
     };

and put the definitions in the *note tp_members: 3340. slot:

     Noddy_members,             /* tp_members */

Each member definition has a member name, type, offset, access flags and
documentation string.  See the *note Generic Attribute Management: 3341.
section below for details.

A disadvantage of this approach is that it doesn’t provide a way to
restrict the types of objects that can be assigned to the Python
attributes.  We expect the first and last names to be strings, but any
Python objects can be assigned.  Further, the attributes can be deleted,
setting the C pointers to `NULL'. Even though we can make sure the
members are initialized to non-`NULL' values, the members can be set to
`NULL' if the attributes are deleted.

We define a single method, ‘name()’, that outputs the objects name as
the concatenation of the first and last names.

     static PyObject *
     Noddy_name(Noddy* self)
     {
         if (self->first == NULL) {
             PyErr_SetString(PyExc_AttributeError, "first");
             return NULL;
         }

         if (self->last == NULL) {
             PyErr_SetString(PyExc_AttributeError, "last");
             return NULL;
         }

         return PyUnicode_FromFormat("%S %S", self->first, self->last);
     }

The method is implemented as a C function that takes a ‘Noddy’ (or
‘Noddy’ subclass) instance as the first argument.  Methods always take
an instance as the first argument.  Methods often take positional and
keyword arguments as well, but in this case we don’t take any and don’t
need to accept a positional argument tuple or keyword argument
dictionary.  This method is equivalent to the Python method:

     def name(self):
        return "%s %s" % (self.first, self.last)

Note that we have to check for the possibility that our ‘first’ and
‘last’ members are `NULL'. This is because they can be deleted, in which
case they are set to `NULL'. It would be better to prevent deletion of
these attributes and to restrict the attribute values to be strings.
We’ll see how to do that in the next section.

Now that we’ve defined the method, we need to create an array of method
definitions:

     static PyMethodDef Noddy_methods[] = {
         {"name", (PyCFunction)Noddy_name, METH_NOARGS,
          "Return the name, combining the first and last name"
         },
         {NULL}  /* Sentinel */
     };

and assign them to the *note tp_methods: 3342. slot:

     Noddy_methods,             /* tp_methods */

Note that we used the *note METH_NOARGS: a9a. flag to indicate that the
method is passed no arguments.

Finally, we’ll make our type usable as a base class.  We’ve written our
methods carefully so far so that they don’t make any assumptions about
the type of the object being created or used, so all we need to do is to
add the *note Py_TPFLAGS_BASETYPE: 3343. to our class flag definition:

     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE, /*tp_flags*/

We rename ‘PyInit_noddy()’ to ‘PyInit_noddy2()’ and update the module
name in the *note PyModuleDef: 3344. struct.

Finally, we update our ‘setup.py’ file to build the new module:

     from distutils.core import setup, Extension
     setup(name="noddy", version="1.0",
           ext_modules=[
              Extension("noddy", ["noddy.c"]),
              Extension("noddy2", ["noddy2.c"]),
              ])

   ---------- Footnotes ----------

   (1) This is true when we know that the object is a basic type, like a
string or a float.

   (2) We relied on this in the *note tp_dealloc: 333c. handler in this
example, because our type doesn’t support garbage collection.  Even if a
type supports garbage collection, there are calls that can be made to
"untrack" the object from garbage collection, however, these calls are
advanced and not covered here.


File: python.info,  Node: Providing finer control over data attributes,  Next: Supporting cyclic garbage collection,  Prev: Adding data and methods to the Basic example,  Up: The Basics

6.2.2.3 Providing finer control over data attributes
....................................................

In this section, we’ll provide finer control over how the ‘first’ and
‘last’ attributes are set in the ‘Noddy’ example.  In the previous
version of our module, the instance variables ‘first’ and ‘last’ could
be set to non-string values or even deleted.  We want to make sure that
these attributes always contain strings.

     #include <Python.h>
     #include "structmember.h"

     typedef struct {
         PyObject_HEAD
         PyObject *first;
         PyObject *last;
         int number;
     } Noddy;

     static void
     Noddy_dealloc(Noddy* self)
     {
         Py_XDECREF(self->first);
         Py_XDECREF(self->last);
         Py_TYPE(self)->tp_free((PyObject*)self);
     }

     static PyObject *
     Noddy_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
     {
         Noddy *self;

         self = (Noddy *)type->tp_alloc(type, 0);
         if (self != NULL) {
             self->first = PyUnicode_FromString("");
             if (self->first == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->last = PyUnicode_FromString("");
             if (self->last == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->number = 0;
         }

         return (PyObject *)self;
     }

     static int
     Noddy_init(Noddy *self, PyObject *args, PyObject *kwds)
     {
         PyObject *first=NULL, *last=NULL, *tmp;

         static char *kwlist[] = {"first", "last", "number", NULL};

         if (! PyArg_ParseTupleAndKeywords(args, kwds, "|SSi", kwlist,
                                           &first, &last,
                                           &self->number))
             return -1;

         if (first) {
             tmp = self->first;
             Py_INCREF(first);
             self->first = first;
             Py_DECREF(tmp);
         }

         if (last) {
             tmp = self->last;
             Py_INCREF(last);
             self->last = last;
             Py_DECREF(tmp);
         }

         return 0;
     }

     static PyMemberDef Noddy_members[] = {
         {"number", T_INT, offsetof(Noddy, number), 0,
          "noddy number"},
         {NULL}  /* Sentinel */
     };

     static PyObject *
     Noddy_getfirst(Noddy *self, void *closure)
     {
         Py_INCREF(self->first);
         return self->first;
     }

     static int
     Noddy_setfirst(Noddy *self, PyObject *value, void *closure)
     {
         if (value == NULL) {
             PyErr_SetString(PyExc_TypeError, "Cannot delete the first attribute");
             return -1;
         }

         if (! PyUnicode_Check(value)) {
             PyErr_SetString(PyExc_TypeError,
                             "The first attribute value must be a string");
             return -1;
         }

         Py_DECREF(self->first);
         Py_INCREF(value);
         self->first = value;

         return 0;
     }

     static PyObject *
     Noddy_getlast(Noddy *self, void *closure)
     {
         Py_INCREF(self->last);
         return self->last;
     }

     static int
     Noddy_setlast(Noddy *self, PyObject *value, void *closure)
     {
         if (value == NULL) {
             PyErr_SetString(PyExc_TypeError, "Cannot delete the last attribute");
             return -1;
         }

         if (! PyUnicode_Check(value)) {
             PyErr_SetString(PyExc_TypeError,
                             "The last attribute value must be a string");
             return -1;
         }

         Py_DECREF(self->last);
         Py_INCREF(value);
         self->last = value;

         return 0;
     }

     static PyGetSetDef Noddy_getseters[] = {
         {"first",
          (getter)Noddy_getfirst, (setter)Noddy_setfirst,
          "first name",
          NULL},
         {"last",
          (getter)Noddy_getlast, (setter)Noddy_setlast,
          "last name",
          NULL},
         {NULL}  /* Sentinel */
     };

     static PyObject *
     Noddy_name(Noddy* self)
     {
         return PyUnicode_FromFormat("%S %S", self->first, self->last);
     }

     static PyMethodDef Noddy_methods[] = {
         {"name", (PyCFunction)Noddy_name, METH_NOARGS,
          "Return the name, combining the first and last name"
         },
         {NULL}  /* Sentinel */
     };

     static PyTypeObject NoddyType = {
         PyVarObject_HEAD_INIT(NULL, 0)
         "noddy.Noddy",             /* tp_name */
         sizeof(Noddy),             /* tp_basicsize */
         0,                         /* tp_itemsize */
         (destructor)Noddy_dealloc, /* tp_dealloc */
         0,                         /* tp_print */
         0,                         /* tp_getattr */
         0,                         /* tp_setattr */
         0,                         /* tp_reserved */
         0,                         /* tp_repr */
         0,                         /* tp_as_number */
         0,                         /* tp_as_sequence */
         0,                         /* tp_as_mapping */
         0,                         /* tp_hash  */
         0,                         /* tp_call */
         0,                         /* tp_str */
         0,                         /* tp_getattro */
         0,                         /* tp_setattro */
         0,                         /* tp_as_buffer */
         Py_TPFLAGS_DEFAULT |
             Py_TPFLAGS_BASETYPE,   /* tp_flags */
         "Noddy objects",           /* tp_doc */
         0,                         /* tp_traverse */
         0,                         /* tp_clear */
         0,                         /* tp_richcompare */
         0,                         /* tp_weaklistoffset */
         0,                         /* tp_iter */
         0,                         /* tp_iternext */
         Noddy_methods,             /* tp_methods */
         Noddy_members,             /* tp_members */
         Noddy_getseters,           /* tp_getset */
         0,                         /* tp_base */
         0,                         /* tp_dict */
         0,                         /* tp_descr_get */
         0,                         /* tp_descr_set */
         0,                         /* tp_dictoffset */
         (initproc)Noddy_init,      /* tp_init */
         0,                         /* tp_alloc */
         Noddy_new,                 /* tp_new */
     };

     static PyModuleDef noddy3module = {
         PyModuleDef_HEAD_INIT,
         "noddy3",
         "Example module that creates an extension type.",
         -1,
         NULL, NULL, NULL, NULL, NULL
     };

     PyMODINIT_FUNC
     PyInit_noddy3(void)
     {
         PyObject* m;

         if (PyType_Ready(&NoddyType) < 0)
             return NULL;

         m = PyModule_Create(&noddy3module);
         if (m == NULL)
             return NULL;

         Py_INCREF(&NoddyType);
         PyModule_AddObject(m, "Noddy", (PyObject *)&NoddyType);
         return m;
     }

To provide greater control, over the ‘first’ and ‘last’ attributes,
we’ll use custom getter and setter functions.  Here are the functions
for getting and setting the ‘first’ attribute:

     Noddy_getfirst(Noddy *self, void *closure)
     {
         Py_INCREF(self->first);
         return self->first;
     }

     static int
     Noddy_setfirst(Noddy *self, PyObject *value, void *closure)
     {
       if (value == NULL) {
         PyErr_SetString(PyExc_TypeError, "Cannot delete the first attribute");
         return -1;
       }

       if (! PyUnicode_Check(value)) {
         PyErr_SetString(PyExc_TypeError,
                         "The first attribute value must be a str");
         return -1;
       }

       Py_DECREF(self->first);
       Py_INCREF(value);
       self->first = value;

       return 0;
     }

The getter function is passed a ‘Noddy’ object and a "closure", which is
void pointer.  In this case, the closure is ignored.  (The closure
supports an advanced usage in which definition data is passed to the
getter and setter.  This could, for example, be used to allow a single
set of getter and setter functions that decide the attribute to get or
set based on data in the closure.)

The setter function is passed the ‘Noddy’ object, the new value, and the
closure.  The new value may be `NULL', in which case the attribute is
being deleted.  In our setter, we raise an error if the attribute is
deleted or if the attribute value is not a string.

We create an array of ‘PyGetSetDef’ structures:

     static PyGetSetDef Noddy_getseters[] = {
         {"first",
          (getter)Noddy_getfirst, (setter)Noddy_setfirst,
          "first name",
          NULL},
         {"last",
          (getter)Noddy_getlast, (setter)Noddy_setlast,
          "last name",
          NULL},
         {NULL}  /* Sentinel */
     };

and register it in the *note tp_getset: 3346. slot:

     Noddy_getseters,           /* tp_getset */

to register our attribute getters and setters.

The last item in a ‘PyGetSetDef’ structure is the closure mentioned
above.  In this case, we aren’t using the closure, so we just pass
`NULL'.

We also remove the member definitions for these attributes:

     static PyMemberDef Noddy_members[] = {
         {"number", T_INT, offsetof(Noddy, number), 0,
          "noddy number"},
         {NULL}  /* Sentinel */
     };

We also need to update the *note tp_init: 333f. handler to only allow
strings (1) to be passed:

     static int
     Noddy_init(Noddy *self, PyObject *args, PyObject *kwds)
     {
         PyObject *first=NULL, *last=NULL, *tmp;

         static char *kwlist[] = {"first", "last", "number", NULL};

         if (! PyArg_ParseTupleAndKeywords(args, kwds, "|SSi", kwlist,
                                           &first, &last,
                                           &self->number))
             return -1;

         if (first) {
             tmp = self->first;
             Py_INCREF(first);
             self->first = first;
             Py_DECREF(tmp);
         }

         if (last) {
             tmp = self->last;
             Py_INCREF(last);
             self->last = last;
             Py_DECREF(tmp);
         }

         return 0;
     }

With these changes, we can assure that the ‘first’ and ‘last’ members
are never `NULL' so we can remove checks for `NULL' values in almost all
cases.  This means that most of the *note Py_XDECREF(): 32fc. calls can
be converted to *note Py_DECREF(): 32fd. calls.  The only place we can’t
change these calls is in the deallocator, where there is the possibility
that the initialization of these members failed in the constructor.

We also rename the module initialization function and module name in the
initialization function, as we did before, and we add an extra
definition to the ‘setup.py’ file.

   ---------- Footnotes ----------

   (1) We now know that the first and last members are strings, so
perhaps we could be less careful about decrementing their reference
counts, however, we accept instances of string subclasses.  Even though
deallocating normal strings won’t call back into our objects, we can’t
guarantee that deallocating an instance of a string subclass won’t call
back into our objects.


File: python.info,  Node: Supporting cyclic garbage collection,  Next: Subclassing other types,  Prev: Providing finer control over data attributes,  Up: The Basics

6.2.2.4 Supporting cyclic garbage collection
............................................

Python has a cyclic-garbage collector that can identify unneeded objects
even when their reference counts are not zero.  This can happen when
objects are involved in cycles.  For example, consider:

     >>> l = []
     >>> l.append(l)
     >>> del l

In this example, we create a list that contains itself.  When we delete
it, it still has a reference from itself.  Its reference count doesn’t
drop to zero.  Fortunately, Python’s cyclic-garbage collector will
eventually figure out that the list is garbage and free it.

In the second version of the ‘Noddy’ example, we allowed any kind of
object to be stored in the ‘first’ or ‘last’ attributes.  (1) This means
that ‘Noddy’ objects can participate in cycles:

     >>> import noddy2
     >>> n = noddy2.Noddy()
     >>> l = [n]
     >>> n.first = l

This is pretty silly, but it gives us an excuse to add support for the
cyclic-garbage collector to the ‘Noddy’ example.  To support cyclic
garbage collection, types need to fill two slots and set a class flag
that enables these slots:

     #include <Python.h>
     #include "structmember.h"

     typedef struct {
         PyObject_HEAD
         PyObject *first;
         PyObject *last;
         int number;
     } Noddy;

     static int
     Noddy_traverse(Noddy *self, visitproc visit, void *arg)
     {
         int vret;

         if (self->first) {
             vret = visit(self->first, arg);
             if (vret != 0)
                 return vret;
         }
         if (self->last) {
             vret = visit(self->last, arg);
             if (vret != 0)
                 return vret;
         }

         return 0;
     }

     static int
     Noddy_clear(Noddy *self)
     {
         PyObject *tmp;

         tmp = self->first;
         self->first = NULL;
         Py_XDECREF(tmp);

         tmp = self->last;
         self->last = NULL;
         Py_XDECREF(tmp);

         return 0;
     }

     static void
     Noddy_dealloc(Noddy* self)
     {
         Noddy_clear(self);
         Py_TYPE(self)->tp_free((PyObject*)self);
     }

     static PyObject *
     Noddy_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
     {
         Noddy *self;

         self = (Noddy *)type->tp_alloc(type, 0);
         if (self != NULL) {
             self->first = PyUnicode_FromString("");
             if (self->first == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->last = PyUnicode_FromString("");
             if (self->last == NULL) {
                 Py_DECREF(self);
                 return NULL;
             }

             self->number = 0;
         }

         return (PyObject *)self;
     }

     static int
     Noddy_init(Noddy *self, PyObject *args, PyObject *kwds)
     {
         PyObject *first=NULL, *last=NULL, *tmp;

         static char *kwlist[] = {"first", "last", "number", NULL};

         if (! PyArg_ParseTupleAndKeywords(args, kwds, "|OOi", kwlist,
                                           &first, &last,
                                           &self->number))
             return -1;

         if (first) {
             tmp = self->first;
             Py_INCREF(first);
             self->first = first;
             Py_XDECREF(tmp);
         }

         if (last) {
             tmp = self->last;
             Py_INCREF(last);
             self->last = last;
             Py_XDECREF(tmp);
         }

         return 0;
     }


     static PyMemberDef Noddy_members[] = {
         {"first", T_OBJECT_EX, offsetof(Noddy, first), 0,
          "first name"},
         {"last", T_OBJECT_EX, offsetof(Noddy, last), 0,
          "last name"},
         {"number", T_INT, offsetof(Noddy, number), 0,
          "noddy number"},
         {NULL}  /* Sentinel */
     };

     static PyObject *
     Noddy_name(Noddy* self)
     {
         if (self->first == NULL) {
             PyErr_SetString(PyExc_AttributeError, "first");
             return NULL;
         }

         if (self->last == NULL) {
             PyErr_SetString(PyExc_AttributeError, "last");
             return NULL;
         }

         return PyUnicode_FromFormat("%S %S", self->first, self->last);
     }

     static PyMethodDef Noddy_methods[] = {
         {"name", (PyCFunction)Noddy_name, METH_NOARGS,
          "Return the name, combining the first and last name"
         },
         {NULL}  /* Sentinel */
     };

     static PyTypeObject NoddyType = {
         PyVarObject_HEAD_INIT(NULL, 0)
         "noddy.Noddy",             /* tp_name */
         sizeof(Noddy),             /* tp_basicsize */
         0,                         /* tp_itemsize */
         (destructor)Noddy_dealloc, /* tp_dealloc */
         0,                         /* tp_print */
         0,                         /* tp_getattr */
         0,                         /* tp_setattr */
         0,                         /* tp_reserved */
         0,                         /* tp_repr */
         0,                         /* tp_as_number */
         0,                         /* tp_as_sequence */
         0,                         /* tp_as_mapping */
         0,                         /* tp_hash  */
         0,                         /* tp_call */
         0,                         /* tp_str */
         0,                         /* tp_getattro */
         0,                         /* tp_setattro */
         0,                         /* tp_as_buffer */
         Py_TPFLAGS_DEFAULT |
             Py_TPFLAGS_BASETYPE |
             Py_TPFLAGS_HAVE_GC,    /* tp_flags */
         "Noddy objects",           /* tp_doc */
         (traverseproc)Noddy_traverse,   /* tp_traverse */
         (inquiry)Noddy_clear,           /* tp_clear */
         0,                         /* tp_richcompare */
         0,                         /* tp_weaklistoffset */
         0,                         /* tp_iter */
         0,                         /* tp_iternext */
         Noddy_methods,             /* tp_methods */
         Noddy_members,             /* tp_members */
         0,                         /* tp_getset */
         0,                         /* tp_base */
         0,                         /* tp_dict */
         0,                         /* tp_descr_get */
         0,                         /* tp_descr_set */
         0,                         /* tp_dictoffset */
         (initproc)Noddy_init,      /* tp_init */
         0,                         /* tp_alloc */
         Noddy_new,                 /* tp_new */
     };

     static PyModuleDef noddy4module = {
         PyModuleDef_HEAD_INIT,
         "noddy4",
         "Example module that creates an extension type.",
         -1,
         NULL, NULL, NULL, NULL, NULL
     };

     PyMODINIT_FUNC
     PyInit_noddy4(void)
     {
         PyObject* m;

         if (PyType_Ready(&NoddyType) < 0)
             return NULL;

         m = PyModule_Create(&noddy4module);
         if (m == NULL)
             return NULL;

         Py_INCREF(&NoddyType);
         PyModule_AddObject(m, "Noddy", (PyObject *)&NoddyType);
         return m;
     }

The traversal method provides access to subobjects that could
participate in cycles:

     static int
     Noddy_traverse(Noddy *self, visitproc visit, void *arg)
     {
         int vret;

         if (self->first) {
             vret = visit(self->first, arg);
             if (vret != 0)
                 return vret;
         }
         if (self->last) {
             vret = visit(self->last, arg);
             if (vret != 0)
                 return vret;
         }

         return 0;
     }

For each subobject that can participate in cycles, we need to call the
‘visit()’ function, which is passed to the traversal method.  The
‘visit()’ function takes as arguments the subobject and the extra
argument `arg' passed to the traversal method.  It returns an integer
value that must be returned if it is non-zero.

Python provides a *note Py_VISIT(): 3348. macro that automates calling
visit functions.  With *note Py_VISIT(): 3348, ‘Noddy_traverse()’ can be
simplified:

     static int
     Noddy_traverse(Noddy *self, visitproc visit, void *arg)
     {
         Py_VISIT(self->first);
         Py_VISIT(self->last);
         return 0;
     }

     Note: Note that the *note tp_traverse: 2ea9. implementation must
     name its arguments exactly `visit' and `arg' in order to use *note
     Py_VISIT(): 3348.  This is to encourage uniformity across these
     boring implementations.

We also need to provide a method for clearing any subobjects that can
participate in cycles.  We implement the method and reimplement the
deallocator to use it:

     static int
     Noddy_clear(Noddy *self)
     {
         PyObject *tmp;

         tmp = self->first;
         self->first = NULL;
         Py_XDECREF(tmp);

         tmp = self->last;
         self->last = NULL;
         Py_XDECREF(tmp);

         return 0;
     }

     static void
     Noddy_dealloc(Noddy* self)
     {
         Noddy_clear(self);
         Py_TYPE(self)->tp_free((PyObject*)self);
     }

Notice the use of a temporary variable in ‘Noddy_clear()’.  We use the
temporary variable so that we can set each member to `NULL' before
decrementing its reference count.  We do this because, as was discussed
earlier, if the reference count drops to zero, we might cause code to
run that calls back into the object.  In addition, because we now
support garbage collection, we also have to worry about code being run
that triggers garbage collection.  If garbage collection is run, our
*note tp_traverse: 2ea9. handler could get called.  We can’t take a
chance of having ‘Noddy_traverse()’ called when a member’s reference
count has dropped to zero and its value hasn’t been set to `NULL'.

Python provides a *note Py_CLEAR(): 3349. that automates the careful
decrementing of reference counts.  With *note Py_CLEAR(): 3349, the
‘Noddy_clear()’ function can be simplified:

     static int
     Noddy_clear(Noddy *self)
     {
         Py_CLEAR(self->first);
         Py_CLEAR(self->last);
         return 0;
     }

Finally, we add the *note Py_TPFLAGS_HAVE_GC: 334a. flag to the class
flags:

     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HAVE_GC, /* tp_flags */

That’s pretty much it.  If we had written custom *note tp_alloc: 333e.
or *note tp_free: 333d. slots, we’d need to modify them for
cyclic-garbage collection.  Most extensions will use the versions
automatically provided.

   ---------- Footnotes ----------

   (1) Even in the third version, we aren’t guaranteed to avoid cycles.
Instances of string subclasses are allowed and string subclasses could
allow cycles even if normal strings don’t.


File: python.info,  Node: Subclassing other types,  Prev: Supporting cyclic garbage collection,  Up: The Basics

6.2.2.5 Subclassing other types
...............................

It is possible to create new extension types that are derived from
existing types.  It is easiest to inherit from the built in types, since
an extension can easily use the ‘PyTypeObject’ it needs.  It can be
difficult to share these ‘PyTypeObject’ structures between extension
modules.

In this example we will create a ‘Shoddy’ type that inherits from the
built-in *note list: 25d. type.  The new type will be completely
compatible with regular lists, but will have an additional ‘increment()’
method that increases an internal counter.

     >>> import shoddy
     >>> s = shoddy.Shoddy(range(3))
     >>> s.extend(s)
     >>> print(len(s))
     6
     >>> print(s.increment())
     1
     >>> print(s.increment())
     2

     #include <Python.h>

     typedef struct {
         PyListObject list;
         int state;
     } Shoddy;


     static PyObject *
     Shoddy_increment(Shoddy *self, PyObject *unused)
     {
         self->state++;
         return PyLong_FromLong(self->state);
     }


     static PyMethodDef Shoddy_methods[] = {
         {"increment", (PyCFunction)Shoddy_increment, METH_NOARGS,
          PyDoc_STR("increment state counter")},
         {NULL,	NULL},
     };

     static int
     Shoddy_init(Shoddy *self, PyObject *args, PyObject *kwds)
     {
         if (PyList_Type.tp_init((PyObject *)self, args, kwds) < 0)
             return -1;
         self->state = 0;
         return 0;
     }


     static PyTypeObject ShoddyType = {
         PyObject_HEAD_INIT(NULL)
         "shoddy.Shoddy",         /* tp_name */
         sizeof(Shoddy),          /* tp_basicsize */
         0,                       /* tp_itemsize */
         0,                       /* tp_dealloc */
         0,                       /* tp_print */
         0,                       /* tp_getattr */
         0,                       /* tp_setattr */
         0,                       /* tp_reserved */
         0,                       /* tp_repr */
         0,                       /* tp_as_number */
         0,                       /* tp_as_sequence */
         0,                       /* tp_as_mapping */
         0,                       /* tp_hash */
         0,                       /* tp_call */
         0,                       /* tp_str */
         0,                       /* tp_getattro */
         0,                       /* tp_setattro */
         0,                       /* tp_as_buffer */
         Py_TPFLAGS_DEFAULT |
             Py_TPFLAGS_BASETYPE, /* tp_flags */
         0,                       /* tp_doc */
         0,                       /* tp_traverse */
         0,                       /* tp_clear */
         0,                       /* tp_richcompare */
         0,                       /* tp_weaklistoffset */
         0,                       /* tp_iter */
         0,                       /* tp_iternext */
         Shoddy_methods,          /* tp_methods */
         0,                       /* tp_members */
         0,                       /* tp_getset */
         0,                       /* tp_base */
         0,                       /* tp_dict */
         0,                       /* tp_descr_get */
         0,                       /* tp_descr_set */
         0,                       /* tp_dictoffset */
         (initproc)Shoddy_init,   /* tp_init */
         0,                       /* tp_alloc */
         0,                       /* tp_new */
     };

     static PyModuleDef shoddymodule = {
         PyModuleDef_HEAD_INIT,
         "shoddy",
         "Shoddy module",
         -1,
         NULL, NULL, NULL, NULL, NULL
     };

     PyMODINIT_FUNC
     PyInit_shoddy(void)
     {
         PyObject *m;

         ShoddyType.tp_base = &PyList_Type;
         if (PyType_Ready(&ShoddyType) < 0)
             return NULL;

         m = PyModule_Create(&shoddymodule);
         if (m == NULL)
             return NULL;

         Py_INCREF(&ShoddyType);
         PyModule_AddObject(m, "Shoddy", (PyObject *) &ShoddyType);
         return m;
     }

As you can see, the source code closely resembles the ‘Noddy’ examples
in previous sections.  We will break down the main differences between
them.

     typedef struct {
         PyListObject list;
         int state;
     } Shoddy;

The primary difference for derived type objects is that the base type’s
object structure must be the first value.  The base type will already
include the *note PyObject_HEAD(): 8de. at the beginning of its
structure.

When a Python object is a ‘Shoddy’ instance, its `PyObject*' pointer can
be safely cast to both `PyListObject*' and `Shoddy*'.

     static int
     Shoddy_init(Shoddy *self, PyObject *args, PyObject *kwds)
     {
         if (PyList_Type.tp_init((PyObject *)self, args, kwds) < 0)
            return -1;
         self->state = 0;
         return 0;
     }

In the ‘__init__’ method for our type, we can see how to call through to
the ‘__init__’ method of the base type.

This pattern is important when writing a type with custom ‘new’ and
‘dealloc’ methods.  The ‘new’ method should not actually create the
memory for the object with *note tp_alloc: 333e, that will be handled by
the base class when calling its *note tp_new: 3339.

When filling out the *note PyTypeObject(): 3bc. for the ‘Shoddy’ type,
you see a slot for ‘tp_base()’.  Due to cross platform compiler issues,
you can’t fill that field directly with the *note PyList_Type(): 334c.;
it can be done later in the module’s ‘init()’ function.

     PyMODINIT_FUNC
     PyInit_shoddy(void)
     {
         PyObject *m;

         ShoddyType.tp_base = &PyList_Type;
         if (PyType_Ready(&ShoddyType) < 0)
             return NULL;

         m = PyModule_Create(&shoddymodule);
         if (m == NULL)
             return NULL;

         Py_INCREF(&ShoddyType);
         PyModule_AddObject(m, "Shoddy", (PyObject *) &ShoddyType);
         return m;
     }

Before calling *note PyType_Ready(): 3335, the type structure must have
the *note tp_base: 334d. slot filled in.  When we are deriving a new
type, it is not necessary to fill out the *note tp_alloc: 333e. slot
with *note PyType_GenericNew(): 333a. – the allocate function from the
base type will be inherited.

After that, calling *note PyType_Ready(): 3335. and adding the type
object to the module is the same as with the basic ‘Noddy’ examples.


File: python.info,  Node: Type Methods,  Prev: The Basics,  Up: Defining New Types

6.2.2.6 Type Methods
....................

This section aims to give a quick fly-by on the various type methods you
can implement and what they do.

Here is the definition of *note PyTypeObject: 3bc, with some fields only
used in debug builds omitted:

     typedef struct _typeobject {
         PyObject_VAR_HEAD
         const char *tp_name; /* For printing, in format "<module>.<name>" */
         Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */

         /* Methods to implement standard operations */

         destructor tp_dealloc;
         printfunc tp_print;
         getattrfunc tp_getattr;
         setattrfunc tp_setattr;
         PyAsyncMethods *tp_as_async; /* formerly known as tp_compare (Python 2)
                                         or tp_reserved (Python 3) */
         reprfunc tp_repr;

         /* Method suites for standard classes */

         PyNumberMethods *tp_as_number;
         PySequenceMethods *tp_as_sequence;
         PyMappingMethods *tp_as_mapping;

         /* More standard operations (here for binary compatibility) */

         hashfunc tp_hash;
         ternaryfunc tp_call;
         reprfunc tp_str;
         getattrofunc tp_getattro;
         setattrofunc tp_setattro;

         /* Functions to access object as input/output buffer */
         PyBufferProcs *tp_as_buffer;

         /* Flags to define presence of optional/expanded features */
         unsigned long tp_flags;

         const char *tp_doc; /* Documentation string */

         /* call function for all accessible objects */
         traverseproc tp_traverse;

         /* delete references to contained objects */
         inquiry tp_clear;

         /* rich comparisons */
         richcmpfunc tp_richcompare;

         /* weak reference enabler */
         Py_ssize_t tp_weaklistoffset;

         /* Iterators */
         getiterfunc tp_iter;
         iternextfunc tp_iternext;

         /* Attribute descriptor and subclassing stuff */
         struct PyMethodDef *tp_methods;
         struct PyMemberDef *tp_members;
         struct PyGetSetDef *tp_getset;
         struct _typeobject *tp_base;
         PyObject *tp_dict;
         descrgetfunc tp_descr_get;
         descrsetfunc tp_descr_set;
         Py_ssize_t tp_dictoffset;
         initproc tp_init;
         allocfunc tp_alloc;
         newfunc tp_new;
         freefunc tp_free; /* Low-level free-memory routine */
         inquiry tp_is_gc; /* For PyObject_IS_GC */
         PyObject *tp_bases;
         PyObject *tp_mro; /* method resolution order */
         PyObject *tp_cache;
         PyObject *tp_subclasses;
         PyObject *tp_weaklist;
         destructor tp_del;

         /* Type attribute cache version tag. Added in version 2.6 */
         unsigned int tp_version_tag;

         destructor tp_finalize;

     } PyTypeObject;

Now that’s a `lot' of methods.  Don’t worry too much though - if you
have a type you want to define, the chances are very good that you will
only implement a handful of these.

As you probably expect by now, we’re going to go over this and give more
information about the various handlers.  We won’t go in the order they
are defined in the structure, because there is a lot of historical
baggage that impacts the ordering of the fields; be sure your type
initialization keeps the fields in the right order!  It’s often easiest
to find an example that includes all the fields you need (even if
they’re initialized to ‘0’) and then change the values to suit your new
type.

     const char *tp_name; /* For printing */

The name of the type - as mentioned in the last section, this will
appear in various places, almost entirely for diagnostic purposes.  Try
to choose something that will be helpful in such a situation!

     Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */

These fields tell the runtime how much memory to allocate when new
objects of this type are created.  Python has some built-in support for
variable length structures (think: strings, lists) which is where the
*note tp_itemsize: 3350. field comes in.  This will be dealt with later.

     const char *tp_doc;

Here you can put a string (or its address) that you want returned when
the Python script references ‘obj.__doc__’ to retrieve the doc string.

Now we come to the basic type methods—the ones most extension types will
implement.

* Menu:

* Finalization and De-allocation:: 
* Object Presentation:: 
* Attribute Management:: 
* Object Comparison:: 
* Abstract Protocol Support:: 
* Weak Reference Support:: 
* More Suggestions:: 


File: python.info,  Node: Finalization and De-allocation,  Next: Object Presentation,  Up: Type Methods

6.2.2.7 Finalization and De-allocation
......................................

     destructor tp_dealloc;

This function is called when the reference count of the instance of your
type is reduced to zero and the Python interpreter wants to reclaim it.
If your type has memory to free or other clean-up to perform, you can
put it here.  The object itself needs to be freed here as well.  Here is
an example of this function:

     static void
     newdatatype_dealloc(newdatatypeobject * obj)
     {
         free(obj->obj_UnderlyingDatatypePtr);
         Py_TYPE(obj)->tp_free(obj);
     }

One important requirement of the deallocator function is that it leaves
any pending exceptions alone.  This is important since deallocators are
frequently called as the interpreter unwinds the Python stack; when the
stack is unwound due to an exception (rather than normal returns),
nothing is done to protect the deallocators from seeing that an
exception has already been set.  Any actions which a deallocator
performs which may cause additional Python code to be executed may
detect that an exception has been set.  This can lead to misleading
errors from the interpreter.  The proper way to protect against this is
to save a pending exception before performing the unsafe action, and
restoring it when done.  This can be done using the *note PyErr_Fetch():
587. and *note PyErr_Restore(): 3352. functions:

     static void
     my_dealloc(PyObject *obj)
     {
         MyObject *self = (MyObject *) obj;
         PyObject *cbresult;

         if (self->my_callback != NULL) {
             PyObject *err_type, *err_value, *err_traceback;

             /* This saves the current exception state */
             PyErr_Fetch(&err_type, &err_value, &err_traceback);

             cbresult = PyObject_CallObject(self->my_callback, NULL);
             if (cbresult == NULL)
                 PyErr_WriteUnraisable(self->my_callback);
             else
                 Py_DECREF(cbresult);

             /* This restores the saved exception state */
             PyErr_Restore(err_type, err_value, err_traceback);

             Py_DECREF(self->my_callback);
         }
         Py_TYPE(obj)->tp_free((PyObject*)self);
     }

     Note: There are limitations to what you can safely do in a
     deallocator function.  First, if your type supports garbage
     collection (using *note tp_traverse: 2ea9. and/or *note tp_clear:
     3353.), some of the object’s members can have been cleared or
     finalized by the time *note tp_dealloc: 333c. is called.  Second,
     in *note tp_dealloc: 333c, your object is in an unstable state: its
     reference count is equal to zero.  Any call to a non-trivial object
     or API (as in the example above) might end up calling *note
     tp_dealloc: 333c. again, causing a double free and a crash.

     Starting with Python 3.4, it is recommended not to put any complex
     finalization code in *note tp_dealloc: 333c, and instead use the
     new *note tp_finalize: 38b. type method.

     See also
     ........

     PEP 442(1) explains the new finalization scheme.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0442


File: python.info,  Node: Object Presentation,  Next: Attribute Management,  Prev: Finalization and De-allocation,  Up: Type Methods

6.2.2.8 Object Presentation
...........................

In Python, there are two ways to generate a textual representation of an
object: the *note repr(): 3bb. function, and the *note str(): 25a.
function.  (The *note print(): 481. function just calls *note str():
25a.)  These handlers are both optional.

     reprfunc tp_repr;
     reprfunc tp_str;

The *note tp_repr: 3355. handler should return a string object
containing a representation of the instance for which it is called.
Here is a simple example:

     static PyObject *
     newdatatype_repr(newdatatypeobject * obj)
     {
         return PyUnicode_FromFormat("Repr-ified_newdatatype{{size:\%d}}",
                                     obj->obj_UnderlyingDatatypePtr->size);
     }

If no *note tp_repr: 3355. handler is specified, the interpreter will
supply a representation that uses the type’s *note tp_name: 3356. and a
uniquely-identifying value for the object.

The *note tp_str: 3357. handler is to *note str(): 25a. what the *note
tp_repr: 3355. handler described above is to *note repr(): 3bb.; that
is, it is called when Python code calls *note str(): 25a. on an instance
of your object.  Its implementation is very similar to the *note
tp_repr: 3355. function, but the resulting string is intended for human
consumption.  If *note tp_str: 3357. is not specified, the *note
tp_repr: 3355. handler is used instead.

Here is a simple example:

     static PyObject *
     newdatatype_str(newdatatypeobject * obj)
     {
         return PyUnicode_FromFormat("Stringified_newdatatype{{size:\%d}}",
                                     obj->obj_UnderlyingDatatypePtr->size);
     }


File: python.info,  Node: Attribute Management,  Next: Object Comparison,  Prev: Object Presentation,  Up: Type Methods

6.2.2.9 Attribute Management
............................

For every object which can support attributes, the corresponding type
must provide the functions that control how the attributes are resolved.
There needs to be a function which can retrieve attributes (if any are
defined), and another to set attributes (if setting attributes is
allowed).  Removing an attribute is a special case, for which the new
value passed to the handler is `NULL'.

Python supports two pairs of attribute handlers; a type that supports
attributes only needs to implement the functions for one pair.  The
difference is that one pair takes the name of the attribute as a
‘char*’, while the other accepts a *note PyObject*: 9f5.  Each type can
use whichever pair makes more sense for the implementation’s
convenience.

     getattrfunc  tp_getattr;        /* char * version */
     setattrfunc  tp_setattr;
     /* ... */
     getattrofunc tp_getattro;       /* PyObject * version */
     setattrofunc tp_setattro;

If accessing attributes of an object is always a simple operation (this
will be explained shortly), there are generic implementations which can
be used to provide the *note PyObject*: 9f5. version of the attribute
management functions.  The actual need for type-specific attribute
handlers almost completely disappeared starting with Python 2.2, though
there are many examples which have not been updated to use some of the
new generic mechanism that is available.

* Menu:

* Generic Attribute Management:: 
* Type-specific Attribute Management:: 


File: python.info,  Node: Generic Attribute Management,  Next: Type-specific Attribute Management,  Up: Attribute Management

6.2.2.10 Generic Attribute Management
.....................................

Most extension types only use `simple' attributes.  So, what makes the
attributes simple?  There are only a couple of conditions that must be
met:

  1. The name of the attributes must be known when *note PyType_Ready():
     3335. is called.

  2. No special processing is needed to record that an attribute was
     looked up or set, nor do actions need to be taken based on the
     value.

Note that this list does not place any restrictions on the values of the
attributes, when the values are computed, or how relevant data is
stored.

When *note PyType_Ready(): 3335. is called, it uses three tables
referenced by the type object to create *note descriptor: 14d4.s which
are placed in the dictionary of the type object.  Each descriptor
controls access to one attribute of the instance object.  Each of the
tables is optional; if all three are `NULL', instances of the type will
only have attributes that are inherited from their base type, and should
leave the *note tp_getattro: 335a. and *note tp_setattro: 335b. fields
`NULL' as well, allowing the base type to handle attributes.

The tables are declared as three fields of the type object:

     struct PyMethodDef *tp_methods;
     struct PyMemberDef *tp_members;
     struct PyGetSetDef *tp_getset;

If *note tp_methods: 3342. is not `NULL', it must refer to an array of
*note PyMethodDef: a9d. structures.  Each entry in the table is an
instance of this structure:

     typedef struct PyMethodDef {
         char        *ml_name;       /* method name */
         PyCFunction  ml_meth;       /* implementation function */
         int          ml_flags;      /* flags */
         char        *ml_doc;        /* docstring */
     } PyMethodDef;

One entry should be defined for each method provided by the type; no
entries are needed for methods inherited from a base type.  One
additional entry is needed at the end; it is a sentinel that marks the
end of the array.  The ‘ml_name’ field of the sentinel must be `NULL'.

The second table is used to define attributes which map directly to data
stored in the instance.  A variety of primitive C types are supported,
and access may be read-only or read-write.  The structures in the table
are defined as:

     typedef struct PyMemberDef {
         char *name;
         int   type;
         int   offset;
         int   flags;
         char *doc;
     } PyMemberDef;

For each entry in the table, a *note descriptor: 14d4. will be
constructed and added to the type which will be able to extract a value
from the instance structure.  The *note type: 376. field should contain
one of the type codes defined in the ‘structmember.h’ header; the value
will be used to determine how to convert Python values to and from C
values.  The ‘flags’ field is used to store flags which control how the
attribute can be accessed.

The following flag constants are defined in ‘structmember.h’; they may
be combined using bitwise-OR.

Constant                        Meaning
                                
-----------------------------------------------------------------------------------
                                
‘READONLY’                      Never writable.
                                
                                
‘READ_RESTRICTED’               Not readable in restricted mode.
                                
                                
‘WRITE_RESTRICTED’              Not writable in restricted mode.
                                
                                
‘RESTRICTED’                    Not readable or writable in restricted mode.
                                

An interesting advantage of using the *note tp_members: 3340. table to
build descriptors that are used at runtime is that any attribute defined
this way can have an associated doc string simply by providing the text
in the table.  An application can use the introspection API to retrieve
the descriptor from the class object, and get the doc string using its
‘__doc__’ attribute.

As with the *note tp_methods: 3342. table, a sentinel entry with a
‘name’ value of `NULL' is required.


File: python.info,  Node: Type-specific Attribute Management,  Prev: Generic Attribute Management,  Up: Attribute Management

6.2.2.11 Type-specific Attribute Management
...........................................

For simplicity, only the ‘char*’ version will be demonstrated here; the
type of the name parameter is the only difference between the ‘char*’
and *note PyObject*: 9f5. flavors of the interface.  This example
effectively does the same thing as the generic example above, but does
not use the generic support added in Python 2.2.  It explains how the
handler functions are called, so that if you do need to extend their
functionality, you’ll understand what needs to be done.

The *note tp_getattr: 335d. handler is called when the object requires
an attribute look-up.  It is called in the same situations where the
*note __getattr__(): 782. method of a class would be called.

Here is an example:

     static PyObject *
     newdatatype_getattr(newdatatypeobject *obj, char *name)
     {
         if (strcmp(name, "data") == 0)
         {
             return PyLong_FromLong(obj->data);
         }

         PyErr_Format(PyExc_AttributeError,
                      "'%.50s' object has no attribute '%.400s'",
                      tp->tp_name, name);
         return NULL;
     }

The *note tp_setattr: 335e. handler is called when the *note
__setattr__(): aaf. or *note __delattr__(): df3. method of a class
instance would be called.  When an attribute should be deleted, the
third parameter will be `NULL'. Here is an example that simply raises an
exception; if this were really all you wanted, the *note tp_setattr:
335e. handler should be set to `NULL'.

     static int
     newdatatype_setattr(newdatatypeobject *obj, char *name, PyObject *v)
     {
         (void)PyErr_Format(PyExc_RuntimeError, "Read-only attribute: \%s", name);
         return -1;
     }


File: python.info,  Node: Object Comparison,  Next: Abstract Protocol Support,  Prev: Attribute Management,  Up: Type Methods

6.2.2.12 Object Comparison
..........................

     richcmpfunc tp_richcompare;

The *note tp_richcompare: 3360. handler is called when comparisons are
needed.  It is analogous to the *note rich comparison methods: dfd, like
*note __lt__(): 899, and also called by *note PyObject_RichCompare():
3361. and *note PyObject_RichCompareBool(): 3362.

This function is called with two Python objects and the operator as
arguments, where the operator is one of ‘Py_EQ’, ‘Py_NE’, ‘Py_LE’,
‘Py_GT’, ‘Py_LT’ or ‘Py_GT’.  It should compare the two objects with
respect to the specified operator and return ‘Py_True’ or ‘Py_False’ if
the comparison is successful, ‘Py_NotImplemented’ to indicate that
comparison is not implemented and the other object’s comparison method
should be tried, or `NULL' if an exception was set.

Here is a sample implementation, for a datatype that is considered equal
if the size of an internal pointer is equal:

     static PyObject *
     newdatatype_richcmp(PyObject *obj1, PyObject *obj2, int op)
     {
         PyObject *result;
         int c, size1, size2;

         /* code to make sure that both arguments are of type
            newdatatype omitted */

         size1 = obj1->obj_UnderlyingDatatypePtr->size;
         size2 = obj2->obj_UnderlyingDatatypePtr->size;

         switch (op) {
         case Py_LT: c = size1 <  size2; break;
         case Py_LE: c = size1 <= size2; break;
         case Py_EQ: c = size1 == size2; break;
         case Py_NE: c = size1 != size2; break;
         case Py_GT: c = size1 >  size2; break;
         case Py_GE: c = size1 >= size2; break;
         }
         result = c ? Py_True : Py_False;
         Py_INCREF(result);
         return result;
      }


File: python.info,  Node: Abstract Protocol Support,  Next: Weak Reference Support,  Prev: Object Comparison,  Up: Type Methods

6.2.2.13 Abstract Protocol Support
..................................

Python supports a variety of `abstract' ’protocols;’ the specific
interfaces provided to use these interfaces are documented in *note
Abstract Objects Layer: 3364.

A number of these abstract interfaces were defined early in the
development of the Python implementation.  In particular, the number,
mapping, and sequence protocols have been part of Python since the
beginning.  Other protocols have been added over time.  For protocols
which depend on several handler routines from the type implementation,
the older protocols have been defined as optional blocks of handlers
referenced by the type object.  For newer protocols there are additional
slots in the main type object, with a flag bit being set to indicate
that the slots are present and should be checked by the interpreter.
(The flag bit does not indicate that the slot values are non-`NULL'. The
flag may be set to indicate the presence of a slot, but a slot may still
be unfilled.)

     PyNumberMethods   *tp_as_number;
     PySequenceMethods *tp_as_sequence;
     PyMappingMethods  *tp_as_mapping;

If you wish your object to be able to act like a number, a sequence, or
a mapping object, then you place the address of a structure that
implements the C type *note PyNumberMethods: 9fa, *note
PySequenceMethods: 3365, or *note PyMappingMethods: 3366, respectively.
It is up to you to fill in this structure with appropriate values.  You
can find examples of the use of each of these in the ‘Objects’ directory
of the Python source distribution.

     hashfunc tp_hash;

This function, if you choose to provide it, should return a hash number
for an instance of your data type.  Here is a moderately pointless
example:

     static long
     newdatatype_hash(newdatatypeobject *obj)
     {
         long result;
         result = obj->obj_UnderlyingDatatypePtr->size;
         result = result * 3;
         return result;
     }

     ternaryfunc tp_call;

This function is called when an instance of your data type is "called",
for example, if ‘obj1’ is an instance of your data type and the Python
script contains ‘obj1('hello')’, the *note tp_call: 3367. handler is
invoked.

This function takes three arguments:

  1. `arg1' is the instance of the data type which is the subject of the
     call.  If the call is ‘obj1('hello')’, then `arg1' is ‘obj1’.

  2. `arg2' is a tuple containing the arguments to the call.  You can
     use *note PyArg_ParseTuple(): 724. to extract the arguments.

  3. `arg3' is a dictionary of keyword arguments that were passed.  If
     this is non-`NULL' and you support keyword arguments, use *note
     PyArg_ParseTupleAndKeywords(): a57. to extract the arguments.  If
     you do not want to support keyword arguments and this is
     non-`NULL', raise a *note TypeError: 562. with a message saying
     that keyword arguments are not supported.

Here is a desultory example of the implementation of the call function.

     /* Implement the call function.
      *    obj1 is the instance receiving the call.
      *    obj2 is a tuple containing the arguments to the call, in this
      *         case 3 strings.
      */
     static PyObject *
     newdatatype_call(newdatatypeobject *obj, PyObject *args, PyObject *other)
     {
         PyObject *result;
         char *arg1;
         char *arg2;
         char *arg3;

         if (!PyArg_ParseTuple(args, "sss:call", &arg1, &arg2, &arg3)) {
             return NULL;
         }
         result = PyUnicode_FromFormat(
             "Returning -- value: [\%d] arg1: [\%s] arg2: [\%s] arg3: [\%s]\n",
             obj->obj_UnderlyingDatatypePtr->size,
             arg1, arg2, arg3);
         return result;
     }

     /* Iterators */
     getiterfunc tp_iter;
     iternextfunc tp_iternext;

These functions provide support for the iterator protocol.  Any object
which wishes to support iteration over its contents (which may be
generated during iteration) must implement the ‘tp_iter’ handler.
Objects which are returned by a ‘tp_iter’ handler must implement both
the ‘tp_iter’ and ‘tp_iternext’ handlers.  Both handlers take exactly
one parameter, the instance for which they are being called, and return
a new reference.  In the case of an error, they should set an exception
and return `NULL'.

For an object which represents an iterable collection, the ‘tp_iter’
handler must return an iterator object.  The iterator object is
responsible for maintaining the state of the iteration.  For collections
which can support multiple iterators which do not interfere with each
other (as lists and tuples do), a new iterator should be created and
returned.  Objects which can only be iterated over once (usually due to
side effects of iteration) should implement this handler by returning a
new reference to themselves, and should also implement the ‘tp_iternext’
handler.  File objects are an example of such an iterator.

Iterator objects should implement both handlers.  The ‘tp_iter’ handler
should return a new reference to the iterator (this is the same as the
‘tp_iter’ handler for objects which can only be iterated over
destructively).  The ‘tp_iternext’ handler should return a new reference
to the next object in the iteration if there is one.  If the iteration
has reached the end, it may return `NULL' without setting an exception
or it may set *note StopIteration: 191.; avoiding the exception can
yield slightly better performance.  If an actual error occurs, it should
set an exception and return `NULL'.


File: python.info,  Node: Weak Reference Support,  Next: More Suggestions,  Prev: Abstract Protocol Support,  Up: Type Methods

6.2.2.14 Weak Reference Support
...............................

One of the goals of Python’s weak-reference implementation is to allow
any type to participate in the weak reference mechanism without
incurring the overhead on those objects which do not benefit by weak
referencing (such as numbers).

For an object to be weakly referencable, the extension must include a
*note PyObject*: 9f5. field in the instance structure for the use of the
weak reference mechanism; it must be initialized to `NULL' by the
object’s constructor.  It must also set the *note tp_weaklistoffset:
3369. field of the corresponding type object to the offset of the field.
For example, the instance type is defined with the following structure:

     typedef struct {
         PyObject_HEAD
         PyClassObject *in_class;       /* The class object */
         PyObject      *in_dict;        /* A dictionary */
         PyObject      *in_weakreflist; /* List of weak references */
     } PyInstanceObject;

The statically-declared type object for instances is defined this way:

     PyTypeObject PyInstance_Type = {
         PyVarObject_HEAD_INIT(&PyType_Type, 0)
         0,
         "module.instance",

         /* Lots of stuff omitted for brevity... */

         Py_TPFLAGS_DEFAULT,                         /* tp_flags */
         0,                                          /* tp_doc */
         0,                                          /* tp_traverse */
         0,                                          /* tp_clear */
         0,                                          /* tp_richcompare */
         offsetof(PyInstanceObject, in_weakreflist), /* tp_weaklistoffset */
     };

The type constructor is responsible for initializing the weak reference
list to `NULL':

     static PyObject *
     instance_new() {
         /* Other initialization stuff omitted for brevity */

         self->in_weakreflist = NULL;

         return (PyObject *) self;
     }

The only further addition is that the destructor needs to call the weak
reference manager to clear any weak references.  This is only required
if the weak reference list is non-`NULL':

     static void
     instance_dealloc(PyInstanceObject *inst)
     {
         /* Allocate temporaries if needed, but do not begin
            destruction just yet.
          */

         if (inst->in_weakreflist != NULL)
             PyObject_ClearWeakRefs((PyObject *) inst);

         /* Proceed with object destruction normally. */
     }


File: python.info,  Node: More Suggestions,  Prev: Weak Reference Support,  Up: Type Methods

6.2.2.15 More Suggestions
.........................

Remember that you can omit most of these functions, in which case you
provide ‘0’ as a value.  There are type definitions for each of the
functions you must provide.  They are in ‘object.h’ in the Python
include directory that comes with the source distribution of Python.

In order to learn how to implement any specific method for your new data
type, do the following: Download and unpack the Python source
distribution.  Go to the ‘Objects’ directory, then search the C source
files for ‘tp_’ plus the function you want (for example,
‘tp_richcompare’).  You will find examples of the function you want to
implement.

When you need to verify that an object is an instance of the type you
are implementing, use the *note PyObject_TypeCheck(): 336b. function.  A
sample of its use might be something like the following:

     if (! PyObject_TypeCheck(some_object, &MyType)) {
         PyErr_SetString(PyExc_TypeError, "arg #1 not a mything");
         return NULL;
     }


File: python.info,  Node: Building C and C++ Extensions,  Next: Building C and C++ Extensions on Windows,  Prev: Defining New Types,  Up: Creating extensions without third party tools

6.2.3 Building C and C++ Extensions
-----------------------------------

A C extension for CPython is a shared library (e.g.  a ‘.so’ file on
Linux, ‘.pyd’ on Windows), which exports an `initialization function'.

To be importable, the shared library must be available on *note
PYTHONPATH: 567, and must be named after the module name, with an
appropriate extension.  When using distutils, the correct filename is
generated automatically.

The initialization function has the signature:

 -- C Function: PyObject* PyInit_modulename (void)

It returns either a fully-initialized module, or a *note PyModuleDef:
3344. instance.  See *note Initializing C modules: 336f. for details.

For modules with ASCII-only names, the function must be named
‘PyInit_<modulename>’, with ‘<modulename>’ replaced by the name of the
module.  When using *note Multi-phase initialization: 3370, non-ASCII
module names are allowed.  In this case, the initialization function
name is ‘PyInitU_<modulename>’, with ‘<modulename>’ encoded using
Python’s `punycode' encoding with hyphens replaced by underscores.  In
Python:

     def initfunc_name(name):
         try:
             suffix = b'_' + name.encode('ascii')
         except UnicodeEncodeError:
             suffix = b'U_' + name.encode('punycode').replace(b'-', b'_')
         return b'PyInit' + suffix

It is possible to export multiple modules from a single shared library
by defining multiple initialization functions.  However, importing them
requires using symbolic links or a custom importer, because by default
only the function corresponding to the filename is found.  See the
`"Multiple modules in one library"' section in PEP 489(1) for details.

* Menu:

* Building C and C++ Extensions with distutils:: 
* Distributing your extension modules:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0489


File: python.info,  Node: Building C and C++ Extensions with distutils,  Next: Distributing your extension modules,  Up: Building C and C++ Extensions

6.2.3.1 Building C and C++ Extensions with distutils
....................................................

Extension modules can be built using distutils, which is included in
Python.  Since distutils also supports creation of binary packages,
users don’t necessarily need a compiler and distutils to install the
extension.

A distutils package contains a driver script, ‘setup.py’.  This is a
plain Python file, which, in the most simple case, could look like this:

     from distutils.core import setup, Extension

     module1 = Extension('demo',
                         sources = ['demo.c'])

     setup (name = 'PackageName',
            version = '1.0',
            description = 'This is a demo package',
            ext_modules = [module1])

With this ‘setup.py’, and a file ‘demo.c’, running

     python setup.py build

will compile ‘demo.c’, and produce an extension module named ‘demo’ in
the ‘build’ directory.  Depending on the system, the module file will
end up in a subdirectory ‘build/lib.system’, and may have a name like
‘demo.so’ or ‘demo.pyd’.

In the ‘setup.py’, all execution is performed by calling the ‘setup’
function.  This takes a variable number of keyword arguments, of which
the example above uses only a subset.  Specifically, the example
specifies meta-information to build packages, and it specifies the
contents of the package.  Normally, a package will contain additional
modules, like Python source modules, documentation, subpackages, etc.
Please refer to the distutils documentation in *note Distributing Python
Modules (Legacy version): 3e8. to learn more about the features of
distutils; this section explains building extension modules only.

It is common to pre-compute arguments to ‘setup()’, to better structure
the driver script.  In the example above, the ‘ext_modules’ argument to
*note setup(): 3372. is a list of extension modules, each of which is an
instance of the ‘Extension’.  In the example, the instance defines an
extension named ‘demo’ which is build by compiling a single source file,
‘demo.c’.

In many cases, building an extension is more complex, since additional
preprocessor defines and libraries may be needed.  This is demonstrated
in the example below.

     from distutils.core import setup, Extension

     module1 = Extension('demo',
                         define_macros = [('MAJOR_VERSION', '1'),
                                          ('MINOR_VERSION', '0')],
                         include_dirs = ['/usr/local/include'],
                         libraries = ['tcl83'],
                         library_dirs = ['/usr/local/lib'],
                         sources = ['demo.c'])

     setup (name = 'PackageName',
            version = '1.0',
            description = 'This is a demo package',
            author = 'Martin v. Loewis',
            author_email = 'martin@v.loewis.de',
            url = 'https://docs.python.org/extending/building',
            long_description = '''
     This is really just a demo package.
     ''',
            ext_modules = [module1])

In this example, *note setup(): 3372. is called with additional
meta-information, which is recommended when distribution packages have
to be built.  For the extension itself, it specifies preprocessor
defines, include directories, library directories, and libraries.
Depending on the compiler, distutils passes this information in
different ways to the compiler.  For example, on Unix, this may result
in the compilation commands

     gcc -DNDEBUG -g -O3 -Wall -Wstrict-prototypes -fPIC -DMAJOR_VERSION=1 -DMINOR_VERSION=0 -I/usr/local/include -I/usr/local/include/python2.2 -c demo.c -o build/temp.linux-i686-2.2/demo.o

     gcc -shared build/temp.linux-i686-2.2/demo.o -L/usr/local/lib -ltcl83 -o build/lib.linux-i686-2.2/demo.so

These lines are for demonstration purposes only; distutils users should
trust that distutils gets the invocations right.


File: python.info,  Node: Distributing your extension modules,  Prev: Building C and C++ Extensions with distutils,  Up: Building C and C++ Extensions

6.2.3.2 Distributing your extension modules
...........................................

When an extension has been successfully build, there are three ways to
use it.

End-users will typically want to install the module, they do so by
running

     python setup.py install

Module maintainers should produce source packages; to do so, they run

     python setup.py sdist

In some cases, additional files need to be included in a source
distribution; this is done through a ‘MANIFEST.in’ file; see *note
Specifying the files to distribute: 3375. for details.

If the source distribution has been build successfully, maintainers can
also create binary distributions.  Depending on the platform, one of the
following commands can be used to do so.

     python setup.py bdist_wininst
     python setup.py bdist_rpm
     python setup.py bdist_dumb


File: python.info,  Node: Building C and C++ Extensions on Windows,  Prev: Building C and C++ Extensions,  Up: Creating extensions without third party tools

6.2.4 Building C and C++ Extensions on Windows
----------------------------------------------

This chapter briefly explains how to create a Windows extension module
for Python using Microsoft Visual C++, and follows with more detailed
background information on how it works.  The explanatory material is
useful for both the Windows programmer learning to build Python
extensions and the Unix programmer interested in producing software
which can be successfully built on both Unix and Windows.

Module authors are encouraged to use the distutils approach for building
extension modules, instead of the one described in this section.  You
will still need the C compiler that was used to build Python; typically
Microsoft Visual C++.

     Note: This chapter mentions a number of filenames that include an
     encoded Python version number.  These filenames are represented
     with the version number shown as ‘XY’; in practice, ‘'X'’ will be
     the major version number and ‘'Y'’ will be the minor version number
     of the Python release you’re working with.  For example, if you are
     using Python 2.2.1, ‘XY’ will actually be ‘22’.

* Menu:

* A Cookbook Approach:: 
* Differences Between Unix and Windows:: 
* Using DLLs in Practice:: 


File: python.info,  Node: A Cookbook Approach,  Next: Differences Between Unix and Windows,  Up: Building C and C++ Extensions on Windows

6.2.4.1 A Cookbook Approach
...........................

There are two approaches to building extension modules on Windows, just
as there are on Unix: use the *note distutils: 37. package to control
the build process, or do things manually.  The distutils approach works
well for most extensions; documentation on using *note distutils: 37. to
build and package extension modules is available in *note Distributing
Python Modules (Legacy version): 3e8.  If you find you really need to do
things manually, it may be instructive to study the project file for the
winsound(1) standard library module.

   ---------- Footnotes ----------

   (1) 
https://hg.python.org/cpython/file/default/PCbuild/winsound.vcxproj


File: python.info,  Node: Differences Between Unix and Windows,  Next: Using DLLs in Practice,  Prev: A Cookbook Approach,  Up: Building C and C++ Extensions on Windows

6.2.4.2 Differences Between Unix and Windows
............................................

Unix and Windows use completely different paradigms for run-time loading
of code.  Before you try to build a module that can be dynamically
loaded, be aware of how your system works.

In Unix, a shared object (‘.so’) file contains code to be used by the
program, and also the names of functions and data that it expects to
find in the program.  When the file is joined to the program, all
references to those functions and data in the file’s code are changed to
point to the actual locations in the program where the functions and
data are placed in memory.  This is basically a link operation.

In Windows, a dynamic-link library (‘.dll’) file has no dangling
references.  Instead, an access to functions or data goes through a
lookup table.  So the DLL code does not have to be fixed up at runtime
to refer to the program’s memory; instead, the code already uses the
DLL’s lookup table, and the lookup table is modified at runtime to point
to the functions and data.

In Unix, there is only one type of library file (‘.a’) which contains
code from several object files (‘.o’).  During the link step to create a
shared object file (‘.so’), the linker may find that it doesn’t know
where an identifier is defined.  The linker will look for it in the
object files in the libraries; if it finds it, it will include all the
code from that object file.

In Windows, there are two types of library, a static library and an
import library (both called ‘.lib’).  A static library is like a Unix
‘.a’ file; it contains code to be included as necessary.  An import
library is basically used only to reassure the linker that a certain
identifier is legal, and will be present in the program when the DLL is
loaded.  So the linker uses the information from the import library to
build the lookup table for using identifiers that are not included in
the DLL. When an application or a DLL is linked, an import library may
be generated, which will need to be used for all future DLLs that depend
on the symbols in the application or DLL.

Suppose you are building two dynamic-load modules, B and C, which should
share another block of code A. On Unix, you would `not' pass ‘A.a’ to
the linker for ‘B.so’ and ‘C.so’; that would cause it to be included
twice, so that B and C would each have their own copy.  In Windows,
building ‘A.dll’ will also build ‘A.lib’.  You `do' pass ‘A.lib’ to the
linker for B and C. ‘A.lib’ does not contain code; it just contains
information which will be used at runtime to access A’s code.

In Windows, using an import library is sort of like using ‘import spam’;
it gives you access to spam’s names, but does not create a separate
copy.  On Unix, linking with a library is more like ‘from spam import
*’; it does create a separate copy.


File: python.info,  Node: Using DLLs in Practice,  Prev: Differences Between Unix and Windows,  Up: Building C and C++ Extensions on Windows

6.2.4.3 Using DLLs in Practice
..............................

Windows Python is built in Microsoft Visual C++; using other compilers
may or may not work (though Borland seems to).  The rest of this section
is MSVC++ specific.

When creating DLLs in Windows, you must pass ‘pythonXY.lib’ to the
linker.  To build two DLLs, spam and ni (which uses C functions found in
spam), you could use these commands:

     cl /LD /I/python/include spam.c ../libs/pythonXY.lib
     cl /LD /I/python/include ni.c spam.lib ../libs/pythonXY.lib

The first command created three files: ‘spam.obj’, ‘spam.dll’ and
‘spam.lib’.  ‘Spam.dll’ does not contain any Python functions (such as
*note PyArg_ParseTuple(): 724.), but it does know how to find the Python
code thanks to ‘pythonXY.lib’.

The second command created ‘ni.dll’ (and ‘.obj’ and ‘.lib’), which knows
how to find the necessary functions from spam, and also from the Python
executable.

Not every identifier is exported to the lookup table.  If you want any
other modules (including Python) to be able to see your identifiers, you
have to say ‘_declspec(dllexport)’, as in ‘void _declspec(dllexport)
initspam(void)’ or ‘PyObject _declspec(dllexport) *NiGetSpamData(void)’.

Developer Studio will throw in a lot of import libraries that you do not
really need, adding about 100K to your executable.  To get rid of them,
use the Project Settings dialog, Link tab, to specify `ignore default
libraries'.  Add the correct ‘msvcrtxx.lib’ to the list of libraries.


File: python.info,  Node: Embedding the CPython runtime in a larger application,  Prev: Creating extensions without third party tools,  Up: Extending and Embedding the Python Interpreter

6.3 Embedding the CPython runtime in a larger application
=========================================================

Sometimes, rather than creating an extension that runs inside the Python
interpreter as the main application, it is desirable to instead embed
the CPython runtime inside a larger application.  This section covers
some of the details involved in doing that successfully.

* Menu:

* Embedding Python in Another Application:: 


File: python.info,  Node: Embedding Python in Another Application,  Up: Embedding the CPython runtime in a larger application

6.3.1 Embedding Python in Another Application
---------------------------------------------

The previous chapters discussed how to extend Python, that is, how to
extend the functionality of Python by attaching a library of C functions
to it.  It is also possible to do it the other way around: enrich your
C/C++ application by embedding Python in it.  Embedding provides your
application with the ability to implement some of the functionality of
your application in Python rather than C or C++.  This can be used for
many purposes; one example would be to allow users to tailor the
application to their needs by writing some scripts in Python.  You can
also use it yourself if some of the functionality can be written in
Python more easily.

Embedding Python is similar to extending it, but not quite.  The
difference is that when you extend Python, the main program of the
application is still the Python interpreter, while if you embed Python,
the main program may have nothing to do with Python — instead, some
parts of the application occasionally call the Python interpreter to run
some Python code.

So if you are embedding Python, you are providing your own main program.
One of the things this main program has to do is initialize the Python
interpreter.  At the very least, you have to call the function *note
Py_Initialize(): 876.  There are optional calls to pass command line
arguments to Python.  Then later you can call the interpreter from any
part of the application.

There are several different ways to call the interpreter: you can pass a
string containing Python statements to *note PyRun_SimpleString(): 3382,
or you can pass a stdio file pointer and a file name (for identification
in error messages only) to *note PyRun_SimpleFile(): 3383.  You can also
call the lower-level operations described in the previous chapters to
construct and use Python objects.

See also
........

*note Python/C API Reference Manual: bc8.

     The details of Python’s C interface are given in this manual.  A
     great deal of necessary information can be found here.

* Menu:

* Very High Level Embedding:: 
* Beyond Very High Level Embedding; An overview: Beyond Very High Level Embedding An overview. 
* Pure Embedding:: 
* Extending Embedded Python:: 
* Embedding Python in C++:: 
* Compiling and Linking under Unix-like systems:: 


File: python.info,  Node: Very High Level Embedding,  Next: Beyond Very High Level Embedding An overview,  Up: Embedding Python in Another Application

6.3.1.1 Very High Level Embedding
.................................

The simplest form of embedding Python is the use of the very high level
interface.  This interface is intended to execute a Python script
without needing to interact with the application directly.  This can for
example be used to perform some operation on a file.

     #include <Python.h>

     int
     main(int argc, char *argv[])
     {
         wchar_t *program = Py_DecodeLocale(argv[0], NULL);
         if (program == NULL) {
             fprintf(stderr, "Fatal error: cannot decode argv[0]\n");
             exit(1);
         }
         Py_SetProgramName(program);  /* optional but recommended */
         Py_Initialize();
         PyRun_SimpleString("from time import time,ctime\n"
                            "print('Today is', ctime(time()))\n");
         if (Py_FinalizeEx() < 0) {
             exit(120);
         }
         PyMem_RawFree(program);
         return 0;
     }

The *note Py_SetProgramName(): d4b. function should be called before
*note Py_Initialize(): 876. to inform the interpreter about paths to
Python run-time libraries.  Next, the Python interpreter is initialized
with *note Py_Initialize(): 876, followed by the execution of a
hard-coded Python script that prints the date and time.  Afterwards, the
*note Py_FinalizeEx(): 185. call shuts the interpreter down, followed by
the end of the program.  In a real program, you may want to get the
Python script from another source, perhaps a text-editor routine, a
file, or a database.  Getting the Python code from a file can better be
done by using the *note PyRun_SimpleFile(): 3383. function, which saves
you the trouble of allocating memory space and loading the file
contents.


File: python.info,  Node: Beyond Very High Level Embedding An overview,  Next: Pure Embedding,  Prev: Very High Level Embedding,  Up: Embedding Python in Another Application

6.3.1.2 Beyond Very High Level Embedding: An overview
.....................................................

The high level interface gives you the ability to execute arbitrary
pieces of Python code from your application, but exchanging data values
is quite cumbersome to say the least.  If you want that, you should use
lower level calls.  At the cost of having to write more C code, you can
achieve almost anything.

It should be noted that extending Python and embedding Python is quite
the same activity, despite the different intent.  Most topics discussed
in the previous chapters are still valid.  To show this, consider what
the extension code from Python to C really does:

  1. Convert data values from Python to C,

  2. Perform a function call to a C routine using the converted values,
     and

  3. Convert the data values from the call from C to Python.

When embedding Python, the interface code does:

  1. Convert data values from C to Python,

  2. Perform a function call to a Python interface routine using the
     converted values, and

  3. Convert the data values from the call from Python to C.

As you can see, the data conversion steps are simply swapped to
accommodate the different direction of the cross-language transfer.  The
only difference is the routine that you call between both data
conversions.  When extending, you call a C routine, when embedding, you
call a Python routine.

This chapter will not discuss how to convert data from Python to C and
vice versa.  Also, proper use of references and dealing with errors is
assumed to be understood.  Since these aspects do not differ from
extending the interpreter, you can refer to earlier chapters for the
required information.


File: python.info,  Node: Pure Embedding,  Next: Extending Embedded Python,  Prev: Beyond Very High Level Embedding An overview,  Up: Embedding Python in Another Application

6.3.1.3 Pure Embedding
......................

The first program aims to execute a function in a Python script.  Like
in the section about the very high level interface, the Python
interpreter does not directly interact with the application (but that
will change in the next section).

The code to run a function defined in a Python script is:

     #include <Python.h>

     int
     main(int argc, char *argv[])
     {
         PyObject *pName, *pModule, *pDict, *pFunc;
         PyObject *pArgs, *pValue;
         int i;

         if (argc < 3) {
             fprintf(stderr,"Usage: call pythonfile funcname [args]\n");
             return 1;
         }

         Py_Initialize();
         pName = PyUnicode_DecodeFSDefault(argv[1]);
         /* Error checking of pName left out */

         pModule = PyImport_Import(pName);
         Py_DECREF(pName);

         if (pModule != NULL) {
             pFunc = PyObject_GetAttrString(pModule, argv[2]);
             /* pFunc is a new reference */

             if (pFunc && PyCallable_Check(pFunc)) {
                 pArgs = PyTuple_New(argc - 3);
                 for (i = 0; i < argc - 3; ++i) {
                     pValue = PyLong_FromLong(atoi(argv[i + 3]));
                     if (!pValue) {
                         Py_DECREF(pArgs);
                         Py_DECREF(pModule);
                         fprintf(stderr, "Cannot convert argument\n");
                         return 1;
                     }
                     /* pValue reference stolen here: */
                     PyTuple_SetItem(pArgs, i, pValue);
                 }
                 pValue = PyObject_CallObject(pFunc, pArgs);
                 Py_DECREF(pArgs);
                 if (pValue != NULL) {
                     printf("Result of call: %ld\n", PyLong_AsLong(pValue));
                     Py_DECREF(pValue);
                 }
                 else {
                     Py_DECREF(pFunc);
                     Py_DECREF(pModule);
                     PyErr_Print();
                     fprintf(stderr,"Call failed\n");
                     return 1;
                 }
             }
             else {
                 if (PyErr_Occurred())
                     PyErr_Print();
                 fprintf(stderr, "Cannot find function \"%s\"\n", argv[2]);
             }
             Py_XDECREF(pFunc);
             Py_DECREF(pModule);
         }
         else {
             PyErr_Print();
             fprintf(stderr, "Failed to load \"%s\"\n", argv[1]);
             return 1;
         }
         if (Py_FinalizeEx() < 0) {
             return 120;
         }
         return 0;
     }

This code loads a Python script using ‘argv[1]’, and calls the function
named in ‘argv[2]’.  Its integer arguments are the other values of the
‘argv’ array.  If you *note compile and link: 338a. this program (let’s
call the finished executable ‘call’), and use it to execute a Python
script, such as:

     def multiply(a,b):
         print("Will compute", a, "times", b)
         c = 0
         for i in range(0, a):
             c = c + b
         return c

then the result should be:

     $ call multiply multiply 3 2
     Will compute 3 times 2
     Result of call: 6

Although the program is quite large for its functionality, most of the
code is for data conversion between Python and C, and for error
reporting.  The interesting part with respect to embedding Python starts
with

     Py_Initialize();
     pName = PyUnicode_DecodeFSDefault(argv[1]);
     /* Error checking of pName left out */
     pModule = PyImport_Import(pName);

After initializing the interpreter, the script is loaded using *note
PyImport_Import(): 9d6.  This routine needs a Python string as its
argument, which is constructed using the *note PyUnicode_FromString():
338b. data conversion routine.

     pFunc = PyObject_GetAttrString(pModule, argv[2]);
     /* pFunc is a new reference */

     if (pFunc && PyCallable_Check(pFunc)) {
         ...
     }
     Py_XDECREF(pFunc);

Once the script is loaded, the name we’re looking for is retrieved using
*note PyObject_GetAttrString(): 331b.  If the name exists, and the
object returned is callable, you can safely assume that it is a
function.  The program then proceeds by constructing a tuple of
arguments as normal.  The call to the Python function is then made with:

     pValue = PyObject_CallObject(pFunc, pArgs);

Upon return of the function, ‘pValue’ is either `NULL' or it contains a
reference to the return value of the function.  Be sure to release the
reference after examining the value.


File: python.info,  Node: Extending Embedded Python,  Next: Embedding Python in C++,  Prev: Pure Embedding,  Up: Embedding Python in Another Application

6.3.1.4 Extending Embedded Python
.................................

Until now, the embedded Python interpreter had no access to
functionality from the application itself.  The Python API allows this
by extending the embedded interpreter.  That is, the embedded
interpreter gets extended with routines provided by the application.
While it sounds complex, it is not so bad.  Simply forget for a while
that the application starts the Python interpreter.  Instead, consider
the application to be a set of subroutines, and write some glue code
that gives Python access to those routines, just like you would write a
normal Python extension.  For example:

     static int numargs=0;

     /* Return the number of arguments of the application command line */
     static PyObject*
     emb_numargs(PyObject *self, PyObject *args)
     {
         if(!PyArg_ParseTuple(args, ":numargs"))
             return NULL;
         return PyLong_FromLong(numargs);
     }

     static PyMethodDef EmbMethods[] = {
         {"numargs", emb_numargs, METH_VARARGS,
          "Return the number of arguments received by the process."},
         {NULL, NULL, 0, NULL}
     };

     static PyModuleDef EmbModule = {
         PyModuleDef_HEAD_INIT, "emb", NULL, -1, EmbMethods,
         NULL, NULL, NULL, NULL
     };

     static PyObject*
     PyInit_emb(void)
     {
         return PyModule_Create(&EmbModule);
     }

Insert the above code just above the ‘main()’ function.  Also, insert
the following two statements before the call to *note Py_Initialize():
876.:

     numargs = argc;
     PyImport_AppendInittab("emb", &PyInit_emb);

These two lines initialize the ‘numargs’ variable, and make the
‘emb.numargs()’ function accessible to the embedded Python interpreter.
With these extensions, the Python script can do things like

     import emb
     print("Number of arguments", emb.numargs())

In a real application, the methods will expose an API of the application
to Python.


File: python.info,  Node: Embedding Python in C++,  Next: Compiling and Linking under Unix-like systems,  Prev: Extending Embedded Python,  Up: Embedding Python in Another Application

6.3.1.5 Embedding Python in C++
...............................

It is also possible to embed Python in a C++ program; precisely how this
is done will depend on the details of the C++ system used; in general
you will need to write the main program in C++, and use the C++ compiler
to compile and link your program.  There is no need to recompile Python
itself using C++.


File: python.info,  Node: Compiling and Linking under Unix-like systems,  Prev: Embedding Python in C++,  Up: Embedding Python in Another Application

6.3.1.6 Compiling and Linking under Unix-like systems
.....................................................

It is not necessarily trivial to find the right flags to pass to your
compiler (and linker) in order to embed the Python interpreter into your
application, particularly because Python needs to load library modules
implemented as C dynamic extensions (‘.so’ files) linked against it.

To find out the required compiler and linker flags, you can execute the
‘python`X.Y'-config’ script which is generated as part of the
installation process (a ‘python3-config’ script may also be available).
This script has several options, of which the following will be directly
useful to you:

   * ‘pythonX.Y-config --cflags’ will give you the recommended flags
     when compiling:

          $ /opt/bin/python3.4-config --cflags
          -I/opt/include/python3.4m -I/opt/include/python3.4m -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes

   * ‘pythonX.Y-config --ldflags’ will give you the recommended flags
     when linking:

          $ /opt/bin/python3.4-config --ldflags
          -L/opt/lib/python3.4/config-3.4m -lpthread -ldl -lutil -lm -lpython3.4m -Xlinker -export-dynamic

     Note: To avoid confusion between several Python installations (and
     especially between the system Python and your own compiled Python),
     it is recommended that you use the absolute path to
     ‘python`X.Y'-config’, as in the above example.

If this procedure doesn’t work for you (it is not guaranteed to work for
all Unix-like platforms; however, we welcome *note bug reports: 3391.)
you will have to read your system’s documentation about dynamic linking
and/or examine Python’s ‘Makefile’ (use *note
sysconfig.get_makefile_filename(): 2e49. to find its location) and
compilation options.  In this case, the *note sysconfig: fc. module is a
useful tool to programmatically extract the configuration values that
you will want to combine together.  For example:

     >>> import sysconfig
     >>> sysconfig.get_config_var('LIBS')
     '-lpthread -ldl  -lutil'
     >>> sysconfig.get_config_var('LINKFORSHARED')
     '-Xlinker -export-dynamic'


File: python.info,  Node: Python/C API Reference Manual,  Next: Distributing Python Modules,  Prev: Extending and Embedding the Python Interpreter,  Up: Top

7 Python/C API Reference Manual
*******************************

This manual documents the API used by C and C++ programmers who want to
write extension modules or embed Python.  It is a companion to *note
Extending and Embedding the Python Interpreter: bc7, which describes the
general principles of extension writing but does not document the API
functions in detail.

* Menu:

* Introduction: Introduction<13>. 
* Stable Application Binary Interface:: 
* The Very High Level Layer:: 
* Reference Counting:: 
* Exception Handling:: 
* Utilities: Utilities<2>. 
* Abstract Objects Layer:: 
* Concrete Objects Layer:: 
* Initialization, Finalization, and Threads: Initialization Finalization and Threads. 
* Memory Management:: 
* Object Implementation Support:: 
* API and ABI Versioning:: 


File: python.info,  Node: Introduction<13>,  Next: Stable Application Binary Interface,  Up: Python/C API Reference Manual

7.1 Introduction
================

The Application Programmer’s Interface to Python gives C and C++
programmers access to the Python interpreter at a variety of levels.
The API is equally usable from C++, but for brevity it is generally
referred to as the Python/C API. There are two fundamentally different
reasons for using the Python/C API. The first reason is to write
`extension modules' for specific purposes; these are C modules that
extend the Python interpreter.  This is probably the most common use.
The second reason is to use Python as a component in a larger
application; this technique is generally referred to as `embedding'
Python in an application.

Writing an extension module is a relatively well-understood process,
where a "cookbook" approach works well.  There are several tools that
automate the process to some extent.  While people have embedded Python
in other applications since its early existence, the process of
embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or
extending Python; moreover, most applications that embed Python will
need to provide a custom extension as well, so it’s probably a good idea
to become familiar with writing an extension before attempting to embed
Python in a real application.

* Menu:

* Include Files:: 
* Objects, Types and Reference Counts: Objects Types and Reference Counts. 
* Exceptions: Exceptions<13>. 
* Embedding Python: Embedding Python<2>. 
* Debugging Builds:: 


File: python.info,  Node: Include Files,  Next: Objects Types and Reference Counts,  Up: Introduction<13>

7.1.1 Include Files
-------------------

All function, type and macro definitions needed to use the Python/C API
are included in your code by the following line:

     #include "Python.h"

This implies inclusion of the following standard headers: ‘<stdio.h>’,
‘<string.h>’, ‘<errno.h>’, ‘<limits.h>’, ‘<assert.h>’ and ‘<stdlib.h>’
(if available).

     Note: Since Python may define some pre-processor definitions which
     affect the standard headers on some systems, you `must' include
     ‘Python.h’ before any standard headers are included.

All user visible names defined by Python.h (except those defined by the
included standard headers) have one of the prefixes ‘Py’ or ‘_Py’.
Names beginning with ‘_Py’ are for internal use by the Python
implementation and should not be used by extension writers.  Structure
member names do not have a reserved prefix.

`Important:' user code should never define names that begin with ‘Py’ or
‘_Py’.  This confuses the reader, and jeopardizes the portability of the
user code to future Python versions, which may define additional names
beginning with one of these prefixes.

The header files are typically installed with Python.  On Unix, these
are located in the directories ‘`prefix'/include/pythonversion/’ and
‘`exec_prefix'/include/pythonversion/’, where ‘prefix’ and ‘exec_prefix’
are defined by the corresponding parameters to Python’s ‘configure’
script and `version' is ‘'%d.%d' % sys.version_info[:2]’.  On Windows,
the headers are installed in ‘`prefix'/include’, where ‘prefix’ is the
installation directory specified to the installer.

To include the headers, place both directories (if different) on your
compiler’s search path for includes.  Do `not' place the parent
directories on the search path and then use ‘#include
<pythonX.Y/Python.h>’; this will break on multi-platform builds since
the platform independent headers under ‘prefix’ include the platform
specific headers from ‘exec_prefix’.

C++ users should note that though the API is defined entirely using C,
the header files do properly declare the entry points to be ‘extern
"C"’, so there is no need to do anything special to use the API from
C++.


File: python.info,  Node: Objects Types and Reference Counts,  Next: Exceptions<13>,  Prev: Include Files,  Up: Introduction<13>

7.1.2 Objects, Types and Reference Counts
-----------------------------------------

Most Python/C API functions have one or more arguments as well as a
return value of type *note PyObject*: 9f5.  This type is a pointer to an
opaque data type representing an arbitrary Python object.  Since all
Python object types are treated the same way by the Python language in
most situations (e.g., assignments, scope rules, and argument passing),
it is only fitting that they should be represented by a single C type.
Almost all Python objects live on the heap: you never declare an
automatic or static variable of type *note PyObject: 9f5, only pointer
variables of type *note PyObject*: 9f5. can be declared.  The sole
exception are the type objects; since these must never be deallocated,
they are typically static *note PyTypeObject: 3bc. objects.

All Python objects (even Python integers) have a `type' and a `reference
count'.  An object’s type determines what kind of object it is (e.g., an
integer, a list, or a user-defined function; there are many more as
explained in *note The standard type hierarchy: de0.).  For each of the
well-known types there is a macro to check whether an object is of that
type; for instance, ‘PyList_Check(a)’ is true if (and only if) the
object pointed to by `a' is a Python list.

* Menu:

* Reference Counts: Reference Counts<2>. 
* Types:: 


File: python.info,  Node: Reference Counts<2>,  Next: Types,  Up: Objects Types and Reference Counts

7.1.2.1 Reference Counts
........................

The reference count is important because today’s computers have a finite
(and often severely limited) memory size; it counts how many different
places there are that have a reference to an object.  Such a place could
be another object, or a global (or static) C variable, or a local
variable in some C function.  When an object’s reference count becomes
zero, the object is deallocated.  If it contains references to other
objects, their reference count is decremented.  Those other objects may
be deallocated in turn, if this decrement makes their reference count
become zero, and so on.  (There’s an obvious problem with objects that
reference each other here; for now, the solution is "don’t do that.")

Reference counts are always manipulated explicitly.  The normal way is
to use the macro *note Py_INCREF(): 32f8. to increment an object’s
reference count by one, and *note Py_DECREF(): 32fd. to decrement it by
one.  The *note Py_DECREF(): 32fd. macro is considerably more complex
than the incref one, since it must check whether the reference count
becomes zero and then cause the object’s deallocator to be called.  The
deallocator is a function pointer contained in the object’s type
structure.  The type-specific deallocator takes care of decrementing the
reference counts for other objects contained in the object if this is a
compound object type, such as a list, as well as performing any
additional finalization that’s needed.  There’s no chance that the
reference count can overflow; at least as many bits are used to hold the
reference count as there are distinct memory locations in virtual memory
(assuming ‘sizeof(Py_ssize_t) >= sizeof(void*)’).  Thus, the reference
count increment is a simple operation.

It is not necessary to increment an object’s reference count for every
local variable that contains a pointer to an object.  In theory, the
object’s reference count goes up by one when the variable is made to
point to it and it goes down by one when the variable goes out of scope.
However, these two cancel each other out, so at the end the reference
count hasn’t changed.  The only real reason to use the reference count
is to prevent the object from being deallocated as long as our variable
is pointing to it.  If we know that there is at least one other
reference to the object that lives at least as long as our variable,
there is no need to increment the reference count temporarily.  An
important situation where this arises is in objects that are passed as
arguments to C functions in an extension module that are called from
Python; the call mechanism guarantees to hold a reference to every
argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold
on to it for a while without incrementing its reference count.  Some
other operation might conceivably remove the object from the list,
decrementing its reference count and possible deallocating it.  The real
danger is that innocent-looking operations may invoke arbitrary Python
code which could do this; there is a code path which allows control to
flow back to the user from a *note Py_DECREF(): 32fd, so almost any
operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose
name begins with ‘PyObject_’, ‘PyNumber_’, ‘PySequence_’ or
‘PyMapping_’).  These operations always increment the reference count of
the object they return.  This leaves the caller with the responsibility
to call *note Py_DECREF(): 32fd. when they are done with the result;
this soon becomes second nature.

* Menu:

* Reference Count Details:: 


File: python.info,  Node: Reference Count Details,  Up: Reference Counts<2>

7.1.2.2 Reference Count Details
...............................

The reference count behavior of functions in the Python/C API is best
explained in terms of `ownership of references'.  Ownership pertains to
references, never to objects (objects are not owned: they are always
shared).  "Owning a reference" means being responsible for calling
Py_DECREF on it when the reference is no longer needed.  Ownership can
also be transferred, meaning that the code that receives ownership of
the reference then becomes responsible for eventually decref’ing it by
calling *note Py_DECREF(): 32fd. or *note Py_XDECREF(): 32fc. when it’s
no longer needed—or passing on this responsibility (usually to its
caller).  When a function passes ownership of a reference on to its
caller, the caller is said to receive a `new' reference.  When no
ownership is transferred, the caller is said to `borrow' the reference.
Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object,
there are two possibilities: the function `steals' a reference to the
object, or it does not.  `Stealing a reference' means that when you pass
a reference to a function, that function assumes that it now owns that
reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are *note
PyList_SetItem(): 3322. and *note PyTuple_SetItem(): 3321, which steal a
reference to the item (but not to the tuple or list into which the item
is put!).  These functions were designed to steal a reference because of
a common idiom for populating a tuple or list with newly created
objects; for example, the code to create the tuple ‘(1, 2, "three")’
could look like this (forgetting about error handling for the moment; a
better way to code this is shown below):

     PyObject *t;

     t = PyTuple_New(3);
     PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
     PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
     PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));

Here, *note PyLong_FromLong(): 32fb. returns a new reference which is
immediately stolen by *note PyTuple_SetItem(): 3321.  When you want to
keep using an object although the reference to it will be stolen, use
*note Py_INCREF(): 32f8. to grab another reference before calling the
reference-stealing function.

Incidentally, *note PyTuple_SetItem(): 3321. is the `only' way to set
tuple items; *note PySequence_SetItem(): 339f. and *note
PyObject_SetItem(): 33a0. refuse to do this since tuples are an
immutable data type.  You should only use *note PyTuple_SetItem(): 3321.
for tuples that you are creating yourself.

Equivalent code for populating a list can be written using *note
PyList_New(): 33a1. and *note PyList_SetItem(): 3322.

However, in practice, you will rarely use these ways of creating and
populating a tuple or list.  There’s a generic function, *note
Py_BuildValue(): 9f7, that can create most common objects from C values,
directed by a `format string'.  For example, the above two blocks of
code could be replaced by the following (which also takes care of the
error checking):

     PyObject *tuple, *list;

     tuple = Py_BuildValue("(iis)", 1, 2, "three");
     list = Py_BuildValue("[iis]", 1, 2, "three");

It is much more common to use *note PyObject_SetItem(): 33a0. and
friends with items whose references you are only borrowing, like
arguments that were passed in to the function you are writing.  In that
case, their behaviour regarding reference counts is much saner, since
you don’t have to increment a reference count so you can give a
reference away ("have it be stolen").  For example, this function sets
all items of a list (actually, any mutable sequence) to a given item:

     int
     set_all(PyObject *target, PyObject *item)
     {
         Py_ssize_t i, n;

         n = PyObject_Length(target);
         if (n < 0)
             return -1;
         for (i = 0; i < n; i++) {
             PyObject *index = PyLong_FromSsize_t(i);
             if (!index)
                 return -1;
             if (PyObject_SetItem(target, index, item) < 0) {
                 Py_DECREF(index);
                 return -1;
             }
             Py_DECREF(index);
         }
         return 0;
     }

The situation is slightly different for function return values.  While
passing a reference to most functions does not change your ownership
responsibilities for that reference, many functions that return a
reference to an object give you ownership of the reference.  The reason
is simple: in many cases, the returned object is created on the fly, and
the reference you get is the only reference to the object.  Therefore,
the generic functions that return object references, like *note
PyObject_GetItem(): 33a2. and *note PySequence_GetItem(): 33a3, always
return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by
a function depends on which function you call only — `the plumage' (the
type of the object passed as an argument to the function) `doesn’t enter
into it!'  Thus, if you extract an item from a list using *note
PyList_GetItem(): 331d, you don’t own the reference — but if you obtain
the same item from the same list using *note PySequence_GetItem(): 33a3.
(which happens to take exactly the same arguments), you do own a
reference to the returned object.

Here is an example of how you could write a function that computes the
sum of the items in a list of integers; once using *note
PyList_GetItem(): 331d, and once using *note PySequence_GetItem(): 33a3.

     long
     sum_list(PyObject *list)
     {
         Py_ssize_t i, n;
         long total = 0, value;
         PyObject *item;

         n = PyList_Size(list);
         if (n < 0)
             return -1; /* Not a list */
         for (i = 0; i < n; i++) {
             item = PyList_GetItem(list, i); /* Can't fail */
             if (!PyLong_Check(item)) continue; /* Skip non-integers */
             value = PyLong_AsLong(item);
             if (value == -1 && PyErr_Occurred())
                 /* Integer too big to fit in a C long, bail out */
                 return -1;
             total += value;
         }
         return total;
     }

     long
     sum_sequence(PyObject *sequence)
     {
         Py_ssize_t i, n;
         long total = 0, value;
         PyObject *item;
         n = PySequence_Length(sequence);
         if (n < 0)
             return -1; /* Has no length */
         for (i = 0; i < n; i++) {
             item = PySequence_GetItem(sequence, i);
             if (item == NULL)
                 return -1; /* Not a sequence, or other failure */
             if (PyLong_Check(item)) {
                 value = PyLong_AsLong(item);
                 Py_DECREF(item);
                 if (value == -1 && PyErr_Occurred())
                     /* Integer too big to fit in a C long, bail out */
                     return -1;
                 total += value;
             }
             else {
                 Py_DECREF(item); /* Discard reference ownership */
             }
         }
         return total;
     }


File: python.info,  Node: Types,  Prev: Reference Counts<2>,  Up: Objects Types and Reference Counts

7.1.2.3 Types
.............

There are few other data types that play a significant role in the
Python/C API; most are simple C types such as ‘int’, ‘long’, ‘double’
and ‘char*’.  A few structure types are used to describe static tables
used to list the functions exported by a module or the data attributes
of a new object type, and another is used to describe the value of a
complex number.  These will be discussed together with the functions
that use them.


File: python.info,  Node: Exceptions<13>,  Next: Embedding Python<2>,  Prev: Objects Types and Reference Counts,  Up: Introduction<13>

7.1.3 Exceptions
----------------

The Python programmer only needs to deal with exceptions if specific
error handling is required; unhandled exceptions are automatically
propagated to the caller, then to the caller’s caller, and so on, until
they reach the top-level interpreter, where they are reported to the
user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit.
All functions in the Python/C API can raise exceptions, unless an
explicit claim is made otherwise in a function’s documentation.  In
general, when a function encounters an error, it sets an exception,
discards any object references that it owns, and returns an error
indicator.  If not documented otherwise, this indicator is either `NULL'
or ‘-1’, depending on the function’s return type.  A few functions
return a Boolean true/false result, with false indicating an error.
Very few functions return no explicit error indicator or have an
ambiguous return value, and require explicit testing for errors with
*note PyErr_Occurred(): 32f9.  These exceptions are always explicitly
documented.

Exception state is maintained in per-thread storage (this is equivalent
to using global storage in an unthreaded application).  A thread can be
in one of two states: an exception has occurred, or not.  The function
*note PyErr_Occurred(): 32f9. can be used to check for this: it returns
a borrowed reference to the exception type object when an exception has
occurred, and `NULL' otherwise.  There are a number of functions to set
the exception state: *note PyErr_SetString(): 32f5. is the most common
(though not the most general) function to set the exception state, and
*note PyErr_Clear(): 588. clears the exception state.

The full exception state consists of three objects (all of which can be
`NULL'): the exception type, the corresponding exception value, and the
traceback.  These have the same meanings as the Python result of
‘sys.exc_info()’; however, they are not the same: the Python objects
represent the last exception being handled by a Python *note try: 9e9.
...  *note except: 785. statement, while the C level exception state
only exists while an exception is being passed on between C functions
until it reaches the Python bytecode interpreter’s main loop, which
takes care of transferring it to ‘sys.exc_info()’ and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to
access the exception state from Python code is to call the function
*note sys.exc_info(): 8ca, which returns the per-thread exception state
for Python code.  Also, the semantics of both ways to access the
exception state have changed so that a function which catches an
exception will save and restore its thread’s exception state so as to
preserve the exception state of its caller.  This prevents common bugs
in exception handling code caused by an innocent-looking function
overwriting the exception being handled; it also reduces the often
unwanted lifetime extension for objects that are referenced by the stack
frames in the traceback.

As a general principle, a function that calls another function to
perform some task should check whether the called function raised an
exception, and if so, pass the exception state on to its caller.  It
should discard any object references that it owns, and return an error
indicator, but it should `not' set another exception — that would
overwrite the exception that was just raised, and lose important
information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in
the ‘sum_sequence()’ example above.  It so happens that this example
doesn’t need to clean up any owned references when it detects an error.
The following example function shows some error cleanup.  First, to
remind you why you like Python, we show the equivalent Python code:

     def incr_item(dict, key):
         try:
             item = dict[key]
         except KeyError:
             item = 0
         dict[key] = item + 1

Here is the corresponding C code, in all its glory:

     int
     incr_item(PyObject *dict, PyObject *key)
     {
         /* Objects all initialized to NULL for Py_XDECREF */
         PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
         int rv = -1; /* Return value initialized to -1 (failure) */

         item = PyObject_GetItem(dict, key);
         if (item == NULL) {
             /* Handle KeyError only: */
             if (!PyErr_ExceptionMatches(PyExc_KeyError))
                 goto error;

             /* Clear the error and use zero: */
             PyErr_Clear();
             item = PyLong_FromLong(0L);
             if (item == NULL)
                 goto error;
         }
         const_one = PyLong_FromLong(1L);
         if (const_one == NULL)
             goto error;

         incremented_item = PyNumber_Add(item, const_one);
         if (incremented_item == NULL)
             goto error;

         if (PyObject_SetItem(dict, key, incremented_item) < 0)
             goto error;
         rv = 0; /* Success */
         /* Continue with cleanup code */

      error:
         /* Cleanup code, shared by success and failure path */

         /* Use Py_XDECREF() to ignore NULL references */
         Py_XDECREF(item);
         Py_XDECREF(const_one);
         Py_XDECREF(incremented_item);

         return rv; /* -1 for error, 0 for success */
     }

This example represents an endorsed use of the ‘goto’ statement in C! It
illustrates the use of *note PyErr_ExceptionMatches(): 33a8. and *note
PyErr_Clear(): 588. to handle specific exceptions, and the use of *note
Py_XDECREF(): 32fc. to dispose of owned references that may be `NULL'
(note the ‘'X'’ in the name; *note Py_DECREF(): 32fd. would crash when
confronted with a `NULL' reference).  It is important that the variables
used to hold owned references are initialized to `NULL' for this to
work; likewise, the proposed return value is initialized to ‘-1’
(failure) and only set to success after the final call made is
successful.


File: python.info,  Node: Embedding Python<2>,  Next: Debugging Builds,  Prev: Exceptions<13>,  Up: Introduction<13>

7.1.4 Embedding Python
----------------------

The one important task that only embedders (as opposed to extension
writers) of the Python interpreter have to worry about is the
initialization, and possibly the finalization, of the Python
interpreter.  Most functionality of the interpreter can only be used
after the interpreter has been initialized.

The basic initialization function is *note Py_Initialize(): 876.  This
initializes the table of loaded modules, and creates the fundamental
modules *note builtins: 13, *note __main__: 1, and *note sys: fb.  It
also initializes the module search path (‘sys.path’).

*note Py_Initialize(): 876. does not set the "script argument list"
(‘sys.argv’).  If this variable is needed by Python code that will be
executed later, it must be set explicitly with a call to
‘PySys_SetArgvEx(argc, argv, updatepath)’ after the call to *note
Py_Initialize(): 876.

On most systems (in particular, on Unix and Windows, although the
details are slightly different), *note Py_Initialize(): 876. calculates
the module search path based upon its best guess for the location of the
standard Python interpreter executable, assuming that the Python library
is found in a fixed location relative to the Python interpreter
executable.  In particular, it looks for a directory named
‘lib/python`X.Y'’ relative to the parent directory where the executable
named ‘python’ is found on the shell command search path (the
environment variable ‘PATH’).

For instance, if the Python executable is found in
‘/usr/local/bin/python’, it will assume that the libraries are in
‘/usr/local/lib/python`X.Y'’.  (In fact, this particular path is also
the "fallback" location, used when no executable file named ‘python’ is
found along ‘PATH’.)  The user can override this behavior by setting the
environment variable *note PYTHONHOME: d04, or insert additional
directories in front of the standard path by setting *note PYTHONPATH:
567.

The embedding application can steer the search by calling
‘Py_SetProgramName(file)’ `before' calling *note Py_Initialize(): 876.
Note that *note PYTHONHOME: d04. still overrides this and *note
PYTHONPATH: 567. is still inserted in front of the standard path.  An
application that requires total control has to provide its own
implementation of *note Py_GetPath(): 33ab, *note Py_GetPrefix(): 33ac,
*note Py_GetExecPrefix(): 33ad, and *note Py_GetProgramFullPath(): 33ae.
(all defined in ‘Modules/getpath.c’).

Sometimes, it is desirable to "uninitialize" Python.  For instance, the
application may want to start over (make another call to *note
Py_Initialize(): 876.) or the application is simply done with its use of
Python and wants to free memory allocated by Python.  This can be
accomplished by calling *note Py_FinalizeEx(): 185.  The function *note
Py_IsInitialized(): 33af. returns true if Python is currently in the
initialized state.  More information about these functions is given in a
later chapter.  Notice that *note Py_FinalizeEx(): 185. does `not' free
all memory allocated by the Python interpreter, e.g.  memory allocated
by extension modules currently cannot be released.


File: python.info,  Node: Debugging Builds,  Prev: Embedding Python<2>,  Up: Introduction<13>

7.1.5 Debugging Builds
----------------------

Python can be built with several macros to enable extra checks of the
interpreter and extension modules.  These checks tend to add a large
amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file
‘Misc/SpecialBuilds.txt’ in the Python source distribution.  Builds are
available that support tracing of reference counts, debugging the memory
allocator, or low-level profiling of the main interpreter loop.  Only
the most frequently-used builds will be described in the remainder of
this section.

Compiling the interpreter with the ‘Py_DEBUG’ macro defined produces
what is generally meant by "a debug build" of Python.  ‘Py_DEBUG’ is
enabled in the Unix build by adding ‘--with-pydebug’ to the
‘./configure’ command.  It is also implied by the presence of the
not-Python-specific ‘_DEBUG’ macro.  When ‘Py_DEBUG’ is enabled in the
Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, the
following extra checks are performed:

   * Extra checks are added to the object allocator.

   * Extra checks are added to the parser and compiler.

   * Downcasts from wide types to narrow types are checked for loss of
     information.

   * A number of assertions are added to the dictionary and set
     implementations.  In addition, the set object acquires a
     ‘test_c_api()’ method.

   * Sanity checks of the input arguments are added to frame creation.

   * The storage for ints is initialized with a known invalid pattern to
     catch reference to uninitialized digits.

   * Low-level tracing and extra exception checking are added to the
     runtime virtual machine.

   * Extra checks are added to the memory arena implementation.

   * Extra debugging is added to the thread module.

There may be additional checks not mentioned here.

Defining ‘Py_TRACE_REFS’ enables reference tracing.  When defined, a
circular doubly linked list of active objects is maintained by adding
two extra fields to every *note PyObject: 9f5.  Total allocations are
tracked as well.  Upon exit, all existing references are printed.  (In
interactive mode this happens after every statement run by the
interpreter.)  Implied by ‘Py_DEBUG’.

Please refer to ‘Misc/SpecialBuilds.txt’ in the Python source
distribution for more detailed information.


File: python.info,  Node: Stable Application Binary Interface,  Next: The Very High Level Layer,  Prev: Introduction<13>,  Up: Python/C API Reference Manual

7.2 Stable Application Binary Interface
=======================================

Traditionally, the C API of Python will change with every release.  Most
changes will be source-compatible, typically by only adding API, rather
than changing existing API or removing API (although some interfaces do
get removed after being deprecated first).

Unfortunately, the API compatibility does not extend to binary
compatibility (the ABI). The reason is primarily the evolution of struct
definitions, where addition of a new field, or changing the type of a
field, might not break the API, but can break the ABI. As a consequence,
extension modules need to be recompiled for every Python release
(although an exception is possible on Unix when none of the affected
interfaces are used).  In addition, on Windows, extension modules link
with a specific pythonXY.dll and need to be recompiled to link with a
newer one.

Since Python 3.2, a subset of the API has been declared to guarantee a
stable ABI. Extension modules wishing to use this API (called "limited
API") need to define ‘Py_LIMITED_API’.  A number of interpreter details
then become hidden from the extension module; in return, a module is
built that works on any 3.x version (x>=2) without recompilation.

In some cases, the stable ABI needs to be extended with new functions.
Extension modules wishing to use these new APIs need to set
‘Py_LIMITED_API’ to the ‘PY_VERSION_HEX’ value (see *note API and ABI
Versioning: 2e35.) of the minimum Python version they want to support
(e.g.  ‘0x03030000’ for Python 3.3).  Such modules will work on all
subsequent Python releases, but fail to load (because of missing
symbols) on the older releases.

As of Python 3.2, the set of functions available to the limited API is
documented in PEP 384(1).  In the C API documentation, API elements that
are not part of the limited API are marked as "Not part of the limited
API."

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0384


File: python.info,  Node: The Very High Level Layer,  Next: Reference Counting,  Prev: Stable Application Binary Interface,  Up: Python/C API Reference Manual

7.3 The Very High Level Layer
=============================

The functions in this chapter will let you execute Python source code
given in a file or a buffer, but they will not let you interact in a
more detailed way with the interpreter.

Several of these functions accept a start symbol from the grammar as a
parameter.  The available start symbols are ‘Py_eval_input’,
‘Py_file_input’, and ‘Py_single_input’.  These are described following
the functions which accept them as parameters.

Note also that several of these functions take ‘FILE*’ parameters.  One
particular issue which needs to be handled carefully is that the ‘FILE’
structure for different C libraries can be different and incompatible.
Under Windows (at least), it is possible for dynamically linked
extensions to actually use different libraries, so care should be taken
that ‘FILE*’ parameters are only passed to these functions if it is
certain that they were created by the same library that the Python
runtime is using.

 -- C Function: int Py_Main (int argc, wchar_t **argv)

     The main program for the standard interpreter.  This is made
     available for programs which embed Python.  The `argc' and `argv'
     parameters should be prepared exactly as those which are passed to
     a C program’s ‘main()’ function (converted to wchar_t according to
     the user’s locale).  It is important to note that the argument list
     may be modified (but the contents of the strings pointed to by the
     argument list are not).  The return value will be ‘0’ if the
     interpreter exits normally (i.e., without an exception), ‘1’ if the
     interpreter exits due to an exception, or ‘2’ if the parameter list
     does not represent a valid Python command line.

     Note that if an otherwise unhandled *note SystemExit: 1a2. is
     raised, this function will not return ‘1’, but exit the process, as
     long as ‘Py_InspectFlag’ is not set.

 -- C Function: int PyRun_AnyFile (FILE *fp, const char *filename)

     This is a simplified interface to *note PyRun_AnyFileExFlags():
     33ba. below, leaving `closeit' set to ‘0’ and `flags' set to
     `NULL'.

 -- C Function: int PyRun_AnyFileFlags (FILE *fp, const char *filename,
          PyCompilerFlags *flags)

     This is a simplified interface to *note PyRun_AnyFileExFlags():
     33ba. below, leaving the `closeit' argument set to ‘0’.

 -- C Function: int PyRun_AnyFileEx (FILE *fp, const char *filename,
          int closeit)

     This is a simplified interface to *note PyRun_AnyFileExFlags():
     33ba. below, leaving the `flags' argument set to `NULL'.

 -- C Function: int PyRun_AnyFileExFlags (FILE *fp, const
          char *filename, int closeit, PyCompilerFlags *flags)

     If `fp' refers to a file associated with an interactive device
     (console or terminal input or Unix pseudo-terminal), return the
     value of *note PyRun_InteractiveLoop(): 33bd, otherwise return the
     result of *note PyRun_SimpleFile(): 3383.  `filename' is decoded
     from the filesystem encoding (*note sys.getfilesystemencoding():
     1758.).  If `filename' is `NULL', this function uses ‘"???"’ as the
     filename.

 -- C Function: int PyRun_SimpleString (const char *command)

     This is a simplified interface to *note PyRun_SimpleStringFlags():
     33be. below, leaving the `PyCompilerFlags*' argument set to NULL.

 -- C Function: int PyRun_SimpleStringFlags (const char *command,
          PyCompilerFlags *flags)

     Executes the Python source code from `command' in the *note
     __main__: 1. module according to the `flags' argument.  If *note
     __main__: 1. does not already exist, it is created.  Returns ‘0’ on
     success or ‘-1’ if an exception was raised.  If there was an error,
     there is no way to get the exception information.  For the meaning
     of `flags', see below.

     Note that if an otherwise unhandled *note SystemExit: 1a2. is
     raised, this function will not return ‘-1’, but exit the process,
     as long as ‘Py_InspectFlag’ is not set.

 -- C Function: int PyRun_SimpleFile (FILE *fp, const char *filename)

     This is a simplified interface to *note PyRun_SimpleFileExFlags():
     33bf. below, leaving `closeit' set to ‘0’ and `flags' set to
     `NULL'.

 -- C Function: int PyRun_SimpleFileEx (FILE *fp, const char *filename,
          int closeit)

     This is a simplified interface to *note PyRun_SimpleFileExFlags():
     33bf. below, leaving `flags' set to `NULL'.

 -- C Function: int PyRun_SimpleFileExFlags (FILE *fp, const
          char *filename, int closeit, PyCompilerFlags *flags)

     Similar to *note PyRun_SimpleStringFlags(): 33be, but the Python
     source code is read from `fp' instead of an in-memory string.
     `filename' should be the name of the file, it is decoded from the
     filesystem encoding (*note sys.getfilesystemencoding(): 1758.).  If
     `closeit' is true, the file is closed before
     PyRun_SimpleFileExFlags returns.

 -- C Function: int PyRun_InteractiveOne (FILE *fp, const
          char *filename)

     This is a simplified interface to *note
     PyRun_InteractiveOneFlags(): 33c2. below, leaving `flags' set to
     `NULL'.

 -- C Function: int PyRun_InteractiveOneFlags (FILE *fp, const
          char *filename, PyCompilerFlags *flags)

     Read and execute a single statement from a file associated with an
     interactive device according to the `flags' argument.  The user
     will be prompted using ‘sys.ps1’ and ‘sys.ps2’.  `filename' is
     decoded from the filesystem encoding (*note
     sys.getfilesystemencoding(): 1758.).

     Returns ‘0’ when the input was executed successfully, ‘-1’ if there
     was an exception, or an error code from the ‘errcode.h’ include
     file distributed as part of Python if there was a parse error.
     (Note that ‘errcode.h’ is not included by ‘Python.h’, so must be
     included specifically if needed.)

 -- C Function: int PyRun_InteractiveLoop (FILE *fp, const
          char *filename)

     This is a simplified interface to *note
     PyRun_InteractiveLoopFlags(): 33c3. below, leaving `flags' set to
     `NULL'.

 -- C Function: int PyRun_InteractiveLoopFlags (FILE *fp, const
          char *filename, PyCompilerFlags *flags)

     Read and execute statements from a file associated with an
     interactive device until EOF is reached.  The user will be prompted
     using ‘sys.ps1’ and ‘sys.ps2’.  `filename' is decoded from the
     filesystem encoding (*note sys.getfilesystemencoding(): 1758.).
     Returns ‘0’ at EOF.

 -- C Variable: int (*PyOS_InputHook) (void)

     Can be set to point to a function with the prototype ‘int
     func(void)’.  The function will be called when Python’s interpreter
     prompt is about to become idle and wait for user input from the
     terminal.  The return value is ignored.  Overriding this hook can
     be used to integrate the interpreter’s prompt with other event
     loops, as done in the ‘Modules/_tkinter.c’ in the Python source
     code.

 -- C Variable: char* (*PyOS_ReadlineFunctionPointer) (FILE *, FILE *,
          const char *)

     Can be set to point to a function with the prototype ‘char
     *func(FILE *stdin, FILE *stdout, char *prompt)’, overriding the
     default function used to read a single line of input at the
     interpreter’s prompt.  The function is expected to output the
     string `prompt' if it’s not `NULL', and then read a line of input
     from the provided standard input file, returning the resulting
     string.  For example, The *note readline: dc. module sets this hook
     to provide line-editing and tab-completion features.

     The result must be a string allocated by *note PyMem_RawMalloc():
     58b. or *note PyMem_RawRealloc(): 58c, or `NULL' if an error
     occurred.

     Changed in version 3.4: The result must be allocated by *note
     PyMem_RawMalloc(): 58b. or *note PyMem_RawRealloc(): 58c, instead
     of being allocated by *note PyMem_Malloc(): 152. or *note
     PyMem_Realloc(): 58d.

 -- C Function: struct _node* PyParser_SimpleParseString (const
          char *str, int start)

     This is a simplified interface to *note
     PyParser_SimpleParseStringFlagsFilename(): 33c6. below, leaving
     `filename' set to `NULL' and `flags' set to ‘0’.

 -- C Function: struct _node* PyParser_SimpleParseStringFlags (const
          char *str, int start, int flags)

     This is a simplified interface to *note
     PyParser_SimpleParseStringFlagsFilename(): 33c6. below, leaving
     `filename' set to `NULL'.

 -- C Function: struct _node* PyParser_SimpleParseStringFlagsFilename
          (const char *str, const char *filename, int start, int flags)

     Parse Python source code from `str' using the start token `start'
     according to the `flags' argument.  The result can be used to
     create a code object which can be evaluated efficiently.  This is
     useful if a code fragment must be evaluated many times.  `filename'
     is decoded from the filesystem encoding (*note
     sys.getfilesystemencoding(): 1758.).

 -- C Function: struct _node* PyParser_SimpleParseFile (FILE *fp, const
          char *filename, int start)

     This is a simplified interface to *note
     PyParser_SimpleParseFileFlags(): 33c9. below, leaving `flags' set
     to ‘0’.

 -- C Function: struct _node* PyParser_SimpleParseFileFlags (FILE *fp,
          const char *filename, int start, int flags)

     Similar to *note PyParser_SimpleParseStringFlagsFilename(): 33c6,
     but the Python source code is read from `fp' instead of an
     in-memory string.

 -- C Function: PyObject* PyRun_String (const char *str, int start,
          PyObject *globals, PyObject *locals)
     `Return value: New reference.'  This is a simplified interface to
     *note PyRun_StringFlags(): 33cb. below, leaving `flags' set to
     `NULL'.

 -- C Function: PyObject* PyRun_StringFlags (const char *str, int start,
          PyObject *globals, PyObject *locals, PyCompilerFlags *flags)
     `Return value: New reference.'  Execute Python source code from
     `str' in the context specified by the dictionaries `globals' and
     `locals' with the compiler flags specified by `flags'.  The
     parameter `start' specifies the start token that should be used to
     parse the source code.

     Returns the result of executing the code as a Python object, or
     `NULL' if an exception was raised.

 -- C Function: PyObject* PyRun_File (FILE *fp, const char *filename,
          int start, PyObject *globals, PyObject *locals)
     `Return value: New reference.'  This is a simplified interface to
     *note PyRun_FileExFlags(): 33cd. below, leaving `closeit' set to
     ‘0’ and `flags' set to `NULL'.

 -- C Function: PyObject* PyRun_FileEx (FILE *fp, const char *filename,
          int start, PyObject *globals, PyObject *locals, int closeit)
     `Return value: New reference.'  This is a simplified interface to
     *note PyRun_FileExFlags(): 33cd. below, leaving `flags' set to
     `NULL'.

 -- C Function: PyObject* PyRun_FileFlags (FILE *fp, const
          char *filename, int start, PyObject *globals,
          PyObject *locals, PyCompilerFlags *flags)
     `Return value: New reference.'  This is a simplified interface to
     *note PyRun_FileExFlags(): 33cd. below, leaving `closeit' set to
     ‘0’.

 -- C Function: PyObject* PyRun_FileExFlags (FILE *fp, const
          char *filename, int start, PyObject *globals,
          PyObject *locals, int closeit, PyCompilerFlags *flags)
     `Return value: New reference.'  Similar to *note
     PyRun_StringFlags(): 33cb, but the Python source code is read from
     `fp' instead of an in-memory string.  `filename' should be the name
     of the file, it is decoded from the filesystem encoding (*note
     sys.getfilesystemencoding(): 1758.).  If `closeit' is true, the
     file is closed before *note PyRun_FileExFlags(): 33cd. returns.

 -- C Function: PyObject* Py_CompileString (const char *str, const
          char *filename, int start)
     `Return value: New reference.'  This is a simplified interface to
     *note Py_CompileStringFlags(): 33d1. below, leaving `flags' set to
     `NULL'.

 -- C Function: PyObject* Py_CompileStringFlags (const char *str, const
          char *filename, int start, PyCompilerFlags *flags)
     `Return value: New reference.'  This is a simplified interface to
     *note Py_CompileStringExFlags(): 33d2. below, with `optimize' set
     to ‘-1’.

 -- C Function: PyObject* Py_CompileStringObject (const char *str,
          PyObject *filename, int start, PyCompilerFlags *flags,
          int optimize)

     Parse and compile the Python source code in `str', returning the
     resulting code object.  The start token is given by `start'; this
     can be used to constrain the code which can be compiled and should
     be ‘Py_eval_input’, ‘Py_file_input’, or ‘Py_single_input’.  The
     filename specified by `filename' is used to construct the code
     object and may appear in tracebacks or *note SyntaxError: 3a6.
     exception messages.  This returns `NULL' if the code cannot be
     parsed or compiled.

     The integer `optimize' specifies the optimization level of the
     compiler; a value of ‘-1’ selects the optimization level of the
     interpreter as given by *note -O: 221. options.  Explicit levels
     are ‘0’ (no optimization; ‘__debug__’ is true), ‘1’ (asserts are
     removed, ‘__debug__’ is false) or ‘2’ (docstrings are removed too).

     New in version 3.4.

 -- C Function: PyObject* Py_CompileStringExFlags (const char *str,
          const char *filename, int start, PyCompilerFlags *flags,
          int optimize)

     Like *note Py_CompileStringExFlags(): 33d2, but `filename' is a
     byte string decoded from the filesystem encoding (*note
     os.fsdecode(): 7eb.).

     New in version 3.2.

 -- C Function: PyObject* PyEval_EvalCode (PyObject *co,
          PyObject *globals, PyObject *locals)
     `Return value: New reference.'  This is a simplified interface to
     *note PyEval_EvalCodeEx(): 33d5, with just the code object, and the
     dictionaries of global and local variables.  The other arguments
     are set to `NULL'.

 -- C Function: PyObject* PyEval_EvalCodeEx (PyObject *co,
          PyObject *globals, PyObject *locals, PyObject **args,
          int argcount, PyObject **kws, int kwcount, PyObject **defs,
          int defcount, PyObject *closure)

     Evaluate a precompiled code object, given a particular environment
     for its evaluation.  This environment consists of dictionaries of
     global and local variables, arrays of arguments, keywords and
     defaults, and a closure tuple of cells.

 -- C Type: PyFrameObject

     The C structure of the objects used to describe frame objects.  The
     fields of this type are subject to change at any time.

 -- C Function: PyObject* PyEval_EvalFrame (PyFrameObject *f)

     Evaluate an execution frame.  This is a simplified interface to
     *note PyEval_EvalFrameEx(): 584, for backward compatibility.

 -- C Function: PyObject* PyEval_EvalFrameEx (PyFrameObject *f,
          int throwflag)

     This is the main, unvarnished function of Python interpretation.
     It is literally 2000 lines long.  The code object associated with
     the execution frame `f' is executed, interpreting bytecode and
     executing calls as needed.  The additional `throwflag' parameter
     can mostly be ignored - if true, then it causes an exception to
     immediately be thrown; this is used for the *note throw(): e56.
     methods of generator objects.

     Changed in version 3.4: This function now includes a debug
     assertion to help ensure that it does not silently discard an
     active exception.

 -- C Function: int PyEval_MergeCompilerFlags (PyCompilerFlags *cf)

     This function changes the flags of the current evaluation frame,
     and returns true on success, false on failure.

 -- C Variable: int Py_eval_input

     The start symbol from the Python grammar for isolated expressions;
     for use with *note Py_CompileString(): 33d0.

 -- C Variable: int Py_file_input

     The start symbol from the Python grammar for sequences of
     statements as read from a file or other source; for use with *note
     Py_CompileString(): 33d0.  This is the symbol to use when compiling
     arbitrarily long Python source code.

 -- C Variable: int Py_single_input

     The start symbol from the Python grammar for a single statement;
     for use with *note Py_CompileString(): 33d0.  This is the symbol
     used for the interactive interpreter loop.

 -- C Type: struct PyCompilerFlags

     This is the structure used to hold compiler flags.  In cases where
     code is only being compiled, it is passed as ‘int flags’, and in
     cases where code is being executed, it is passed as
     ‘PyCompilerFlags *flags’.  In this case, ‘from __future__ import’
     can modify `flags'.

     Whenever ‘PyCompilerFlags *flags’ is `NULL', ‘cf_flags’ is treated
     as equal to ‘0’, and any modification due to ‘from __future__
     import’ is discarded.

          struct PyCompilerFlags {
              int cf_flags;
          }

 -- C Variable: int CO_FUTURE_DIVISION

     This bit can be set in `flags' to cause division operator ‘/’ to be
     interpreted as "true division" according to PEP 238(1).

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0238


File: python.info,  Node: Reference Counting,  Next: Exception Handling,  Prev: The Very High Level Layer,  Up: Python/C API Reference Manual

7.4 Reference Counting
======================

The macros in this section are used for managing reference counts of
Python objects.

 -- C Function: void Py_INCREF (PyObject *o)

     Increment the reference count for object `o'.  The object must not
     be `NULL'; if you aren’t sure that it isn’t `NULL', use *note
     Py_XINCREF(): 330c.

 -- C Function: void Py_XINCREF (PyObject *o)

     Increment the reference count for object `o'.  The object may be
     `NULL', in which case the macro has no effect.

 -- C Function: void Py_DECREF (PyObject *o)

     Decrement the reference count for object `o'.  The object must not
     be `NULL'; if you aren’t sure that it isn’t `NULL', use *note
     Py_XDECREF(): 32fc.  If the reference count reaches zero, the
     object’s type’s deallocation function (which must not be `NULL') is
     invoked.

          Warning: The deallocation function can cause arbitrary Python
          code to be invoked (e.g.  when a class instance with a *note
          __del__(): 525. method is deallocated).  While exceptions in
          such code are not propagated, the executed code has free
          access to all Python global variables.  This means that any
          object that is reachable from a global variable should be in a
          consistent state before *note Py_DECREF(): 32fd. is invoked.
          For example, code to delete an object from a list should copy
          a reference to the deleted object in a temporary variable,
          update the list data structure, and then call *note
          Py_DECREF(): 32fd. for the temporary variable.

 -- C Function: void Py_XDECREF (PyObject *o)

     Decrement the reference count for object `o'.  The object may be
     `NULL', in which case the macro has no effect; otherwise the effect
     is the same as for *note Py_DECREF(): 32fd, and the same warning
     applies.

 -- C Function: void Py_CLEAR (PyObject *o)

     Decrement the reference count for object `o'.  The object may be
     `NULL', in which case the macro has no effect; otherwise the effect
     is the same as for *note Py_DECREF(): 32fd, except that the
     argument is also set to `NULL'. The warning for *note Py_DECREF():
     32fd. does not apply with respect to the object passed because the
     macro carefully uses a temporary variable and sets the argument to
     `NULL' before decrementing its reference count.

     It is a good idea to use this macro whenever decrementing the value
     of a variable that might be traversed during garbage collection.

The following functions are for runtime dynamic embedding of Python:
‘Py_IncRef(PyObject *o)’, ‘Py_DecRef(PyObject *o)’.  They are simply
exported function versions of *note Py_XINCREF(): 330c. and *note
Py_XDECREF(): 32fc, respectively.

The following functions or macros are only for use within the
interpreter core: ‘_Py_Dealloc()’, ‘_Py_ForgetReference()’,
‘_Py_NewReference()’, as well as the global variable ‘_Py_RefTotal’.


File: python.info,  Node: Exception Handling,  Next: Utilities<2>,  Prev: Reference Counting,  Up: Python/C API Reference Manual

7.5 Exception Handling
======================

The functions described in this chapter will let you handle and raise
Python exceptions.  It is important to understand some of the basics of
Python exception handling.  It works somewhat like the POSIX ‘errno’
variable: there is a global indicator (per thread) of the last error
that occurred.  Most C API functions don’t clear this on success, but
will set it to indicate the cause of the error on failure.  Most C API
functions also return an error indicator, usually `NULL' if they are
supposed to return a pointer, or ‘-1’ if they return an integer
(exception: the ‘PyArg_*()’ functions return ‘1’ for success and ‘0’ for
failure).

Concretely, the error indicator consists of three object pointers: the
exception’s type, the exception’s value, and the traceback object.  Any
of those pointers can be NULL if non-set (although some combinations are
forbidden, for example you can’t have a non-NULL traceback if the
exception type is NULL).

When a function must fail because some function it called failed, it
generally doesn’t set the error indicator; the function it called
already set it.  It is responsible for either handling the error and
clearing the exception or returning after cleaning up any resources it
holds (such as object references or memory allocations); it should `not'
continue normally if it is not prepared to handle the error.  If
returning due to an error, it is important to indicate to the caller
that an error has been set.  If the error is not handled or carefully
propagated, additional calls into the Python/C API may not behave as
intended and may fail in mysterious ways.

     Note: The error indicator is `not' the result of *note
     sys.exc_info(): 8ca.  The former corresponds to an exception that
     is not yet caught (and is therefore still propagating), while the
     latter returns an exception after it is caught (and has therefore
     stopped propagating).

* Menu:

* Printing and clearing:: 
* Raising exceptions:: 
* Issuing warnings:: 
* Querying the error indicator:: 
* Signal Handling: Signal Handling<2>. 
* Exception Classes:: 
* Exception Objects:: 
* Unicode Exception Objects:: 
* Recursion Control:: 
* Standard Exceptions:: 


File: python.info,  Node: Printing and clearing,  Next: Raising exceptions,  Up: Exception Handling

7.5.1 Printing and clearing
---------------------------

 -- C Function: void PyErr_Clear ()

     Clear the error indicator.  If the error indicator is not set,
     there is no effect.

 -- C Function: void PyErr_PrintEx (int set_sys_last_vars)

     Print a standard traceback to ‘sys.stderr’ and clear the error
     indicator.  Call this function only when the error indicator is
     set.  (Otherwise it will cause a fatal error!)

     If `set_sys_last_vars' is nonzero, the variables *note
     sys.last_type: 8c3, *note sys.last_value: 2e36. and *note
     sys.last_traceback: 2d1b. will be set to the type, value and
     traceback of the printed exception, respectively.

 -- C Function: void PyErr_Print ()

     Alias for ‘PyErr_PrintEx(1)’.

 -- C Function: void PyErr_WriteUnraisable (PyObject *obj)

     This utility function prints a warning message to ‘sys.stderr’ when
     an exception has been set but it is impossible for the interpreter
     to actually raise the exception.  It is used, for example, when an
     exception occurs in an *note __del__(): 525. method.

     The function is called with a single argument `obj' that identifies
     the context in which the unraisable exception occurred.  If
     possible, the repr of `obj' will be printed in the warning message.


File: python.info,  Node: Raising exceptions,  Next: Issuing warnings,  Prev: Printing and clearing,  Up: Exception Handling

7.5.2 Raising exceptions
------------------------

These functions help you set the current thread’s error indicator.  For
convenience, some of these functions will always return a NULL pointer
for use in a ‘return’ statement.

 -- C Function: void PyErr_SetString (PyObject *type, const
          char *message)

     This is the most common way to set the error indicator.  The first
     argument specifies the exception type; it is normally one of the
     standard exceptions, e.g.  ‘PyExc_RuntimeError’.  You need not
     increment its reference count.  The second argument is an error
     message; it is decoded from ‘'utf-8’’.

 -- C Function: void PyErr_SetObject (PyObject *type, PyObject *value)

     This function is similar to *note PyErr_SetString(): 32f5. but lets
     you specify an arbitrary Python object for the "value" of the
     exception.

 -- C Function: PyObject* PyErr_Format (PyObject *exception, const
          char *format, ...)
     `Return value: Always NULL.' This function sets the error indicator
     and returns `NULL'. `exception' should be a Python exception class.
     The `format' and subsequent parameters help format the error
     message; they have the same meaning and values as in *note
     PyUnicode_FromFormat(): 3ba.  `format' is an ASCII-encoded string.

 -- C Function: PyObject* PyErr_FormatV (PyObject *exception, const
          char *format, va_list vargs)
     `Return value: Always NULL.' Same as *note PyErr_Format(): 385, but
     taking a ‘va_list’ argument rather than a variable number of
     arguments.

     New in version 3.5.

 -- C Function: void PyErr_SetNone (PyObject *type)

     This is a shorthand for ‘PyErr_SetObject(type, Py_None)’.

 -- C Function: int PyErr_BadArgument ()

     This is a shorthand for ‘PyErr_SetString(PyExc_TypeError,
     message)’, where `message' indicates that a built-in operation was
     invoked with an illegal argument.  It is mostly for internal use.

 -- C Function: PyObject* PyErr_NoMemory ()
     `Return value: Always NULL.' This is a shorthand for
     ‘PyErr_SetNone(PyExc_MemoryError)’; it returns `NULL' so an object
     allocation function can write ‘return PyErr_NoMemory();’ when it
     runs out of memory.

 -- C Function: PyObject* PyErr_SetFromErrno (PyObject *type)
     `Return value: Always NULL.'

     This is a convenience function to raise an exception when a C
     library function has returned an error and set the C variable
     ‘errno’.  It constructs a tuple object whose first item is the
     integer ‘errno’ value and whose second item is the corresponding
     error message (gotten from ‘strerror()’), and then calls
     ‘PyErr_SetObject(type, object)’.  On Unix, when the ‘errno’ value
     is ‘EINTR’, indicating an interrupted system call, this calls *note
     PyErr_CheckSignals(): 33e9, and if that set the error indicator,
     leaves it set to that.  The function always returns `NULL', so a
     wrapper function around a system call can write ‘return
     PyErr_SetFromErrno(type);’ when the system call returns an error.

 -- C Function: PyObject* PyErr_SetFromErrnoWithFilenameObject
          (PyObject *type, PyObject *filenameObject)

     Similar to *note PyErr_SetFromErrno(): 32f6, with the additional
     behavior that if `filenameObject' is not `NULL', it is passed to
     the constructor of `type' as a third parameter.  In the case of
     *note OSError: 4b6. exception, this is used to define the
     ‘filename’ attribute of the exception instance.

 -- C Function: PyObject* PyErr_SetFromErrnoWithFilenameObjects
          (PyObject *type, PyObject *filenameObject,
          PyObject *filenameObject2)

     Similar to *note PyErr_SetFromErrnoWithFilenameObject(): 33ea, but
     takes a second filename object, for raising errors when a function
     that takes two filenames fails.

     New in version 3.4.

 -- C Function: PyObject* PyErr_SetFromErrnoWithFilename
          (PyObject *type, const char *filename)
     `Return value: Always NULL.' Similar to *note
     PyErr_SetFromErrnoWithFilenameObject(): 33ea, but the filename is
     given as a C string.  `filename' is decoded from the filesystem
     encoding (*note os.fsdecode(): 7eb.).

 -- C Function: PyObject* PyErr_SetFromWindowsErr (int ierr)
     `Return value: Always NULL.' This is a convenience function to
     raise *note WindowsError: 5b2.  If called with `ierr' of ‘0’, the
     error code returned by a call to ‘GetLastError()’ is used instead.
     It calls the Win32 function ‘FormatMessage()’ to retrieve the
     Windows description of error code given by `ierr' or
     ‘GetLastError()’, then it constructs a tuple object whose first
     item is the `ierr' value and whose second item is the corresponding
     error message (gotten from ‘FormatMessage()’), and then calls
     ‘PyErr_SetObject(PyExc_WindowsError, object)’.  This function
     always returns `NULL'. Availability: Windows.

 -- C Function: PyObject* PyErr_SetExcFromWindowsErr (PyObject *type,
          int ierr)
     `Return value: Always NULL.' Similar to *note
     PyErr_SetFromWindowsErr(): 33ed, with an additional parameter
     specifying the exception type to be raised.  Availability: Windows.

 -- C Function: PyObject* PyErr_SetFromWindowsErrWithFilename (int ierr,
          const char *filename)
     `Return value: Always NULL.' Similar to
     ‘PyErr_SetFromWindowsErrWithFilenameObject()’, but the filename is
     given as a C string.  `filename' is decoded from the filesystem
     encoding (*note os.fsdecode(): 7eb.).  Availability: Windows.

 -- C Function: PyObject* PyErr_SetExcFromWindowsErrWithFilenameObject
          (PyObject *type, int ierr, PyObject *filename)

     Similar to ‘PyErr_SetFromWindowsErrWithFilenameObject()’, with an
     additional parameter specifying the exception type to be raised.
     Availability: Windows.

 -- C Function: PyObject* PyErr_SetExcFromWindowsErrWithFilenameObjects
          (PyObject *type, int ierr, PyObject *filename,
          PyObject *filename2)

     Similar to *note PyErr_SetExcFromWindowsErrWithFilenameObject():
     33f0, but accepts a second filename object.  Availability: Windows.

     New in version 3.4.

 -- C Function: PyObject* PyErr_SetExcFromWindowsErrWithFilename
          (PyObject *type, int ierr, const char *filename)
     `Return value: Always NULL.' Similar to *note
     PyErr_SetFromWindowsErrWithFilename(): 33ef, with an additional
     parameter specifying the exception type to be raised.
     Availability: Windows.

 -- C Function: PyObject* PyErr_SetImportError (PyObject *msg,
          PyObject *name, PyObject *path)

     This is a convenience function to raise *note ImportError: 19f.
     `msg' will be set as the exception’s message string.  `name' and
     `path', both of which can be ‘NULL’, will be set as the *note
     ImportError: 19f.’s respective ‘name’ and ‘path’ attributes.

     New in version 3.3.

 -- C Function: void PyErr_SyntaxLocationObject (PyObject *filename,
          int lineno, int col_offset)

     Set file, line, and offset information for the current exception.
     If the current exception is not a *note SyntaxError: 3a6, then it
     sets additional attributes, which make the exception printing
     subsystem think the exception is a *note SyntaxError: 3a6.

     New in version 3.4.

 -- C Function: void PyErr_SyntaxLocationEx (const char *filename,
          int lineno, int col_offset)

     Like *note PyErr_SyntaxLocationObject(): 33f3, but `filename' is a
     byte string decoded from the filesystem encoding (*note
     os.fsdecode(): 7eb.).

     New in version 3.2.

 -- C Function: void PyErr_SyntaxLocation (const char *filename,
          int lineno)

     Like *note PyErr_SyntaxLocationEx(): 33f4, but the col_offset
     parameter is omitted.

 -- C Function: void PyErr_BadInternalCall ()

     This is a shorthand for ‘PyErr_SetString(PyExc_SystemError,
     message)’, where `message' indicates that an internal operation
     (e.g.  a Python/C API function) was invoked with an illegal
     argument.  It is mostly for internal use.


File: python.info,  Node: Issuing warnings,  Next: Querying the error indicator,  Prev: Raising exceptions,  Up: Exception Handling

7.5.3 Issuing warnings
----------------------

Use these functions to issue warnings from C code.  They mirror similar
functions exported by the Python *note warnings: 123. module.  They
normally print a warning message to `sys.stderr'; however, it is also
possible that the user has specified that warnings are to be turned into
errors, and in that case they will raise an exception.  It is also
possible that the functions raise an exception because of a problem with
the warning machinery.  The return value is ‘0’ if no exception is
raised, or ‘-1’ if an exception is raised.  (It is not possible to
determine whether a warning message is actually printed, nor what the
reason is for the exception; this is intentional.)  If an exception is
raised, the caller should do its normal exception handling (for example,
*note Py_DECREF(): 32fd. owned references and return an error value).

 -- C Function: int PyErr_WarnEx (PyObject *category, const
          char *message, Py_ssize_t stack_level)

     Issue a warning message.  The `category' argument is a warning
     category (see below) or `NULL'; the `message' argument is a UTF-8
     encoded string.  `stack_level' is a positive number giving a number
     of stack frames; the warning will be issued from the currently
     executing line of code in that stack frame.  A `stack_level' of 1
     is the function calling *note PyErr_WarnEx(): a2d, 2 is the
     function above that, and so forth.

     Warning categories must be subclasses of ‘Warning’; the default
     warning category is ‘RuntimeWarning’.  The standard Python warning
     categories are available as global variables whose names are
     ‘PyExc_’ followed by the Python exception name.  These have the
     type *note PyObject*: 9f5.; they are all class objects.  Their
     names are ‘PyExc_Warning’, ‘PyExc_UserWarning’,
     ‘PyExc_UnicodeWarning’, ‘PyExc_DeprecationWarning’,
     ‘PyExc_SyntaxWarning’, ‘PyExc_RuntimeWarning’, and
     ‘PyExc_FutureWarning’.  ‘PyExc_Warning’ is a subclass of
     ‘PyExc_Exception’; the other warning categories are subclasses of
     ‘PyExc_Warning’.

     For information about warning control, see the documentation for
     the *note warnings: 123. module and the *note -W: 8eb. option in
     the command line documentation.  There is no C API for warning
     control.

 -- C Function: int PyErr_WarnExplicitObject (PyObject *category,
          PyObject *message, PyObject *filename, int lineno,
          PyObject *module, PyObject *registry)

     Issue a warning message with explicit control over all warning
     attributes.  This is a straightforward wrapper around the Python
     function *note warnings.warn_explicit(): 178, see there for more
     information.  The `module' and `registry' arguments may be set to
     `NULL' to get the default effect described there.

     New in version 3.4.

 -- C Function: int PyErr_WarnExplicit (PyObject *category, const
          char *message, const char *filename, int lineno, const
          char *module, PyObject *registry)

     Similar to *note PyErr_WarnExplicitObject(): 33f8. except that
     `message' and `module' are UTF-8 encoded strings, and `filename' is
     decoded from the filesystem encoding (*note os.fsdecode(): 7eb.).

 -- C Function: int PyErr_WarnFormat (PyObject *category,
          Py_ssize_t stack_level, const char *format, ...)

     Function similar to *note PyErr_WarnEx(): a2d, but use *note
     PyUnicode_FromFormat(): 3ba. to format the warning message.
     `format' is an ASCII-encoded string.

     New in version 3.2.

 -- C Function: int PyErr_ResourceWarning (PyObject *source,
          Py_ssize_t stack_level, const char *format, ...)

     Function similar to *note PyErr_WarnFormat(): 33fa, but `category'
     is *note ResourceWarning: 166. and pass `source' to
     ‘warnings.WarningMessage()’.

     New in version 3.6.


File: python.info,  Node: Querying the error indicator,  Next: Signal Handling<2>,  Prev: Issuing warnings,  Up: Exception Handling

7.5.4 Querying the error indicator
----------------------------------

 -- C Function: PyObject* PyErr_Occurred ()
     `Return value: Borrowed reference.'  Test whether the error
     indicator is set.  If set, return the exception `type' (the first
     argument to the last call to one of the ‘PyErr_Set*()’ functions or
     to *note PyErr_Restore(): 3352.).  If not set, return `NULL'. You
     do not own a reference to the return value, so you do not need to
     *note Py_DECREF(): 32fd. it.

          Note: Do not compare the return value to a specific exception;
          use *note PyErr_ExceptionMatches(): 33a8. instead, shown
          below.  (The comparison could easily fail since the exception
          may be an instance instead of a class, in the case of a class
          exception, or it may be a subclass of the expected exception.)

 -- C Function: int PyErr_ExceptionMatches (PyObject *exc)

     Equivalent to ‘PyErr_GivenExceptionMatches(PyErr_Occurred(), exc)’.
     This should only be called when an exception is actually set; a
     memory access violation will occur if no exception has been raised.

 -- C Function: int PyErr_GivenExceptionMatches (PyObject *given,
          PyObject *exc)

     Return true if the `given' exception matches the exception type in
     `exc'.  If `exc' is a class object, this also returns true when
     `given' is an instance of a subclass.  If `exc' is a tuple, all
     exception types in the tuple (and recursively in subtuples) are
     searched for a match.

 -- C Function: void PyErr_Fetch (PyObject **ptype, PyObject **pvalue,
          PyObject **ptraceback)

     Retrieve the error indicator into three variables whose addresses
     are passed.  If the error indicator is not set, set all three
     variables to `NULL'. If it is set, it will be cleared and you own a
     reference to each object retrieved.  The value and traceback object
     may be `NULL' even when the type object is not.

          Note: This function is normally only used by code that needs
          to catch exceptions or by code that needs to save and restore
          the error indicator temporarily, e.g.:

               {
                  PyObject **type, **value, **traceback;
                  PyErr_Fetch(&type, &value, &traceback);

                  /* ... code that might produce other errors ... */

                  PyErr_Restore(type, value, traceback);
               }

 -- C Function: void PyErr_Restore (PyObject *type, PyObject *value,
          PyObject *traceback)

     Set the error indicator from the three objects.  If the error
     indicator is already set, it is cleared first.  If the objects are
     `NULL', the error indicator is cleared.  Do not pass a `NULL' type
     and non-`NULL' value or traceback.  The exception type should be a
     class.  Do not pass an invalid exception type or value.  (Violating
     these rules will cause subtle problems later.)  This call takes
     away a reference to each object: you must own a reference to each
     object before the call and after the call you no longer own these
     references.  (If you don’t understand this, don’t use this
     function.  I warned you.)

          Note: This function is normally only used by code that needs
          to save and restore the error indicator temporarily.  Use
          *note PyErr_Fetch(): 587. to save the current error indicator.

 -- C Function: void PyErr_NormalizeException (PyObject**exc,
          PyObject**val, PyObject**tb)

     Under certain circumstances, the values returned by *note
     PyErr_Fetch(): 587. below can be "unnormalized", meaning that
     ‘*exc’ is a class object but ‘*val’ is not an instance of the same
     class.  This function can be used to instantiate the class in that
     case.  If the values are already normalized, nothing happens.  The
     delayed normalization is implemented to improve performance.

          Note: This function `does not' implicitly set the
          ‘__traceback__’ attribute on the exception value.  If setting
          the traceback appropriately is desired, the following
          additional snippet is needed:

               if (tb != NULL) {
                 PyException_SetTraceback(val, tb);
               }

 -- C Function: void PyErr_GetExcInfo (PyObject **ptype,
          PyObject **pvalue, PyObject **ptraceback)

     Retrieve the exception info, as known from ‘sys.exc_info()’.  This
     refers to an exception that was `already caught', not to an
     exception that was freshly raised.  Returns new references for the
     three objects, any of which may be `NULL'. Does not modify the
     exception info state.

          Note: This function is not normally used by code that wants to
          handle exceptions.  Rather, it can be used when code needs to
          save and restore the exception state temporarily.  Use *note
          PyErr_SetExcInfo(): 33ff. to restore or clear the exception
          state.

     New in version 3.3.

 -- C Function: void PyErr_SetExcInfo (PyObject *type, PyObject *value,
          PyObject *traceback)

     Set the exception info, as known from ‘sys.exc_info()’.  This
     refers to an exception that was `already caught', not to an
     exception that was freshly raised.  This function steals the
     references of the arguments.  To clear the exception state, pass
     `NULL' for all three arguments.  For general rules about the three
     arguments, see *note PyErr_Restore(): 3352.

          Note: This function is not normally used by code that wants to
          handle exceptions.  Rather, it can be used when code needs to
          save and restore the exception state temporarily.  Use *note
          PyErr_GetExcInfo(): 33fe. to read the exception state.

     New in version 3.3.


File: python.info,  Node: Signal Handling<2>,  Next: Exception Classes,  Prev: Querying the error indicator,  Up: Exception Handling

7.5.5 Signal Handling
---------------------

 -- C Function: int PyErr_CheckSignals ()

     This function interacts with Python’s signal handling.  It checks
     whether a signal has been sent to the processes and if so, invokes
     the corresponding signal handler.  If the *note signal: e8. module
     is supported, this can invoke a signal handler written in Python.
     In all cases, the default effect for ‘SIGINT’ is to raise the *note
     KeyboardInterrupt: 1a3. exception.  If an exception is raised the
     error indicator is set and the function returns ‘-1’; otherwise the
     function returns ‘0’.  The error indicator may or may not be
     cleared if it was previously set.

 -- C Function: void PyErr_SetInterrupt ()

     This function simulates the effect of a ‘SIGINT’ signal arriving —
     the next time *note PyErr_CheckSignals(): 33e9. is called, *note
     KeyboardInterrupt: 1a3. will be raised.  It may be called without
     holding the interpreter lock.

 -- C Function: int PySignal_SetWakeupFd (int fd)

     This utility function specifies a file descriptor to which the
     signal number is written as a single byte whenever a signal is
     received.  `fd' must be non-blocking.  It returns the previous such
     file descriptor.

     The value ‘-1’ disables the feature; this is the initial state.
     This is equivalent to *note signal.set_wakeup_fd(): 307. in Python,
     but without any error checking.  `fd' should be a valid file
     descriptor.  The function should only be called from the main
     thread.

     Changed in version 3.5: On Windows, the function now also supports
     socket handles.

