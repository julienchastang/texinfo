This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: Miscellaneous<3>,  Next: Connection Objects<2>,  Prev: Pipes and Queues,  Up: Reference

5.17.2.11 Miscellaneous
.......................

 -- Function: multiprocessing.active_children ()

     Return list of all live children of the current process.

     Calling this has the side effect of "joining" any processes which
     have already finished.

 -- Function: multiprocessing.cpu_count ()

     Return the number of CPUs in the system.

     This number is not equivalent to the number of CPUs the current
     process can use.  The number of usable CPUs can be obtained with
     ‘len(os.sched_getaffinity(0))’

     May raise *note NotImplementedError: 569.

     See also
     ........

     *note os.cpu_count(): 478.

 -- Function: multiprocessing.current_process ()

     Return the *note Process: 655. object corresponding to the current
     process.

     An analogue of *note threading.current_thread(): 1cb6.

 -- Function: multiprocessing.freeze_support ()

     Add support for when a program which uses *note multiprocessing:
     b6. has been frozen to produce a Windows executable.  (Has been
     tested with `py2exe', `PyInstaller' and `cx_Freeze'.)

     One needs to call this function straight after the ‘if __name__ ==
     '__main__'’ line of the main module.  For example:

          from multiprocessing import Process, freeze_support

          def f():
              print('hello world!')

          if __name__ == '__main__':
              freeze_support()
              Process(target=f).start()

     If the ‘freeze_support()’ line is omitted then trying to run the
     frozen executable will raise *note RuntimeError: 193.

     Calling ‘freeze_support()’ has no effect when invoked on any
     operating system other than Windows.  In addition, if the module is
     being run normally by the Python interpreter on Windows (the
     program has not been frozen), then ‘freeze_support()’ has no
     effect.

 -- Function: multiprocessing.get_all_start_methods ()

     Returns a list of the supported start methods, the first of which
     is the default.  The possible start methods are ‘'fork'’, ‘'spawn'’
     and ‘'forkserver'’.  On Windows only ‘'spawn'’ is available.  On
     Unix ‘'fork'’ and ‘'spawn'’ are always supported, with ‘'fork'’
     being the default.

     New in version 3.4.

 -- Function: multiprocessing.get_context (method=None)

     Return a context object which has the same attributes as the *note
     multiprocessing: b6. module.

     If `method' is `None' then the default context is returned.
     Otherwise `method' should be ‘'fork'’, ‘'spawn'’, ‘'forkserver'’.
     *note ValueError: 19c. is raised if the specified start method is
     not available.

     New in version 3.4.

 -- Function: multiprocessing.get_start_method (allow_none=False)

     Return the name of start method used for starting processes.

     If the start method has not been fixed and `allow_none' is false,
     then the start method is fixed to the default and the name is
     returned.  If the start method has not been fixed and `allow_none'
     is true then `None' is returned.

     The return value can be ‘'fork'’, ‘'spawn'’, ‘'forkserver'’ or
     `None'.  ‘'fork'’ is the default on Unix, while ‘'spawn'’ is the
     default on Windows.

     New in version 3.4.

 -- Function: multiprocessing.set_executable ()

     Sets the path of the Python interpreter to use when starting a
     child process.  (By default *note sys.executable: 1d34. is used).
     Embedders will probably need to do some thing like

          set_executable(os.path.join(sys.exec_prefix, 'pythonw.exe'))

     before they can create child processes.

     Changed in version 3.4: Now supported on Unix when the ‘'spawn'’
     start method is used.

 -- Function: multiprocessing.set_start_method (method)

     Set the method which should be used to start child processes.
     `method' can be ‘'fork'’, ‘'spawn'’ or ‘'forkserver'’.

     Note that this should be called at most once, and it should be
     protected inside the ‘if __name__ == '__main__'’ clause of the main
     module.

     New in version 3.4.

     Note: *note multiprocessing: b6. contains no analogues of *note
     threading.active_count(): 1cb4, *note threading.enumerate(): 1cb5,
     *note threading.settrace(): 1cb7, *note threading.setprofile():
     1cb9, *note threading.Timer: 6e8, or *note threading.local: 1c56.


File: python.info,  Node: Connection Objects<2>,  Next: Synchronization primitives,  Prev: Miscellaneous<3>,  Up: Reference

5.17.2.12 Connection Objects
............................

Connection objects allow the sending and receiving of picklable objects
or strings.  They can be thought of as message oriented connected
sockets.

Connection objects are usually created using *note Pipe(): 1cf7. – see
also *note Listeners and Clients: 1d36.

 -- Class: multiprocessing.Connection

      -- Method: send (obj)

          Send an object to the other end of the connection which should
          be read using *note recv(): 1cf9.

          The object must be picklable.  Very large pickles
          (approximately 32 MB+, though it depends on the OS) may raise
          a ValueError exception.

      -- Method: recv ()

          Return an object sent from the other end of the connection
          using *note send(): 1cf8.  Blocks until there its something to
          receive.  Raises *note EOFError: 8d8. if there is nothing left
          to receive and the other end was closed.

      -- Method: fileno ()

          Return the file descriptor or handle used by the connection.

      -- Method: close ()

          Close the connection.

          This is called automatically when the connection is garbage
          collected.

      -- Method: poll ([timeout])

          Return whether there is any data available to be read.

          If `timeout' is not specified then it will return immediately.
          If `timeout' is a number then this specifies the maximum time
          in seconds to block.  If `timeout' is ‘None’ then an infinite
          timeout is used.

          Note that multiple connection objects may be polled at once by
          using *note multiprocessing.connection.wait(): 653.

      -- Method: send_bytes (buffer[, offset[, size]])

          Send byte data from a *note bytes-like object: 36b. as a
          complete message.

          If `offset' is given then data is read from that position in
          `buffer'.  If `size' is given then that many bytes will be
          read from buffer.  Very large buffers (approximately 32 MB+,
          though it depends on the OS) may raise a *note ValueError:
          19c. exception

      -- Method: recv_bytes ([maxlength])

          Return a complete message of byte data sent from the other end
          of the connection as a string.  Blocks until there is
          something to receive.  Raises *note EOFError: 8d8. if there is
          nothing left to receive and the other end has closed.

          If `maxlength' is specified and the message is longer than
          `maxlength' then *note OSError: 4b6. is raised and the
          connection will no longer be readable.

          Changed in version 3.3: This function used to raise *note
          IOError: 5b0, which is now an alias of *note OSError: 4b6.

      -- Method: recv_bytes_into (buffer[, offset])

          Read into `buffer' a complete message of byte data sent from
          the other end of the connection and return the number of bytes
          in the message.  Blocks until there is something to receive.
          Raises *note EOFError: 8d8. if there is nothing left to
          receive and the other end was closed.

          `buffer' must be a writable *note bytes-like object: 36b.  If
          `offset' is given then the message will be written into the
          buffer from that position.  Offset must be a non-negative
          integer less than the length of `buffer' (in bytes).

          If the buffer is too short then a *note BufferTooShort: 1d13.
          exception is raised and the complete message is available as
          ‘e.args[0]’ where ‘e’ is the exception instance.

     Changed in version 3.3: Connection objects themselves can now be
     transferred between processes using *note Connection.send(): 1cf8.
     and *note Connection.recv(): 1cf9.

     New in version 3.3: Connection objects now support the context
     management protocol – see *note Context Manager Types: e4a.  *note
     __enter__(): 1090. returns the connection object, and *note
     __exit__(): 1092. calls *note close(): 1d38.

For example:

     >>> from multiprocessing import Pipe
     >>> a, b = Pipe()
     >>> a.send([1, 'hello', None])
     >>> b.recv()
     [1, 'hello', None]
     >>> b.send_bytes(b'thank you')
     >>> a.recv_bytes()
     b'thank you'
     >>> import array
     >>> arr1 = array.array('i', range(5))
     >>> arr2 = array.array('i', [0] * 10)
     >>> a.send_bytes(arr1)
     >>> count = b.recv_bytes_into(arr2)
     >>> assert count == len(arr1) * arr1.itemsize
     >>> arr2
     array('i', [0, 1, 2, 3, 4, 0, 0, 0, 0, 0])

     Warning: The *note Connection.recv(): 1cf9. method automatically
     unpickles the data it receives, which can be a security risk unless
     you can trust the process which sent the message.

     Therefore, unless the connection object was produced using *note
     Pipe(): 1cf7. you should only use the *note recv(): 1cf9. and *note
     send(): 1cf8. methods after performing some sort of authentication.
     See *note Authentication keys: 1d10.

     Warning: If a process is killed while it is trying to read or write
     to a pipe then the data in the pipe is likely to become corrupted,
     because it may become impossible to be sure where the message
     boundaries lie.


File: python.info,  Node: Synchronization primitives,  Next: Shared ctypes Objects,  Prev: Connection Objects<2>,  Up: Reference

5.17.2.13 Synchronization primitives
....................................

Generally synchronization primitives are not as necessary in a
multiprocess program as they are in a multithreaded program.  See the
documentation for *note threading: 106. module.

Note that one can also create synchronization primitives by using a
manager object – see *note Managers: 1d1d.

 -- Class: multiprocessing.Barrier (parties[, action[, timeout]])

     A barrier object: a clone of *note threading.Barrier: 7a9.

     New in version 3.3.

 -- Class: multiprocessing.BoundedSemaphore ([value])

     A bounded semaphore object: a close analog of *note
     threading.BoundedSemaphore: 6e6.

     A solitary difference from its close analog exists: its ‘acquire’
     method’s first argument is named `block', as is consistent with
     *note Lock.acquire(): 1d3d.

          Note: On Mac OS X, this is indistinguishable from *note
          Semaphore: 1d01. because ‘sem_getvalue()’ is not implemented
          on that platform.

 -- Class: multiprocessing.Condition ([lock])

     A condition variable: an alias for *note threading.Condition: 6e4.

     If `lock' is specified then it should be a *note Lock: 1cff. or
     *note RLock: 1d00. object from *note multiprocessing: b6.

     Changed in version 3.3: The *note wait_for(): 1cd7. method was
     added.

 -- Class: multiprocessing.Event

     A clone of *note threading.Event: 6e7.

 -- Class: multiprocessing.Lock

     A non-recursive lock object: a close analog of *note
     threading.Lock: 1ccd.  Once a process or thread has acquired a
     lock, subsequent attempts to acquire it from any process or thread
     will block until it is released; any process or thread may release
     it.  The concepts and behaviors of *note threading.Lock: 1ccd. as
     it applies to threads are replicated here in *note
     multiprocessing.Lock: 1cff. as it applies to either processes or
     threads, except as noted.

     Note that *note Lock: 1cff. is actually a factory function which
     returns an instance of ‘multiprocessing.synchronize.Lock’
     initialized with a default context.

     *note Lock: 1cff. supports the *note context manager: 165. protocol
     and thus may be used in *note with: 29d. statements.

      -- Method: acquire (block=True, timeout=None)

          Acquire a lock, blocking or non-blocking.

          With the `block' argument set to ‘True’ (the default), the
          method call will block until the lock is in an unlocked state,
          then set it to locked and return ‘True’.  Note that the name
          of this first argument differs from that in *note
          threading.Lock.acquire(): 33d.

          With the `block' argument set to ‘False’, the method call does
          not block.  If the lock is currently in a locked state, return
          ‘False’; otherwise set the lock to a locked state and return
          ‘True’.

          When invoked with a positive, floating-point value for
          `timeout', block for at most the number of seconds specified
          by `timeout' as long as the lock can not be acquired.
          Invocations with a negative value for `timeout' are equivalent
          to a `timeout' of zero.  Invocations with a `timeout' value of
          ‘None’ (the default) set the timeout period to infinite.  Note
          that the treatment of negative or ‘None’ values for `timeout'
          differs from the implemented behavior in *note
          threading.Lock.acquire(): 33d.  The `timeout' argument has no
          practical implications if the `block' argument is set to
          ‘False’ and is thus ignored.  Returns ‘True’ if the lock has
          been acquired or ‘False’ if the timeout period has elapsed.

      -- Method: release ()

          Release a lock.  This can be called from any process or
          thread, not only the process or thread which originally
          acquired the lock.

          Behavior is the same as in *note threading.Lock.release():
          1ccb. except that when invoked on an unlocked lock, a *note
          ValueError: 19c. is raised.

 -- Class: multiprocessing.RLock

     A recursive lock object: a close analog of *note threading.RLock:
     84f.  A recursive lock must be released by the process or thread
     that acquired it.  Once a process or thread has acquired a
     recursive lock, the same process or thread may acquire it again
     without blocking; that process or thread must release it once for
     each time it has been acquired.

     Note that *note RLock: 1d00. is actually a factory function which
     returns an instance of ‘multiprocessing.synchronize.RLock’
     initialized with a default context.

     *note RLock: 1d00. supports the *note context manager: 165.
     protocol and thus may be used in *note with: 29d. statements.

      -- Method: acquire (block=True, timeout=None)

          Acquire a lock, blocking or non-blocking.

          When invoked with the `block' argument set to ‘True’, block
          until the lock is in an unlocked state (not owned by any
          process or thread) unless the lock is already owned by the
          current process or thread.  The current process or thread then
          takes ownership of the lock (if it does not already have
          ownership) and the recursion level inside the lock increments
          by one, resulting in a return value of ‘True’.  Note that
          there are several differences in this first argument’s
          behavior compared to the implementation of *note
          threading.RLock.acquire(): 33e, starting with the name of the
          argument itself.

          When invoked with the `block' argument set to ‘False’, do not
          block.  If the lock has already been acquired (and thus is
          owned) by another process or thread, the current process or
          thread does not take ownership and the recursion level within
          the lock is not changed, resulting in a return value of
          ‘False’.  If the lock is in an unlocked state, the current
          process or thread takes ownership and the recursion level is
          incremented, resulting in a return value of ‘True’.

          Use and behaviors of the `timeout' argument are the same as in
          *note Lock.acquire(): 1d3d.  Note that some of these behaviors
          of `timeout' differ from the implemented behaviors in *note
          threading.RLock.acquire(): 33e.

      -- Method: release ()

          Release a lock, decrementing the recursion level.  If after
          the decrement the recursion level is zero, reset the lock to
          unlocked (not owned by any process or thread) and if any other
          processes or threads are blocked waiting for the lock to
          become unlocked, allow exactly one of them to proceed.  If
          after the decrement the recursion level is still nonzero, the
          lock remains locked and owned by the calling process or
          thread.

          Only call this method when the calling process or thread owns
          the lock.  An *note AssertionError: f30. is raised if this
          method is called by a process or thread other than the owner
          or if the lock is in an unlocked (unowned) state.  Note that
          the type of exception raised in this situation differs from
          the implemented behavior in *note threading.RLock.release():
          1cd0.

 -- Class: multiprocessing.Semaphore ([value])

     A semaphore object: a close analog of *note threading.Semaphore:
     6e5.

     A solitary difference from its close analog exists: its ‘acquire’
     method’s first argument is named `block', as is consistent with
     *note Lock.acquire(): 1d3d.

     Note: On Mac OS X, ‘sem_timedwait’ is unsupported, so calling
     ‘acquire()’ with a timeout will emulate that function’s behavior
     using a sleeping loop.

     Note: If the SIGINT signal generated by ‘Ctrl-C’ arrives while the
     main thread is blocked by a call to ‘BoundedSemaphore.acquire()’,
     *note Lock.acquire(): 1d3d, *note RLock.acquire(): 1d3f,
     ‘Semaphore.acquire()’, ‘Condition.acquire()’ or ‘Condition.wait()’
     then the call will be immediately interrupted and *note
     KeyboardInterrupt: 1a3. will be raised.

     This differs from the behaviour of *note threading: 106. where
     SIGINT will be ignored while the equivalent blocking calls are in
     progress.

     Note: Some of this package’s functionality requires a functioning
     shared semaphore implementation on the host operating system.
     Without one, the ‘multiprocessing.synchronize’ module will be
     disabled, and attempts to import it will result in an *note
     ImportError: 19f.  See issue 3770(1) for additional information.

   ---------- Footnotes ----------

   (1) https://bugs.python.org/issue3770


File: python.info,  Node: Shared ctypes Objects,  Next: Managers,  Prev: Synchronization primitives,  Up: Reference

5.17.2.14 Shared ‘ctypes’ Objects
.................................

It is possible to create shared objects using shared memory which can be
inherited by child processes.

 -- Function: multiprocessing.Value (typecode_or_type, *args, lock=True)

     Return a *note ctypes: 2a. object allocated from shared memory.  By
     default the return value is actually a synchronized wrapper for the
     object.  The object itself can be accessed via the `value'
     attribute of a *note Value: 1cfc.

     `typecode_or_type' determines the type of the returned object: it
     is either a ctypes type or a one character typecode of the kind
     used by the *note array: 7. module.  `*args' is passed on to the
     constructor for the type.

     If `lock' is ‘True’ (the default) then a new recursive lock object
     is created to synchronize access to the value.  If `lock' is a
     *note Lock: 1cff. or *note RLock: 1d00. object then that will be
     used to synchronize access to the value.  If `lock' is ‘False’ then
     access to the returned object will not be automatically protected
     by a lock, so it will not necessarily be "process-safe".

     Operations like ‘+=’ which involve a read and write are not atomic.
     So if, for instance, you want to atomically increment a shared
     value it is insufficient to just do

          counter.value += 1

     Assuming the associated lock is recursive (which it is by default)
     you can instead do

          with counter.get_lock():
              counter.value += 1

     Note that `lock' is a keyword-only argument.

 -- Function: multiprocessing.Array (typecode_or_type,
          size_or_initializer, *, lock=True)

     Return a ctypes array allocated from shared memory.  By default the
     return value is actually a synchronized wrapper for the array.

     `typecode_or_type' determines the type of the elements of the
     returned array: it is either a ctypes type or a one character
     typecode of the kind used by the *note array: 7. module.  If
     `size_or_initializer' is an integer, then it determines the length
     of the array, and the array will be initially zeroed.  Otherwise,
     `size_or_initializer' is a sequence which is used to initialize the
     array and whose length determines the length of the array.

     If `lock' is ‘True’ (the default) then a new lock object is created
     to synchronize access to the value.  If `lock' is a *note Lock:
     1cff. or *note RLock: 1d00. object then that will be used to
     synchronize access to the value.  If `lock' is ‘False’ then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be "process-safe".

     Note that `lock' is a keyword only argument.

     Note that an array of *note ctypes.c_char: 1c1d. has `value' and
     `raw' attributes which allow one to use it to store and retrieve
     strings.

* Menu:

* The multiprocessing.sharedctypes module: The multiprocessing sharedctypes module. 


File: python.info,  Node: The multiprocessing sharedctypes module,  Up: Shared ctypes Objects

5.17.2.15 The ‘multiprocessing.sharedctypes’ module
...................................................

The *note multiprocessing.sharedctypes: bb. module provides functions
for allocating *note ctypes: 2a. objects from shared memory which can be
inherited by child processes.

     Note: Although it is possible to store a pointer in shared memory
     remember that this will refer to a location in the address space of
     a specific process.  However, the pointer is quite likely to be
     invalid in the context of a second process and trying to
     dereference the pointer from the second process may cause a crash.

 -- Function: multiprocessing.sharedctypes.RawArray (typecode_or_type,
          size_or_initializer)

     Return a ctypes array allocated from shared memory.

     `typecode_or_type' determines the type of the elements of the
     returned array: it is either a ctypes type or a one character
     typecode of the kind used by the *note array: 7. module.  If
     `size_or_initializer' is an integer then it determines the length
     of the array, and the array will be initially zeroed.  Otherwise
     `size_or_initializer' is a sequence which is used to initialize the
     array and whose length determines the length of the array.

     Note that setting and getting an element is potentially non-atomic
     – use *note Array(): 1d44. instead to make sure that access is
     automatically synchronized using a lock.

 -- Function: multiprocessing.sharedctypes.RawValue (typecode_or_type,
          *args)

     Return a ctypes object allocated from shared memory.

     `typecode_or_type' determines the type of the returned object: it
     is either a ctypes type or a one character typecode of the kind
     used by the *note array: 7. module.  `*args' is passed on to the
     constructor for the type.

     Note that setting and getting the value is potentially non-atomic –
     use *note Value(): 1d46. instead to make sure that access is
     automatically synchronized using a lock.

     Note that an array of *note ctypes.c_char: 1c1d. has ‘value’ and
     ‘raw’ attributes which allow one to use it to store and retrieve
     strings – see documentation for *note ctypes: 2a.

 -- Function: multiprocessing.sharedctypes.Array (typecode_or_type,
          size_or_initializer, *, lock=True)

     The same as *note RawArray(): 1d43. except that depending on the
     value of `lock' a process-safe synchronization wrapper may be
     returned instead of a raw ctypes array.

     If `lock' is ‘True’ (the default) then a new lock object is created
     to synchronize access to the value.  If `lock' is a *note Lock:
     1cff. or *note RLock: 1d00. object then that will be used to
     synchronize access to the value.  If `lock' is ‘False’ then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be "process-safe".

     Note that `lock' is a keyword-only argument.

 -- Function: multiprocessing.sharedctypes.Value (typecode_or_type,
          *args, lock=True)

     The same as *note RawValue(): 1d45. except that depending on the
     value of `lock' a process-safe synchronization wrapper may be
     returned instead of a raw ctypes object.

     If `lock' is ‘True’ (the default) then a new lock object is created
     to synchronize access to the value.  If `lock' is a *note Lock:
     1cff. or *note RLock: 1d00. object then that will be used to
     synchronize access to the value.  If `lock' is ‘False’ then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be "process-safe".

     Note that `lock' is a keyword-only argument.

 -- Function: multiprocessing.sharedctypes.copy (obj)

     Return a ctypes object allocated from shared memory which is a copy
     of the ctypes object `obj'.

 -- Function: multiprocessing.sharedctypes.synchronized (obj[, lock])

     Return a process-safe wrapper object for a ctypes object which uses
     `lock' to synchronize access.  If `lock' is ‘None’ (the default)
     then a *note multiprocessing.RLock: 1d00. object is created
     automatically.

     A synchronized wrapper will have two methods in addition to those
     of the object it wraps: ‘get_obj()’ returns the wrapped object and
     ‘get_lock()’ returns the lock object used for synchronization.

     Note that accessing the ctypes object through the wrapper can be a
     lot slower than accessing the raw ctypes object.

     Changed in version 3.5: Synchronized objects support the *note
     context manager: 165. protocol.

The table below compares the syntax for creating shared ctypes objects
from shared memory with the normal ctypes syntax.  (In the table
‘MyStruct’ is some subclass of *note ctypes.Structure: 1c3f.)

ctypes                   sharedctypes using type        sharedctypes using typecode
                                                        
----------------------------------------------------------------------------------------
                                                        
c_double(2.4)            RawValue(c_double, 2.4)        RawValue(’d’, 2.4)
                                                        
                                                        
MyStruct(4, 6)           RawValue(MyStruct, 4, 6)
                         
                                                        
(c_short * 7)()          RawArray(c_short, 7)           RawArray(’h’, 7)
                                                        
                                                        
(c_int * 3)(9, 2, 8)     RawArray(c_int, (9, 2, 8))     RawArray(’i’, (9, 2, 8))
                                                        

Below is an example where a number of ctypes objects are modified by a
child process:

     from multiprocessing import Process, Lock
     from multiprocessing.sharedctypes import Value, Array
     from ctypes import Structure, c_double

     class Point(Structure):
         _fields_ = [('x', c_double), ('y', c_double)]

     def modify(n, x, s, A):
         n.value **= 2
         x.value **= 2
         s.value = s.value.upper()
         for a in A:
             a.x **= 2
             a.y **= 2

     if __name__ == '__main__':
         lock = Lock()

         n = Value('i', 7)
         x = Value(c_double, 1.0/3.0, lock=False)
         s = Array('c', b'hello world', lock=lock)
         A = Array(Point, [(1.875,-6.25), (-5.75,2.0), (2.375,9.5)], lock=lock)

         p = Process(target=modify, args=(n, x, s, A))
         p.start()
         p.join()

         print(n.value)
         print(x.value)
         print(s.value)
         print([(a.x, a.y) for a in A])

The results printed are

     49
     0.1111111111111111
     HELLO WORLD
     [(3.515625, 39.0625), (33.0625, 4.0), (5.640625, 90.25)]


File: python.info,  Node: Managers,  Next: Proxy Objects,  Prev: Shared ctypes Objects,  Up: Reference

5.17.2.16 Managers
..................

Managers provide a way to create data which can be shared between
different processes, including sharing over a network between processes
running on different machines.  A manager object controls a server
process which manages `shared objects'.  Other processes can access the
shared objects by using proxies.

 -- Function: multiprocessing.Manager ()

     Returns a started *note SyncManager: 1d4a. object which can be used
     for sharing objects between processes.  The returned manager object
     corresponds to a spawned child process and has methods which will
     create shared objects and return corresponding proxies.

Manager processes will be shutdown as soon as they are garbage collected
or their parent process exits.  The manager classes are defined in the
*note multiprocessing.managers: b9. module:

 -- Class: multiprocessing.managers.BaseManager ([address[, authkey]])

     Create a BaseManager object.

     Once created one should call *note start(): 1d4c. or
     ‘get_server().serve_forever()’ to ensure that the manager object
     refers to a started manager process.

     `address' is the address on which the manager process listens for
     new connections.  If `address' is ‘None’ then an arbitrary one is
     chosen.

     `authkey' is the authentication key which will be used to check the
     validity of incoming connections to the server process.  If
     `authkey' is ‘None’ then ‘current_process().authkey’ is used.
     Otherwise `authkey' is used and it must be a byte string.

      -- Method: start ([initializer[, initargs]])

          Start a subprocess to start the manager.  If `initializer' is
          not ‘None’ then the subprocess will call
          ‘initializer(*initargs)’ when it starts.

      -- Method: get_server ()

          Returns a ‘Server’ object which represents the actual server
          under the control of the Manager.  The ‘Server’ object
          supports the ‘serve_forever()’ method:

               >>> from multiprocessing.managers import BaseManager
               >>> manager = BaseManager(address=('', 50000), authkey=b'abc')
               >>> server = manager.get_server()
               >>> server.serve_forever()

          ‘Server’ additionally has an *note address: 1d4e. attribute.

      -- Method: connect ()

          Connect a local manager object to a remote manager process:

               >>> from multiprocessing.managers import BaseManager
               >>> m = BaseManager(address=('127.0.0.1', 5000), authkey=b'abc')
               >>> m.connect()

      -- Method: shutdown ()

          Stop the process used by the manager.  This is only available
          if *note start(): 1d4c. has been used to start the server
          process.

          This can be called multiple times.

      -- Method: register (typeid[, callable[, proxytype[, exposed[,
               method_to_typeid[, create_method]]]]])

          A classmethod which can be used for registering a type or
          callable with the manager class.

          `typeid' is a "type identifier" which is used to identify a
          particular type of shared object.  This must be a string.

          `callable' is a callable used for creating objects for this
          type identifier.  If a manager instance will be connected to
          the server using the *note connect(): 1d4f. method, or if the
          `create_method' argument is ‘False’ then this can be left as
          ‘None’.

          `proxytype' is a subclass of *note BaseProxy: 1d52. which is
          used to create proxies for shared objects with this `typeid'.
          If ‘None’ then a proxy class is created automatically.

          `exposed' is used to specify a sequence of method names which
          proxies for this typeid should be allowed to access using
          *note BaseProxy._callmethod(): 1d53.  (If `exposed' is ‘None’
          then ‘proxytype._exposed_’ is used instead if it exists.)  In
          the case where no exposed list is specified, all "public
          methods" of the shared object will be accessible.  (Here a
          "public method" means any attribute which has a *note
          __call__(): dee. method and whose name does not begin with
          ‘'_'’.)

          `method_to_typeid' is a mapping used to specify the return
          type of those exposed methods which should return a proxy.  It
          maps method names to typeid strings.  (If `method_to_typeid'
          is ‘None’ then ‘proxytype._method_to_typeid_’ is used instead
          if it exists.)  If a method’s name is not a key of this
          mapping or if the mapping is ‘None’ then the object returned
          by the method will be copied by value.

          `create_method' determines whether a method should be created
          with name `typeid' which can be used to tell the server
          process to create a new shared object and return a proxy for
          it.  By default it is ‘True’.

     *note BaseManager: 1d4b. instances also have one read-only
     property:

      -- Attribute: address

          The address used by the manager.

     Changed in version 3.3: Manager objects support the context
     management protocol – see *note Context Manager Types: e4a.  *note
     __enter__(): 1090. starts the server process (if it has not already
     started) and then returns the manager object.  *note __exit__():
     1092. calls *note shutdown(): 1d50.

     In previous versions *note __enter__(): 1090. did not start the
     manager’s server process if it was not already started.

 -- Class: multiprocessing.managers.SyncManager

     A subclass of *note BaseManager: 1d4b. which can be used for the
     synchronization of processes.  Objects of this type are returned by
     ‘multiprocessing.Manager()’.

     It also supports creation of shared lists and dictionaries.

      -- Method: Barrier (parties[, action[, timeout]])

          Create a shared *note threading.Barrier: 7a9. object and
          return a proxy for it.

          New in version 3.3.

      -- Method: BoundedSemaphore ([value])

          Create a shared *note threading.BoundedSemaphore: 6e6. object
          and return a proxy for it.

      -- Method: Condition ([lock])

          Create a shared *note threading.Condition: 6e4. object and
          return a proxy for it.

          If `lock' is supplied then it should be a proxy for a *note
          threading.Lock: 1ccd. or *note threading.RLock: 84f. object.

          Changed in version 3.3: The *note wait_for(): 1cd7. method was
          added.

      -- Method: Event ()

          Create a shared *note threading.Event: 6e7. object and return
          a proxy for it.

      -- Method: Lock ()

          Create a shared *note threading.Lock: 1ccd. object and return
          a proxy for it.

      -- Method: Namespace ()

          Create a shared *note Namespace: 1cfe. object and return a
          proxy for it.

      -- Method: Queue ([maxsize])

          Create a shared *note queue.Queue: cc5. object and return a
          proxy for it.

      -- Method: RLock ()

          Create a shared *note threading.RLock: 84f. object and return
          a proxy for it.

      -- Method: Semaphore ([value])

          Create a shared *note threading.Semaphore: 6e5. object and
          return a proxy for it.

      -- Method: Array (typecode, sequence)

          Create an array and return a proxy for it.

      -- Method: Value (typecode, value)

          Create an object with a writable ‘value’ attribute and return
          a proxy for it.

      -- Method: dict ()

      -- Method: dict (mapping)

      -- Method: dict (sequence)

          Create a shared ‘dict’ object and return a proxy for it.

      -- Method: list ()

      -- Method: list (sequence)

          Create a shared ‘list’ object and return a proxy for it.

          Note: Modifications to mutable values or items in dict and
          list proxies will not be propagated through the manager,
          because the proxy has no way of knowing when its values or
          items are modified.  To modify such an item, you can re-assign
          the modified object to the container proxy:

               # create a list proxy and append a mutable object (a dictionary)
               lproxy = manager.list()
               lproxy.append({})
               # now mutate the dictionary
               d = lproxy[0]
               d['a'] = 1
               d['b'] = 2
               # at this point, the changes to d are not yet synced, but by
               # reassigning the dictionary, the proxy is notified of the change
               lproxy[0] = d

 -- Class: multiprocessing.managers.Namespace

     A type that can register with *note SyncManager: 1d4a.

     A namespace object has no public methods, but does have writable
     attributes.  Its representation shows the values of its attributes.

     However, when using a proxy for a namespace object, an attribute
     beginning with ‘'_'’ will be an attribute of the proxy and not an
     attribute of the referent:

          >>> manager = multiprocessing.Manager()
          >>> Global = manager.Namespace()
          >>> Global.x = 10
          >>> Global.y = 'hello'
          >>> Global._z = 12.3    # this is an attribute of the proxy
          >>> print(Global)
          Namespace(x=10, y='hello')

* Menu:

* Customized managers:: 
* Using a remote manager:: 


File: python.info,  Node: Customized managers,  Next: Using a remote manager,  Up: Managers

5.17.2.17 Customized managers
.............................

To create one’s own manager, one creates a subclass of *note
BaseManager: 1d4b. and uses the *note register(): 1d51. classmethod to
register new types or callables with the manager class.  For example:

     from multiprocessing.managers import BaseManager

     class MathsClass:
         def add(self, x, y):
             return x + y
         def mul(self, x, y):
             return x * y

     class MyManager(BaseManager):
         pass

     MyManager.register('Maths', MathsClass)

     if __name__ == '__main__':
         with MyManager() as manager:
             maths = manager.Maths()
             print(maths.add(4, 3))         # prints 7
             print(maths.mul(7, 8))         # prints 56


File: python.info,  Node: Using a remote manager,  Prev: Customized managers,  Up: Managers

5.17.2.18 Using a remote manager
................................

It is possible to run a manager server on one machine and have clients
use it from other machines (assuming that the firewalls involved allow
it).

Running the following commands creates a server for a single shared
queue which remote clients can access:

     >>> from multiprocessing.managers import BaseManager
     >>> import queue
     >>> queue = queue.Queue()
     >>> class QueueManager(BaseManager): pass
     >>> QueueManager.register('get_queue', callable=lambda:queue)
     >>> m = QueueManager(address=('', 50000), authkey=b'abracadabra')
     >>> s = m.get_server()
     >>> s.serve_forever()

One client can access the server as follows:

     >>> from multiprocessing.managers import BaseManager
     >>> class QueueManager(BaseManager): pass
     >>> QueueManager.register('get_queue')
     >>> m = QueueManager(address=('foo.bar.org', 50000), authkey=b'abracadabra')
     >>> m.connect()
     >>> queue = m.get_queue()
     >>> queue.put('hello')

Another client can also use it:

     >>> from multiprocessing.managers import BaseManager
     >>> class QueueManager(BaseManager): pass
     >>> QueueManager.register('get_queue')
     >>> m = QueueManager(address=('foo.bar.org', 50000), authkey=b'abracadabra')
     >>> m.connect()
     >>> queue = m.get_queue()
     >>> queue.get()
     'hello'

Local processes can also access that queue, using the code from above on
the client to access it remotely:

     >>> from multiprocessing import Process, Queue
     >>> from multiprocessing.managers import BaseManager
     >>> class Worker(Process):
     ...     def __init__(self, q):
     ...         self.q = q
     ...         super(Worker, self).__init__()
     ...     def run(self):
     ...         self.q.put('local hello')
     ...
     >>> queue = Queue()
     >>> w = Worker(queue)
     >>> w.start()
     >>> class QueueManager(BaseManager): pass
     ...
     >>> QueueManager.register('get_queue', callable=lambda: queue)
     >>> m = QueueManager(address=('', 50000), authkey=b'abracadabra')
     >>> s = m.get_server()
     >>> s.serve_forever()


File: python.info,  Node: Proxy Objects,  Next: Process Pools,  Prev: Managers,  Up: Reference

5.17.2.19 Proxy Objects
.......................

A proxy is an object which `refers' to a shared object which lives
(presumably) in a different process.  The shared object is said to be
the `referent' of the proxy.  Multiple proxy objects may have the same
referent.

A proxy object has methods which invoke corresponding methods of its
referent (although not every method of the referent will necessarily be
available through the proxy).  A proxy can usually be used in most of
the same ways that its referent can:

     >>> from multiprocessing import Manager
     >>> manager = Manager()
     >>> l = manager.list([i*i for i in range(10)])
     >>> print(l)
     [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
     >>> print(repr(l))
     <ListProxy object, typeid 'list' at 0x...>
     >>> l[4]
     16
     >>> l[2:5]
     [4, 9, 16]

Notice that applying *note str(): 25a. to a proxy will return the
representation of the referent, whereas applying *note repr(): 3bb. will
return the representation of the proxy.

An important feature of proxy objects is that they are picklable so they
can be passed between processes.  Note, however, that if a proxy is sent
to the corresponding manager’s process then unpickling it will produce
the referent itself.  This means, for example, that one shared object
can contain a second:

     >>> a = manager.list()
     >>> b = manager.list()
     >>> a.append(b)         # referent of a now contains referent of b
     >>> print(a, b)
     [[]] []
     >>> b.append('hello')
     >>> print(a, b)
     [['hello']] ['hello']

     Note: The proxy types in *note multiprocessing: b6. do nothing to
     support comparisons by value.  So, for instance, we have:

          >>> manager.list([1,2,3]) == [1,2,3]
          False

     One should just use a copy of the referent instead when making
     comparisons.

 -- Class: multiprocessing.managers.BaseProxy

     Proxy objects are instances of subclasses of *note BaseProxy: 1d52.

      -- Method: _callmethod (methodname[, args[, kwds]])

          Call and return the result of a method of the proxy’s
          referent.

          If ‘proxy’ is a proxy whose referent is ‘obj’ then the
          expression

               proxy._callmethod(methodname, args, kwds)

          will evaluate the expression

               getattr(obj, methodname)(*args, **kwds)

          in the manager’s process.

          The returned value will be a copy of the result of the call or
          a proxy to a new shared object – see documentation for the
          `method_to_typeid' argument of *note BaseManager.register():
          1d51.

          If an exception is raised by the call, then is re-raised by
          *note _callmethod(): 1d53.  If some other exception is raised
          in the manager’s process then this is converted into a
          ‘RemoteError’ exception and is raised by *note _callmethod():
          1d53.

          Note in particular that an exception will be raised if
          `methodname' has not been `exposed'.

          An example of the usage of *note _callmethod(): 1d53.:

               >>> l = manager.list(range(10))
               >>> l._callmethod('__len__')
               10
               >>> l._callmethod('__getitem__', (slice(2, 7),)) # equivalent to l[2:7]
               [2, 3, 4, 5, 6]
               >>> l._callmethod('__getitem__', (20,))          # equivalent to l[20]
               Traceback (most recent call last):
               ...
               IndexError: list index out of range

      -- Method: _getvalue ()

          Return a copy of the referent.

          If the referent is unpicklable then this will raise an
          exception.

      -- Method: __repr__ ()

          Return a representation of the proxy object.

      -- Method: __str__ ()

          Return the representation of the referent.

* Menu:

* Cleanup:: 


File: python.info,  Node: Cleanup,  Up: Proxy Objects

5.17.2.20 Cleanup
.................

A proxy object uses a weakref callback so that when it gets garbage
collected it deregisters itself from the manager which owns its
referent.

A shared object gets deleted from the manager process when there are no
longer any proxies referring to it.


File: python.info,  Node: Process Pools,  Next: Listeners and Clients,  Prev: Proxy Objects,  Up: Reference

5.17.2.21 Process Pools
.......................

One can create a pool of processes which will carry out tasks submitted
to it with the *note Pool: 474. class.

 -- Class: multiprocessing.pool.Pool ([processes[, initializer[,
          initargs[, maxtasksperchild[, context]]]]])

     A process pool object which controls a pool of worker processes to
     which jobs can be submitted.  It supports asynchronous results with
     timeouts and callbacks and has a parallel map implementation.

     `processes' is the number of worker processes to use.  If
     `processes' is ‘None’ then the number returned by *note
     os.cpu_count(): 478. is used.

     If `initializer' is not ‘None’ then each worker process will call
     ‘initializer(*initargs)’ when it starts.

     `maxtasksperchild' is the number of tasks a worker process can
     complete before it will exit and be replaced with a fresh worker
     process, to enable unused resources to be freed.  The default
     `maxtasksperchild' is None, which means worker processes will live
     as long as the pool.

     `context' can be used to specify the context used for starting the
     worker processes.  Usually a pool is created using the function
     ‘multiprocessing.Pool()’ or the *note Pool(): 474. method of a
     context object.  In both cases `context' is set appropriately.

     Note that the methods of the pool object should only be called by
     the process which created the pool.

     New in version 3.2: `maxtasksperchild'

     New in version 3.4: `context'

          Note: Worker processes within a *note Pool: 474. typically
          live for the complete duration of the Pool’s work queue.  A
          frequent pattern found in other systems (such as Apache,
          mod_wsgi, etc) to free resources held by workers is to allow a
          worker within a pool to complete only a set amount of work
          before being exiting, being cleaned up and a new process
          spawned to replace the old one.  The `maxtasksperchild'
          argument to the *note Pool: 474. exposes this ability to the
          end user.

      -- Method: apply (func[, args[, kwds]])

          Call `func' with arguments `args' and keyword arguments
          `kwds'.  It blocks until the result is ready.  Given this
          blocks, *note apply_async(): 1d6a. is better suited for
          performing work in parallel.  Additionally, `func' is only
          executed in one of the workers of the pool.

      -- Method: apply_async (func[, args[, kwds[, callback[,
               error_callback]]]])

          A variant of the *note apply(): 1d69. method which returns a
          result object.

          If `callback' is specified then it should be a callable which
          accepts a single argument.  When the result becomes ready
          `callback' is applied to it, that is unless the call failed,
          in which case the `error_callback' is applied instead.

          If `error_callback' is specified then it should be a callable
          which accepts a single argument.  If the target function
          fails, then the `error_callback' is called with the exception
          instance.

          Callbacks should complete immediately since otherwise the
          thread which handles the results will get blocked.

      -- Method: map (func, iterable[, chunksize])

          A parallel equivalent of the *note map(): 892. built-in
          function (it supports only one `iterable' argument though).
          It blocks until the result is ready.

          This method chops the iterable into a number of chunks which
          it submits to the process pool as separate tasks.  The
          (approximate) size of these chunks can be specified by setting
          `chunksize' to a positive integer.

      -- Method: map_async (func, iterable[, chunksize[, callback[,
               error_callback]]])

          A variant of the *note map(): 65a. method which returns a
          result object.

          If `callback' is specified then it should be a callable which
          accepts a single argument.  When the result becomes ready
          `callback' is applied to it, that is unless the call failed,
          in which case the `error_callback' is applied instead.

          If `error_callback' is specified then it should be a callable
          which accepts a single argument.  If the target function
          fails, then the `error_callback' is called with the exception
          instance.

          Callbacks should complete immediately since otherwise the
          thread which handles the results will get blocked.

      -- Method: imap (func, iterable[, chunksize])

          A lazier version of *note map(): 892.

          The `chunksize' argument is the same as the one used by the
          *note map(): 65a. method.  For very long iterables using a
          large value for `chunksize' can make the job complete `much'
          faster than using the default value of ‘1’.

          Also if `chunksize' is ‘1’ then the ‘next()’ method of the
          iterator returned by the *note imap(): 1d6b. method has an
          optional `timeout' parameter: ‘next(timeout)’ will raise *note
          multiprocessing.TimeoutError: 1d16. if the result cannot be
          returned within `timeout' seconds.

      -- Method: imap_unordered (func, iterable[, chunksize])

          The same as *note imap(): 1d6b. except that the ordering of
          the results from the returned iterator should be considered
          arbitrary.  (Only when there is only one worker process is the
          order guaranteed to be "correct".)

      -- Method: starmap (func, iterable[, chunksize])

          Like *note map(): 892. except that the elements of the
          `iterable' are expected to be iterables that are unpacked as
          arguments.

          Hence an `iterable' of ‘[(1,2), (3, 4)]’ results in
          ‘[func(1,2), func(3,4)]’.

          New in version 3.3.

      -- Method: starmap_async (func, iterable[, chunksize[, callback[,
               error_back]]])

          A combination of *note starmap(): 657. and *note map_async():
          65b. that iterates over `iterable' of iterables and calls
          `func' with the iterables unpacked.  Returns a result object.

          New in version 3.3.

      -- Method: close ()

          Prevents any more tasks from being submitted to the pool.
          Once all the tasks have been completed the worker processes
          will exit.

      -- Method: terminate ()

          Stops the worker processes immediately without completing
          outstanding work.  When the pool object is garbage collected
          *note terminate(): 1d6e. will be called immediately.

      -- Method: join ()

          Wait for the worker processes to exit.  One must call *note
          close(): 1d6d. or *note terminate(): 1d6e. before using *note
          join(): 1d6f.

     New in version 3.3: Pool objects now support the context management
     protocol – see *note Context Manager Types: e4a.  *note
     __enter__(): 1090. returns the pool object, and *note __exit__():
     1092. calls *note terminate(): 1d6e.

 -- Class: multiprocessing.pool.AsyncResult

     The class of the result returned by *note Pool.apply_async(): 1d6a.
     and *note Pool.map_async(): 65b.

      -- Method: get ([timeout])

          Return the result when it arrives.  If `timeout' is not ‘None’
          and the result does not arrive within `timeout' seconds then
          *note multiprocessing.TimeoutError: 1d16. is raised.  If the
          remote call raised an exception then that exception will be
          reraised by *note get(): 1d71.

      -- Method: wait ([timeout])

          Wait until the result is available or until `timeout' seconds
          pass.

      -- Method: ready ()

          Return whether the call has completed.

      -- Method: successful ()

          Return whether the call completed without raising an
          exception.  Will raise *note AssertionError: f30. if the
          result is not ready.

The following example demonstrates the use of a pool:

     from multiprocessing import Pool
     import time

     def f(x):
         return x*x

     if __name__ == '__main__':
         with Pool(processes=4) as pool:         # start 4 worker processes
             result = pool.apply_async(f, (10,)) # evaluate "f(10)" asynchronously in a single process
             print(result.get(timeout=1))        # prints "100" unless your computer is *very* slow

             print(pool.map(f, range(10)))       # prints "[0, 1, 4,..., 81]"

             it = pool.imap(f, range(10))
             print(next(it))                     # prints "0"
             print(next(it))                     # prints "1"
             print(it.next(timeout=1))           # prints "4" unless your computer is *very* slow

             result = pool.apply_async(time.sleep, (10,))
             print(result.get(timeout=1))        # raises multiprocessing.TimeoutError


File: python.info,  Node: Listeners and Clients,  Next: Authentication keys,  Prev: Process Pools,  Up: Reference

5.17.2.22 Listeners and Clients
...............................

Usually message passing between processes is done using queues or by
using *note Connection: 654. objects returned by *note Pipe(): 1cf7.

However, the *note multiprocessing.connection: b7. module allows some
extra flexibility.  It basically gives a high level message oriented API
for dealing with sockets or Windows named pipes.  It also has support
for `digest authentication' using the *note hmac: 8e. module, and for
polling multiple connections at the same time.

 -- Function: multiprocessing.connection.deliver_challenge (connection,
          authkey)

     Send a randomly generated message to the other end of the
     connection and wait for a reply.

     If the reply matches the digest of the message using `authkey' as
     the key then a welcome message is sent to the other end of the
     connection.  Otherwise *note AuthenticationError: 1d15. is raised.

 -- Function: multiprocessing.connection.answer_challenge (connection,
          authkey)

     Receive a message, calculate the digest of the message using
     `authkey' as the key, and then send the digest back.

     If a welcome message is not received, then *note
     AuthenticationError: 1d15. is raised.

 -- Function: multiprocessing.connection.Client (address[, family[,
          authenticate[, authkey]]])

     Attempt to set up a connection to the listener which is using
     address `address', returning a *note Connection: 654.

     The type of the connection is determined by `family' argument, but
     this can generally be omitted since it can usually be inferred from
     the format of `address'.  (See *note Address Formats: 1d79.)

     If `authenticate' is ‘True’ or `authkey' is a byte string then
     digest authentication is used.  The key used for authentication
     will be either `authkey' or ‘current_process().authkey’ if
     `authkey' is ‘None’.  If authentication fails then *note
     AuthenticationError: 1d15. is raised.  See *note Authentication
     keys: 1d10.

 -- Class: multiprocessing.connection.Listener ([address[, family[,
          backlog[, authenticate[, authkey]]]]])

     A wrapper for a bound socket or Windows named pipe which is
     ’listening’ for connections.

     `address' is the address to be used by the bound socket or named
     pipe of the listener object.

          Note: If an address of ’0.0.0.0’ is used, the address will not
          be a connectable end point on Windows.  If you require a
          connectable end-point, you should use ’127.0.0.1’.

     `family' is the type of socket (or named pipe) to use.  This can be
     one of the strings ‘'AF_INET'’ (for a TCP socket), ‘'AF_UNIX'’ (for
     a Unix domain socket) or ‘'AF_PIPE'’ (for a Windows named pipe).
     Of these only the first is guaranteed to be available.  If `family'
     is ‘None’ then the family is inferred from the format of `address'.
     If `address' is also ‘None’ then a default is chosen.  This default
     is the family which is assumed to be the fastest available.  See
     *note Address Formats: 1d79.  Note that if `family' is ‘'AF_UNIX'’
     and address is ‘None’ then the socket will be created in a private
     temporary directory created using *note tempfile.mkstemp(): 160c.

     If the listener object uses a socket then `backlog' (1 by default)
     is passed to the *note listen(): 316. method of the socket once it
     has been bound.

     If `authenticate' is ‘True’ (‘False’ by default) or `authkey' is
     not ‘None’ then digest authentication is used.

     If `authkey' is a byte string then it will be used as the
     authentication key; otherwise it must be `None'.

     If `authkey' is ‘None’ and `authenticate' is ‘True’ then
     ‘current_process().authkey’ is used as the authentication key.  If
     `authkey' is ‘None’ and `authenticate' is ‘False’ then no
     authentication is done.  If authentication fails then *note
     AuthenticationError: 1d15. is raised.  See *note Authentication
     keys: 1d10.

      -- Method: accept ()

          Accept a connection on the bound socket or named pipe of the
          listener object and return a *note Connection: 654. object.
          If authentication is attempted and fails, then *note
          AuthenticationError: 1d15. is raised.

      -- Method: close ()

          Close the bound socket or named pipe of the listener object.
          This is called automatically when the listener is garbage
          collected.  However it is advisable to call it explicitly.

     Listener objects have the following read-only properties:

      -- Attribute: address

          The address which is being used by the Listener object.

      -- Attribute: last_accepted

          The address from which the last accepted connection came.  If
          this is unavailable then it is ‘None’.

     New in version 3.3: Listener objects now support the context
     management protocol – see *note Context Manager Types: e4a.  *note
     __enter__(): 1090. returns the listener object, and *note
     __exit__(): 1092. calls *note close(): 1d7c.

 -- Function: multiprocessing.connection.wait (object_list,
          timeout=None)

     Wait till an object in `object_list' is ready.  Returns the list of
     those objects in `object_list' which are ready.  If `timeout' is a
     float then the call blocks for at most that many seconds.  If
     `timeout' is ‘None’ then it will block for an unlimited period.  A
     negative timeout is equivalent to a zero timeout.

     For both Unix and Windows, an object can appear in `object_list' if
     it is

        * a readable *note Connection: 654. object;

        * a connected and readable *note socket.socket: 20a. object; or

        * the *note sentinel: 656. attribute of a *note Process: 655.
          object.

     A connection or socket object is ready when there is data available
     to be read from it, or the other end has been closed.

     `Unix': ‘wait(object_list, timeout)’ almost equivalent
     ‘select.select(object_list, [], [], timeout)’.  The difference is
     that, if *note select.select(): 209. is interrupted by a signal, it
     can raise *note OSError: 4b6. with an error number of ‘EINTR’,
     whereas *note wait(): 653. will not.

     `Windows': An item in `object_list' must either be an integer
     handle which is waitable (according to the definition used by the
     documentation of the Win32 function ‘WaitForMultipleObjects()’) or
     it can be an object with a ‘fileno()’ method which returns a socket
     handle or pipe handle.  (Note that pipe handles and socket handles
     are `not' waitable handles.)

     New in version 3.3.

`Examples'

The following server code creates a listener which uses ‘'secret
password'’ as an authentication key.  It then waits for a connection and
sends some data to the client:

     from multiprocessing.connection import Listener
     from array import array

     address = ('localhost', 6000)     # family is deduced to be 'AF_INET'

     with Listener(address, authkey=b'secret password') as listener:
         with listener.accept() as conn:
             print('connection accepted from', listener.last_accepted)

             conn.send([2.25, None, 'junk', float])

             conn.send_bytes(b'hello')

             conn.send_bytes(array('i', [42, 1729]))

The following code connects to the server and receives some data from
the server:

     from multiprocessing.connection import Client
     from array import array

     address = ('localhost', 6000)

     with Client(address, authkey=b'secret password') as conn:
         print(conn.recv())                  # => [2.25, None, 'junk', float]

         print(conn.recv_bytes())            # => 'hello'

         arr = array('i', [0, 0, 0, 0, 0])
         print(conn.recv_bytes_into(arr))    # => 8
         print(arr)                          # => array('i', [42, 1729, 0, 0, 0])

The following code uses *note wait(): 653. to wait for messages from
multiple processes at once:

     import time, random
     from multiprocessing import Process, Pipe, current_process
     from multiprocessing.connection import wait

     def foo(w):
         for i in range(10):
             w.send((i, current_process().name))
         w.close()

     if __name__ == '__main__':
         readers = []

         for i in range(4):
             r, w = Pipe(duplex=False)
             readers.append(r)
             p = Process(target=foo, args=(w,))
             p.start()
             # We close the writable end of the pipe now to be sure that
             # p is the only process which owns a handle for it.  This
             # ensures that when p closes its handle for the writable end,
             # wait() will promptly report the readable end as being ready.
             w.close()

         while readers:
             for r in wait(readers):
                 try:
                     msg = r.recv()
                 except EOFError:
                     readers.remove(r)
                 else:
                     print(msg)

* Menu:

* Address Formats:: 


File: python.info,  Node: Address Formats,  Up: Listeners and Clients

5.17.2.23 Address Formats
.........................

   * An ‘'AF_INET'’ address is a tuple of the form ‘(hostname, port)’
     where `hostname' is a string and `port' is an integer.

   * An ‘'AF_UNIX'’ address is a string representing a filename on the
     filesystem.

   * 
     An ‘'AF_PIPE'’ address is a string of the form

          ‘r'\\.\pipe\`PipeName''’.  To use *note Client(): 1d78. to
          connect to a named pipe on a remote computer called
          `ServerName' one should use an address of the form
          ‘r'\\`ServerName'\pipe\`PipeName''’ instead.

Note that any string beginning with two backslashes is assumed by
default to be an ‘'AF_PIPE'’ address rather than an ‘'AF_UNIX'’ address.


File: python.info,  Node: Authentication keys,  Next: Logging<2>,  Prev: Listeners and Clients,  Up: Reference

5.17.2.24 Authentication keys
.............................

When one uses *note Connection.recv: 1cf9, the data received is
automatically unpickled.  Unfortunately unpickling data from an
untrusted source is a security risk.  Therefore *note Listener: 1d7a.
and *note Client(): 1d78. use the *note hmac: 8e. module to provide
digest authentication.

An authentication key is a byte string which can be thought of as a
password: once a connection is established both ends will demand proof
that the other knows the authentication key.  (Demonstrating that both
ends are using the same key does `not' involve sending the key over the
connection.)

If authentication is requested but no authentication key is specified
then the return value of ‘current_process().authkey’ is used (see *note
Process: 655.).  This value will automatically inherited by any *note
Process: 655. object that the current process creates.  This means that
(by default) all processes of a multi-process program will share a
single authentication key which can be used when setting up connections
between themselves.

Suitable authentication keys can also be generated by using *note
os.urandom(): 2df.


File: python.info,  Node: Logging<2>,  Next: The multiprocessing dummy module,  Prev: Authentication keys,  Up: Reference

5.17.2.25 Logging
.................

Some support for logging is available.  Note, however, that the *note
logging: a8. package does not use process shared locks so it is possible
(depending on the handler type) for messages from different processes to
get mixed up.

 -- Function: multiprocessing.get_logger ()

     Returns the logger used by *note multiprocessing: b6.  If
     necessary, a new one will be created.

     When first created the logger has level ‘logging.NOTSET’ and no
     default handler.  Messages sent to this logger will not by default
     propagate to the root logger.

     Note that on Windows child processes will only inherit the level of
     the parent process’s logger – any other customization of the logger
     will not be inherited.

 -- Function: multiprocessing.log_to_stderr ()

     This function performs a call to *note get_logger(): 1d82. but in
     addition to returning the logger created by get_logger, it adds a
     handler which sends output to *note sys.stderr: 270. using format
     ‘'[%(levelname)s/%(processName)s] %(message)s'’.

Below is an example session with logging turned on:

     >>> import multiprocessing, logging
     >>> logger = multiprocessing.log_to_stderr()
     >>> logger.setLevel(logging.INFO)
     >>> logger.warning('doomed')
     [WARNING/MainProcess] doomed
     >>> m = multiprocessing.Manager()
     [INFO/SyncManager-...] child process calling self.run()
     [INFO/SyncManager-...] created temp directory /.../pymp-...
     [INFO/SyncManager-...] manager serving at '/.../listener-...'
     >>> del m
     [INFO/MainProcess] sending shutdown message to manager
     [INFO/SyncManager-...] manager exiting with exitcode 0

For a full table of logging levels, see the *note logging: a8. module.


File: python.info,  Node: The multiprocessing dummy module,  Prev: Logging<2>,  Up: Reference

5.17.2.26 The ‘multiprocessing.dummy’ module
............................................

*note multiprocessing.dummy: b8. replicates the API of *note
multiprocessing: b6. but is no more than a wrapper around the *note
threading: 106. module.


File: python.info,  Node: Programming guidelines,  Next: Examples<9>,  Prev: Reference,  Up: multiprocessing --- Process-based parallelism

5.17.2.27 Programming guidelines
................................

There are certain guidelines and idioms which should be adhered to when
using *note multiprocessing: b6.

* Menu:

* All start methods:: 
* The spawn and forkserver start methods:: 


File: python.info,  Node: All start methods,  Next: The spawn and forkserver start methods,  Up: Programming guidelines

5.17.2.28 All start methods
...........................

The following applies to all start methods.

Avoid shared state

     As far as possible one should try to avoid shifting large amounts
     of data between processes.

     It is probably best to stick to using queues or pipes for
     communication between processes rather than using the lower level
     synchronization primitives.

Picklability

     Ensure that the arguments to the methods of proxies are picklable.

Thread safety of proxies

     Do not use a proxy object from more than one thread unless you
     protect it with a lock.

     (There is never a problem with different processes using the `same'
     proxy.)

Joining zombie processes

     On Unix when a process finishes but has not been joined it becomes
     a zombie.  There should never be very many because each time a new
     process starts (or *note active_children(): 1d30. is called) all
     completed processes which have not yet been joined will be joined.
     Also calling a finished process’s *note Process.is_alive: 1d0c.
     will join the process.  Even so it is probably good practice to
     explicitly join all the processes that you start.

Better to inherit than pickle/unpickle

     When using the `spawn' or `forkserver' start methods many types
     from *note multiprocessing: b6. need to be picklable so that child
     processes can use them.  However, one should generally avoid
     sending shared objects to other processes using pipes or queues.
     Instead you should arrange the program so that a process which
     needs access to a shared resource created elsewhere can inherit it
     from an ancestor process.

Avoid terminating processes

     Using the *note Process.terminate: 1d11. method to stop a process
     is liable to cause any shared resources (such as locks, semaphores,
     pipes and queues) currently being used by the process to become
     broken or unavailable to other processes.

     Therefore it is probably best to only consider using *note
     Process.terminate: 1d11. on processes which never use any shared
     resources.

Joining processes that use queues

     Bear in mind that a process that has put items in a queue will wait
     before terminating until all the buffered items are fed by the
     "feeder" thread to the underlying pipe.  (The child process can
     call the *note Queue.cancel_join_thread: 1d22. method of the queue
     to avoid this behaviour.)

     This means that whenever you use a queue you need to make sure that
     all items which have been put on the queue will eventually be
     removed before the process is joined.  Otherwise you cannot be sure
     that processes which have put items on the queue will terminate.
     Remember also that non-daemonic processes will be joined
     automatically.

     An example which will deadlock is the following:

          from multiprocessing import Process, Queue

          def f(q):
              q.put('X' * 1000000)

          if __name__ == '__main__':
              queue = Queue()
              p = Process(target=f, args=(queue,))
              p.start()
              p.join()                    # this deadlocks
              obj = queue.get()

     A fix here would be to swap the last two lines (or simply remove
     the ‘p.join()’ line).

Explicitly pass resources to child processes

     On Unix using the `fork' start method, a child process can make use
     of a shared resource created in a parent process using a global
     resource.  However, it is better to pass the object as an argument
     to the constructor for the child process.

     Apart from making the code (potentially) compatible with Windows
     and the other start methods this also ensures that as long as the
     child process is still alive the object will not be garbage
     collected in the parent process.  This might be important if some
     resource is freed when the object is garbage collected in the
     parent process.

     So for instance

          from multiprocessing import Process, Lock

          def f():
              ... do something using "lock" ...

          if __name__ == '__main__':
             lock = Lock()
             for i in range(10):
                  Process(target=f).start()

     should be rewritten as

          from multiprocessing import Process, Lock

          def f(l):
              ... do something using "l" ...

          if __name__ == '__main__':
             lock = Lock()
             for i in range(10):
                  Process(target=f, args=(lock,)).start()

Beware of replacing *note sys.stdin: 1b9. with a "file like object"

     *note multiprocessing: b6. originally unconditionally called:

          os.close(sys.stdin.fileno())

     in the ‘multiprocessing.Process._bootstrap()’ method — this
     resulted in issues with processes-in-processes.  This has been
     changed to:

          sys.stdin.close()
          sys.stdin = open(os.open(os.devnull, os.O_RDONLY), closefd=False)

     Which solves the fundamental issue of processes colliding with each
     other resulting in a bad file descriptor error, but introduces a
     potential danger to applications which replace *note sys.stdin():
     1b9. with a "file-like object" with output buffering.  This danger
     is that if multiple processes call *note close(): 187c. on this
     file-like object, it could result in the same data being flushed to
     the object multiple times, resulting in corruption.

     If you write a file-like object and implement your own caching, you
     can make it fork-safe by storing the pid whenever you append to the
     cache, and discarding the cache when the pid changes.  For example:

          @property
          def cache(self):
              pid = os.getpid()
              if pid != self._pid:
                  self._pid = pid
                  self._cache = []
              return self._cache

     For more information, see issue 5155(1), issue 5313(2) and issue
     5331(3)

   ---------- Footnotes ----------

   (1) https://bugs.python.org/issue5155

   (2) https://bugs.python.org/issue5313

   (3) https://bugs.python.org/issue5331


File: python.info,  Node: The spawn and forkserver start methods,  Prev: All start methods,  Up: Programming guidelines

5.17.2.29 The `spawn' and `forkserver' start methods
....................................................

There are a few extra restriction which don’t apply to the `fork' start
method.

More picklability

     Ensure that all arguments to ‘Process.__init__()’ are picklable.
     This means, in particular, that bound or unbound methods cannot be
     used directly as the ‘target’ (unless you use the `fork' start
     method) — just define a function and use that instead.

     Also, if you subclass *note Process: 655. then make sure that
     instances will be picklable when the *note Process.start: 1cf1.
     method is called.

Global variables

     Bear in mind that if code run in a child process tries to access a
     global variable, then the value it sees (if any) may not be the
     same as the value in the parent process at the time that *note
     Process.start: 1cf1. was called.

     However, global variables which are just module level constants
     cause no problems.

Safe importing of main module

     Make sure that the main module can be safely imported by a new
     Python interpreter without causing unintended side effects (such a
     starting a new process).

     For example, using the `spawn' or `forkserver' start method running
     the following module would fail with a *note RuntimeError: 193.:

          from multiprocessing import Process

          def foo():
              print('hello')

          p = Process(target=foo)
          p.start()

     Instead one should protect the "entry point" of the program by
     using ‘if __name__ == '__main__':’ as follows:

          from multiprocessing import Process, freeze_support, set_start_method

          def foo():
              print('hello')

          if __name__ == '__main__':
              freeze_support()
              set_start_method('spawn')
              p = Process(target=foo)
              p.start()

     (The ‘freeze_support()’ line can be omitted if the program will be
     run normally instead of frozen.)

     This allows the newly spawned Python interpreter to safely import
     the module and then run the module’s ‘foo()’ function.

     Similar restrictions apply if a pool or manager is created in the
     main module.


File: python.info,  Node: Examples<9>,  Prev: Programming guidelines,  Up: multiprocessing --- Process-based parallelism

5.17.2.30 Examples
..................

Demonstration of how to create and use customized managers and proxies:

     from multiprocessing import freeze_support
     from multiprocessing.managers import BaseManager, BaseProxy
     import operator

     ##

     class Foo:
         def f(self):
             print('you called Foo.f()')
         def g(self):
             print('you called Foo.g()')
         def _h(self):
             print('you called Foo._h()')

     # A simple generator function
     def baz():
         for i in range(10):
             yield i*i

     # Proxy type for generator objects
     class GeneratorProxy(BaseProxy):
         _exposed_ = ['__next__']
         def __iter__(self):
             return self
         def __next__(self):
             return self._callmethod('__next__')

     # Function to return the operator module
     def get_operator_module():
         return operator

     ##

     class MyManager(BaseManager):
         pass

     # register the Foo class; make `f()` and `g()` accessible via proxy
     MyManager.register('Foo1', Foo)

     # register the Foo class; make `g()` and `_h()` accessible via proxy
     MyManager.register('Foo2', Foo, exposed=('g', '_h'))

     # register the generator function baz; use `GeneratorProxy` to make proxies
     MyManager.register('baz', baz, proxytype=GeneratorProxy)

     # register get_operator_module(); make public functions accessible via proxy
     MyManager.register('operator', get_operator_module)

     ##

     def test():
         manager = MyManager()
         manager.start()

         print('-' * 20)

         f1 = manager.Foo1()
         f1.f()
         f1.g()
         assert not hasattr(f1, '_h')
         assert sorted(f1._exposed_) == sorted(['f', 'g'])

         print('-' * 20)

         f2 = manager.Foo2()
         f2.g()
         f2._h()
         assert not hasattr(f2, 'f')
         assert sorted(f2._exposed_) == sorted(['g', '_h'])

         print('-' * 20)

         it = manager.baz()
         for i in it:
             print('<%d>' % i, end=' ')
         print()

         print('-' * 20)

         op = manager.operator()
         print('op.add(23, 45) =', op.add(23, 45))
         print('op.pow(2, 94) =', op.pow(2, 94))
         print('op._exposed_ =', op._exposed_)

     ##

     if __name__ == '__main__':
         freeze_support()
         test()

Using *note Pool: 474.:

     import multiprocessing
     import time
     import random
     import sys

     #
     # Functions used by test code
     #

     def calculate(func, args):
         result = func(*args)
         return '%s says that %s%s = %s' % (
             multiprocessing.current_process().name,
             func.__name__, args, result
             )

     def calculatestar(args):
         return calculate(*args)

     def mul(a, b):
         time.sleep(0.5 * random.random())
         return a * b

     def plus(a, b):
         time.sleep(0.5 * random.random())
         return a + b

     def f(x):
         return 1.0 / (x - 5.0)

     def pow3(x):
         return x ** 3

     def noop(x):
         pass

     #
     # Test code
     #

     def test():
         PROCESSES = 4
         print('Creating pool with %d processes\n' % PROCESSES)

         with multiprocessing.Pool(PROCESSES) as pool:
             #
             # Tests
             #

             TASKS = [(mul, (i, 7)) for i in range(10)] + \
                     [(plus, (i, 8)) for i in range(10)]

             results = [pool.apply_async(calculate, t) for t in TASKS]
             imap_it = pool.imap(calculatestar, TASKS)
             imap_unordered_it = pool.imap_unordered(calculatestar, TASKS)

             print('Ordered results using pool.apply_async():')
             for r in results:
                 print('\t', r.get())
             print()

             print('Ordered results using pool.imap():')
             for x in imap_it:
                 print('\t', x)
             print()

             print('Unordered results using pool.imap_unordered():')
             for x in imap_unordered_it:
                 print('\t', x)
             print()

             print('Ordered results using pool.map() --- will block till complete:')
             for x in pool.map(calculatestar, TASKS):
                 print('\t', x)
             print()

             #
             # Test error handling
             #

             print('Testing error handling:')

             try:
                 print(pool.apply(f, (5,)))
             except ZeroDivisionError:
                 print('\tGot ZeroDivisionError as expected from pool.apply()')
             else:
                 raise AssertionError('expected ZeroDivisionError')

             try:
                 print(pool.map(f, list(range(10))))
             except ZeroDivisionError:
                 print('\tGot ZeroDivisionError as expected from pool.map()')
             else:
                 raise AssertionError('expected ZeroDivisionError')

             try:
                 print(list(pool.imap(f, list(range(10)))))
             except ZeroDivisionError:
                 print('\tGot ZeroDivisionError as expected from list(pool.imap())')
             else:
                 raise AssertionError('expected ZeroDivisionError')

             it = pool.imap(f, list(range(10)))
             for i in range(10):
                 try:
                     x = next(it)
                 except ZeroDivisionError:
                     if i == 5:
                         pass
                 except StopIteration:
                     break
                 else:
                     if i == 5:
                         raise AssertionError('expected ZeroDivisionError')

             assert i == 9
             print('\tGot ZeroDivisionError as expected from IMapIterator.next()')
             print()

             #
             # Testing timeouts
             #

             print('Testing ApplyResult.get() with timeout:', end=' ')
             res = pool.apply_async(calculate, TASKS[0])
             while 1:
                 sys.stdout.flush()
                 try:
                     sys.stdout.write('\n\t%s' % res.get(0.02))
                     break
                 except multiprocessing.TimeoutError:
                     sys.stdout.write('.')
             print()
             print()

             print('Testing IMapIterator.next() with timeout:', end=' ')
             it = pool.imap(calculatestar, TASKS)
             while 1:
                 sys.stdout.flush()
                 try:
                     sys.stdout.write('\n\t%s' % it.next(0.02))
                 except StopIteration:
                     break
                 except multiprocessing.TimeoutError:
                     sys.stdout.write('.')
             print()
             print()


     if __name__ == '__main__':
         multiprocessing.freeze_support()
         test()

An example showing how to use queues to feed tasks to a collection of
worker processes and collect the results:

     import time
     import random

     from multiprocessing import Process, Queue, current_process, freeze_support

     #
     # Function run by worker processes
     #

     def worker(input, output):
         for func, args in iter(input.get, 'STOP'):
             result = calculate(func, args)
             output.put(result)

     #
     # Function used to calculate result
     #

     def calculate(func, args):
         result = func(*args)
         return '%s says that %s%s = %s' % \
             (current_process().name, func.__name__, args, result)

     #
     # Functions referenced by tasks
     #

     def mul(a, b):
         time.sleep(0.5*random.random())
         return a * b

     def plus(a, b):
         time.sleep(0.5*random.random())
         return a + b

     #
     #
     #

     def test():
         NUMBER_OF_PROCESSES = 4
         TASKS1 = [(mul, (i, 7)) for i in range(20)]
         TASKS2 = [(plus, (i, 8)) for i in range(10)]

         # Create queues
         task_queue = Queue()
         done_queue = Queue()

         # Submit tasks
         for task in TASKS1:
             task_queue.put(task)

         # Start worker processes
         for i in range(NUMBER_OF_PROCESSES):
             Process(target=worker, args=(task_queue, done_queue)).start()

         # Get and print results
         print('Unordered results:')
         for i in range(len(TASKS1)):
             print('\t', done_queue.get())

         # Add more tasks using `put()`
         for task in TASKS2:
             task_queue.put(task)

         # Get and print some more results
         for i in range(len(TASKS2)):
             print('\t', done_queue.get())

         # Tell child processes to stop
         for i in range(NUMBER_OF_PROCESSES):
             task_queue.put('STOP')


     if __name__ == '__main__':
         freeze_support()
         test()


File: python.info,  Node: The concurrent package,  Next: concurrent futures --- Launching parallel tasks,  Prev: multiprocessing --- Process-based parallelism,  Up: Concurrent Execution

5.17.3 The ‘concurrent’ package
-------------------------------

Currently, there is only one module in this package:

   * *note concurrent.futures: 22. – Launching parallel tasks


File: python.info,  Node: concurrent futures --- Launching parallel tasks,  Next: subprocess --- Subprocess management,  Prev: The concurrent package,  Up: Concurrent Execution

5.17.4 ‘concurrent.futures’ — Launching parallel tasks
------------------------------------------------------

New in version 3.2.

`Source code:' Lib/concurrent/futures/thread.py(1) and
Lib/concurrent/futures/process.py(2)

__________________________________________________________________

The *note concurrent.futures: 22. module provides a high-level interface
for asynchronously executing callables.

The asynchronous execution can be performed with threads, using *note
ThreadPoolExecutor: 26a, or separate processes, using *note
ProcessPoolExecutor: 269.  Both implement the same interface, which is
defined by the abstract *note Executor: 1d8d. class.

* Menu:

* Executor Objects:: 
* ThreadPoolExecutor:: 
* ProcessPoolExecutor:: 
* Future Objects:: 
* Module Functions:: 
* Exception classes:: 

   ---------- Footnotes ----------

   (1) 
https://hg.python.org/cpython/file/default/Lib/concurrent/futures/thread.py

   (2) 
https://hg.python.org/cpython/file/default/Lib/concurrent/futures/process.py


File: python.info,  Node: Executor Objects,  Next: ThreadPoolExecutor,  Up: concurrent futures --- Launching parallel tasks

5.17.4.1 Executor Objects
.........................

 -- Class: concurrent.futures.Executor

     An abstract class that provides methods to execute calls
     asynchronously.  It should not be used directly, but through its
     concrete subclasses.

           -- Method: submit (fn, *args, **kwargs)

               Schedules the callable, `fn', to be executed as ‘fn(*args
               **kwargs)’ and returns a *note Future: 76f. object
               representing the execution of the callable.

                    with ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(pow, 323, 1235)
                        print(future.result())

           -- Method: map (func, *iterables, timeout=None, chunksize=1)

               Equivalent to *note map(func, *iterables): 892. except
               `func' is executed asynchronously and several calls to
               `func' may be made concurrently.  The returned iterator
               raises a *note concurrent.futures.TimeoutError: 1d8f. if
               *note __next__(): 8cf. is called and the result isn’t
               available after `timeout' seconds from the original call
               to *note Executor.map(): 268.  `timeout' can be an int or
               a float.  If `timeout' is not specified or ‘None’, there
               is no limit to the wait time.  If a call raises an
               exception, then that exception will be raised when its
               value is retrieved from the iterator.  When using *note
               ProcessPoolExecutor: 269, this method chops `iterables'
               into a number of chunks which it submits to the pool as
               separate tasks.  The (approximate) size of these chunks
               can be specified by setting `chunksize' to a positive
               integer.  For very long iterables, using a large value
               for `chunksize' can significantly improve performance
               compared to the default size of 1.  With *note
               ThreadPoolExecutor: 26a, `chunksize' has no effect.

               Changed in version 3.5: Added the `chunksize' argument.

           -- Method: shutdown (wait=True)

               Signal the executor that it should free any resources
               that it is using when the currently pending futures are
               done executing.  Calls to *note Executor.submit(): 770.
               and *note Executor.map(): 268. made after shutdown will
               raise *note RuntimeError: 193.

               If `wait' is ‘True’ then this method will not return
               until all the pending futures are done executing and the
               resources associated with the executor have been freed.
               If `wait' is ‘False’ then this method will return
               immediately and the resources associated with the
               executor will be freed when all pending futures are done
               executing.  Regardless of the value of `wait', the entire
               Python program will not exit until all pending futures
               are done executing.

               You can avoid having to call this method explicitly if
               you use the *note with: 29d. statement, which will
               shutdown the *note Executor: 1d8d. (waiting as if *note
               Executor.shutdown(): 771. were called with `wait' set to
               ‘True’):

                    import shutil
                    with ThreadPoolExecutor(max_workers=4) as e:
                        e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
                        e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
                        e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
                        e.submit(shutil.copy, 'src4.txt', 'dest4.txt')


File: python.info,  Node: ThreadPoolExecutor,  Next: ProcessPoolExecutor,  Prev: Executor Objects,  Up: concurrent futures --- Launching parallel tasks

5.17.4.2 ThreadPoolExecutor
...........................

*note ThreadPoolExecutor: 26a. is an *note Executor: 1d8d. subclass that
uses a pool of threads to execute calls asynchronously.

Deadlocks can occur when the callable associated with a *note Future:
76f. waits on the results of another *note Future: 76f.  For example:

     import time
     def wait_on_b():
         time.sleep(5)
         print(b.result()) # b will never complete because it is waiting on a.
         return 5

     def wait_on_a():
         time.sleep(5)
         print(a.result()) # a will never complete because it is waiting on b.
         return 6


     executor = ThreadPoolExecutor(max_workers=2)
     a = executor.submit(wait_on_b)
     b = executor.submit(wait_on_a)

And:

     def wait_on_future():
         f = executor.submit(pow, 5, 2)
         # This will never complete because there is only one worker thread and
         # it is executing this function.
         print(f.result())

     executor = ThreadPoolExecutor(max_workers=1)
     executor.submit(wait_on_future)

 -- Class: concurrent.futures.ThreadPoolExecutor (max_workers=None)

     An *note Executor: 1d8d. subclass that uses a pool of at most
     `max_workers' threads to execute calls asynchronously.

     Changed in version 3.5: If `max_workers' is ‘None’ or not given, it
     will default to the number of processors on the machine, multiplied
     by ‘5’, assuming that *note ThreadPoolExecutor: 26a. is often used
     to overlap I/O instead of CPU work and the number of workers should
     be higher than the number of workers for *note ProcessPoolExecutor:
     269.

* Menu:

* ThreadPoolExecutor Example:: 


File: python.info,  Node: ThreadPoolExecutor Example,  Up: ThreadPoolExecutor

5.17.4.3 ThreadPoolExecutor Example
...................................

     import concurrent.futures
     import urllib.request

     URLS = ['http://www.foxnews.com/',
             'http://www.cnn.com/',
             'http://europe.wsj.com/',
             'http://www.bbc.co.uk/',
             'http://some-made-up-domain.com/']

     # Retrieve a single page and report the url and contents
     def load_url(url, timeout):
         with urllib.request.urlopen(url, timeout=timeout) as conn:
             return conn.read()

     # We can use a with statement to ensure threads are cleaned up promptly
     with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
         # Start the load operations and mark each future with its URL
         future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
         for future in concurrent.futures.as_completed(future_to_url):
             url = future_to_url[future]
             try:
                 data = future.result()
             except Exception as exc:
                 print('%r generated an exception: %s' % (url, exc))
             else:
                 print('%r page is %d bytes' % (url, len(data)))


File: python.info,  Node: ProcessPoolExecutor,  Next: Future Objects,  Prev: ThreadPoolExecutor,  Up: concurrent futures --- Launching parallel tasks

5.17.4.4 ProcessPoolExecutor
............................

The *note ProcessPoolExecutor: 269. class is an *note Executor: 1d8d.
subclass that uses a pool of processes to execute calls asynchronously.
*note ProcessPoolExecutor: 269. uses the *note multiprocessing: b6.
module, which allows it to side-step the *note Global Interpreter Lock:
153. but also means that only picklable objects can be executed and
returned.

The ‘__main__’ module must be importable by worker subprocesses.  This
means that *note ProcessPoolExecutor: 269. will not work in the
interactive interpreter.

Calling *note Executor: 1d8d. or *note Future: 76f. methods from a
callable submitted to a *note ProcessPoolExecutor: 269. will result in
deadlock.

 -- Class: concurrent.futures.ProcessPoolExecutor (max_workers=None)

     An *note Executor: 1d8d. subclass that executes calls
     asynchronously using a pool of at most `max_workers' processes.  If
     `max_workers' is ‘None’ or not given, it will default to the number
     of processors on the machine.  If `max_workers' is lower or equal
     to ‘0’, then a *note ValueError: 19c. will be raised.

     Changed in version 3.3: When one of the worker processes terminates
     abruptly, a ‘BrokenProcessPool’ error is now raised.  Previously,
     behaviour was undefined but operations on the executor or its
     futures would often freeze or deadlock.

* Menu:

* ProcessPoolExecutor Example:: 


File: python.info,  Node: ProcessPoolExecutor Example,  Up: ProcessPoolExecutor

5.17.4.5 ProcessPoolExecutor Example
....................................

     import concurrent.futures
     import math

     PRIMES = [
         112272535095293,
         112582705942171,
         112272535095293,
         115280095190773,
         115797848077099,
         1099726899285419]

     def is_prime(n):
         if n % 2 == 0:
             return False

         sqrt_n = int(math.floor(math.sqrt(n)))
         for i in range(3, sqrt_n + 1, 2):
             if n % i == 0:
                 return False
         return True

     def main():
         with concurrent.futures.ProcessPoolExecutor() as executor:
             for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
                 print('%d is prime: %s' % (number, prime))

     if __name__ == '__main__':
         main()


File: python.info,  Node: Future Objects,  Next: Module Functions,  Prev: ProcessPoolExecutor,  Up: concurrent futures --- Launching parallel tasks

5.17.4.6 Future Objects
.......................

The *note Future: 76f. class encapsulates the asynchronous execution of
a callable.  *note Future: 76f. instances are created by *note
Executor.submit(): 770.

 -- Class: concurrent.futures.Future

     Encapsulates the asynchronous execution of a callable.  *note
     Future: 76f. instances are created by *note Executor.submit(): 770.
     and should not be created directly except for testing.

           -- Method: cancel ()

               Attempt to cancel the call.  If the call is currently
               being executed and cannot be cancelled then the method
               will return ‘False’, otherwise the call will be cancelled
               and the method will return ‘True’.

           -- Method: cancelled ()

               Return ‘True’ if the call was successfully cancelled.

           -- Method: running ()

               Return ‘True’ if the call is currently being executed and
               cannot be cancelled.

           -- Method: done ()

               Return ‘True’ if the call was successfully cancelled or
               finished running.

           -- Method: result (timeout=None)

               Return the value returned by the call.  If the call
               hasn’t yet completed then this method will wait up to
               `timeout' seconds.  If the call hasn’t completed in
               `timeout' seconds, then a *note
               concurrent.futures.TimeoutError: 1d8f. will be raised.
               `timeout' can be an int or float.  If `timeout' is not
               specified or ‘None’, there is no limit to the wait time.

               If the future is cancelled before completing then *note
               CancelledError: 1d9a. will be raised.

               If the call raised, this method will raise the same
               exception.

           -- Method: exception (timeout=None)

               Return the exception raised by the call.  If the call
               hasn’t yet completed then this method will wait up to
               `timeout' seconds.  If the call hasn’t completed in
               `timeout' seconds, then a *note
               concurrent.futures.TimeoutError: 1d8f. will be raised.
               `timeout' can be an int or float.  If `timeout' is not
               specified or ‘None’, there is no limit to the wait time.

               If the future is cancelled before completing then *note
               CancelledError: 1d9a. will be raised.

               If the call completed without raising, ‘None’ is
               returned.

           -- Method: add_done_callback (fn)

               Attaches the callable `fn' to the future.  `fn' will be
               called, with the future as its only argument, when the
               future is cancelled or finishes running.

               Added callables are called in the order that they were
               added and are always called in a thread belonging to the
               process that added them.  If the callable raises an *note
               Exception: 1a1. subclass, it will be logged and ignored.
               If the callable raises a *note BaseException: 8c9.
               subclass, the behavior is undefined.

               If the future has already completed or been cancelled,
               `fn' will be called immediately.

     The following *note Future: 76f. methods are meant for use in unit
     tests and *note Executor: 1d8d. implementations.

           -- Method: set_running_or_notify_cancel ()

               This method should only be called by *note Executor:
               1d8d. implementations before executing the work
               associated with the *note Future: 76f. and by unit tests.

               If the method returns ‘False’ then the *note Future: 76f.
               was cancelled, i.e.  *note Future.cancel(): 1d95. was
               called and returned ‘True’.  Any threads waiting on the
               *note Future: 76f. completing (i.e.  through *note
               as_completed(): 1d9e. or *note wait(): 1d9f.) will be
               woken up.

               If the method returns ‘True’ then the *note Future: 76f.
               was not cancelled and has been put in the running state,
               i.e.  calls to *note Future.running(): 1d97. will return
               ‘True’.

               This method can only be called once and cannot be called
               after *note Future.set_result(): 1da0. or *note
               Future.set_exception(): 1da1. have been called.

           -- Method: set_result (result)

               Sets the result of the work associated with the *note
               Future: 76f. to `result'.

               This method should only be used by *note Executor: 1d8d.
               implementations and unit tests.

           -- Method: set_exception (exception)

               Sets the result of the work associated with the *note
               Future: 76f. to the *note Exception: 1a1. `exception'.

               This method should only be used by *note Executor: 1d8d.
               implementations and unit tests.


File: python.info,  Node: Module Functions,  Next: Exception classes,  Prev: Future Objects,  Up: concurrent futures --- Launching parallel tasks

5.17.4.7 Module Functions
.........................

 -- Function: concurrent.futures.wait (fs, timeout=None,
          return_when=ALL_COMPLETED)

     Wait for the *note Future: 76f. instances (possibly created by
     different *note Executor: 1d8d. instances) given by `fs' to
     complete.  Returns a named 2-tuple of sets.  The first set, named
     ‘done’, contains the futures that completed (finished or were
     cancelled) before the wait completed.  The second set, named
     ‘not_done’, contains uncompleted futures.

     `timeout' can be used to control the maximum number of seconds to
     wait before returning.  `timeout' can be an int or float.  If
     `timeout' is not specified or ‘None’, there is no limit to the wait
     time.

     `return_when' indicates when this function should return.  It must
     be one of the following constants:

     Constant                          Description
                                       
     -------------------------------------------------------------------------------
                                       
     ‘FIRST_COMPLETED’                 The function will return when any future
                                       finishes or is cancelled.
                                       
                                       
     ‘FIRST_EXCEPTION’                 The function will return when any future
                                       finishes by raising an exception.  If no
                                       future raises an exception then it is
                                       equivalent to ‘ALL_COMPLETED’.
                                       
                                       
     ‘ALL_COMPLETED’                   The function will return when all futures
                                       finish or are cancelled.
                                       

 -- Function: concurrent.futures.as_completed (fs, timeout=None)

     Returns an iterator over the *note Future: 76f. instances (possibly
     created by different *note Executor: 1d8d. instances) given by `fs'
     that yields futures as they complete (finished or were cancelled).
     Any futures given by `fs' that are duplicated will be returned
     once.  Any futures that completed before *note as_completed():
     1d9e. is called will be yielded first.  The returned iterator
     raises a *note concurrent.futures.TimeoutError: 1d8f. if *note
     __next__(): 8cf. is called and the result isn’t available after
     `timeout' seconds from the original call to *note as_completed():
     1d9e.  `timeout' can be an int or float.  If `timeout' is not
     specified or ‘None’, there is no limit to the wait time.

See also
........

PEP 3148(1) – futures - execute computations asynchronously

     The proposal which described this feature for inclusion in the
     Python standard library.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3148


File: python.info,  Node: Exception classes,  Prev: Module Functions,  Up: concurrent futures --- Launching parallel tasks

5.17.4.8 Exception classes
..........................

 -- Exception: concurrent.futures.CancelledError

     Raised when a future is cancelled.

 -- Exception: concurrent.futures.TimeoutError

     Raised when a future operation exceeds the given timeout.

 -- Exception: concurrent.futures.process.BrokenProcessPool

     Derived from *note RuntimeError: 193, this exception class is
     raised when one of the workers of a ‘ProcessPoolExecutor’ has
     terminated in a non-clean fashion (for example, if it was killed
     from the outside).

     New in version 3.3.


File: python.info,  Node: subprocess --- Subprocess management,  Next: sched --- Event scheduler,  Prev: concurrent futures --- Launching parallel tasks,  Up: Concurrent Execution

5.17.5 ‘subprocess’ — Subprocess management
-------------------------------------------

The *note subprocess: f7. module allows you to spawn new processes,
connect to their input/output/error pipes, and obtain their return
codes.  This module intends to replace several older modules and
functions:

     os.system
     os.spawn*

Information about how the *note subprocess: f7. module can be used to
replace these modules and functions can be found in the following
sections.

See also
........

PEP 324(1) – PEP proposing the subprocess module

* Menu:

* Using the subprocess Module:: 
* Security Considerations:: 
* Popen Objects:: 
* Windows Popen Helpers:: 
* Older high-level API:: 
* Replacing Older Functions with the subprocess Module:: 
* Legacy Shell Invocation Functions:: 
* Notes:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0324


File: python.info,  Node: Using the subprocess Module,  Next: Security Considerations,  Up: subprocess --- Subprocess management

5.17.5.1 Using the ‘subprocess’ Module
......................................

The recommended approach to invoking subprocesses is to use the *note
run(): 1c3. function for all use cases it can handle.  For more advanced
use cases, the underlying *note Popen: 7d8. interface can be used
directly.

The *note run(): 1c3. function was added in Python 3.5; if you need to
retain compatibility with older versions, see the *note Older high-level
API: 1da8. section.

 -- Function: subprocess.run (args, *, stdin=None, input=None,
          stdout=None, stderr=None, shell=False, timeout=None,
          check=False)

     Run the command described by `args'.  Wait for command to complete,
     then return a *note CompletedProcess: 32f. instance.

     The arguments shown above are merely the most common ones,
     described below in *note Frequently Used Arguments: 1da9. (hence
     the use of keyword-only notation in the abbreviated signature).
     The full function signature is largely the same as that of the
     *note Popen: 7d8. constructor - apart from `timeout', `input' and
     `check', all the arguments to this function are passed through to
     that interface.

     This does not capture stdout or stderr by default.  To do so, pass
     *note PIPE: 1daa. for the `stdout' and/or `stderr' arguments.

     The `timeout' argument is passed to *note Popen.communicate():
     1dab.  If the timeout expires, the child process will be killed and
     waited for.  The *note TimeoutExpired: 1dac. exception will be
     re-raised after the child process has terminated.

     The `input' argument is passed to *note Popen.communicate(): 1dab.
     and thus to the subprocess’s stdin.  If used it must be a byte
     sequence, or a string if ‘universal_newlines=True’.  When used, the
     internal *note Popen: 7d8. object is automatically created with
     ‘stdin=PIPE’, and the `stdin' argument may not be used as well.

     If `check' is True, and the process exits with a non-zero exit
     code, a *note CalledProcessError: 92a. exception will be raised.
     Attributes of that exception hold the arguments, the exit code, and
     stdout and stderr if they were captured.

     Examples:

          >>> subprocess.run(["ls", "-l"])  # doesn't capture output
          CompletedProcess(args=['ls', '-l'], returncode=0)

          >>> subprocess.run("exit 1", shell=True, check=True)
          Traceback (most recent call last):
            ...
          subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

          >>> subprocess.run(["ls", "-l", "/dev/null"], stdout=subprocess.PIPE)
          CompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0,
          stdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\n')

     New in version 3.5.

 -- Class: subprocess.CompletedProcess

     The return value from *note run(): 1c3, representing a process that
     has finished.

      -- Attribute: args

          The arguments used to launch the process.  This may be a list
          or a string.

      -- Attribute: returncode

          Exit status of the child process.  Typically, an exit status
          of 0 indicates that it ran successfully.

          A negative value ‘-N’ indicates that the child was terminated
          by signal ‘N’ (POSIX only).

      -- Attribute: stdout

          Captured stdout from the child process.  A bytes sequence, or
          a string if *note run(): 1c3. was called with
          ‘universal_newlines=True’.  None if stdout was not captured.

          If you ran the process with ‘stderr=subprocess.STDOUT’, stdout
          and stderr will be combined in this attribute, and *note
          stderr: 1db0. will be None.

      -- Attribute: stderr

          Captured stderr from the child process.  A bytes sequence, or
          a string if *note run(): 1c3. was called with
          ‘universal_newlines=True’.  None if stderr was not captured.

      -- Method: check_returncode ()

          If *note returncode: 1dae. is non-zero, raise a *note
          CalledProcessError: 92a.

     New in version 3.5.

 -- Data: subprocess.DEVNULL

     Special value that can be used as the `stdin', `stdout' or `stderr'
     argument to *note Popen: 7d8. and indicates that the special file
     *note os.devnull: bb9. will be used.

     New in version 3.3.

 -- Data: subprocess.PIPE

     Special value that can be used as the `stdin', `stdout' or `stderr'
     argument to *note Popen: 7d8. and indicates that a pipe to the
     standard stream should be opened.  Most useful with *note
     Popen.communicate(): 1dab.

 -- Data: subprocess.STDOUT

     Special value that can be used as the `stderr' argument to *note
     Popen: 7d8. and indicates that standard error should go into the
     same handle as standard output.

 -- Exception: subprocess.SubprocessError

     Base class for all other exceptions from this module.

     New in version 3.3.

 -- Exception: subprocess.TimeoutExpired

     Subclass of *note SubprocessError: 1db3, raised when a timeout
     expires while waiting for a child process.

      -- Attribute: cmd

          Command that was used to spawn the child process.

      -- Attribute: timeout

          Timeout in seconds.

      -- Attribute: output

          Output of the child process if it was captured by *note run():
          1c3. or *note check_output(): 4db.  Otherwise, ‘None’.

      -- Attribute: stdout

          Alias for output, for symmetry with *note stderr: 1db8.

      -- Attribute: stderr

          Stderr output of the child process if it was captured by *note
          run(): 1c3.  Otherwise, ‘None’.

     New in version 3.3.

     Changed in version 3.5: `stdout' and `stderr' attributes added

 -- Exception: subprocess.CalledProcessError

     Subclass of *note SubprocessError: 1db3, raised when a process run
     by *note check_call(): 1db9. or *note check_output(): 4db. returns
     a non-zero exit status.

      -- Attribute: returncode

          Exit status of the child process.

      -- Attribute: cmd

          Command that was used to spawn the child process.

      -- Attribute: output

          Output of the child process if it was captured by *note run():
          1c3. or *note check_output(): 4db.  Otherwise, ‘None’.

      -- Attribute: stdout

          Alias for output, for symmetry with *note stderr: 1dbe.

      -- Attribute: stderr

          Stderr output of the child process if it was captured by *note
          run(): 1c3.  Otherwise, ‘None’.

     Changed in version 3.5: `stdout' and `stderr' attributes added

* Menu:

* Frequently Used Arguments:: 
* Popen Constructor:: 
* Exceptions: Exceptions<6>. 


File: python.info,  Node: Frequently Used Arguments,  Next: Popen Constructor,  Up: Using the subprocess Module

5.17.5.2 Frequently Used Arguments
..................................

To support a wide variety of use cases, the *note Popen: 7d8.
constructor (and the convenience functions) accept a large number of
optional arguments.  For most typical use cases, many of these arguments
can be safely left at their default values.  The arguments that are most
commonly needed are:

     `args' is required for all calls and should be a string, or a
     sequence of program arguments.  Providing a sequence of arguments
     is generally preferred, as it allows the module to take care of any
     required escaping and quoting of arguments (e.g.  to permit spaces
     in file names).  If passing a single string, either `shell' must be
     *note True: 9ff. (see below) or else the string must simply name
     the program to be executed without specifying any arguments.

     `stdin', `stdout' and `stderr' specify the executed program’s
     standard input, standard output and standard error file handles,
     respectively.  Valid values are *note PIPE: 1daa, *note DEVNULL:
     6da, an existing file descriptor (a positive integer), an existing
     file object, and ‘None’.  *note PIPE: 1daa. indicates that a new
     pipe to the child should be created.  *note DEVNULL: 6da. indicates
     that the special file *note os.devnull: bb9. will be used.  With
     the default settings of ‘None’, no redirection will occur; the
     child’s file handles will be inherited from the parent.
     Additionally, `stderr' can be *note STDOUT: 1db2, which indicates
     that the stderr data from the child process should be captured into
     the same file handle as for `stdout'.

     If `universal_newlines' is ‘False’ the file objects `stdin',
     `stdout' and `stderr' will be opened as binary streams, and no line
     ending conversion is done.

     If `universal_newlines' is ‘True’, these file objects will be
     opened as text streams in *note universal newlines: 994. mode using
     the encoding returned by *note locale.getpreferredencoding(False):
     fb0.  For `stdin', line ending characters ‘'\n'’ in the input will
     be converted to the default line separator *note os.linesep: fb3.
     For `stdout' and `stderr', all line endings in the output will be
     converted to ‘'\n'’.  For more information see the documentation of
     the *note io.TextIOWrapper: 557. class when the `newline' argument
     to its constructor is ‘None’.

          Note: The newlines attribute of the file objects *note
          Popen.stdin: 1dc0, *note Popen.stdout: 1dc1. and *note
          Popen.stderr: 1dc2. are not updated by the *note
          Popen.communicate(): 1dab. method.

     If `shell' is ‘True’, the specified command will be executed
     through the shell.  This can be useful if you are using Python
     primarily for the enhanced control flow it offers over most system
     shells and still want convenient access to other shell features
     such as shell pipes, filename wildcards, environment variable
     expansion, and expansion of ‘~’ to a user’s home directory.
     However, note that Python itself offers implementations of many
     shell-like features (in particular, *note glob: 89, *note fnmatch:
     7f, *note os.walk(): 1e1, *note os.path.expandvars(): 9ba, *note
     os.path.expanduser(): 1569, and *note shutil: e7.).

     Changed in version 3.3: When `universal_newlines' is ‘True’, the
     class uses the encoding *note locale.getpreferredencoding(False):
     fb0. instead of ‘locale.getpreferredencoding()’.  See the *note
     io.TextIOWrapper: 557. class for more information on this change.

          Note: Read the *note Security Considerations: 1dc3. section
          before using ‘shell=True’.

These options, along with all of the other options, are described in
more detail in the *note Popen: 7d8. constructor documentation.


File: python.info,  Node: Popen Constructor,  Next: Exceptions<6>,  Prev: Frequently Used Arguments,  Up: Using the subprocess Module

5.17.5.3 Popen Constructor
..........................

The underlying process creation and management in this module is handled
by the *note Popen: 7d8. class.  It offers a lot of flexibility so that
developers are able to handle the less common cases not covered by the
convenience functions.

 -- Class: subprocess.Popen (args, bufsize=-1, executable=None,
          stdin=None, stdout=None, stderr=None, preexec_fn=None,
          close_fds=True, shell=False, cwd=None, env=None,
          universal_newlines=False, startupinfo=None, creationflags=0,
          restore_signals=True, start_new_session=False, pass_fds=())

     Execute a child program in a new process.  On POSIX, the class uses
     *note os.execvp(): 18eb.-like behavior to execute the child
     program.  On Windows, the class uses the Windows ‘CreateProcess()’
     function.  The arguments to *note Popen: 7d8. are as follows.

     `args' should be a sequence of program arguments or else a single
     string.  By default, the program to execute is the first item in
     `args' if `args' is a sequence.  If `args' is a string, the
     interpretation is platform-dependent and described below.  See the
     `shell' and `executable' arguments for additional differences from
     the default behavior.  Unless otherwise stated, it is recommended
     to pass `args' as a sequence.

     On POSIX, if `args' is a string, the string is interpreted as the
     name or path of the program to execute.  However, this can only be
     done if not passing arguments to the program.

          Note: *note shlex.split(): 1dc5. can be useful when
          determining the correct tokenization for `args', especially in
          complex cases:

               >>> import shlex, subprocess
               >>> command_line = input()
               /bin/vikings -input eggs.txt -output "spam spam.txt" -cmd "echo '$MONEY'"
               >>> args = shlex.split(command_line)
               >>> print(args)
               ['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
               >>> p = subprocess.Popen(args) # Success!

          Note in particular that options (such as `-input') and
          arguments (such as `eggs.txt') that are separated by
          whitespace in the shell go in separate list elements, while
          arguments that need quoting or backslash escaping when used in
          the shell (such as filenames containing spaces or the `echo'
          command shown above) are single list elements.

     On Windows, if `args' is a sequence, it will be converted to a
     string in a manner described in *note Converting an argument
     sequence to a string on Windows: 1dc6.  This is because the
     underlying ‘CreateProcess()’ operates on strings.

     The `shell' argument (which defaults to `False') specifies whether
     to use the shell as the program to execute.  If `shell' is `True',
     it is recommended to pass `args' as a string rather than as a
     sequence.

     On POSIX with ‘shell=True’, the shell defaults to ‘/bin/sh’.  If
     `args' is a string, the string specifies the command to execute
     through the shell.  This means that the string must be formatted
     exactly as it would be when typed at the shell prompt.  This
     includes, for example, quoting or backslash escaping filenames with
     spaces in them.  If `args' is a sequence, the first item specifies
     the command string, and any additional items will be treated as
     additional arguments to the shell itself.  That is to say, *note
     Popen: 7d8. does the equivalent of:

          Popen(['/bin/sh', '-c', args[0], args[1], ...])

     On Windows with ‘shell=True’, the ‘COMSPEC’ environment variable
     specifies the default shell.  The only time you need to specify
     ‘shell=True’ on Windows is when the command you wish to execute is
     built into the shell (e.g.  ‘dir’ or ‘copy’).  You do not need
     ‘shell=True’ to run a batch file or console-based executable.

          Note: Read the *note Security Considerations: 1dc3. section
          before using ‘shell=True’.

     `bufsize' will be supplied as the corresponding argument to the
     *note open(): 1e8. function when creating the stdin/stdout/stderr
     pipe file objects:

        - ‘0’ means unbuffered (read and write are one system call and
          can return short)

        - ‘1’ means line buffered (only usable if
          ‘universal_newlines=True’ i.e., in a text mode)

        - any other positive value means use a buffer of approximately
          that size

        - negative bufsize (the default) means the system default of
          io.DEFAULT_BUFFER_SIZE will be used.

     Changed in version 3.3.1: `bufsize' now defaults to -1 to enable
     buffering by default to match the behavior that most code expects.
     In versions prior to Python 3.2.4 and 3.3.1 it incorrectly
     defaulted to ‘0’ which was unbuffered and allowed short reads.
     This was unintentional and did not match the behavior of Python 2
     as most code expected.

     The `executable' argument specifies a replacement program to
     execute.  It is very seldom needed.  When ‘shell=False’,
     `executable' replaces the program to execute specified by `args'.
     However, the original `args' is still passed to the program.  Most
     programs treat the program specified by `args' as the command name,
     which can then be different from the program actually executed.  On
     POSIX, the `args' name becomes the display name for the executable
     in utilities such as ‘ps’.  If ‘shell=True’, on POSIX the
     `executable' argument specifies a replacement shell for the default
     ‘/bin/sh’.

     `stdin', `stdout' and `stderr' specify the executed program’s
     standard input, standard output and standard error file handles,
     respectively.  Valid values are *note PIPE: 1daa, *note DEVNULL:
     6da, an existing file descriptor (a positive integer), an existing
     *note file object: 78b, and ‘None’.  *note PIPE: 1daa. indicates
     that a new pipe to the child should be created.  *note DEVNULL:
     6da. indicates that the special file *note os.devnull: bb9. will be
     used.  With the default settings of ‘None’, no redirection will
     occur; the child’s file handles will be inherited from the parent.
     Additionally, `stderr' can be *note STDOUT: 1db2, which indicates
     that the stderr data from the applications should be captured into
     the same file handle as for stdout.

     If `preexec_fn' is set to a callable object, this object will be
     called in the child process just before the child is executed.
     (POSIX only)

          Warning: The `preexec_fn' parameter is not safe to use in the
          presence of threads in your application.  The child process
          could deadlock before exec is called.  If you must use it,
          keep it trivial!  Minimize the number of libraries you call
          into.

          Note: If you need to modify the environment for the child use
          the `env' parameter rather than doing it in a `preexec_fn'.
          The `start_new_session' parameter can take the place of a
          previously common use of `preexec_fn' to call os.setsid() in
          the child.

     If `close_fds' is true, all file descriptors except ‘0’, ‘1’ and
     ‘2’ will be closed before the child process is executed.  (POSIX
     only).  The default varies by platform: Always true on POSIX. On
     Windows it is true when `stdin'/`stdout'/`stderr' are *note None:
     19d, false otherwise.  On Windows, if `close_fds' is true then no
     handles will be inherited by the child process.  Note that on
     Windows, you cannot set `close_fds' to true and also redirect the
     standard handles by setting `stdin', `stdout' or `stderr'.

     Changed in version 3.2: The default for `close_fds' was changed
     from *note False: 60d. to what is described above.

     `pass_fds' is an optional sequence of file descriptors to keep open
     between the parent and child.  Providing any `pass_fds' forces
     `close_fds' to be *note True: 9ff.  (POSIX only)

     New in version 3.2: The `pass_fds' parameter was added.

     If `cwd' is not ‘None’, the function changes the working directory
     to `cwd' before executing the child.  In particular, the function
     looks for `executable' (or for the first item in `args') relative
     to `cwd' if the executable path is a relative path.

     If `restore_signals' is true (the default) all signals that Python
     has set to SIG_IGN are restored to SIG_DFL in the child process
     before the exec.  Currently this includes the SIGPIPE, SIGXFZ and
     SIGXFSZ signals.  (POSIX only)

     Changed in version 3.2: `restore_signals' was added.

     If `start_new_session' is true the setsid() system call will be
     made in the child process prior to the execution of the subprocess.
     (POSIX only)

     Changed in version 3.2: `start_new_session' was added.

     If `env' is not ‘None’, it must be a mapping that defines the
     environment variables for the new process; these are used instead
     of the default behavior of inheriting the current process’
     environment.

          Note: If specified, `env' must provide any variables required
          for the program to execute.  On Windows, in order to run a
          side-by-side assembly(1) the specified `env' `must' include a
          valid ‘SystemRoot’.

     If `universal_newlines' is ‘True’, the file objects `stdin',
     `stdout' and `stderr' are opened as text streams in universal
     newlines mode, as described above in *note Frequently Used
     Arguments: 1da9, otherwise they are opened as binary streams.

     If given, `startupinfo' will be a *note STARTUPINFO: 1dc7. object,
     which is passed to the underlying ‘CreateProcess’ function.
     `creationflags', if given, can be *note CREATE_NEW_CONSOLE: 1dc8.
     or *note CREATE_NEW_PROCESS_GROUP: 1dc9.  (Windows only)

     Popen objects are supported as context managers via the *note with:
     29d. statement: on exit, standard file descriptors are closed, and
     the process is waited for.

          with Popen(["ifconfig"], stdout=PIPE) as proc:
              log.write(proc.stdout.read())

     Changed in version 3.2: Added context manager support.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Side-by-Side_Assembly


File: python.info,  Node: Exceptions<6>,  Prev: Popen Constructor,  Up: Using the subprocess Module

5.17.5.4 Exceptions
...................

Exceptions raised in the child process, before the new program has
started to execute, will be re-raised in the parent.  Additionally, the
exception object will have one extra attribute called ‘child_traceback’,
which is a string containing traceback information from the child’s
point of view.

The most common exception raised is *note OSError: 4b6.  This occurs,
for example, when trying to execute a non-existent file.  Applications
should prepare for *note OSError: 4b6. exceptions.

A *note ValueError: 19c. will be raised if *note Popen: 7d8. is called
with invalid arguments.

*note check_call(): 1db9. and *note check_output(): 4db. will raise
*note CalledProcessError: 92a. if the called process returns a non-zero
return code.

All of the functions and methods that accept a `timeout' parameter, such
as *note call(): 1dcb. and *note Popen.communicate(): 1dab. will raise
*note TimeoutExpired: 1dac. if the timeout expires before the process
exits.

Exceptions defined in this module all inherit from *note
SubprocessError: 1db3.

     New in version 3.3: The *note SubprocessError: 1db3. base class was
     added.


File: python.info,  Node: Security Considerations,  Next: Popen Objects,  Prev: Using the subprocess Module,  Up: subprocess --- Subprocess management

5.17.5.5 Security Considerations
................................

Unlike some other popen functions, this implementation will never
implicitly call a system shell.  This means that all characters,
including shell metacharacters, can safely be passed to child processes.
If the shell is invoked explicitly, via ‘shell=True’, it is the
application’s responsibility to ensure that all whitespace and
metacharacters are quoted appropriately to avoid shell injection(1)
vulnerabilities.

When using ‘shell=True’, the *note shlex.quote(): 6aa. function can be
used to properly escape whitespace and shell metacharacters in strings
that are going to be used to construct shell commands.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Shell_injection#Shell_injection


File: python.info,  Node: Popen Objects,  Next: Windows Popen Helpers,  Prev: Security Considerations,  Up: subprocess --- Subprocess management

5.17.5.6 Popen Objects
......................

Instances of the *note Popen: 7d8. class have the following methods:

 -- Method: Popen.poll ()

     Check if child process has terminated.  Set and return *note
     returncode: 1dce. attribute.

 -- Method: Popen.wait (timeout=None)

     Wait for child process to terminate.  Set and return *note
     returncode: 1dce. attribute.

     If the process does not terminate after `timeout' seconds, raise a
     *note TimeoutExpired: 1dac. exception.  It is safe to catch this
     exception and retry the wait.

          Note: This will deadlock when using ‘stdout=PIPE’ or
          ‘stderr=PIPE’ and the child process generates enough output to
          a pipe such that it blocks waiting for the OS pipe buffer to
          accept more data.  Use *note Popen.communicate(): 1dab. when
          using pipes to avoid that.

          Note: The function is implemented using a busy loop
          (non-blocking call and short sleeps).  Use the *note asyncio:
          a. module for an asynchronous wait: see *note
          asyncio.create_subprocess_exec: 1dcf.

     Changed in version 3.3: `timeout' was added.

     Deprecated since version 3.4: Do not use the `endtime' parameter.
     It is was unintentionally exposed in 3.3 but was left undocumented
     as it was intended to be private for internal use.  Use `timeout'
     instead.

 -- Method: Popen.communicate (input=None, timeout=None)

     Interact with process: Send data to stdin.  Read data from stdout
     and stderr, until end-of-file is reached.  Wait for process to
     terminate.  The optional `input' argument should be data to be sent
     to the child process, or ‘None’, if no data should be sent to the
     child.  The type of `input' must be bytes or, if
     `universal_newlines' was ‘True’, a string.

     *note communicate(): 1dab. returns a tuple ‘(stdout_data,
     stderr_data)’.  The data will be bytes or, if `universal_newlines'
     was ‘True’, strings.

     Note that if you want to send data to the process’s stdin, you need
     to create the Popen object with ‘stdin=PIPE’.  Similarly, to get
     anything other than ‘None’ in the result tuple, you need to give
     ‘stdout=PIPE’ and/or ‘stderr=PIPE’ too.

     If the process does not terminate after `timeout' seconds, a *note
     TimeoutExpired: 1dac. exception will be raised.  Catching this
     exception and retrying communication will not lose any output.

     The child process is not killed if the timeout expires, so in order
     to cleanup properly a well-behaved application should kill the
     child process and finish communication:

          proc = subprocess.Popen(...)
          try:
              outs, errs = proc.communicate(timeout=15)
          except TimeoutExpired:
              proc.kill()
              outs, errs = proc.communicate()

          Note: The data read is buffered in memory, so do not use this
          method if the data size is large or unlimited.

     Changed in version 3.3: `timeout' was added.

 -- Method: Popen.send_signal (signal)

     Sends the signal `signal' to the child.

          Note: On Windows, SIGTERM is an alias for *note terminate():
          1dd1.  CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to
          processes started with a `creationflags' parameter which
          includes ‘CREATE_NEW_PROCESS_GROUP’.

 -- Method: Popen.terminate ()

     Stop the child.  On Posix OSs the method sends SIGTERM to the
     child.  On Windows the Win32 API function ‘TerminateProcess()’ is
     called to stop the child.

 -- Method: Popen.kill ()

     Kills the child.  On Posix OSs the function sends SIGKILL to the
     child.  On Windows *note kill(): 1dd2. is an alias for *note
     terminate(): 1dd1.

The following attributes are also available:

 -- Attribute: Popen.args

     The `args' argument as it was passed to *note Popen: 7d8. – a
     sequence of program arguments or else a single string.

     New in version 3.3.

 -- Attribute: Popen.stdin

     If the `stdin' argument was *note PIPE: 1daa, this attribute is a
     writeable stream object as returned by *note open(): 1e8.  If the
     `universal_newlines' argument was ‘True’, the stream is a text
     stream, otherwise it is a byte stream.  If the `stdin' argument was
     not *note PIPE: 1daa, this attribute is ‘None’.

 -- Attribute: Popen.stdout

     If the `stdout' argument was *note PIPE: 1daa, this attribute is a
     readable stream object as returned by *note open(): 1e8.  Reading
     from the stream provides output from the child process.  If the
     `universal_newlines' argument was ‘True’, the stream is a text
     stream, otherwise it is a byte stream.  If the `stdout' argument
     was not *note PIPE: 1daa, this attribute is ‘None’.

 -- Attribute: Popen.stderr

     If the `stderr' argument was *note PIPE: 1daa, this attribute is a
     readable stream object as returned by *note open(): 1e8.  Reading
     from the stream provides error output from the child process.  If
     the `universal_newlines' argument was ‘True’, the stream is a text
     stream, otherwise it is a byte stream.  If the `stderr' argument
     was not *note PIPE: 1daa, this attribute is ‘None’.

     Warning: Use *note communicate(): 1dab. rather than *note
     .stdin.write: 1dc0, *note .stdout.read: 1dc1. or *note
     .stderr.read: 1dc2. to avoid deadlocks due to any of the other OS
     pipe buffers filling up and blocking the child process.

 -- Attribute: Popen.pid

     The process ID of the child process.

     Note that if you set the `shell' argument to ‘True’, this is the
     process ID of the spawned shell.

 -- Attribute: Popen.returncode

     The child return code, set by *note poll(): 1dcd. and *note wait():
     551. (and indirectly by *note communicate(): 1dab.).  A ‘None’
     value indicates that the process hasn’t terminated yet.

     A negative value ‘-N’ indicates that the child was terminated by
     signal ‘N’ (POSIX only).


File: python.info,  Node: Windows Popen Helpers,  Next: Older high-level API,  Prev: Popen Objects,  Up: subprocess --- Subprocess management

5.17.5.7 Windows Popen Helpers
..............................

The *note STARTUPINFO: 1dc7. class and following constants are only
available on Windows.

 -- Class: subprocess.STARTUPINFO

     Partial support of the Windows STARTUPINFO(1) structure is used for
     *note Popen: 7d8. creation.

      -- Attribute: dwFlags

          A bit field that determines whether certain *note STARTUPINFO:
          1dc7. attributes are used when the process creates a window.

               si = subprocess.STARTUPINFO()
               si.dwFlags = subprocess.STARTF_USESTDHANDLES | subprocess.STARTF_USESHOWWINDOW

      -- Attribute: hStdInput

          If *note dwFlags: 1dd6. specifies *note STARTF_USESTDHANDLES:
          1dd8, this attribute is the standard input handle for the
          process.  If *note STARTF_USESTDHANDLES: 1dd8. is not
          specified, the default for standard input is the keyboard
          buffer.

      -- Attribute: hStdOutput

          If *note dwFlags: 1dd6. specifies *note STARTF_USESTDHANDLES:
          1dd8, this attribute is the standard output handle for the
          process.  Otherwise, this attribute is ignored and the default
          for standard output is the console window’s buffer.

      -- Attribute: hStdError

          If *note dwFlags: 1dd6. specifies *note STARTF_USESTDHANDLES:
          1dd8, this attribute is the standard error handle for the
          process.  Otherwise, this attribute is ignored and the default
          for standard error is the console window’s buffer.

      -- Attribute: wShowWindow

          If *note dwFlags: 1dd6. specifies *note STARTF_USESHOWWINDOW:
          1ddc, this attribute can be any of the values that can be
          specified in the ‘nCmdShow’ parameter for the ShowWindow(2)
          function, except for ‘SW_SHOWDEFAULT’.  Otherwise, this
          attribute is ignored.

          *note SW_HIDE: 1ddd. is provided for this attribute.  It is
          used when *note Popen: 7d8. is called with ‘shell=True’.

* Menu:

* Constants: Constants<5>. 

   ---------- Footnotes ----------

   (1) https://msdn.microsoft.com/en-us/library/ms686331(v=vs.85).aspx

   (2) https://msdn.microsoft.com/en-us/library/ms633548(v=vs.85).aspx


File: python.info,  Node: Constants<5>,  Up: Windows Popen Helpers

5.17.5.8 Constants
..................

The *note subprocess: f7. module exposes the following constants.

 -- Data: subprocess.STD_INPUT_HANDLE

     The standard input device.  Initially, this is the console input
     buffer, ‘CONIN$’.

 -- Data: subprocess.STD_OUTPUT_HANDLE

     The standard output device.  Initially, this is the active console
     screen buffer, ‘CONOUT$’.

 -- Data: subprocess.STD_ERROR_HANDLE

     The standard error device.  Initially, this is the active console
     screen buffer, ‘CONOUT$’.

 -- Data: subprocess.SW_HIDE

     Hides the window.  Another window will be activated.

 -- Data: subprocess.STARTF_USESTDHANDLES

     Specifies that the *note STARTUPINFO.hStdInput: 1dd7, *note
     STARTUPINFO.hStdOutput: 1dd9, and *note STARTUPINFO.hStdError:
     1dda. attributes contain additional information.

 -- Data: subprocess.STARTF_USESHOWWINDOW

     Specifies that the *note STARTUPINFO.wShowWindow: 1ddb. attribute
     contains additional information.

 -- Data: subprocess.CREATE_NEW_CONSOLE

     The new process has a new console, instead of inheriting its
     parent’s console (the default).

 -- Data: subprocess.CREATE_NEW_PROCESS_GROUP

     A *note Popen: 7d8. ‘creationflags’ parameter to specify that a new
     process group will be created.  This flag is necessary for using
     *note os.kill(): 96e. on the subprocess.

     This flag is ignored if *note CREATE_NEW_CONSOLE: 1dc8. is
     specified.


File: python.info,  Node: Older high-level API,  Next: Replacing Older Functions with the subprocess Module,  Prev: Windows Popen Helpers,  Up: subprocess --- Subprocess management

5.17.5.9 Older high-level API
.............................

Prior to Python 3.5, these three functions comprised the high level API
to subprocess.  You can now use *note run(): 1c3. in many cases, but
lots of existing code calls these functions.

 -- Function: subprocess.call (args, *, stdin=None, stdout=None,
          stderr=None, shell=False, timeout=None)

     Run the command described by `args'.  Wait for command to complete,
     then return the *note returncode: 1dce. attribute.

     This is equivalent to:

          run(...).returncode

     (except that the `input' and `check' parameters are not supported)

     The arguments shown above are merely the most common ones.  The
     full function signature is largely the same as that of the *note
     Popen: 7d8. constructor - this function passes all supplied
     arguments other than `timeout' directly through to that interface.

          Note: Do not use ‘stdout=PIPE’ or ‘stderr=PIPE’ with this
          function.  The child process will block if it generates enough
          output to a pipe to fill up the OS pipe buffer as the pipes
          are not being read from.

     Changed in version 3.3: `timeout' was added.

 -- Function: subprocess.check_call (args, *, stdin=None, stdout=None,
          stderr=None, shell=False, timeout=None)

     Run command with arguments.  Wait for command to complete.  If the
     return code was zero then return, otherwise raise *note
     CalledProcessError: 92a.  The *note CalledProcessError: 92a. object
     will have the return code in the *note returncode: 1dba. attribute.

     This is equivalent to:

          run(..., check=True)

     (except that the `input' parameter is not supported)

     The arguments shown above are merely the most common ones.  The
     full function signature is largely the same as that of the *note
     Popen: 7d8. constructor - this function passes all supplied
     arguments other than `timeout' directly through to that interface.

          Note: Do not use ‘stdout=PIPE’ or ‘stderr=PIPE’ with this
          function.  The child process will block if it generates enough
          output to a pipe to fill up the OS pipe buffer as the pipes
          are not being read from.

     Changed in version 3.3: `timeout' was added.

 -- Function: subprocess.check_output (args, *, stdin=None, stderr=None,
          shell=False, universal_newlines=False, timeout=None)

     Run command with arguments and return its output.

     If the return code was non-zero it raises a *note
     CalledProcessError: 92a.  The *note CalledProcessError: 92a. object
     will have the return code in the *note returncode: 1dba. attribute
     and any output in the *note output: 1dbc. attribute.

     This is equivalent to:

          run(..., check=True, stdout=PIPE).stdout

     The arguments shown above are merely the most common ones.  The
     full function signature is largely the same as that of *note run():
     1c3. - most arguments are passed directly through to that
     interface.  However, explicitly passing ‘input=None’ to inherit the
     parent’s standard input file handle is not supported.

     By default, this function will return the data as encoded bytes.
     The actual encoding of the output data may depend on the command
     being invoked, so the decoding to text will often need to be
     handled at the application level.

     This behaviour may be overridden by setting `universal_newlines' to
     ‘True’ as described above in *note Frequently Used Arguments: 1da9.

     To also capture standard error in the result, use
     ‘stderr=subprocess.STDOUT’:

          >>> subprocess.check_output(
          ...     "ls non_existent_file; exit 0",
          ...     stderr=subprocess.STDOUT,
          ...     shell=True)
          'ls: non_existent_file: No such file or directory\n'

     New in version 3.1.

     Changed in version 3.3: `timeout' was added.

     Changed in version 3.4: Support for the `input' keyword argument
     was added.


File: python.info,  Node: Replacing Older Functions with the subprocess Module,  Next: Legacy Shell Invocation Functions,  Prev: Older high-level API,  Up: subprocess --- Subprocess management

5.17.5.10 Replacing Older Functions with the ‘subprocess’ Module
................................................................

In this section, "a becomes b" means that b can be used as a replacement
for a.

     Note: All "a" functions in this section fail (more or less)
     silently if the executed program cannot be found; the "b"
     replacements raise *note OSError: 4b6. instead.

     In addition, the replacements using *note check_output(): 4db. will
     fail with a *note CalledProcessError: 92a. if the requested
     operation produces a non-zero return code.  The output is still
     available as the *note output: 1dbc. attribute of the raised
     exception.

In the following examples, we assume that the relevant functions have
already been imported from the *note subprocess: f7. module.

* Menu:

* Replacing /bin/sh shell backquote:: 
* Replacing shell pipeline:: 
* Replacing os.system(): Replacing os system. 
* Replacing the os.spawn family: Replacing the os spawn family. 
* Replacing os.popen(), os.popen2(), os.popen3(): Replacing os popen os popen2 os popen3. 
* Replacing functions from the popen2 module:: 


File: python.info,  Node: Replacing /bin/sh shell backquote,  Next: Replacing shell pipeline,  Up: Replacing Older Functions with the subprocess Module

5.17.5.11 Replacing /bin/sh shell backquote
...........................................

     output=`mycmd myarg`
     # becomes
     output = check_output(["mycmd", "myarg"])


File: python.info,  Node: Replacing shell pipeline,  Next: Replacing os system,  Prev: Replacing /bin/sh shell backquote,  Up: Replacing Older Functions with the subprocess Module

5.17.5.12 Replacing shell pipeline
..................................

     output=`dmesg | grep hda`
     # becomes
     p1 = Popen(["dmesg"], stdout=PIPE)
     p2 = Popen(["grep", "hda"], stdin=p1.stdout, stdout=PIPE)
     p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.
     output = p2.communicate()[0]

The p1.stdout.close() call after starting the p2 is important in order
for p1 to receive a SIGPIPE if p2 exits before p1.

Alternatively, for trusted input, the shell’s own pipeline support may
still be used directly:

     output=`dmesg | grep hda`
     # becomes
     output=check_output("dmesg | grep hda", shell=True)


File: python.info,  Node: Replacing os system,  Next: Replacing the os spawn family,  Prev: Replacing shell pipeline,  Up: Replacing Older Functions with the subprocess Module

5.17.5.13 Replacing ‘os.system()’
.................................

     sts = os.system("mycmd" + " myarg")
     # becomes
     sts = call("mycmd" + " myarg", shell=True)

Notes:

   * Calling the program through the shell is usually not required.

A more realistic example would look like this:

     try:
         retcode = call("mycmd" + " myarg", shell=True)
         if retcode < 0:
             print("Child was terminated by signal", -retcode, file=sys.stderr)
         else:
             print("Child returned", retcode, file=sys.stderr)
     except OSError as e:
         print("Execution failed:", e, file=sys.stderr)


File: python.info,  Node: Replacing the os spawn family,  Next: Replacing os popen os popen2 os popen3,  Prev: Replacing os system,  Up: Replacing Older Functions with the subprocess Module

5.17.5.14 Replacing the ‘os.spawn’ family
.........................................

P_NOWAIT example:

     pid = os.spawnlp(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg")
     ==>
     pid = Popen(["/bin/mycmd", "myarg"]).pid

P_WAIT example:

     retcode = os.spawnlp(os.P_WAIT, "/bin/mycmd", "mycmd", "myarg")
     ==>
     retcode = call(["/bin/mycmd", "myarg"])

Vector example:

     os.spawnvp(os.P_NOWAIT, path, args)
     ==>
     Popen([path] + args[1:])

Environment example:

     os.spawnlpe(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg", env)
     ==>
     Popen(["/bin/mycmd", "myarg"], env={"PATH": "/usr/bin"})


File: python.info,  Node: Replacing os popen os popen2 os popen3,  Next: Replacing functions from the popen2 module,  Prev: Replacing the os spawn family,  Up: Replacing Older Functions with the subprocess Module

5.17.5.15 Replacing ‘os.popen()’, ‘os.popen2()’, ‘os.popen3()’
..............................................................

     (child_stdin, child_stdout) = os.popen2(cmd, mode, bufsize)
     ==>
     p = Popen(cmd, shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, close_fds=True)
     (child_stdin, child_stdout) = (p.stdin, p.stdout)

     (child_stdin,
      child_stdout,
      child_stderr) = os.popen3(cmd, mode, bufsize)
     ==>
     p = Popen(cmd, shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)
     (child_stdin,
      child_stdout,
      child_stderr) = (p.stdin, p.stdout, p.stderr)

     (child_stdin, child_stdout_and_stderr) = os.popen4(cmd, mode, bufsize)
     ==>
     p = Popen(cmd, shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
     (child_stdin, child_stdout_and_stderr) = (p.stdin, p.stdout)

Return code handling translates as follows:

     pipe = os.popen(cmd, 'w')
     ...
     rc = pipe.close()
     if rc is not None and rc >> 8:
         print("There were some errors")
     ==>
     process = Popen(cmd, stdin=PIPE)
     ...
     process.stdin.close()
     if process.wait() != 0:
         print("There were some errors")


File: python.info,  Node: Replacing functions from the popen2 module,  Prev: Replacing os popen os popen2 os popen3,  Up: Replacing Older Functions with the subprocess Module

5.17.5.16 Replacing functions from the ‘popen2’ module
......................................................

     Note: If the cmd argument to popen2 functions is a string, the
     command is executed through /bin/sh.  If it is a list, the command
     is directly executed.

     (child_stdout, child_stdin) = popen2.popen2("somestring", bufsize, mode)
     ==>
     p = Popen("somestring", shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, close_fds=True)
     (child_stdout, child_stdin) = (p.stdout, p.stdin)

     (child_stdout, child_stdin) = popen2.popen2(["mycmd", "myarg"], bufsize, mode)
     ==>
     p = Popen(["mycmd", "myarg"], bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, close_fds=True)
     (child_stdout, child_stdin) = (p.stdout, p.stdin)

‘popen2.Popen3’ and ‘popen2.Popen4’ basically work as *note
subprocess.Popen: 7d8, except that:

   * *note Popen: 7d8. raises an exception if the execution fails.

   * the `capturestderr' argument is replaced with the `stderr'
     argument.

   * ‘stdin=PIPE’ and ‘stdout=PIPE’ must be specified.

   * popen2 closes all file descriptors by default, but you have to
     specify ‘close_fds=True’ with *note Popen: 7d8. to guarantee this
     behavior on all platforms or past Python versions.


File: python.info,  Node: Legacy Shell Invocation Functions,  Next: Notes,  Prev: Replacing Older Functions with the subprocess Module,  Up: subprocess --- Subprocess management

5.17.5.17 Legacy Shell Invocation Functions
...........................................

This module also provides the following legacy functions from the 2.x
‘commands’ module.  These operations implicitly invoke the system shell
and none of the guarantees described above regarding security and
exception handling consistency are valid for these functions.

 -- Function: subprocess.getstatusoutput (cmd)

     Return ‘(status, output)’ of executing `cmd' in a shell.

     Execute the string `cmd' in a shell with ‘Popen.check_output()’ and
     return a 2-tuple ‘(status, output)’.  Universal newlines mode is
     used; see the notes on *note Frequently Used Arguments: 1da9. for
     more details.

     A trailing newline is stripped from the output.  The exit status
     for the command can be interpreted according to the rules for the C
     function ‘wait()’.  Example:

          >>> subprocess.getstatusoutput('ls /bin/ls')
          (0, '/bin/ls')
          >>> subprocess.getstatusoutput('cat /bin/junk')
          (256, 'cat: /bin/junk: No such file or directory')
          >>> subprocess.getstatusoutput('/bin/junk')
          (256, 'sh: /bin/junk: not found')

     Availability: POSIX & Windows

     Changed in version 3.3.4: Windows support added

 -- Function: subprocess.getoutput (cmd)

     Return output (stdout and stderr) of executing `cmd' in a shell.

     Like *note getstatusoutput(): 4dc, except the exit status is
     ignored and the return value is a string containing the command’s
     output.  Example:

          >>> subprocess.getoutput('ls /bin/ls')
          '/bin/ls'

     Availability: POSIX & Windows

     Changed in version 3.3.4: Windows support added


File: python.info,  Node: Notes,  Prev: Legacy Shell Invocation Functions,  Up: subprocess --- Subprocess management

5.17.5.18 Notes
...............

* Menu:

* Converting an argument sequence to a string on Windows:: 


File: python.info,  Node: Converting an argument sequence to a string on Windows,  Up: Notes

5.17.5.19 Converting an argument sequence to a string on Windows
................................................................

On Windows, an `args' sequence is converted to a string that can be
parsed using the following rules (which correspond to the rules used by
the MS C runtime):

  1. Arguments are delimited by white space, which is either a space or
     a tab.

  2. A string surrounded by double quotation marks is interpreted as a
     single argument, regardless of white space contained within.  A
     quoted string can be embedded in an argument.

  3. A double quotation mark preceded by a backslash is interpreted as a
     literal double quotation mark.

  4. Backslashes are interpreted literally, unless they immediately
     precede a double quotation mark.

  5. If backslashes immediately precede a double quotation mark, every
     pair of backslashes is interpreted as a literal backslash.  If the
     number of backslashes is odd, the last backslash escapes the next
     double quotation mark as described in rule 3.

See also
........

*note shlex: e6.

     Module which provides function to parse and escape command lines.


File: python.info,  Node: sched --- Event scheduler,  Next: queue --- A synchronized queue class,  Prev: subprocess --- Subprocess management,  Up: Concurrent Execution

5.17.6 ‘sched’ — Event scheduler
--------------------------------

`Source code:' Lib/sched.py(1)

__________________________________________________________________

The *note sched: e1. module defines a class which implements a general
purpose event scheduler:

 -- Class: sched.scheduler (timefunc=time.monotonic,
          delayfunc=time.sleep)

     The *note scheduler: 6a4. class defines a generic interface to
     scheduling events.  It needs two functions to actually deal with
     the "outside world" — `timefunc' should be callable without
     arguments, and return a number (the "time", in any units
     whatsoever).  If time.monotonic is not available, the `timefunc'
     default is time.time instead.  The `delayfunc' function should be
     callable with one argument, compatible with the output of
     `timefunc', and should delay that many time units.  `delayfunc'
     will also be called with the argument ‘0’ after each event is run
     to allow other threads an opportunity to run in multi-threaded
     applications.

     Changed in version 3.3: `timefunc' and `delayfunc' parameters are
     optional.

     Changed in version 3.3: *note scheduler: 6a4. class can be safely
     used in multi-threaded environments.

Example:

     >>> import sched, time
     >>> s = sched.scheduler(time.time, time.sleep)
     >>> def print_time(a='default'):
     ...     print("From print_time", time.time(), a)
     ...
     >>> def print_some_times():
     ...     print(time.time())
     ...     s.enter(10, 1, print_time)
     ...     s.enter(5, 2, print_time, argument=('positional',))
     ...     s.enter(5, 1, print_time, kwargs={'a': 'keyword'})
     ...     s.run()
     ...     print(time.time())
     ...
     >>> print_some_times()
     930343690.257
     From print_time 930343695.274 positional
     From print_time 930343695.275 keyword
     From print_time 930343700.273 default
     930343700.276

* Menu:

* Scheduler Objects:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/sched.py


File: python.info,  Node: Scheduler Objects,  Up: sched --- Event scheduler

5.17.6.1 Scheduler Objects
..........................

*note scheduler: 6a4. instances have the following methods and
attributes:

 -- Method: scheduler.enterabs (time, priority, action, argument=(),
          kwargs={})

     Schedule a new event.  The `time' argument should be a numeric type
     compatible with the return value of the `timefunc' function passed
     to the constructor.  Events scheduled for the same `time' will be
     executed in the order of their `priority'.

     Executing the event means executing ‘action(*argument, **kwargs)’.
     `argument' is a sequence holding the positional arguments for
     `action'.  `kwargs' is a dictionary holding the keyword arguments
     for `action'.

     Return value is an event which may be used for later cancellation
     of the event (see *note cancel(): 1df2.).

     Changed in version 3.3: `argument' parameter is optional.

     New in version 3.3: `kwargs' parameter was added.

 -- Method: scheduler.enter (delay, priority, action, argument=(),
          kwargs={})

     Schedule an event for `delay' more time units.  Other than the
     relative time, the other arguments, the effect and the return value
     are the same as those for *note enterabs(): 6a7.

     Changed in version 3.3: `argument' parameter is optional.

     New in version 3.3: `kwargs' parameter was added.

 -- Method: scheduler.cancel (event)

     Remove the event from the queue.  If `event' is not an event
     currently in the queue, this method will raise a *note ValueError:
     19c.

 -- Method: scheduler.empty ()

     Return true if the event queue is empty.

 -- Method: scheduler.run (blocking=True)

     Run all scheduled events.  This method will wait (using the
     ‘delayfunc()’ function passed to the constructor) for the next
     event, then execute it and so on until there are no more scheduled
     events.

     If `blocking' is false executes the scheduled events due to expire
     soonest (if any) and then return the deadline of the next scheduled
     call in the scheduler (if any).

     Either `action' or `delayfunc' can raise an exception.  In either
     case, the scheduler will maintain a consistent state and propagate
     the exception.  If an exception is raised by `action', the event
     will not be attempted in future calls to *note run(): 6a3.

     If a sequence of events takes longer to run than the time available
     before the next event, the scheduler will simply fall behind.  No
     events will be dropped; the calling code is responsible for
     canceling events which are no longer pertinent.

     New in version 3.3: `blocking' parameter was added.

 -- Attribute: scheduler.queue

     Read-only attribute returning a list of upcoming events in the
     order they will be run.  Each event is shown as a *note named
     tuple: 787. with the following fields: time, priority, action,
     argument, kwargs.


File: python.info,  Node: queue --- A synchronized queue class,  Next: dummy_threading --- Drop-in replacement for the threading module,  Prev: sched --- Event scheduler,  Up: Concurrent Execution

5.17.7 ‘queue’ — A synchronized queue class
-------------------------------------------

`Source code:' Lib/queue.py(1)

__________________________________________________________________

The *note queue: d8. module implements multi-producer, multi-consumer
queues.  It is especially useful in threaded programming when
information must be exchanged safely between multiple threads.  The
*note Queue: cc5. class in this module implements all the required
locking semantics.  It depends on the availability of thread support in
Python; see the *note threading: 106. module.

The module implements three types of queue, which differ only in the
order in which the entries are retrieved.  In a FIFO queue, the first
tasks added are the first retrieved.  In a LIFO queue, the most recently
added entry is the first retrieved (operating like a stack).  With a
priority queue, the entries are kept sorted (using the *note heapq: 8d.
module) and the lowest valued entry is retrieved first.

The *note queue: d8. module defines the following classes and
exceptions:

 -- Class: queue.Queue (maxsize=0)

     Constructor for a FIFO queue.  `maxsize' is an integer that sets
     the upperbound limit on the number of items that can be placed in
     the queue.  Insertion will block once this size has been reached,
     until queue items are consumed.  If `maxsize' is less than or equal
     to zero, the queue size is infinite.

 -- Class: queue.LifoQueue (maxsize=0)

     Constructor for a LIFO queue.  `maxsize' is an integer that sets
     the upperbound limit on the number of items that can be placed in
     the queue.  Insertion will block once this size has been reached,
     until queue items are consumed.  If `maxsize' is less than or equal
     to zero, the queue size is infinite.

 -- Class: queue.PriorityQueue (maxsize=0)

     Constructor for a priority queue.  `maxsize' is an integer that
     sets the upperbound limit on the number of items that can be placed
     in the queue.  Insertion will block once this size has been
     reached, until queue items are consumed.  If `maxsize' is less than
     or equal to zero, the queue size is infinite.

     The lowest valued entries are retrieved first (the lowest valued
     entry is the one returned by ‘sorted(list(entries))[0]’).  A
     typical pattern for entries is a tuple in the form:
     ‘(priority_number, data)’.

 -- Exception: queue.Empty

     Exception raised when non-blocking *note get(): 1df9. (or *note
     get_nowait(): 1dfa.) is called on a *note Queue: cc5. object which
     is empty.

 -- Exception: queue.Full

     Exception raised when non-blocking *note put(): 1dfb. (or *note
     put_nowait(): 1dfc.) is called on a *note Queue: cc5. object which
     is full.

* Menu:

* Queue Objects:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/queue.py


File: python.info,  Node: Queue Objects,  Up: queue --- A synchronized queue class

5.17.7.1 Queue Objects
......................

Queue objects (*note Queue: cc5, *note LifoQueue: 1df7, or *note
PriorityQueue: 1df8.) provide the public methods described below.

 -- Method: Queue.qsize ()

     Return the approximate size of the queue.  Note, qsize() > 0
     doesn’t guarantee that a subsequent get() will not block, nor will
     qsize() < maxsize guarantee that put() will not block.

 -- Method: Queue.empty ()

     Return ‘True’ if the queue is empty, ‘False’ otherwise.  If empty()
     returns ‘True’ it doesn’t guarantee that a subsequent call to put()
     will not block.  Similarly, if empty() returns ‘False’ it doesn’t
     guarantee that a subsequent call to get() will not block.

 -- Method: Queue.full ()

     Return ‘True’ if the queue is full, ‘False’ otherwise.  If full()
     returns ‘True’ it doesn’t guarantee that a subsequent call to get()
     will not block.  Similarly, if full() returns ‘False’ it doesn’t
     guarantee that a subsequent call to put() will not block.

 -- Method: Queue.put (item, block=True, timeout=None)

     Put `item' into the queue.  If optional args `block' is true and
     `timeout' is None (the default), block if necessary until a free
     slot is available.  If `timeout' is a positive number, it blocks at
     most `timeout' seconds and raises the *note Full: 1d1f. exception
     if no free slot was available within that time.  Otherwise (`block'
     is false), put an item on the queue if a free slot is immediately
     available, else raise the *note Full: 1d1f. exception (`timeout' is
     ignored in that case).

 -- Method: Queue.put_nowait (item)

     Equivalent to ‘put(item, False)’.

 -- Method: Queue.get (block=True, timeout=None)

     Remove and return an item from the queue.  If optional args `block'
     is true and `timeout' is None (the default), block if necessary
     until an item is available.  If `timeout' is a positive number, it
     blocks at most `timeout' seconds and raises the *note Empty: 1d1e.
     exception if no item was available within that time.  Otherwise
     (`block' is false), return an item if one is immediately available,
     else raise the *note Empty: 1d1e. exception (`timeout' is ignored
     in that case).

 -- Method: Queue.get_nowait ()

     Equivalent to ‘get(False)’.

Two methods are offered to support tracking whether enqueued tasks have
been fully processed by daemon consumer threads.

 -- Method: Queue.task_done ()

     Indicate that a formerly enqueued task is complete.  Used by queue
     consumer threads.  For each *note get(): 1df9. used to fetch a
     task, a subsequent call to *note task_done(): 1d1a. tells the queue
     that the processing on the task is complete.

     If a *note join(): 1d1b. is currently blocking, it will resume when
     all items have been processed (meaning that a *note task_done():
     1d1a. call was received for every item that had been *note put():
     1dfb. into the queue).

     Raises a *note ValueError: 19c. if called more times than there
     were items placed in the queue.

 -- Method: Queue.join ()

     Blocks until all items in the queue have been gotten and processed.

     The count of unfinished tasks goes up whenever an item is added to
     the queue.  The count goes down whenever a consumer thread calls
     *note task_done(): 1d1a. to indicate that the item was retrieved
     and all work on it is complete.  When the count of unfinished tasks
     drops to zero, *note join(): 1d1b. unblocks.

Example of how to wait for enqueued tasks to be completed:

     def worker():
         while True:
             item = q.get()
             if item is None:
                 break
             do_work(item)
             q.task_done()

     q = queue.Queue()
     threads = []
     for i in range(num_worker_threads):
         t = threading.Thread(target=worker)
         t.start()
         threads.append(t)

     for item in source():
         q.put(item)

     # block until all tasks are done
     q.join()

     # stop workers
     for i in range(num_worker_threads):
         q.put(None)
     for t in threads:
         t.join()

See also
........

Class *note multiprocessing.Queue: 1cf6.

     A queue class for use in a multi-processing (rather than
     multi-threading) context.

*note collections.deque: 24e. is an alternative implementation of
unbounded queues with fast atomic *note append(): 12d9. and *note
popleft(): 12df. operations that do not require locking.

The following are support modules for some of the above services:


File: python.info,  Node: dummy_threading --- Drop-in replacement for the threading module,  Next: _thread --- Low-level threading API,  Prev: queue --- A synchronized queue class,  Up: Concurrent Execution

5.17.8 ‘dummy_threading’ — Drop-in replacement for the ‘threading’ module
-------------------------------------------------------------------------

`Source code:' Lib/dummy_threading.py(1)

__________________________________________________________________

This module provides a duplicate interface to the *note threading: 106.
module.  It is meant to be imported when the *note _thread: 3. module is
not provided on a platform.

Suggested usage is:

     try:
         import threading
     except ImportError:
         import dummy_threading as threading

Be careful to not use this module where deadlock might occur from a
thread being created that blocks waiting for another thread to be
created.  This often occurs with blocking I/O.

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/dummy_threading.py


File: python.info,  Node: _thread --- Low-level threading API,  Next: _dummy_thread --- Drop-in replacement for the _thread module,  Prev: dummy_threading --- Drop-in replacement for the threading module,  Up: Concurrent Execution

5.17.9 ‘_thread’ — Low-level threading API
------------------------------------------

This module provides low-level primitives for working with multiple
threads (also called `light-weight processes' or `tasks') — multiple
threads of control sharing their global data space.  For
synchronization, simple locks (also called `mutexes' or `binary
semaphores') are provided.  The *note threading: 106. module provides an
easier to use and higher-level threading API built on top of this
module.

The module is optional.  It is supported on Windows, Linux, SGI IRIX,
Solaris 2.x, as well as on systems that have a POSIX thread (a.k.a.
"pthread") implementation.  For systems lacking the *note _thread: 3.
module, the *note _dummy_thread: 2. module is available.  It duplicates
this module’s interface and can be used as a drop-in replacement.

It defines the following constants and functions:

 -- Exception: _thread.error

     Raised on thread-specific errors.

     Changed in version 3.3: This is now a synonym of the built-in *note
     RuntimeError: 193.

 -- Data: _thread.LockType

     This is the type of lock objects.

 -- Function: _thread.start_new_thread (function, args[, kwargs])

     Start a new thread and return its identifier.  The thread executes
     the function `function' with the argument list `args' (which must
     be a tuple).  The optional `kwargs' argument specifies a dictionary
     of keyword arguments.  When the function returns, the thread
     silently exits.  When the function terminates with an unhandled
     exception, a stack trace is printed and then the thread exits (but
     other threads continue to run).

 -- Function: _thread.interrupt_main ()

     Raise a *note KeyboardInterrupt: 1a3. exception in the main thread.
     A subthread can use this function to interrupt the main thread.

 -- Function: _thread.exit ()

     Raise the *note SystemExit: 1a2. exception.  When not caught, this
     will cause the thread to exit silently.

 -- Function: _thread.allocate_lock ()

     Return a new lock object.  Methods of locks are described below.
     The lock is initially unlocked.

 -- Function: _thread.get_ident ()

     Return the ’thread identifier’ of the current thread.  This is a
     nonzero integer.  Its value has no direct meaning; it is intended
     as a magic cookie to be used e.g.  to index a dictionary of
     thread-specific data.  Thread identifiers may be recycled when a
     thread exits and another thread is created.

 -- Function: _thread.stack_size ([size])

     Return the thread stack size used when creating new threads.  The
     optional `size' argument specifies the stack size to be used for
     subsequently created threads, and must be 0 (use platform or
     configured default) or a positive integer value of at least 32,768
     (32 KiB). If `size' is not specified, 0 is used.  If changing the
     thread stack size is unsupported, a *note RuntimeError: 193. is
     raised.  If the specified stack size is invalid, a *note
     ValueError: 19c. is raised and the stack size is unmodified.  32
     KiB is currently the minimum supported stack size value to
     guarantee sufficient stack space for the interpreter itself.  Note
     that some platforms may have particular restrictions on values for
     the stack size, such as requiring a minimum stack size > 32 KiB or
     requiring allocation in multiples of the system memory page size -
     platform documentation should be referred to for more information
     (4 KiB pages are common; using multiples of 4096 for the stack size
     is the suggested approach in the absence of more specific
     information).  Availability: Windows, systems with POSIX threads.

 -- Data: _thread.TIMEOUT_MAX

     The maximum value allowed for the `timeout' parameter of
     ‘Lock.acquire()’.  Specifying a timeout greater than this value
     will raise an *note OverflowError: 578.

     New in version 3.2.

Lock objects have the following methods:

 -- Method: lock.acquire (waitflag=1, timeout=-1)

     Without any optional argument, this method acquires the lock
     unconditionally, if necessary waiting until it is released by
     another thread (only one thread at a time can acquire a lock —
     that’s their reason for existence).

     If the integer `waitflag' argument is present, the action depends
     on its value: if it is zero, the lock is only acquired if it can be
     acquired immediately without waiting, while if it is nonzero, the
     lock is acquired unconditionally as above.

     If the floating-point `timeout' argument is present and positive,
     it specifies the maximum wait time in seconds before returning.  A
     negative `timeout' argument specifies an unbounded wait.  You
     cannot specify a `timeout' if `waitflag' is zero.

     The return value is ‘True’ if the lock is acquired successfully,
     ‘False’ if not.

     Changed in version 3.2: The `timeout' parameter is new.

     Changed in version 3.2: Lock acquires can now be interrupted by
     signals on POSIX.

 -- Method: lock.release ()

     Releases the lock.  The lock must have been acquired earlier, but
     not necessarily by the same thread.

 -- Method: lock.locked ()

     Return the status of the lock: ‘True’ if it has been acquired by
     some thread, ‘False’ if not.

In addition to these methods, lock objects can also be used via the
*note with: 29d. statement, e.g.:

     import _thread

     a_lock = _thread.allocate_lock()

     with a_lock:
         print("a_lock is locked while this executes")

`Caveats:'

   * Threads interact strangely with interrupts: the *note
     KeyboardInterrupt: 1a3. exception will be received by an arbitrary
     thread.  (When the *note signal: e8. module is available,
     interrupts always go to the main thread.)

   * Calling *note sys.exit(): 95a. or raising the *note SystemExit:
     1a2. exception is equivalent to calling *note _thread.exit(): 1e0a.

   * It is not possible to interrupt the ‘acquire()’ method on a lock —
     the *note KeyboardInterrupt: 1a3. exception will happen after the
     lock has been acquired.

   * When the main thread exits, it is system defined whether the other
     threads survive.  On most systems, they are killed without
     executing *note try: 9e9. ...  *note finally: 526. clauses or
     executing object destructors.

   * When the main thread exits, it does not do any of its usual cleanup
     (except that *note try: 9e9. ...  *note finally: 526. clauses are
     honored), and the standard I/O files are not flushed.


File: python.info,  Node: _dummy_thread --- Drop-in replacement for the _thread module,  Prev: _thread --- Low-level threading API,  Up: Concurrent Execution

5.17.10 ‘_dummy_thread’ — Drop-in replacement for the ‘_thread’ module
----------------------------------------------------------------------

`Source code:' Lib/_dummy_thread.py(1)

__________________________________________________________________

This module provides a duplicate interface to the *note _thread: 3.
module.  It is meant to be imported when the *note _thread: 3. module is
not provided on a platform.

Suggested usage is:

     try:
         import _thread
     except ImportError:
         import _dummy_thread as _thread

Be careful to not use this module where deadlock might occur from a
thread being created that blocks waiting for another thread to be
created.  This often occurs with blocking I/O.

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/_dummy_thread.py


File: python.info,  Node: Interprocess Communication and Networking,  Next: Internet Data Handling,  Prev: Concurrent Execution,  Up: The Python Standard Library

5.18 Interprocess Communication and Networking
==============================================

The modules described in this chapter provide mechanisms for different
processes to communicate.

Some modules only work for two processes that are on the same machine,
e.g.  *note signal: e8. and *note mmap: b2.  Other modules support
networking protocols that two or more processes can use to communicate
across machines.

The list of modules described in this chapter is:

* Menu:

* socket: socket --- Low-level networking interface. Low-level networking interface
* ssl: ssl --- TLS/SSL wrapper for socket objects. TLS/SSL wrapper for socket objects
* select: select --- Waiting for I/O completion. Waiting for I/O completion
* selectors: selectors -- High-level I/O multiplexing. High-level I/O multiplexing
* asyncio: asyncio -- Asynchronous I/O event loop coroutines and tasks. Asynchronous I/O, event loop, coroutines and tasks
* asyncore: asyncore --- Asynchronous socket handler. Asynchronous socket handler
* asynchat: asynchat --- Asynchronous socket command/response handler. Asynchronous socket command/response handler
* signal: signal --- Set handlers for asynchronous events. Set handlers for asynchronous events
* mmap: mmap --- Memory-mapped file support. Memory-mapped file support


File: python.info,  Node: socket --- Low-level networking interface,  Next: ssl --- TLS/SSL wrapper for socket objects,  Up: Interprocess Communication and Networking

5.18.1 ‘socket’ — Low-level networking interface
------------------------------------------------

This module provides access to the BSD `socket' interface.  It is
available on all modern Unix systems, Windows, MacOS, and probably
additional platforms.

     Note: Some behavior may be platform dependent, since calls are made
     to the operating system socket APIs.

The Python interface is a straightforward transliteration of the Unix
system call and library interface for sockets to Python’s
object-oriented style: the *note socket(): 20a. function returns a
`socket object' whose methods implement the various socket system calls.
Parameter types are somewhat higher-level than in the C interface: as
with ‘read()’ and ‘write()’ operations on Python files, buffer
allocation on receive operations is automatic, and buffer length is
implicit on send operations.

See also
........

Module *note socketserver: ee.

     Classes that simplify writing network servers.

Module *note ssl: f1.

     A TLS/SSL wrapper for socket objects.

* Menu:

* Socket families:: 
* Module contents:: 
* Socket Objects:: 
* Notes on socket timeouts:: 
* Example: Example<7>. 


File: python.info,  Node: Socket families,  Next: Module contents,  Up: socket --- Low-level networking interface

5.18.1.1 Socket families
........................

Depending on the system and the build options, various socket families
are supported by this module.

The address format required by a particular socket object is
automatically selected based on the address family specified when the
socket object was created.  Socket addresses are represented as follows:

   - The address of an *note AF_UNIX: 1e19. socket bound to a file
     system node is represented as a string, using the file system
     encoding and the ‘'surrogateescape'’ error handler (see PEP
     383(1)).  An address in Linux’s abstract namespace is returned as a
     *note bytes-like object: 36b. with an initial null byte; note that
     sockets in this namespace can communicate with normal file system
     sockets, so programs intended to run on Linux may need to deal with
     both types of address.  A string or bytes-like object can be used
     for either type of address when passing it as an argument.

          Changed in version 3.3: Previously, *note AF_UNIX: 1e19.
          socket paths were assumed to use UTF-8 encoding.

          Changed in version 3.5: Writable *note bytes-like object: 36b.
          is now accepted.

   - A pair ‘(host, port)’ is used for the *note AF_INET: 1e1a. address
     family, where `host' is a string representing either a hostname in
     Internet domain notation like ‘'daring.cwi.nl'’ or an IPv4 address
     like ‘'100.50.200.5'’, and `port' is an integer.

   - For *note AF_INET6: 1e1b. address family, a four-tuple ‘(host,
     port, flowinfo, scopeid)’ is used, where `flowinfo' and `scopeid'
     represent the ‘sin6_flowinfo’ and ‘sin6_scope_id’ members in
     ‘struct sockaddr_in6’ in C. For *note socket: ed. module methods,
     `flowinfo' and `scopeid' can be omitted just for backward
     compatibility.  Note, however, omission of `scopeid' can cause
     problems in manipulating scoped IPv6 addresses.

   - ‘AF_NETLINK’ sockets are represented as pairs ‘(pid, groups)’.

   - Linux-only support for TIPC is available using the ‘AF_TIPC’
     address family.  TIPC is an open, non-IP based networked protocol
     designed for use in clustered computer environments.  Addresses are
     represented by a tuple, and the fields depend on the address type.
     The general tuple form is ‘(addr_type, v1, v2, v3 [, scope])’,
     where:

        - `addr_type' is one of ‘TIPC_ADDR_NAMESEQ’, ‘TIPC_ADDR_NAME’,
          or ‘TIPC_ADDR_ID’.

        - `scope' is one of ‘TIPC_ZONE_SCOPE’, ‘TIPC_CLUSTER_SCOPE’, and
          ‘TIPC_NODE_SCOPE’.

        - If `addr_type' is ‘TIPC_ADDR_NAME’, then `v1' is the server
          type, `v2' is the port identifier, and `v3' should be 0.

          If `addr_type' is ‘TIPC_ADDR_NAMESEQ’, then `v1' is the server
          type, `v2' is the lower port number, and `v3' is the upper
          port number.

          If `addr_type' is ‘TIPC_ADDR_ID’, then `v1' is the node, `v2'
          is the reference, and `v3' should be set to 0.

   - A tuple ‘(interface, )’ is used for the *note AF_CAN: 1e1c. address
     family, where `interface' is a string representing a network
     interface name like ‘'can0'’.  The network interface name ‘''’ can
     be used to receive packets from all network interfaces of this
     family.

   - A string or a tuple ‘(id, unit)’ is used for the ‘SYSPROTO_CONTROL’
     protocol of the ‘PF_SYSTEM’ family.  The string is the name of a
     kernel control using a dynamically-assigned ID. The tuple can be
     used if ID and unit number of the kernel control are known or if a
     registered ID is used.

     New in version 3.3.

   - ‘AF_BLUETOOTH’ supports the following protocols and address
     formats:

        - ‘BTPROTO_L2CAP’ accepts ‘(bdaddr, psm)’ where ‘bdaddr’ is the
          Bluetooth address as a string and ‘psm’ is an integer.

        - ‘BTPROTO_RFCOMM’ accepts ‘(bdaddr, channel)’ where ‘bdaddr’ is
          the Bluetooth address as a string and ‘channel’ is an integer.

        - ‘BTPROTO_HCI’ accepts ‘(device_id,)’ where ‘device_id’ is
          either an integer or a string with the Bluetooth address of
          the interface.  (This depends on your OS; NetBSD and
          DragonFlyBSD expect a Bluetooth address while everything else
          expects an integer.)

          Changed in version 3.2: NetBSD and DragonFlyBSD support added.

        - ‘BTPROTO_SCO’ accepts ‘bdaddr’ where ‘bdaddr’ is a *note
          bytes: 1db. object containing the Bluetooth address in a
          string format.  (ex.  ‘b'12:23:34:45:56:67'’) This protocol is
          not supported under FreeBSD.

   - Certain other address families (‘AF_PACKET’, *note AF_CAN: 1e1c.)
     support specific representations.

For IPv4 addresses, two special forms are accepted instead of a host
address: the empty string represents ‘INADDR_ANY’, and the string
‘'<broadcast>'’ represents ‘INADDR_BROADCAST’.  This behavior is not
compatible with IPv6, therefore, you may want to avoid these if you
intend to support IPv6 with your Python programs.

If you use a hostname in the `host' portion of IPv4/v6 socket address,
the program may show a nondeterministic behavior, as Python uses the
first address returned from the DNS resolution.  The socket address will
be resolved differently into an actual IPv4/v6 address, depending on the
results from DNS resolution and/or the host configuration.  For
deterministic behavior use a numeric address in `host' portion.

All errors raise exceptions.  The normal exceptions for invalid argument
types and out-of-memory conditions can be raised; starting from Python
3.3, errors related to socket or address semantics raise *note OSError:
4b6. or one of its subclasses (they used to raise *note socket.error:
5b3.).

Non-blocking mode is supported through *note setblocking(): 1883.  A
generalization of this based on timeouts is supported through *note
settimeout(): 1e1d.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0383


File: python.info,  Node: Module contents,  Next: Socket Objects,  Prev: Socket families,  Up: socket --- Low-level networking interface

5.18.1.2 Module contents
........................

The module *note socket: ed. exports the following elements.

* Menu:

* Exceptions: Exceptions<7>. 
* Constants: Constants<6>. 
* Functions: Functions<4>. 


File: python.info,  Node: Exceptions<7>,  Next: Constants<6>,  Up: Module contents

5.18.1.3 Exceptions
...................

 -- Exception: socket.error

     A deprecated alias of *note OSError: 4b6.

     Changed in version 3.3: Following PEP 3151(1), this class was made
     an alias of *note OSError: 4b6.

 -- Exception: socket.herror

     A subclass of *note OSError: 4b6, this exception is raised for
     address-related errors, i.e.  for functions that use `h_errno' in
     the POSIX C API, including *note gethostbyname_ex(): 1e21. and
     *note gethostbyaddr(): 1e22.  The accompanying value is a pair
     ‘(h_errno, string)’ representing an error returned by a library
     call.  `h_errno' is a numeric value, while `string' represents the
     description of `h_errno', as returned by the ‘hstrerror()’ C
     function.

     Changed in version 3.3: This class was made a subclass of *note
     OSError: 4b6.

 -- Exception: socket.gaierror

     A subclass of *note OSError: 4b6, this exception is raised for
     address-related errors by *note getaddrinfo(): 1e24. and *note
     getnameinfo(): 1e25.  The accompanying value is a pair ‘(error,
     string)’ representing an error returned by a library call.
     `string' represents the description of `error', as returned by the
     ‘gai_strerror()’ C function.  The numeric `error' value will match
     one of the ‘EAI_*’ constants defined in this module.

     Changed in version 3.3: This class was made a subclass of *note
     OSError: 4b6.

 -- Exception: socket.timeout

     A subclass of *note OSError: 4b6, this exception is raised when a
     timeout occurs on a socket which has had timeouts enabled via a
     prior call to *note settimeout(): 1e1d. (or implicitly through
     *note setdefaulttimeout(): 1e26.).  The accompanying value is a
     string whose value is currently always "timed out".

     Changed in version 3.3: This class was made a subclass of *note
     OSError: 4b6.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3151


File: python.info,  Node: Constants<6>,  Next: Functions<4>,  Prev: Exceptions<7>,  Up: Module contents

5.18.1.4 Constants
..................

     The AF_* and SOCK_* constants are now ‘AddressFamily’ and
     ‘SocketKind’ *note IntEnum: 1393. collections.

     New in version 3.4.

 -- Data: socket.AF_UNIX
 -- Data: socket.AF_INET
 -- Data: socket.AF_INET6

     These constants represent the address (and protocol) families, used
     for the first argument to *note socket(): 20a.  If the *note
     AF_UNIX: 1e19. constant is not defined then this protocol is
     unsupported.  More constants may be available depending on the
     system.

 -- Data: socket.SOCK_STREAM
 -- Data: socket.SOCK_DGRAM
 -- Data: socket.SOCK_RAW
 -- Data: socket.SOCK_RDM
 -- Data: socket.SOCK_SEQPACKET

     These constants represent the socket types, used for the second
     argument to *note socket(): 20a.  More constants may be available
     depending on the system.  (Only *note SOCK_STREAM: 8fb. and *note
     SOCK_DGRAM: 8fa. appear to be generally useful.)

 -- Data: socket.SOCK_CLOEXEC
 -- Data: socket.SOCK_NONBLOCK

     These two constants, if defined, can be combined with the socket
     types and allow you to set some flags atomically (thus avoiding
     possible race conditions and the need for separate calls).

     See also
     ........

     Secure File Descriptor Handling(1) for a more thorough explanation.

     Availability: Linux >= 2.6.27.

     New in version 3.2.

 -- Data: SO_*
 -- Data: socket.SOMAXCONN

 -- Data: MSG_*

 -- Data: SOL_*

 -- Data: SCM_*

 -- Data: IPPROTO_*

 -- Data: IPPORT_*

 -- Data: INADDR_*

 -- Data: IP_*

 -- Data: IPV6_*

 -- Data: EAI_*

 -- Data: AI_*

 -- Data: NI_*

 -- Data: TCP_*

     Many constants of these forms, documented in the Unix documentation
     on sockets and/or the IP protocol, are also defined in the socket
     module.  They are generally used in arguments to the ‘setsockopt()’
     and ‘getsockopt()’ methods of socket objects.  In most cases, only
     those symbols that are defined in the Unix header files are
     defined; for a few symbols, default values are provided.

 -- Data: socket.AF_CAN
 -- Data: socket.PF_CAN

 -- Data: SOL_CAN_*

 -- Data: CAN_*

     Many constants of these forms, documented in the Linux
     documentation, are also defined in the socket module.

     Availability: Linux >= 2.6.25.

     New in version 3.3.

 -- Data: socket.CAN_BCM

 -- Data: CAN_BCM_*

     CAN_BCM, in the CAN protocol family, is the broadcast manager (BCM)
     protocol.  Broadcast manager constants, documented in the Linux
     documentation, are also defined in the socket module.

     Availability: Linux >= 2.6.25.

     New in version 3.4.

 -- Data: socket.CAN_RAW_FD_FRAMES

     Enables CAN FD support in a CAN_RAW socket.  This is disabled by
     default.  This allows your application to send both CAN and CAN FD
     frames; however, you one must accept both CAN and CAN FD frames
     when reading from the socket.

     This constant is documented in the Linux documentation.

     Availability: Linux >= 3.6.

     New in version 3.5.

 -- Data: socket.AF_RDS
 -- Data: socket.PF_RDS
 -- Data: socket.SOL_RDS

 -- Data: RDS_*

     Many constants of these forms, documented in the Linux
     documentation, are also defined in the socket module.

     Availability: Linux >= 2.6.30.

     New in version 3.3.

 -- Data: SIO_*

 -- Data: RCVALL_*

     Constants for Windows’ WSAIoctl().  The constants are used as
     arguments to the *note ioctl(): 1e31. method of socket objects.

 -- Data: TIPC_*

     TIPC related constants, matching the ones exported by the C socket
     API. See the TIPC documentation for more information.

 -- Data: socket.AF_LINK

     Availability: BSD, OSX.

     New in version 3.4.

 -- Data: socket.has_ipv6

     This constant contains a boolean value which indicates if IPv6 is
     supported on this platform.

 -- Data: socket.BDADDR_ANY
 -- Data: socket.BDADDR_LOCAL

     These are string constants containing Bluetooth addresses with
     special meanings.  For example, *note BDADDR_ANY: 1e33. can be used
     to indicate any address when specifying the binding socket with
     ‘BTPROTO_RFCOMM’.

 -- Data: socket.HCI_FILTER
 -- Data: socket.HCI_TIME_STAMP
 -- Data: socket.HCI_DATA_DIR

     For use with ‘BTPROTO_HCI’.  *note HCI_FILTER: 1e35. is not
     available for NetBSD or DragonFlyBSD. *note HCI_TIME_STAMP: 1e36.
     and *note HCI_DATA_DIR: 1e37. are not available for FreeBSD,
     NetBSD, or DragonFlyBSD.

   ---------- Footnotes ----------

   (1) http://udrepper.livejournal.com/20407.html


File: python.info,  Node: Functions<4>,  Prev: Constants<6>,  Up: Module contents

5.18.1.5 Functions
..................

* Menu:

* Creating sockets:: 
* Other functions: Other functions<2>. 


File: python.info,  Node: Creating sockets,  Next: Other functions<2>,  Up: Functions<4>

5.18.1.6 Creating sockets
.........................

The following functions all create *note socket objects: 1e3a.

 -- Function: socket.socket (family=AF_INET, type=SOCK_STREAM, proto=0,
          fileno=None)

     Create a new socket using the given address family, socket type and
     protocol number.  The address family should be *note AF_INET: 1e1a.
     (the default), *note AF_INET6: 1e1b, *note AF_UNIX: 1e19, *note
     AF_CAN: 1e1c. or *note AF_RDS: 1e2e.  The socket type should be
     *note SOCK_STREAM: 8fb. (the default), *note SOCK_DGRAM: 8fa, *note
     SOCK_RAW: 1e28. or perhaps one of the other ‘SOCK_’ constants.  The
     protocol number is usually zero and may be omitted or in the case
     where the address family is *note AF_CAN: 1e1c. the protocol should
     be one of ‘CAN_RAW’ or *note CAN_BCM: 4b8.  If `fileno' is
     specified, the other arguments are ignored, causing the socket with
     the specified file descriptor to return.  Unlike *note
     socket.fromfd(): 1e3b, `fileno' will return the same socket and not
     a duplicate.  This may help close a detached socket using *note
     socket.close(): 1a8.

     The newly created socket is *note non-inheritable: 3ea.

     Changed in version 3.3: The AF_CAN family was added.  The AF_RDS
     family was added.

     Changed in version 3.4: The CAN_BCM protocol was added.

     Changed in version 3.4: The returned socket is now non-inheritable.

 -- Function: socket.socketpair ([family[, type[, proto]]])

     Build a pair of connected socket objects using the given address
     family, socket type, and protocol number.  Address family, socket
     type, and protocol number are as for the *note socket(): 20a.
     function above.  The default family is *note AF_UNIX: 1e19. if
     defined on the platform; otherwise, the default is *note AF_INET:
     1e1a.

     The newly created sockets are *note non-inheritable: 3ea.

     Changed in version 3.2: The returned socket objects now support the
     whole socket API, rather than a subset.

     Changed in version 3.4: The returned sockets are now
     non-inheritable.

     Changed in version 3.5: Windows support added.

 -- Function: socket.create_connection (address[, timeout[,
          source_address]])

     Connect to a TCP service listening on the Internet `address' (a
     2-tuple ‘(host, port)’), and return the socket object.  This is a
     higher-level function than *note socket.connect(): 20c.: if `host'
     is a non-numeric hostname, it will try to resolve it for both *note
     AF_INET: 1e1a. and *note AF_INET6: 1e1b, and then try to connect to
     all possible addresses in turn until a connection succeeds.  This
     makes it easy to write clients that are compatible to both IPv4 and
     IPv6.

     Passing the optional `timeout' parameter will set the timeout on
     the socket instance before attempting to connect.  If no `timeout'
     is supplied, the global default timeout setting returned by *note
     getdefaulttimeout(): 1e3d. is used.

     If supplied, `source_address' must be a 2-tuple ‘(host, port)’ for
     the socket to bind to as its source address before connecting.  If
     host or port are ’’ or 0 respectively the OS default behavior will
     be used.

     Changed in version 3.2: `source_address' was added.

 -- Function: socket.fromfd (fd, family, type, proto=0)

     Duplicate the file descriptor `fd' (an integer as returned by a
     file object’s ‘fileno()’ method) and build a socket object from the
     result.  Address family, socket type and protocol number are as for
     the *note socket(): 20a. function above.  The file descriptor
     should refer to a socket, but this is not checked — subsequent
     operations on the object may fail if the file descriptor is
     invalid.  This function is rarely needed, but can be used to get or
     set socket options on a socket passed to a program as standard
     input or output (such as a server started by the Unix inet daemon).
     The socket is assumed to be in blocking mode.

     The newly created socket is *note non-inheritable: 3ea.

     Changed in version 3.4: The returned socket is now non-inheritable.

 -- Function: socket.fromshare (data)

     Instantiate a socket from data obtained from the *note
     socket.share(): 1e3f. method.  The socket is assumed to be in
     blocking mode.

     Availability: Windows.

     New in version 3.3.

 -- Data: socket.SocketType

     This is a Python type object that represents the socket object
     type.  It is the same as ‘type(socket(...))’.


File: python.info,  Node: Other functions<2>,  Prev: Creating sockets,  Up: Functions<4>

5.18.1.7 Other functions
........................

The *note socket: ed. module also offers various network-related
services:

 -- Function: socket.getaddrinfo (host, port, family=0, type=0, proto=0,
          flags=0)

     Translate the `host'/`port' argument into a sequence of 5-tuples
     that contain all the necessary arguments for creating a socket
     connected to that service.  `host' is a domain name, a string
     representation of an IPv4/v6 address or ‘None’.  `port' is a string
     service name such as ‘'http'’, a numeric port number or ‘None’.  By
     passing ‘None’ as the value of `host' and `port', you can pass
     ‘NULL’ to the underlying C API.

     The `family', `type' and `proto' arguments can be optionally
     specified in order to narrow the list of addresses returned.
     Passing zero as a value for each of these arguments selects the
     full range of results.  The `flags' argument can be one or several
     of the ‘AI_*’ constants, and will influence how results are
     computed and returned.  For example, ‘AI_NUMERICHOST’ will disable
     domain name resolution and will raise an error if `host' is a
     domain name.

     The function returns a list of 5-tuples with the following
     structure:

     ‘(family, type, proto, canonname, sockaddr)’

     In these tuples, `family', `type', `proto' are all integers and are
     meant to be passed to the *note socket(): 20a. function.
     `canonname' will be a string representing the canonical name of the
     `host' if ‘AI_CANONNAME’ is part of the `flags' argument; else
     `canonname' will be empty.  `sockaddr' is a tuple describing a
     socket address, whose format depends on the returned `family' (a
     ‘(address, port)’ 2-tuple for *note AF_INET: 1e1a, a ‘(address,
     port, flow info, scope id)’ 4-tuple for *note AF_INET6: 1e1b.), and
     is meant to be passed to the *note socket.connect(): 20c. method.

     The following example fetches address information for a
     hypothetical TCP connection to ‘example.org’ on port 80 (results
     may differ on your system if IPv6 isn’t enabled):

          >>> socket.getaddrinfo("example.org", 80, proto=socket.IPPROTO_TCP)
          [(<AddressFamily.AF_INET6: 10>, <SocketType.SOCK_STREAM: 1>,
           6, '', ('2606:2800:220:1:248:1893:25c8:1946', 80, 0, 0)),
           (<AddressFamily.AF_INET: 2>, <SocketType.SOCK_STREAM: 1>,
           6, '', ('93.184.216.34', 80))]

     Changed in version 3.2: parameters can now be passed using keyword
     arguments.

 -- Function: socket.getfqdn ([name])

     Return a fully qualified domain name for `name'.  If `name' is
     omitted or empty, it is interpreted as the local host.  To find the
     fully qualified name, the hostname returned by *note
     gethostbyaddr(): 1e22. is checked, followed by aliases for the
     host, if available.  The first name which includes a period is
     selected.  In case no fully qualified domain name is available, the
     hostname as returned by *note gethostname(): 1875. is returned.

 -- Function: socket.gethostbyname (hostname)

     Translate a host name to IPv4 address format.  The IPv4 address is
     returned as a string, such as ‘'100.50.200.5'’.  If the host name
     is an IPv4 address itself it is returned unchanged.  See *note
     gethostbyname_ex(): 1e21. for a more complete interface.  *note
     gethostbyname(): 1e43. does not support IPv6 name resolution, and
     *note getaddrinfo(): 1e24. should be used instead for IPv4/v6 dual
     stack support.

 -- Function: socket.gethostbyname_ex (hostname)

     Translate a host name to IPv4 address format, extended interface.
     Return a triple ‘(hostname, aliaslist, ipaddrlist)’ where
     `hostname' is the primary host name responding to the given
     `ip_address', `aliaslist' is a (possibly empty) list of alternative
     host names for the same address, and `ipaddrlist' is a list of IPv4
     addresses for the same interface on the same host (often but not
     always a single address).  *note gethostbyname_ex(): 1e21. does not
     support IPv6 name resolution, and *note getaddrinfo(): 1e24. should
     be used instead for IPv4/v6 dual stack support.

 -- Function: socket.gethostname ()

     Return a string containing the hostname of the machine where the
     Python interpreter is currently executing.

     Note: *note gethostname(): 1875. doesn’t always return the fully
     qualified domain name; use *note getfqdn(): 1e42. for that.

 -- Function: socket.gethostbyaddr (ip_address)

     Return a triple ‘(hostname, aliaslist, ipaddrlist)’ where
     `hostname' is the primary host name responding to the given
     `ip_address', `aliaslist' is a (possibly empty) list of alternative
     host names for the same address, and `ipaddrlist' is a list of
     IPv4/v6 addresses for the same interface on the same host (most
     likely containing only a single address).  To find the fully
     qualified domain name, use the function *note getfqdn(): 1e42.
     *note gethostbyaddr(): 1e22. supports both IPv4 and IPv6.

 -- Function: socket.getnameinfo (sockaddr, flags)

     Translate a socket address `sockaddr' into a 2-tuple ‘(host,
     port)’.  Depending on the settings of `flags', the result can
     contain a fully-qualified domain name or numeric address
     representation in `host'.  Similarly, `port' can contain a string
     port name or a numeric port number.

 -- Function: socket.getprotobyname (protocolname)

     Translate an Internet protocol name (for example, ‘'icmp'’) to a
     constant suitable for passing as the (optional) third argument to
     the *note socket(): 20a. function.  This is usually only needed for
     sockets opened in "raw" mode (*note SOCK_RAW: 1e28.); for the
     normal socket modes, the correct protocol is chosen automatically
     if the protocol is omitted or zero.

 -- Function: socket.getservbyname (servicename[, protocolname])

     Translate an Internet service name and protocol name to a port
     number for that service.  The optional protocol name, if given,
     should be ‘'tcp'’ or ‘'udp'’, otherwise any protocol will match.

 -- Function: socket.getservbyport (port[, protocolname])

     Translate an Internet port number and protocol name to a service
     name for that service.  The optional protocol name, if given,
     should be ‘'tcp'’ or ‘'udp'’, otherwise any protocol will match.

 -- Function: socket.ntohl (x)

     Convert 32-bit positive integers from network to host byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 4-byte swap
     operation.

 -- Function: socket.ntohs (x)

     Convert 16-bit positive integers from network to host byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 2-byte swap
     operation.

 -- Function: socket.htonl (x)

     Convert 32-bit positive integers from host to network byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 4-byte swap
     operation.

 -- Function: socket.htons (x)

     Convert 16-bit positive integers from host to network byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 2-byte swap
     operation.

 -- Function: socket.inet_aton (ip_string)

     Convert an IPv4 address from dotted-quad string format (for
     example, ’123.45.67.89’) to 32-bit packed binary format, as a bytes
     object four characters in length.  This is useful when conversing
     with a program that uses the standard C library and needs objects
     of type ‘struct in_addr’, which is the C type for the 32-bit packed
     binary this function returns.

     *note inet_aton(): 1e4b. also accepts strings with less than three
     dots; see the Unix manual page ‘inet(3)’ for details.

     If the IPv4 address string passed to this function is invalid,
     *note OSError: 4b6. will be raised.  Note that exactly what is
     valid depends on the underlying C implementation of ‘inet_aton()’.

     *note inet_aton(): 1e4b. does not support IPv6, and *note
     inet_pton(): 4ba. should be used instead for IPv4/v6 dual stack
     support.

 -- Function: socket.inet_ntoa (packed_ip)

     Convert a 32-bit packed IPv4 address (a *note bytes-like object:
     36b. four bytes in length) to its standard dotted-quad string
     representation (for example, ’123.45.67.89’).  This is useful when
     conversing with a program that uses the standard C library and
     needs objects of type ‘struct in_addr’, which is the C type for the
     32-bit packed binary data this function takes as an argument.

     If the byte sequence passed to this function is not exactly 4 bytes
     in length, *note OSError: 4b6. will be raised.  *note inet_ntoa():
     1e4c. does not support IPv6, and *note inet_ntop(): 4bb. should be
     used instead for IPv4/v6 dual stack support.

     Changed in version 3.5: Writable *note bytes-like object: 36b. is
     now accepted.

 -- Function: socket.inet_pton (address_family, ip_string)

     Convert an IP address from its family-specific string format to a
     packed, binary format.  *note inet_pton(): 4ba. is useful when a
     library or network protocol calls for an object of type ‘struct
     in_addr’ (similar to *note inet_aton(): 1e4b.) or ‘struct
     in6_addr’.

     Supported values for `address_family' are currently *note AF_INET:
     1e1a. and *note AF_INET6: 1e1b.  If the IP address string
     `ip_string' is invalid, *note OSError: 4b6. will be raised.  Note
     that exactly what is valid depends on both the value of
     `address_family' and the underlying implementation of
     ‘inet_pton()’.

     Availability: Unix (maybe not all platforms), Windows.

     Changed in version 3.4: Windows support added

 -- Function: socket.inet_ntop (address_family, packed_ip)

     Convert a packed IP address (a *note bytes-like object: 36b. of
     some number of bytes) to its standard, family-specific string
     representation (for example, ‘'7.10.0.5'’ or ‘'5aef:2b::8'’).
     *note inet_ntop(): 4bb. is useful when a library or network
     protocol returns an object of type ‘struct in_addr’ (similar to
     *note inet_ntoa(): 1e4c.) or ‘struct in6_addr’.

     Supported values for `address_family' are currently *note AF_INET:
     1e1a. and *note AF_INET6: 1e1b.  If the bytes object `packed_ip' is
     not the correct length for the specified address family, *note
     ValueError: 19c. will be raised.  *note OSError: 4b6. is raised for
     errors from the call to *note inet_ntop(): 4bb.

     Availability: Unix (maybe not all platforms), Windows.

     Changed in version 3.4: Windows support added

     Changed in version 3.5: Writable *note bytes-like object: 36b. is
     now accepted.

 -- Function: socket.CMSG_LEN (length)

     Return the total length, without trailing padding, of an ancillary
     data item with associated data of the given `length'.  This value
     can often be used as the buffer size for *note recvmsg(): 20f. to
     receive a single item of ancillary data, but RFC 3542(1) requires
     portable applications to use *note CMSG_SPACE(): 1e4e. and thus
     include space for padding, even when the item will be the last in
     the buffer.  Raises *note OverflowError: 578. if `length' is
     outside the permissible range of values.

     Availability: most Unix platforms, possibly others.

     New in version 3.3.

 -- Function: socket.CMSG_SPACE (length)

     Return the buffer size needed for *note recvmsg(): 20f. to receive
     an ancillary data item with associated data of the given `length',
     along with any trailing padding.  The buffer space needed to
     receive multiple items is the sum of the *note CMSG_SPACE(): 1e4e.
     values for their associated data lengths.  Raises *note
     OverflowError: 578. if `length' is outside the permissible range of
     values.

     Note that some systems might support ancillary data without
     providing this function.  Also note that setting the buffer size
     using the results of this function may not precisely limit the
     amount of ancillary data that can be received, since additional
     data may be able to fit into the padding area.

     Availability: most Unix platforms, possibly others.

     New in version 3.3.

 -- Function: socket.getdefaulttimeout ()

     Return the default timeout in seconds (float) for new socket
     objects.  A value of ‘None’ indicates that new socket objects have
     no timeout.  When the socket module is first imported, the default
     is ‘None’.

 -- Function: socket.setdefaulttimeout (timeout)

     Set the default timeout in seconds (float) for new socket objects.
     When the socket module is first imported, the default is ‘None’.
     See *note settimeout(): 1e1d. for possible values and their
     respective meanings.

 -- Function: socket.sethostname (name)

     Set the machine’s hostname to `name'.  This will raise an *note
     OSError: 4b6. if you don’t have enough rights.

     Availability: Unix.

     New in version 3.3.

 -- Function: socket.if_nameindex ()

     Return a list of network interface information (index int, name
     string) tuples.  *note OSError: 4b6. if the system call fails.

     Availability: Unix.

     New in version 3.3.

 -- Function: socket.if_nametoindex (if_name)

     Return a network interface index number corresponding to an
     interface name.  *note OSError: 4b6. if no interface with the given
     name exists.

     Availability: Unix.

     New in version 3.3.

 -- Function: socket.if_indextoname (if_index)

     Return a network interface name corresponding to an interface index
     number.  *note OSError: 4b6. if no interface with the given index
     exists.

     Availability: Unix.

     New in version 3.3.

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc3542.html


File: python.info,  Node: Socket Objects,  Next: Notes on socket timeouts,  Prev: Module contents,  Up: socket --- Low-level networking interface

5.18.1.8 Socket Objects
.......................

Socket objects have the following methods.  Except for *note makefile():
75b, these correspond to Unix system calls applicable to sockets.

Changed in version 3.2: Support for the *note context manager: 165.
protocol was added.  Exiting the context manager is equivalent to
calling *note close(): 1a8.

 -- Method: socket.accept ()

     Accept a connection.  The socket must be bound to an address and
     listening for connections.  The return value is a pair ‘(conn,
     address)’ where `conn' is a `new' socket object usable to send and
     receive data on the connection, and `address' is the address bound
     to the socket on the other end of the connection.

     The newly created socket is *note non-inheritable: 3ea.

     Changed in version 3.4: The socket is now non-inheritable.

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(1) for the rationale).

 -- Method: socket.bind (address)

     Bind the socket to `address'.  The socket must not already be
     bound.  (The format of `address' depends on the address family —
     see above.)

 -- Method: socket.close ()

     Mark the socket closed.  The underlying system resource (e.g.  a
     file descriptor) is also closed when all file objects from *note
     makefile(): 75b. are closed.  Once that happens, all future
     operations on the socket object will fail.  The remote end will
     receive no more data (after queued data is flushed).

     Sockets are automatically closed when they are garbage-collected,
     but it is recommended to *note close(): 1a8. them explicitly, or to
     use a *note with: 29d. statement around them.

     Changed in version 3.6: *note OSError: 4b6. is now raised if an
     error occurs when the underlying ‘close()’ call is made.

          Note: *note close(): 1a8. releases the resource associated
          with a connection but does not necessarily close the
          connection immediately.  If you want to close the connection
          in a timely fashion, call *note shutdown(): 1e54. before *note
          close(): 1a8.

 -- Method: socket.connect (address)

     Connect to a remote socket at `address'.  (The format of `address'
     depends on the address family — see above.)

     If the connection is interrupted by a signal, the method waits
     until the connection completes, or raise a *note socket.timeout:
     86f. on timeout, if the signal handler doesn’t raise an exception
     and the socket is blocking or has a timeout.  For non-blocking
     sockets, the method raises an *note InterruptedError: 1e7.
     exception if the connection is interrupted by a signal (or the
     exception raised by the signal handler).

     Changed in version 3.5: The method now waits until the connection
     completes instead of raising an *note InterruptedError: 1e7.
     exception if the connection is interrupted by a signal, the signal
     handler doesn’t raise an exception and the socket is blocking or
     has a timeout (see the PEP 475(2) for the rationale).

 -- Method: socket.connect_ex (address)

     Like ‘connect(address)’, but return an error indicator instead of
     raising an exception for errors returned by the C-level ‘connect()’
     call (other problems, such as "host not found," can still raise
     exceptions).  The error indicator is ‘0’ if the operation
     succeeded, otherwise the value of the ‘errno’ variable.  This is
     useful to support, for example, asynchronous connects.

 -- Method: socket.detach ()

     Put the socket object into closed state without actually closing
     the underlying file descriptor.  The file descriptor is returned,
     and can be reused for other purposes.

     New in version 3.2.

 -- Method: socket.dup ()

     Duplicate the socket.

     The newly created socket is *note non-inheritable: 3ea.

     Changed in version 3.4: The socket is now non-inheritable.

 -- Method: socket.fileno ()

     Return the socket’s file descriptor (a small integer).  This is
     useful with *note select.select(): 209.

     Under Windows the small integer returned by this method cannot be
     used where a file descriptor can be used (such as *note
     os.fdopen(): df6.).  Unix does not have this limitation.

 -- Method: socket.get_inheritable ()

     Get the *note inheritable flag: 3ea. of the socket’s file
     descriptor or socket’s handle: ‘True’ if the socket can be
     inherited in child processes, ‘False’ if it cannot.

     New in version 3.4.

 -- Method: socket.getpeername ()

     Return the remote address to which the socket is connected.  This
     is useful to find out the port number of a remote IPv4/v6 socket,
     for instance.  (The format of the address returned depends on the
     address family — see above.)  On some systems this function is not
     supported.

 -- Method: socket.getsockname ()

     Return the socket’s own address.  This is useful to find out the
     port number of an IPv4/v6 socket, for instance.  (The format of the
     address returned depends on the address family — see above.)

 -- Method: socket.getsockopt (level, optname[, buflen])

     Return the value of the given socket option (see the Unix man page
     ‘getsockopt(2)’).  The needed symbolic constants (‘SO_*’ etc.)  are
     defined in this module.  If `buflen' is absent, an integer option
     is assumed and its integer value is returned by the function.  If
     `buflen' is present, it specifies the maximum length of the buffer
     used to receive the option in, and this buffer is returned as a
     bytes object.  It is up to the caller to decode the contents of the
     buffer (see the optional built-in module *note struct: f6. for a
     way to decode C structures encoded as byte strings).

 -- Method: socket.gettimeout ()

     Return the timeout in seconds (float) associated with socket
     operations, or ‘None’ if no timeout is set.  This reflects the last
     call to *note setblocking(): 1883. or *note settimeout(): 1e1d.

 -- Method: socket.ioctl (control, option)


     Platform: Windows

     The *note ioctl(): 1e31. method is a limited interface to the
     WSAIoctl system interface.  Please refer to the Win32
     documentation(3) for more information.

     On other platforms, the generic *note fcntl.fcntl(): 1e5c. and
     *note fcntl.ioctl(): a5b. functions may be used; they accept a
     socket object as their first argument.

 -- Method: socket.listen ([backlog])

     Enable a server to accept connections.  If `backlog' is specified,
     it must be at least 0 (if it is lower, it is set to 0); it
     specifies the number of unaccepted connections that the system will
     allow before refusing new connections.  If not specified, a default
     reasonable value is chosen.

     Changed in version 3.5: The `backlog' parameter is now optional.

 -- Method: socket.makefile (mode='r', buffering=None, *, encoding=None,
          errors=None, newline=None)

     Return a *note file object: 78b. associated with the socket.  The
     exact returned type depends on the arguments given to *note
     makefile(): 75b.  These arguments are interpreted the same way as
     by the built-in *note open(): 1e8. function, except the only
     supported `mode' values are ‘'r'’ (default), ‘'w'’ and ‘'b'’.

     The socket must be in blocking mode; it can have a timeout, but the
     file object’s internal buffer may end up in an inconsistent state
     if a timeout occurs.

     Closing the file object returned by *note makefile(): 75b. won’t
     close the original socket unless all other file objects have been
     closed and *note socket.close(): 1a8. has been called on the socket
     object.

          Note: On Windows, the file-like object created by *note
          makefile(): 75b. cannot be used where a file object with a
          file descriptor is expected, such as the stream arguments of
          *note subprocess.Popen(): 7d8.

 -- Method: socket.recv (bufsize[, flags])

     Receive data from the socket.  The return value is a bytes object
     representing the data received.  The maximum amount of data to be
     received at once is specified by `bufsize'.  See the Unix manual
     page ‘recv(2)’ for the meaning of the optional argument `flags'; it
     defaults to zero.

          Note: For best match with hardware and network realities, the
          value of `bufsize' should be a relatively small power of 2,
          for example, 4096.

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(4) for the rationale).

 -- Method: socket.recvfrom (bufsize[, flags])

     Receive data from the socket.  The return value is a pair ‘(bytes,
     address)’ where `bytes' is a bytes object representing the data
     received and `address' is the address of the socket sending the
     data.  See the Unix manual page ‘recv(2)’ for the meaning of the
     optional argument `flags'; it defaults to zero.  (The format of
     `address' depends on the address family — see above.)

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(5) for the rationale).

 -- Method: socket.recvmsg (bufsize[, ancbufsize[, flags]])

     Receive normal data (up to `bufsize' bytes) and ancillary data from
     the socket.  The `ancbufsize' argument sets the size in bytes of
     the internal buffer used to receive the ancillary data; it defaults
     to 0, meaning that no ancillary data will be received.  Appropriate
     buffer sizes for ancillary data can be calculated using *note
     CMSG_SPACE(): 1e4e. or *note CMSG_LEN(): 1e4d, and items which do
     not fit into the buffer might be truncated or discarded.  The
     `flags' argument defaults to 0 and has the same meaning as for
     *note recv(): 20d.

     The return value is a 4-tuple: ‘(data, ancdata, msg_flags,
     address)’.  The `data' item is a *note bytes: 1db. object holding
     the non-ancillary data received.  The `ancdata' item is a list of
     zero or more tuples ‘(cmsg_level, cmsg_type, cmsg_data)’
     representing the ancillary data (control messages) received:
     `cmsg_level' and `cmsg_type' are integers specifying the protocol
     level and protocol-specific type respectively, and `cmsg_data' is a
     *note bytes: 1db. object holding the associated data.  The
     `msg_flags' item is the bitwise OR of various flags indicating
     conditions on the received message; see your system documentation
     for details.  If the receiving socket is unconnected, `address' is
     the address of the sending socket, if available; otherwise, its
     value is unspecified.

     On some systems, *note sendmsg(): 212. and *note recvmsg(): 20f.
     can be used to pass file descriptors between processes over an
     *note AF_UNIX: 1e19. socket.  When this facility is used (it is
     often restricted to *note SOCK_STREAM: 8fb. sockets), *note
     recvmsg(): 20f. will return, in its ancillary data, items of the
     form ‘(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds)’, where `fds' is
     a *note bytes: 1db. object representing the new file descriptors as
     a binary array of the native C ‘int’ type.  If *note recvmsg():
     20f. raises an exception after the system call returns, it will
     first attempt to close any file descriptors received via this
     mechanism.

     Some systems do not indicate the truncated length of ancillary data
     items which have been only partially received.  If an item appears
     to extend beyond the end of the buffer, *note recvmsg(): 20f. will
     issue a *note RuntimeWarning: 10cd, and will return the part of it
     which is inside the buffer provided it has not been truncated
     before the start of its associated data.

     On systems which support the ‘SCM_RIGHTS’ mechanism, the following
     function will receive up to `maxfds' file descriptors, returning
     the message data and a list containing the descriptors (while
     ignoring unexpected conditions such as unrelated control messages
     being received).  See also *note sendmsg(): 212.

          import socket, array

          def recv_fds(sock, msglen, maxfds):
              fds = array.array("i")   # Array of ints
              msg, ancdata, flags, addr = sock.recvmsg(msglen, socket.CMSG_LEN(maxfds * fds.itemsize))
              for cmsg_level, cmsg_type, cmsg_data in ancdata:
                  if (cmsg_level == socket.SOL_SOCKET and cmsg_type == socket.SCM_RIGHTS):
                      # Append data, ignoring any truncated integers at the end.
                      fds.fromstring(cmsg_data[:len(cmsg_data) - (len(cmsg_data) % fds.itemsize)])
              return msg, list(fds)

     Availability: most Unix platforms, possibly others.

     New in version 3.3.

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(6) for the rationale).

 -- Method: socket.recvmsg_into (buffers[, ancbufsize[, flags]])

     Receive normal data and ancillary data from the socket, behaving as
     *note recvmsg(): 20f. would, but scatter the non-ancillary data
     into a series of buffers instead of returning a new bytes object.
     The `buffers' argument must be an iterable of objects that export
     writable buffers (e.g.  *note bytearray: 1dc. objects); these will
     be filled with successive chunks of the non-ancillary data until it
     has all been written or there are no more buffers.  The operating
     system may set a limit (*note sysconf(): 1934. value ‘SC_IOV_MAX’)
     on the number of buffers that can be used.  The `ancbufsize' and
     `flags' arguments have the same meaning as for *note recvmsg():
     20f.

     The return value is a 4-tuple: ‘(nbytes, ancdata, msg_flags,
     address)’, where `nbytes' is the total number of bytes of
     non-ancillary data written into the buffers, and `ancdata',
     `msg_flags' and `address' are the same as for *note recvmsg(): 20f.

     Example:

          >>> import socket
          >>> s1, s2 = socket.socketpair()
          >>> b1 = bytearray(b'----')
          >>> b2 = bytearray(b'0123456789')
          >>> b3 = bytearray(b'--------------')
          >>> s1.send(b'Mary had a little lamb')
          22
          >>> s2.recvmsg_into([b1, memoryview(b2)[2:9], b3])
          (22, [], 0, None)
          >>> [b1, b2, b3]
          [bytearray(b'Mary'), bytearray(b'01 had a 9'), bytearray(b'little lamb---')]

     Availability: most Unix platforms, possibly others.

     New in version 3.3.

 -- Method: socket.recvfrom_into (buffer[, nbytes[, flags]])

     Receive data from the socket, writing it into `buffer' instead of
     creating a new bytestring.  The return value is a pair ‘(nbytes,
     address)’ where `nbytes' is the number of bytes received and
     `address' is the address of the socket sending the data.  See the
     Unix manual page ‘recv(2)’ for the meaning of the optional argument
     `flags'; it defaults to zero.  (The format of `address' depends on
     the address family — see above.)

 -- Method: socket.recv_into (buffer[, nbytes[, flags]])

     Receive up to `nbytes' bytes from the socket, storing the data into
     a buffer rather than creating a new bytestring.  If `nbytes' is not
     specified (or 0), receive up to the size available in the given
     buffer.  Returns the number of bytes received.  See the Unix manual
     page ‘recv(2)’ for the meaning of the optional argument `flags'; it
     defaults to zero.

 -- Method: socket.send (bytes[, flags])

     Send data to the socket.  The socket must be connected to a remote
     socket.  The optional `flags' argument has the same meaning as for
     *note recv(): 20d. above.  Returns the number of bytes sent.
     Applications are responsible for checking that all data has been
     sent; if only some of the data was transmitted, the application
     needs to attempt delivery of the remaining data.  For further
     information on this topic, consult the *note Socket Programming
     HOWTO: 1e5d.

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(7) for the rationale).

 -- Method: socket.sendall (bytes[, flags])

     Send data to the socket.  The socket must be connected to a remote
     socket.  The optional `flags' argument has the same meaning as for
     *note recv(): 20d. above.  Unlike *note send(): 210, this method
     continues to send data from `bytes' until either all data has been
     sent or an error occurs.  ‘None’ is returned on success.  On error,
     an exception is raised, and there is no way to determine how much
     data, if any, was successfully sent.

     Changed in version 3.5: The socket timeout is no more reset each
     time data is sent successfuly.  The socket timeout is now the
     maximum total duration to send all data.

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(8) for the rationale).

 -- Method: socket.sendto (bytes, address)

 -- Method: socket.sendto (bytes, flags, address)

     Send data to the socket.  The socket should not be connected to a
     remote socket, since the destination socket is specified by
     `address'.  The optional `flags' argument has the same meaning as
     for *note recv(): 20d. above.  Return the number of bytes sent.
     (The format of `address' depends on the address family — see
     above.)

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(9) for the rationale).

 -- Method: socket.sendmsg (buffers[, ancdata[, flags[, address]]])

     Send normal and ancillary data to the socket, gathering the
     non-ancillary data from a series of buffers and concatenating it
     into a single message.  The `buffers' argument specifies the
     non-ancillary data as an iterable of *note bytes-like objects: 36b.
     (e.g.  *note bytes: 1db. objects); the operating system may set a
     limit (*note sysconf(): 1934. value ‘SC_IOV_MAX’) on the number of
     buffers that can be used.  The `ancdata' argument specifies the
     ancillary data (control messages) as an iterable of zero or more
     tuples ‘(cmsg_level, cmsg_type, cmsg_data)’, where `cmsg_level' and
     `cmsg_type' are integers specifying the protocol level and
     protocol-specific type respectively, and `cmsg_data' is a
     bytes-like object holding the associated data.  Note that some
     systems (in particular, systems without *note CMSG_SPACE(): 1e4e.)
     might support sending only one control message per call.  The
     `flags' argument defaults to 0 and has the same meaning as for
     *note send(): 210.  If `address' is supplied and not ‘None’, it
     sets a destination address for the message.  The return value is
     the number of bytes of non-ancillary data sent.

     The following function sends the list of file descriptors `fds'
     over an *note AF_UNIX: 1e19. socket, on systems which support the
     ‘SCM_RIGHTS’ mechanism.  See also *note recvmsg(): 20f.

          import socket, array

          def send_fds(sock, msg, fds):
              return sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, array.array("i", fds))])

     Availability: most Unix platforms, possibly others.

     New in version 3.3.

     Changed in version 3.5: If the system call is interrupted and the
     signal handler does not raise an exception, the method now retries
     the system call instead of raising an *note InterruptedError: 1e7.
     exception (see PEP 475(10) for the rationale).

 -- Method: socket.sendfile (file, offset=0, count=None)

     Send a file until EOF is reached by using high-performance *note
     os.sendfile: 1fb. and return the total number of bytes which were
     sent.  `file' must be a regular file object opened in binary mode.
     If *note os.sendfile: 1fb. is not available (e.g.  Windows) or
     `file' is not a regular file *note send(): 210. will be used
     instead.  `offset' tells from where to start reading the file.  If
     specified, `count' is the total number of bytes to transmit as
     opposed to sending the file until EOF is reached.  File position is
     updated on return or also in case of error in which case *note
     file.tell(): 194e. can be used to figure out the number of bytes
     which were sent.  The socket must be of *note SOCK_STREAM: 8fb.
     type.  Non- blocking sockets are not supported.

     New in version 3.5.

 -- Method: socket.set_inheritable (inheritable)

     Set the *note inheritable flag: 3ea. of the socket’s file
     descriptor or socket’s handle.

     New in version 3.4.

 -- Method: socket.setblocking (flag)

     Set blocking or non-blocking mode of the socket: if `flag' is
     false, the socket is set to non-blocking, else to blocking mode.

     This method is a shorthand for certain *note settimeout(): 1e1d.
     calls:

        * ‘sock.setblocking(True)’ is equivalent to
          ‘sock.settimeout(None)’

        * ‘sock.setblocking(False)’ is equivalent to
          ‘sock.settimeout(0.0)’

 -- Method: socket.settimeout (value)

     Set a timeout on blocking socket operations.  The `value' argument
     can be a nonnegative floating point number expressing seconds, or
     ‘None’.  If a non-zero value is given, subsequent socket operations
     will raise a *note timeout: 86f. exception if the timeout period
     `value' has elapsed before the operation has completed.  If zero is
     given, the socket is put in non-blocking mode.  If ‘None’ is given,
     the socket is put in blocking mode.

     For further information, please consult the *note notes on socket
     timeouts: 1e5e.

 -- Method: socket.setsockopt (level, optname, value)

     Set the value of the given socket option (see the Unix manual page
     ‘setsockopt(2)’).  The needed symbolic constants are defined in the
     *note socket: ed. module (‘SO_*’ etc.).  The value can be an
     integer or a *note bytes-like object: 36b. representing a buffer.
     In the latter case it is up to the caller to ensure that the
     bytestring contains the proper bits (see the optional built-in
     module *note struct: f6. for a way to encode C structures as
     bytestrings).

     Changed in version 3.5: Writable *note bytes-like object: 36b. is
     now accepted.

 -- Method: socket.shutdown (how)

     Shut down one or both halves of the connection.  If `how' is
     ‘SHUT_RD’, further receives are disallowed.  If `how' is ‘SHUT_WR’,
     further sends are disallowed.  If `how' is ‘SHUT_RDWR’, further
     sends and receives are disallowed.

 -- Method: socket.share (process_id)

     Duplicate a socket and prepare it for sharing with a target
     process.  The target process must be provided with `process_id'.
     The resulting bytes object can then be passed to the target process
     using some form of interprocess communication and the socket can be
     recreated there using *note fromshare(): 1e3e.  Once this method
     has been called, it is safe to close the socket since the operating
     system has already duplicated it for the target process.

     Availability: Windows.

     New in version 3.3.

Note that there are no methods ‘read()’ or ‘write()’; use *note recv():
20d. and *note send(): 210. without `flags' argument instead.

Socket objects also have these (read-only) attributes that correspond to
the values given to the *note socket: ed. constructor.

 -- Attribute: socket.family

     The socket family.

 -- Attribute: socket.type

     The socket type.

 -- Attribute: socket.proto

     The socket protocol.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475

   (2) https://www.python.org/dev/peps/pep-0475

   (3) https://msdn.microsoft.com/en-us/library/ms741621%28VS.85%29.aspx

   (4) https://www.python.org/dev/peps/pep-0475

   (5) https://www.python.org/dev/peps/pep-0475

   (6) https://www.python.org/dev/peps/pep-0475

   (7) https://www.python.org/dev/peps/pep-0475

   (8) https://www.python.org/dev/peps/pep-0475

   (9) https://www.python.org/dev/peps/pep-0475

   (10) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Notes on socket timeouts,  Next: Example<7>,  Prev: Socket Objects,  Up: socket --- Low-level networking interface

5.18.1.9 Notes on socket timeouts
.................................

A socket object can be in one of three modes: blocking, non-blocking, or
timeout.  Sockets are by default always created in blocking mode, but
this can be changed by calling *note setdefaulttimeout(): 1e26.

   * In `blocking mode', operations block until complete or the system
     returns an error (such as connection timed out).

   * In `non-blocking mode', operations fail (with an error that is
     unfortunately system-dependent) if they cannot be completed
     immediately: functions from the *note select: e3. can be used to
     know when and whether a socket is available for reading or writing.

   * In `timeout mode', operations fail if they cannot be completed
     within the timeout specified for the socket (they raise a *note
     timeout: 86f. exception) or if the system returns an error.

     Note: At the operating system level, sockets in `timeout mode' are
     internally set in non-blocking mode.  Also, the blocking and
     timeout modes are shared between file descriptors and socket
     objects that refer to the same network endpoint.  This
     implementation detail can have visible consequences if e.g.  you
     decide to use the *note fileno(): 1e57. of a socket.

* Menu:

* Timeouts and the connect method:: 
* Timeouts and the accept method:: 


File: python.info,  Node: Timeouts and the connect method,  Next: Timeouts and the accept method,  Up: Notes on socket timeouts

5.18.1.10 Timeouts and the ‘connect’ method
...........................................

The *note connect(): 20c. operation is also subject to the timeout
setting, and in general it is recommended to call *note settimeout():
1e1d. before calling *note connect(): 20c. or pass a timeout parameter
to *note create_connection(): 7f9.  However, the system network stack
may also return a connection timeout error of its own regardless of any
Python socket timeout setting.


File: python.info,  Node: Timeouts and the accept method,  Prev: Timeouts and the connect method,  Up: Notes on socket timeouts

5.18.1.11 Timeouts and the ‘accept’ method
..........................................

If *note getdefaulttimeout(): 1e3d. is not *note None: 19d, sockets
returned by the *note accept(): 20b. method inherit that timeout.
Otherwise, the behaviour depends on settings of the listening socket:

   * if the listening socket is in `blocking mode' or in `timeout mode',
     the socket returned by *note accept(): 20b. is in `blocking mode';

   * if the listening socket is in `non-blocking mode', whether the
     socket returned by *note accept(): 20b. is in blocking or
     non-blocking mode is operating system-dependent.  If you want to
     ensure cross-platform behaviour, it is recommended you manually
     override this setting.


File: python.info,  Node: Example<7>,  Prev: Notes on socket timeouts,  Up: socket --- Low-level networking interface

5.18.1.12 Example
.................

Here are four minimal example programs using the TCP/IP protocol: a
server that echoes all data that it receives back (servicing only one
client), and a client using it.  Note that a server must perform the
sequence *note socket(): 20a, *note bind(): 1e53, *note listen(): 316,
*note accept(): 20b. (possibly repeating the *note accept(): 20b. to
service more than one client), while a client only needs the sequence
*note socket(): 20a, *note connect(): 20c.  Also note that the server
does not *note sendall(): 211./*note recv(): 20d. on the socket it is
listening on but on the new socket returned by *note accept(): 20b.

The first two examples support IPv4 only.

     # Echo server program
     import socket

     HOST = ''                 # Symbolic name meaning all available interfaces
     PORT = 50007              # Arbitrary non-privileged port
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
         s.bind((HOST, PORT))
         s.listen(1)
         conn, addr = s.accept()
         with conn:
             print('Connected by', addr)
             while True:
                 data = conn.recv(1024)
                 if not data: break
                 conn.sendall(data)

     # Echo client program
     import socket

     HOST = 'daring.cwi.nl'    # The remote host
     PORT = 50007              # The same port as used by the server
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
         s.connect((HOST, PORT))
         s.sendall(b'Hello, world')
         data = s.recv(1024)
     print('Received', repr(data))

The next two examples are identical to the above two, but support both
IPv4 and IPv6.  The server side will listen to the first address family
available (it should listen to both instead).  On most of IPv6-ready
systems, IPv6 will take precedence and the server may not accept IPv4
traffic.  The client side will try to connect to the all addresses
returned as a result of the name resolution, and sends traffic to the
first one connected successfully.

     # Echo server program
     import socket
     import sys

     HOST = None               # Symbolic name meaning all available interfaces
     PORT = 50007              # Arbitrary non-privileged port
     s = None
     for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC,
                                   socket.SOCK_STREAM, 0, socket.AI_PASSIVE):
         af, socktype, proto, canonname, sa = res
         try:
             s = socket.socket(af, socktype, proto)
         except OSError as msg:
             s = None
             continue
         try:
             s.bind(sa)
             s.listen(1)
         except OSError as msg:
             s.close()
             s = None
             continue
         break
     if s is None:
         print('could not open socket')
         sys.exit(1)
     conn, addr = s.accept()
     with conn:
         print('Connected by', addr)
         while True:
             data = conn.recv(1024)
             if not data: break
             conn.send(data)

     # Echo client program
     import socket
     import sys

     HOST = 'daring.cwi.nl'    # The remote host
     PORT = 50007              # The same port as used by the server
     s = None
     for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC, socket.SOCK_STREAM):
         af, socktype, proto, canonname, sa = res
         try:
             s = socket.socket(af, socktype, proto)
         except OSError as msg:
             s = None
             continue
         try:
             s.connect(sa)
         except OSError as msg:
             s.close()
             s = None
             continue
         break
     if s is None:
         print('could not open socket')
         sys.exit(1)
     with s:
         s.sendall(b'Hello, world')
         data = s.recv(1024)
     print('Received', repr(data))

The next example shows how to write a very simple network sniffer with
raw sockets on Windows.  The example requires administrator privileges
to modify the interface:

     import socket

     # the public network interface
     HOST = socket.gethostbyname(socket.gethostname())

     # create a raw socket and bind it to the public interface
     s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
     s.bind((HOST, 0))

     # Include IP headers
     s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)

     # receive all packages
     s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)

     # receive a package
     print(s.recvfrom(65565))

     # disabled promiscuous mode
     s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)

The last example shows how to use the socket interface to communicate to
a CAN network using the raw socket protocol.  To use CAN with the
broadcast manager protocol instead, open a socket with:

     socket.socket(socket.AF_CAN, socket.SOCK_DGRAM, socket.CAN_BCM)

After binding (‘CAN_RAW’) or connecting (*note CAN_BCM: 4b8.) the
socket, you can use the *note socket.send(): 210, and the *note
socket.recv(): 20d. operations (and their counterparts) on the socket
object as usual.

This example might require special privileges:

     import socket
     import struct


     # CAN frame packing/unpacking (see 'struct can_frame' in <linux/can.h>)

     can_frame_fmt = "=IB3x8s"
     can_frame_size = struct.calcsize(can_frame_fmt)

     def build_can_frame(can_id, data):
         can_dlc = len(data)
         data = data.ljust(8, b'\x00')
         return struct.pack(can_frame_fmt, can_id, can_dlc, data)

     def dissect_can_frame(frame):
         can_id, can_dlc, data = struct.unpack(can_frame_fmt, frame)
         return (can_id, can_dlc, data[:can_dlc])


     # create a raw socket and bind it to the 'vcan0' interface
     s = socket.socket(socket.AF_CAN, socket.SOCK_RAW, socket.CAN_RAW)
     s.bind(('vcan0',))

     while True:
         cf, addr = s.recvfrom(can_frame_size)

         print('Received: can_id=%x, can_dlc=%x, data=%s' % dissect_can_frame(cf))

         try:
             s.send(cf)
         except OSError:
             print('Error sending CAN frame')

         try:
             s.send(build_can_frame(0x01, b'\x01\x02\x03'))
         except OSError:
             print('Error sending CAN frame')

Running an example several times with too small delay between
executions, could lead to this error:

     OSError: [Errno 98] Address already in use

This is because the previous execution has left the socket in a
‘TIME_WAIT’ state, and can’t be immediately reused.

There is a *note socket: ed. flag to set, in order to prevent this,
‘socket.SO_REUSEADDR’:

     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
     s.bind((HOST, PORT))

the ‘SO_REUSEADDR’ flag tells the kernel to reuse a local socket in
‘TIME_WAIT’ state, without waiting for its natural timeout to expire.

See also
........

For an introduction to socket programming (in C), see the following
papers:

   - `An Introductory 4.3BSD Interprocess Communication Tutorial', by
     Stuart Sechrest

   - `An Advanced 4.3BSD Interprocess Communication Tutorial', by Samuel
     J. Leffler et al,

both in the UNIX Programmer’s Manual, Supplementary Documents 1
(sections PS1:7 and PS1:8).  The platform-specific reference material
for the various socket-related system calls are also a valuable source
of information on the details of socket semantics.  For Unix, refer to
the manual pages; for Windows, see the WinSock (or Winsock 2)
specification.  For IPv6-ready APIs, readers may want to refer to RFC
3493(1) titled Basic Socket Interface Extensions for IPv6.

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc3493.html


File: python.info,  Node: ssl --- TLS/SSL wrapper for socket objects,  Next: select --- Waiting for I/O completion,  Prev: socket --- Low-level networking interface,  Up: Interprocess Communication and Networking

5.18.2 ‘ssl’ — TLS/SSL wrapper for socket objects
-------------------------------------------------

`Source code:' Lib/ssl.py(1)

__________________________________________________________________

This module provides access to Transport Layer Security (often known as
"Secure Sockets Layer") encryption and peer authentication facilities
for network sockets, both client-side and server-side.  This module uses
the OpenSSL library.  It is available on all modern Unix systems,
Windows, Mac OS X, and probably additional platforms, as long as OpenSSL
is installed on that platform.

     Note: Some behavior may be platform dependent, since calls are made
     to the operating system socket APIs.  The installed version of
     OpenSSL may also cause variations in behavior.  For example,
     TLSv1.1 and TLSv1.2 come with openssl version 1.0.1.

     Warning: Don’t use this module without reading the *note Security
     considerations: 1e6a.  Doing so may lead to a false sense of
     security, as the default settings of the ssl module are not
     necessarily appropriate for your application.

This section documents the objects and functions in the ‘ssl’ module;
for more general information about TLS, SSL, and certificates, the
reader is referred to the documents in the "See Also" section at the
bottom.

This module provides a class, *note ssl.SSLSocket: 31b, which is derived
from the *note socket.socket: 20a. type, and provides a socket-like
wrapper that also encrypts and decrypts the data going over the socket
with SSL. It supports additional methods such as ‘getpeercert()’, which
retrieves the certificate of the other side of the connection, and
‘cipher()’,which retrieves the cipher being used for the secure
connection.

For more sophisticated applications, the *note ssl.SSLContext: 1c6.
class helps manage settings and certificates, which can then be
inherited by SSL sockets created through the *note
SSLContext.wrap_socket(): 7fb. method.

* Menu:

* Functions, Constants, and Exceptions: Functions Constants and Exceptions. 
* SSL Sockets:: 
* SSL Contexts:: 
* Certificates:: 
* Examples: Examples<10>. 
* Notes on non-blocking sockets:: 
* Memory BIO Support: Memory BIO Support<2>. 
* Security considerations:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/ssl.py


File: python.info,  Node: Functions Constants and Exceptions,  Next: SSL Sockets,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.1 Functions, Constants, and Exceptions
.............................................

 -- Exception: ssl.SSLError

     Raised to signal an error from the underlying SSL implementation
     (currently provided by the OpenSSL library).  This signifies some
     problem in the higher-level encryption and authentication layer
     that’s superimposed on the underlying network connection.  This
     error is a subtype of *note OSError: 4b6.  The error code and
     message of *note SSLError: 870. instances are provided by the
     OpenSSL library.

     Changed in version 3.3: *note SSLError: 870. used to be a subtype
     of *note socket.error: 5b3.

      -- Attribute: library

          A string mnemonic designating the OpenSSL submodule in which
          the error occurred, such as ‘SSL’, ‘PEM’ or ‘X509’.  The range
          of possible values depends on the OpenSSL version.

          New in version 3.3.

      -- Attribute: reason

          A string mnemonic designating the reason this error occurred,
          for example ‘CERTIFICATE_VERIFY_FAILED’.  The range of
          possible values depends on the OpenSSL version.

          New in version 3.3.

 -- Exception: ssl.SSLZeroReturnError

     A subclass of *note SSLError: 870. raised when trying to read or
     write and the SSL connection has been closed cleanly.  Note that
     this doesn’t mean that the underlying transport (read TCP) has been
     closed.

     New in version 3.3.

 -- Exception: ssl.SSLWantReadError

     A subclass of *note SSLError: 870. raised by a *note non-blocking
     SSL socket: 1e6d. when trying to read or write data, but more data
     needs to be received on the underlying TCP transport before the
     request can be fulfilled.

     New in version 3.3.

 -- Exception: ssl.SSLWantWriteError

     A subclass of *note SSLError: 870. raised by a *note non-blocking
     SSL socket: 1e6d. when trying to read or write data, but more data
     needs to be sent on the underlying TCP transport before the request
     can be fulfilled.

     New in version 3.3.

 -- Exception: ssl.SSLSyscallError

     A subclass of *note SSLError: 870. raised when a system error was
     encountered while trying to fulfill an operation on a SSL socket.
     Unfortunately, there is no easy way to inspect the original errno
     number.

     New in version 3.3.

 -- Exception: ssl.SSLEOFError

     A subclass of *note SSLError: 870. raised when the SSL connection
     has been terminated abruptly.  Generally, you shouldn’t try to
     reuse the underlying transport when this error is encountered.

     New in version 3.3.

 -- Exception: ssl.CertificateError

     Raised to signal an error with a certificate (such as mismatching
     hostname).  Certificate errors detected by OpenSSL, though, raise
     an *note SSLError: 870.

* Menu:

* Socket creation:: 
* Context creation:: 
* Random generation:: 
* Certificate handling:: 
* Constants: Constants<7>. 


File: python.info,  Node: Socket creation,  Next: Context creation,  Up: Functions Constants and Exceptions

5.18.2.2 Socket creation
........................

The following function allows for standalone socket creation.  Starting
from Python 3.2, it can be more flexible to use *note
SSLContext.wrap_socket(): 7fb. instead.

 -- Function: ssl.wrap_socket (sock, keyfile=None, certfile=None,
          server_side=False, cert_reqs=CERT_NONE, ssl_version={see
          docs}, ca_certs=None, do_handshake_on_connect=True,
          suppress_ragged_eofs=True, ciphers=None)

     Takes an instance ‘sock’ of *note socket.socket: 20a, and returns
     an instance of *note ssl.SSLSocket: 31b, a subtype of *note
     socket.socket: 20a, which wraps the underlying socket in an SSL
     context.  ‘sock’ must be a *note SOCK_STREAM: 8fb. socket; other
     socket types are unsupported.

     For client-side sockets, the context construction is lazy; if the
     underlying socket isn’t connected yet, the context construction
     will be performed after ‘connect()’ is called on the socket.  For
     server-side sockets, if the socket has no remote peer, it is
     assumed to be a listening socket, and the server-side SSL wrapping
     is automatically performed on client connections accepted via the
     ‘accept()’ method.  *note wrap_socket(): 7fc. may raise *note
     SSLError: 870.

     The ‘keyfile’ and ‘certfile’ parameters specify optional files
     which contain a certificate to be used to identify the local side
     of the connection.  See the discussion of *note Certificates: 1e72.
     for more information on how the certificate is stored in the
     ‘certfile’.

     The parameter ‘server_side’ is a boolean which identifies whether
     server-side or client-side behavior is desired from this socket.

     The parameter ‘cert_reqs’ specifies whether a certificate is
     required from the other side of the connection, and whether it will
     be validated if provided.  It must be one of the three values *note
     CERT_NONE: 1e73. (certificates ignored), *note CERT_OPTIONAL: 1e74.
     (not required, but validated if provided), or *note CERT_REQUIRED:
     1e75. (required and validated).  If the value of this parameter is
     not *note CERT_NONE: 1e73, then the ‘ca_certs’ parameter must point
     to a file of CA certificates.

     The ‘ca_certs’ file contains a set of concatenated "certification
     authority" certificates, which are used to validate certificates
     passed from the other end of the connection.  See the discussion of
     *note Certificates: 1e72. for more information about how to arrange
     the certificates in this file.

     The parameter ‘ssl_version’ specifies which version of the SSL
     protocol to use.  Typically, the server chooses a particular
     protocol version, and the client must adapt to the server’s choice.
     Most of the versions are not interoperable with the other versions.
     If not specified, the default is *note PROTOCOL_SSLv23: 1e76.; it
     provides the most compatibility with other versions.

     Here’s a table showing which versions in a client (down the side)
     can connect to which versions in a server (along the top):

          `client' / `server'          `SSLv2'       `SSLv3'       `SSLv23'       `TLSv1'       `TLSv1.1'       `TLSv1.2'
                                                                                                                
                                                                                                                
          `SSLv2'                      yes           no            yes            no            no              no
                                                                                                                
                                                                                                                
          `SSLv3'                      no            yes           yes            no            no              no
                                                                                                                
                                                                                                                
          `SSLv23'                     no            yes           yes            yes           yes             yes
                                                                                                                
                                                                                                                
          `TLSv1'                      no            no            yes            yes           no              no
                                                                                                                
                                                                                                                
          `TLSv1.1'                    no            no            yes            no            yes             no
                                                                                                                
                                                                                                                
          `TLSv1.2'                    no            no            yes            no            no              yes
                                                                                                                

          Note: Which connections succeed will vary depending on the
          version of OpenSSL. For example, before OpenSSL 1.0.0, an
          SSLv23 client would always attempt SSLv2 connections.

     The `ciphers' parameter sets the available ciphers for this SSL
     object.  It should be a string in the OpenSSL cipher list
     format(1).

     The parameter ‘do_handshake_on_connect’ specifies whether to do the
     SSL handshake automatically after doing a ‘socket.connect()’, or
     whether the application program will call it explicitly, by
     invoking the *note SSLSocket.do_handshake(): 328. method.  Calling
     *note SSLSocket.do_handshake(): 328. explicitly gives the program
     control over the blocking behavior of the socket I/O involved in
     the handshake.

     The parameter ‘suppress_ragged_eofs’ specifies how the
     ‘SSLSocket.recv()’ method should signal unexpected EOF from the
     other end of the connection.  If specified as *note True: 9ff. (the
     default), it returns a normal EOF (an empty bytes object) in
     response to unexpected EOF errors raised from the underlying
     socket; if *note False: 60d, it will raise the exceptions back to
     the caller.

     Changed in version 3.2: New optional argument `ciphers'.

   ---------- Footnotes ----------

   (1) http://www.openssl.org/docs/apps/ciphers.html#CIPHER-LIST-FORMAT


File: python.info,  Node: Context creation,  Next: Random generation,  Prev: Socket creation,  Up: Functions Constants and Exceptions

5.18.2.3 Context creation
.........................

A convenience function helps create *note SSLContext: 1c6. objects for
common purposes.

 -- Function: ssl.create_default_context (purpose=Purpose.SERVER_AUTH,
          cafile=None, capath=None, cadata=None)

     Return a new *note SSLContext: 1c6. object with default settings
     for the given `purpose'.  The settings are chosen by the *note ssl:
     f1. module, and usually represent a higher security level than when
     calling the *note SSLContext: 1c6. constructor directly.

     `cafile', `capath', `cadata' represent optional CA certificates to
     trust for certificate verification, as in *note
     SSLContext.load_verify_locations(): 3da.  If all three are *note
     None: 19d, this function can choose to trust the system’s default
     CA certificates instead.

     The settings are: *note PROTOCOL_SSLv23: 1e76, *note OP_NO_SSLv2:
     7fd, and *note OP_NO_SSLv3: 1e78. with high encryption cipher
     suites without RC4 and without unauthenticated cipher suites.
     Passing *note SERVER_AUTH: 4cc. as `purpose' sets *note
     verify_mode: 1e79. to *note CERT_REQUIRED: 1e75. and either loads
     CA certificates (when at least one of `cafile', `capath' or
     `cadata' is given) or uses *note SSLContext.load_default_certs():
     4cb. to load default CA certificates.

          Note: The protocol, options, cipher and other settings may
          change to more restrictive values anytime without prior
          deprecation.  The values represent a fair balance between
          compatibility and security.

          If your application needs specific settings, you should create
          a *note SSLContext: 1c6. and apply the settings yourself.

          Note: If you find that when certain older clients or servers
          attempt to connect with a *note SSLContext: 1c6. created by
          this function that they get an error stating "Protocol or
          cipher suite mismatch", it may be that they only support
          SSL3.0 which this function excludes using the *note
          OP_NO_SSLv3: 1e78.  SSL3.0 is widely considered to be
          completely broken(1).  If you still wish to continue to use
          this function but still allow SSL 3.0 connections you can
          re-enable them using:

               ctx = ssl.create_default_context(Purpose.CLIENT_AUTH)
               ctx.options &= ~ssl.OP_NO_SSLv3

     New in version 3.4.

     Changed in version 3.4.4: RC4 was dropped from the default cipher
     string.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/POODLE


File: python.info,  Node: Random generation,  Next: Certificate handling,  Prev: Context creation,  Up: Functions Constants and Exceptions

5.18.2.4 Random generation
..........................

 -- Function: ssl.RAND_bytes (num)

     Return `num' cryptographically strong pseudo-random bytes.  Raises
     an *note SSLError: 870. if the PRNG has not been seeded with enough
     data or if the operation is not supported by the current RAND
     method.  *note RAND_status(): 1e7b. can be used to check the status
     of the PRNG and *note RAND_add(): 1e7c. can be used to seed the
     PRNG.

     For almost all applications *note os.urandom(): 2df. is preferable.

     Read the Wikipedia article, Cryptographically secure pseudorandom
     number generator (CSPRNG)(1), to get the requirements of a
     cryptographically generator.

     New in version 3.3.

 -- Function: ssl.RAND_pseudo_bytes (num)

     Return (bytes, is_cryptographic): bytes are `num' pseudo-random
     bytes, is_cryptographic is ‘True’ if the bytes generated are
     cryptographically strong.  Raises an *note SSLError: 870. if the
     operation is not supported by the current RAND method.

     Generated pseudo-random byte sequences will be unique if they are
     of sufficient length, but are not necessarily unpredictable.  They
     can be used for non-cryptographic purposes and for certain purposes
     in cryptographic protocols, but usually not for key generation etc.

     For almost all applications *note os.urandom(): 2df. is preferable.

     New in version 3.3.

 -- Function: ssl.RAND_status ()

     Return ‘True’ if the SSL pseudo-random number generator has been
     seeded with ’enough’ randomness, and ‘False’ otherwise.  You can
     use *note ssl.RAND_egd(): 1e7d. and *note ssl.RAND_add(): 1e7c. to
     increase the randomness of the pseudo-random number generator.

 -- Function: ssl.RAND_egd (path)

     If you are running an entropy-gathering daemon (EGD) somewhere, and
     `path' is the pathname of a socket connection open to it, this will
     read 256 bytes of randomness from the socket, and add it to the SSL
     pseudo-random number generator to increase the security of
     generated secret keys.  This is typically only necessary on systems
     without better sources of randomness.

     See ‘http://egd.sourceforge.net/’ or
     ‘http://prngd.sourceforge.net/’ for sources of entropy-gathering
     daemons.

     Availability: not available with LibreSSL.

 -- Function: ssl.RAND_add (bytes, entropy)

     Mix the given `bytes' into the SSL pseudo-random number generator.
     The parameter `entropy' (a float) is a lower bound on the entropy
     contained in string (so you can always use ‘0.0’).  See RFC 1750(2)
     for more information on sources of entropy.

     Changed in version 3.5: Writable *note bytes-like object: 36b. is
     now accepted.

   ---------- Footnotes ----------

   (1) 
https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator

   (2) https://tools.ietf.org/html/rfc1750.html


File: python.info,  Node: Certificate handling,  Next: Constants<7>,  Prev: Random generation,  Up: Functions Constants and Exceptions

5.18.2.5 Certificate handling
.............................

 -- Function: ssl.match_hostname (cert, hostname)

     Verify that `cert' (in decoded format as returned by *note
     SSLSocket.getpeercert(): 4d1.) matches the given `hostname'.  The
     rules applied are those for checking the identity of HTTPS servers
     as outlined in RFC 2818(1) and RFC 6125(2).  In addition to HTTPS,
     this function should be suitable for checking the identity of
     servers in various SSL-based protocols such as FTPS, IMAPS, POPS
     and others.

     *note CertificateError: 1e70. is raised on failure.  On success,
     the function returns nothing:

          >>> cert = {'subject': ((('commonName', 'example.com'),),)}
          >>> ssl.match_hostname(cert, "example.com")
          >>> ssl.match_hostname(cert, "example.org")
          Traceback (most recent call last):
            File "<stdin>", line 1, in <module>
            File "/home/py3k/Lib/ssl.py", line 130, in match_hostname
          ssl.CertificateError: hostname 'example.org' doesn't match 'example.com'

     New in version 3.2.

     Changed in version 3.3.3: The function now follows RFC 6125(3),
     section 6.4.3 and does neither match multiple wildcards (e.g.
     ‘*.*.com’ or ‘*a*.example.org’) nor a wildcard inside an
     internationalized domain names (IDN) fragment.  IDN A-labels such
     as ‘www*.xn--pthon-kva.org’ are still supported, but
     ‘x*.python.org’ no longer matches ‘xn--tda.python.org’.

     Changed in version 3.5: Matching of IP addresses, when present in
     the subjectAltName field of the certificate, is now supported.

 -- Function: ssl.cert_time_to_seconds (cert_time)

     Return the time in seconds since the Epoch, given the ‘cert_time’
     string representing the "notBefore" or "notAfter" date from a
     certificate in ‘"%b %d %H:%M:%S %Y %Z"’ strptime format (C locale).

     Here’s an example:

          >>> import ssl
          >>> timestamp = ssl.cert_time_to_seconds("Jan  5 09:34:43 2018 GMT")
          >>> timestamp
          1515144883
          >>> from datetime import datetime
          >>> print(datetime.utcfromtimestamp(timestamp))
          2018-01-05 09:34:43

     "notBefore" or "notAfter" dates must use GMT ( RFC 5280(4)).

     Changed in version 3.5: Interpret the input time as a time in UTC
     as specified by ’GMT’ timezone in the input string.  Local timezone
     was used previously.  Return an integer (no fractions of a second
     in the input format)

 -- Function: ssl.get_server_certificate (addr,
          ssl_version=PROTOCOL_SSLv23, ca_certs=None)

     Given the address ‘addr’ of an SSL-protected server, as a
     (`hostname', `port-number') pair, fetches the server’s certificate,
     and returns it as a PEM-encoded string.  If ‘ssl_version’ is
     specified, uses that version of the SSL protocol to attempt to
     connect to the server.  If ‘ca_certs’ is specified, it should be a
     file containing a list of root certificates, the same format as
     used for the same parameter in *note wrap_socket(): 7fc.  The call
     will attempt to validate the server certificate against that set of
     root certificates, and will fail if the validation attempt fails.

     Changed in version 3.3: This function is now IPv6-compatible.

     Changed in version 3.5: The default `ssl_version' is changed from
     *note PROTOCOL_SSLv3: 1e7f. to *note PROTOCOL_SSLv23: 1e76. for
     maximum compatibility with modern servers.

 -- Function: ssl.DER_cert_to_PEM_cert (DER_cert_bytes)

     Given a certificate as a DER-encoded blob of bytes, returns a
     PEM-encoded string version of the same certificate.

 -- Function: ssl.PEM_cert_to_DER_cert (PEM_cert_string)

     Given a certificate as an ASCII PEM string, returns a DER-encoded
     sequence of bytes for that same certificate.

 -- Function: ssl.get_default_verify_paths ()

     Returns a named tuple with paths to OpenSSL’s default cafile and
     capath.  The paths are the same as used by *note
     SSLContext.set_default_verify_paths(): 4c3.  The return value is a
     *note named tuple: 787. ‘DefaultVerifyPaths’:

        * ‘cafile’ - resolved path to cafile or None if the file doesn’t
          exist,

        * ‘capath’ - resolved path to capath or None if the directory
          doesn’t exist,

        * ‘openssl_cafile_env’ - OpenSSL’s environment key that points
          to a cafile,

        * ‘openssl_cafile’ - hard coded path to a cafile,

        * ‘openssl_capath_env’ - OpenSSL’s environment key that points
          to a capath,

        * ‘openssl_capath’ - hard coded path to a capath directory

     New in version 3.4.

 -- Function: ssl.enum_certificates (store_name)

     Retrieve certificates from Windows’ system cert store.
     `store_name' may be one of ‘CA’, ‘ROOT’ or ‘MY’.  Windows may
     provide additional cert stores, too.

     The function returns a list of (cert_bytes, encoding_type, trust)
     tuples.  The encoding_type specifies the encoding of cert_bytes.
     It is either ‘x509_asn’ for X.509 ASN.1 data or ‘pkcs_7_asn’ for
     PKCS#7 ASN.1 data.  Trust specifies the purpose of the certificate
     as a set of OIDS or exactly ‘True’ if the certificate is
     trustworthy for all purposes.

     Example:

          >>> ssl.enum_certificates("CA")
          [(b'data...', 'x509_asn', {'1.3.6.1.5.5.7.3.1', '1.3.6.1.5.5.7.3.2'}),
           (b'data...', 'x509_asn', True)]

     Availability: Windows.

     New in version 3.4.

 -- Function: ssl.enum_crls (store_name)

     Retrieve CRLs from Windows’ system cert store.  `store_name' may be
     one of ‘CA’, ‘ROOT’ or ‘MY’.  Windows may provide additional cert
     stores, too.

     The function returns a list of (cert_bytes, encoding_type, trust)
     tuples.  The encoding_type specifies the encoding of cert_bytes.
     It is either ‘x509_asn’ for X.509 ASN.1 data or ‘pkcs_7_asn’ for
     PKCS#7 ASN.1 data.

     Availability: Windows.

     New in version 3.4.

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc2818.html

   (2) https://tools.ietf.org/html/rfc6125.html

   (3) https://tools.ietf.org/html/rfc6125.html

   (4) https://tools.ietf.org/html/rfc5280.html


File: python.info,  Node: Constants<7>,  Prev: Certificate handling,  Up: Functions Constants and Exceptions

5.18.2.6 Constants
..................

 -- Data: ssl.CERT_NONE

     Possible value for *note SSLContext.verify_mode: 1e79, or the
     ‘cert_reqs’ parameter to *note wrap_socket(): 7fc.  In this mode
     (the default), no certificates will be required from the other side
     of the socket connection.  If a certificate is received from the
     other end, no attempt to validate it is made.

     See the discussion of *note Security considerations: 1e6a. below.

 -- Data: ssl.CERT_OPTIONAL

     Possible value for *note SSLContext.verify_mode: 1e79, or the
     ‘cert_reqs’ parameter to *note wrap_socket(): 7fc.  In this mode no
     certificates will be required from the other side of the socket
     connection; but if they are provided, validation will be attempted
     and an *note SSLError: 870. will be raised on failure.

     Use of this setting requires a valid set of CA certificates to be
     passed, either to *note SSLContext.load_verify_locations(): 3da. or
     as a value of the ‘ca_certs’ parameter to *note wrap_socket(): 7fc.

 -- Data: ssl.CERT_REQUIRED

     Possible value for *note SSLContext.verify_mode: 1e79, or the
     ‘cert_reqs’ parameter to *note wrap_socket(): 7fc.  In this mode,
     certificates are required from the other side of the socket
     connection; an *note SSLError: 870. will be raised if no
     certificate is provided, or if its validation fails.

     Use of this setting requires a valid set of CA certificates to be
     passed, either to *note SSLContext.load_verify_locations(): 3da. or
     as a value of the ‘ca_certs’ parameter to *note wrap_socket(): 7fc.

 -- Data: ssl.VERIFY_DEFAULT

     Possible value for *note SSLContext.verify_flags: 4c6.  In this
     mode, certificate revocation lists (CRLs) are not checked.  By
     default OpenSSL does neither require nor verify CRLs.

     New in version 3.4.

 -- Data: ssl.VERIFY_CRL_CHECK_LEAF

     Possible value for *note SSLContext.verify_flags: 4c6.  In this
     mode, only the peer cert is check but non of the intermediate CA
     certificates.  The mode requires a valid CRL that is signed by the
     peer cert’s issuer (its direct ancestor CA). If no proper has been
     loaded *note SSLContext.load_verify_locations: 3da, validation will
     fail.

     New in version 3.4.

 -- Data: ssl.VERIFY_CRL_CHECK_CHAIN

     Possible value for *note SSLContext.verify_flags: 4c6.  In this
     mode, CRLs of all certificates in the peer cert chain are checked.

     New in version 3.4.

 -- Data: ssl.VERIFY_X509_STRICT

     Possible value for *note SSLContext.verify_flags: 4c6. to disable
     workarounds for broken X.509 certificates.

     New in version 3.4.

 -- Data: ssl.VERIFY_X509_TRUSTED_FIRST

     Possible value for *note SSLContext.verify_flags: 4c6.  It
     instructs OpenSSL to prefer trusted certificates when building the
     trust chain to validate a certificate.  This flag is enabled by
     default.

     New in version 3.4.4.

 -- Data: ssl.PROTOCOL_SSLv23

     Selects the highest protocol version that both the client and
     server support.  Despite the name, this option can select "TLS"
     protocols as well as "SSL".

 -- Data: ssl.PROTOCOL_SSLv2

     Selects SSL version 2 as the channel encryption protocol.

     This protocol is not available if OpenSSL is compiled with the
     ‘OPENSSL_NO_SSL2’ flag.

          Warning: SSL version 2 is insecure.  Its use is highly
          discouraged.

 -- Data: ssl.PROTOCOL_SSLv3

     Selects SSL version 3 as the channel encryption protocol.

     This protocol is not be available if OpenSSL is compiled with the
     ‘OPENSSL_NO_SSLv3’ flag.

          Warning: SSL version 3 is insecure.  Its use is highly
          discouraged.

 -- Data: ssl.PROTOCOL_TLSv1

     Selects TLS version 1.0 as the channel encryption protocol.

 -- Data: ssl.PROTOCOL_TLSv1_1

     Selects TLS version 1.1 as the channel encryption protocol.
     Available only with openssl version 1.0.1+.

     New in version 3.4.

 -- Data: ssl.PROTOCOL_TLSv1_2

     Selects TLS version 1.2 as the channel encryption protocol.  This
     is the most modern version, and probably the best choice for
     maximum protection, if both sides can speak it.  Available only
     with openssl version 1.0.1+.

     New in version 3.4.

 -- Data: ssl.OP_ALL

     Enables workarounds for various bugs present in other SSL
     implementations.  This option is set by default.  It does not
     necessarily set the same flags as OpenSSL’s ‘SSL_OP_ALL’ constant.

     New in version 3.2.

 -- Data: ssl.OP_NO_SSLv2

     Prevents an SSLv2 connection.  This option is only applicable in
     conjunction with *note PROTOCOL_SSLv23: 1e76.  It prevents the
     peers from choosing SSLv2 as the protocol version.

     New in version 3.2.

 -- Data: ssl.OP_NO_SSLv3

     Prevents an SSLv3 connection.  This option is only applicable in
     conjunction with *note PROTOCOL_SSLv23: 1e76.  It prevents the
     peers from choosing SSLv3 as the protocol version.

     New in version 3.2.

 -- Data: ssl.OP_NO_TLSv1

     Prevents a TLSv1 connection.  This option is only applicable in
     conjunction with *note PROTOCOL_SSLv23: 1e76.  It prevents the
     peers from choosing TLSv1 as the protocol version.

     New in version 3.2.

 -- Data: ssl.OP_NO_TLSv1_1

     Prevents a TLSv1.1 connection.  This option is only applicable in
     conjunction with *note PROTOCOL_SSLv23: 1e76.  It prevents the
     peers from choosing TLSv1.1 as the protocol version.  Available
     only with openssl version 1.0.1+.

     New in version 3.4.

 -- Data: ssl.OP_NO_TLSv1_2

     Prevents a TLSv1.2 connection.  This option is only applicable in
     conjunction with *note PROTOCOL_SSLv23: 1e76.  It prevents the
     peers from choosing TLSv1.2 as the protocol version.  Available
     only with openssl version 1.0.1+.

     New in version 3.4.

 -- Data: ssl.OP_CIPHER_SERVER_PREFERENCE

     Use the server’s cipher ordering preference, rather than the
     client’s.  This option has no effect on client sockets and SSLv2
     server sockets.

     New in version 3.3.

 -- Data: ssl.OP_SINGLE_DH_USE

     Prevents re-use of the same DH key for distinct SSL sessions.  This
     improves forward secrecy but requires more computational resources.
     This option only applies to server sockets.

     New in version 3.3.

 -- Data: ssl.OP_SINGLE_ECDH_USE

     Prevents re-use of the same ECDH key for distinct SSL sessions.
     This improves forward secrecy but requires more computational
     resources.  This option only applies to server sockets.

     New in version 3.3.

 -- Data: ssl.OP_NO_COMPRESSION

     Disable compression on the SSL channel.  This is useful if the
     application protocol supports its own compression scheme.

     This option is only available with OpenSSL 1.0.0 and later.

     New in version 3.3.

 -- Data: ssl.HAS_ALPN

     Whether the OpenSSL library has built-in support for the
     `Application-Layer Protocol Negotiation' TLS extension as described
     in RFC 7301(1).

     New in version 3.5.

 -- Data: ssl.HAS_ECDH

     Whether the OpenSSL library has built-in support for Elliptic
     Curve-based Diffie-Hellman key exchange.  This should be true
     unless the feature was explicitly disabled by the distributor.

     New in version 3.3.

 -- Data: ssl.HAS_SNI

     Whether the OpenSSL library has built-in support for the `Server
     Name Indication' extension (as defined in RFC 4366(2)).

     New in version 3.2.

 -- Data: ssl.HAS_NPN

     Whether the OpenSSL library has built-in support for `Next Protocol
     Negotiation' as described in the NPN draft specification(3).  When
     true, you can use the *note SSLContext.set_npn_protocols(): 6d1.
     method to advertise which protocols you want to support.

     New in version 3.3.

 -- Data: ssl.CHANNEL_BINDING_TYPES

     List of supported TLS channel binding types.  Strings in this list
     can be used as arguments to *note SSLSocket.get_channel_binding():
     6ce.

     New in version 3.3.

 -- Data: ssl.OPENSSL_VERSION

     The version string of the OpenSSL library loaded by the
     interpreter:

          >>> ssl.OPENSSL_VERSION
          'OpenSSL 0.9.8k 25 Mar 2009'

     New in version 3.2.

 -- Data: ssl.OPENSSL_VERSION_INFO

     A tuple of five integers representing version information about the
     OpenSSL library:

          >>> ssl.OPENSSL_VERSION_INFO
          (0, 9, 8, 11, 15)

     New in version 3.2.

 -- Data: ssl.OPENSSL_VERSION_NUMBER

     The raw version number of the OpenSSL library, as a single integer:

          >>> ssl.OPENSSL_VERSION_NUMBER
          9470143
          >>> hex(ssl.OPENSSL_VERSION_NUMBER)
          '0x9080bf'

     New in version 3.2.

 -- Data: ssl.ALERT_DESCRIPTION_HANDSHAKE_FAILURE
 -- Data: ssl.ALERT_DESCRIPTION_INTERNAL_ERROR

 -- Data: ALERT_DESCRIPTION_*

     Alert Descriptions from RFC 5246(4) and others.  The IANA TLS Alert
     Registry(5) contains this list and references to the RFCs where
     their meaning is defined.

     Used as the return value of the callback function in *note
     SSLContext.set_servername_callback(): 4d0.

     New in version 3.4.

 -- Data: Purpose.SERVER_AUTH

     Option for *note create_default_context(): 4c1. and *note
     SSLContext.load_default_certs(): 4cb.  This value indicates that
     the context may be used to authenticate Web servers (therefore, it
     will be used to create client-side sockets).

     New in version 3.4.

 -- Data: Purpose.CLIENT_AUTH

     Option for *note create_default_context(): 4c1. and *note
     SSLContext.load_default_certs(): 4cb.  This value indicates that
     the context may be used to authenticate Web clients (therefore, it
     will be used to create server-side sockets).

     New in version 3.4.

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc7301.html

   (2) https://tools.ietf.org/html/rfc4366.html

   (3) https://tools.ietf.org/html/draft-agl-tls-nextprotoneg

   (4) https://tools.ietf.org/html/rfc5246.html

   (5) 
http://www.iana.org/assignments/tls-parameters/tls-parameters.xml#tls-parameters-6


File: python.info,  Node: SSL Sockets,  Next: SSL Contexts,  Prev: Functions Constants and Exceptions,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.7 SSL Sockets
....................

 -- Class: ssl.SSLSocket (socket.socket)

     SSL sockets provide the following methods of *note Socket Objects:
     1e3a.:

        - *note accept(): 20b.

        - *note bind(): 1e53.

        - *note close(): 1a8.

        - *note connect(): 20c.

        - *note detach(): 7f8.

        - *note fileno(): 1e57.

        - *note getpeername(): 1e58, *note getsockname(): 1e59.

        - *note getsockopt(): 1e5a, *note setsockopt(): 1e5f.

        - *note gettimeout(): 1e5b, *note settimeout(): 1e1d, *note
          setblocking(): 1883.

        - *note listen(): 316.

        - *note makefile(): 75b.

        - *note recv(): 20d, *note recv_into(): 926. (but passing a
          non-zero ‘flags’ argument is not allowed)

        - *note send(): 210, *note sendall(): 211. (with the same
          limitation)

        - *note sendfile(): 315. (but *note os.sendfile: 1fb. will be
          used for plain-text sockets only, else *note send(): 210. will
          be used)

        - *note shutdown(): 1e54.

     However, since the SSL (and TLS) protocol has its own framing atop
     of TCP, the SSL sockets abstraction can, in certain respects,
     diverge from the specification of normal, OS-level sockets.  See
     especially the *note notes on non-blocking sockets: 1e6d.

     Usually, *note SSLSocket: 31b. are not created directly, but using
     the *note wrap_socket(): 7fc. function or the *note
     SSLContext.wrap_socket(): 7fb. method.

     Changed in version 3.5: The ‘sendfile()’ method was added.

     Changed in version 3.5: The ‘shutdown()’ does not reset the socket
     timeout each time bytes are received or sent.  The socket timeout
     is now to maximum total duration of the shutdown.

SSL sockets also have the following additional methods and attributes:

 -- Method: SSLSocket.read (len=1024, buffer=None)

     Read up to `len' bytes of data from the SSL socket and return the
     result as a ‘bytes’ instance.  If `buffer' is specified, then read
     into the buffer instead, and return the number of bytes read.

     Raise *note SSLWantReadError: 324. or *note SSLWantWriteError: 325.
     if the socket is *note non-blocking: 1e6d. and the read would
     block.

     As at any time a re-negotiation is possible, a call to *note
     read(): 329. can also cause write operations.

     Changed in version 3.5: The socket timeout is no more reset each
     time bytes are received or sent.  The socket timeout is now to
     maximum total duration to read up to `len' bytes.

 -- Method: SSLSocket.write (buf)

     Write `buf' to the SSL socket and return the number of bytes
     written.  The `buf' argument must be an object supporting the
     buffer interface.

     Raise *note SSLWantReadError: 324. or *note SSLWantWriteError: 325.
     if the socket is *note non-blocking: 1e6d. and the write would
     block.

     As at any time a re-negotiation is possible, a call to *note
     write(): 32a. can also cause read operations.

     Changed in version 3.5: The socket timeout is no more reset each
     time bytes are received or sent.  The socket timeout is now to
     maximum total duration to write `buf'.

     Note: The *note read(): 329. and *note write(): 32a. methods are
     the low-level methods that read and write unencrypted,
     application-level data and decrypt/encrypt it to encrypted,
     wire-level data.  These methods require an active SSL connection,
     i.e.  the handshake was completed and *note SSLSocket.unwrap():
     1e93. was not called.

     Normally you should use the socket API methods like *note recv():
     20d. and *note send(): 210. instead of these methods.

 -- Method: SSLSocket.do_handshake ()

     Perform the SSL setup handshake.

     Changed in version 3.4: The handshake method also performs *note
     match_hostname(): 32b. when the *note check_hostname: 1e94.
     attribute of the socket’s *note context: 1e95. is true.

     Changed in version 3.5: The socket timeout is no more reset each
     time bytes are received or sent.  The socket timeout is now to
     maximum total duration of the handshake.

 -- Method: SSLSocket.getpeercert (binary_form=False)

     If there is no certificate for the peer on the other end of the
     connection, return ‘None’.  If the SSL handshake hasn’t been done
     yet, raise *note ValueError: 19c.

     If the ‘binary_form’ parameter is *note False: 60d, and a
     certificate was received from the peer, this method returns a *note
     dict: 3b0. instance.  If the certificate was not validated, the
     dict is empty.  If the certificate was validated, it returns a dict
     with several keys, amongst them ‘subject’ (the principal for which
     the certificate was issued) and ‘issuer’ (the principal issuing the
     certificate).  If a certificate contains an instance of the
     `Subject Alternative Name' extension (see RFC 3280(1)), there will
     also be a ‘subjectAltName’ key in the dictionary.

     The ‘subject’ and ‘issuer’ fields are tuples containing the
     sequence of relative distinguished names (RDNs) given in the
     certificate’s data structure for the respective fields, and each
     RDN is a sequence of name-value pairs.  Here is a real-world
     example:

          {'issuer': ((('countryName', 'IL'),),
                      (('organizationName', 'StartCom Ltd.'),),
                      (('organizationalUnitName',
                        'Secure Digital Certificate Signing'),),
                      (('commonName',
                        'StartCom Class 2 Primary Intermediate Server CA'),)),
           'notAfter': 'Nov 22 08:15:19 2013 GMT',
           'notBefore': 'Nov 21 03:09:52 2011 GMT',
           'serialNumber': '95F0',
           'subject': ((('description', '571208-SLe257oHY9fVQ07Z'),),
                       (('countryName', 'US'),),
                       (('stateOrProvinceName', 'California'),),
                       (('localityName', 'San Francisco'),),
                       (('organizationName', 'Electronic Frontier Foundation, Inc.'),),
                       (('commonName', '*.eff.org'),),
                       (('emailAddress', 'hostmaster@eff.org'),)),
           'subjectAltName': (('DNS', '*.eff.org'), ('DNS', 'eff.org')),
           'version': 3}

          Note: To validate a certificate for a particular service, you
          can use the *note match_hostname(): 32b. function.

     If the ‘binary_form’ parameter is *note True: 9ff, and a
     certificate was provided, this method returns the DER-encoded form
     of the entire certificate as a sequence of bytes, or *note None:
     19d. if the peer did not provide a certificate.  Whether the peer
     provides a certificate depends on the SSL socket’s role:

        * for a client SSL socket, the server will always provide a
          certificate, regardless of whether validation was required;

        * for a server SSL socket, the client will only provide a
          certificate when requested by the server; therefore *note
          getpeercert(): 4d1. will return *note None: 19d. if you used
          *note CERT_NONE: 1e73. (rather than *note CERT_OPTIONAL: 1e74.
          or *note CERT_REQUIRED: 1e75.).

     Changed in version 3.2: The returned dictionary includes additional
     items such as ‘issuer’ and ‘notBefore’.

     Changed in version 3.4: *note ValueError: 19c. is raised when the
     handshake isn’t done.  The returned dictionary includes additional
     X509v3 extension items such as ‘crlDistributionPoints’, ‘caIssuers’
     and ‘OCSP’ URIs.

 -- Method: SSLSocket.cipher ()

     Returns a three-value tuple containing the name of the cipher being
     used, the version of the SSL protocol that defines its use, and the
     number of secret bits being used.  If no connection has been
     established, returns ‘None’.

 -- Method: SSLSocket.shared_ciphers ()

     Return the list of ciphers shared by the client during the
     handshake.  Each entry of the returned list is a three-value tuple
     containing the name of the cipher, the version of the SSL protocol
     that defines its use, and the number of secret bits the cipher
     uses.  *note shared_ciphers(): 327. returns ‘None’ if no connection
     has been established or the socket is a client socket.

     New in version 3.5.

 -- Method: SSLSocket.compression ()

     Return the compression algorithm being used as a string, or ‘None’
     if the connection isn’t compressed.

     If the higher-level protocol supports its own compression
     mechanism, you can use *note OP_NO_COMPRESSION: 6d0. to disable
     SSL-level compression.

     New in version 3.3.

 -- Method: SSLSocket.get_channel_binding (cb_type="tls-unique")

     Get channel binding data for current connection, as a bytes object.
     Returns ‘None’ if not connected or the handshake has not been
     completed.

     The `cb_type' parameter allow selection of the desired channel
     binding type.  Valid channel binding types are listed in the *note
     CHANNEL_BINDING_TYPES: 1e8f. list.  Currently only the ’tls-unique’
     channel binding, defined by RFC 5929(2), is supported.  *note
     ValueError: 19c. will be raised if an unsupported channel binding
     type is requested.

     New in version 3.3.

 -- Method: SSLSocket.selected_alpn_protocol ()

     Return the protocol that was selected during the TLS handshake.  If
     *note SSLContext.set_alpn_protocols(): 31f. was not called, if the
     other party does not support ALPN, if this socket does not support
     any of the client’s proposed protocols, or if the handshake has not
     happened yet, ‘None’ is returned.

     New in version 3.5.

 -- Method: SSLSocket.selected_npn_protocol ()

     Return the higher-level protocol that was selected during the
     TLS/SSL handshake.  If *note SSLContext.set_npn_protocols(): 6d1.
     was not called, or if the other party does not support NPN, or if
     the handshake has not yet happened, this will return ‘None’.

     New in version 3.3.

 -- Method: SSLSocket.unwrap ()

     Performs the SSL shutdown handshake, which removes the TLS layer
     from the underlying socket, and returns the underlying socket
     object.  This can be used to go from encrypted operation over a
     connection to unencrypted.  The returned socket should always be
     used for further communication with the other side of the
     connection, rather than the original socket.

 -- Method: SSLSocket.version ()

     Return the actual SSL protocol version negotiated by the connection
     as a string, or ‘None’ is no secure connection is established.  As
     of this writing, possible return values include ‘"SSLv2"’,
     ‘"SSLv3"’, ‘"TLSv1"’, ‘"TLSv1.1"’ and ‘"TLSv1.2"’.  Recent OpenSSL
     versions may define more return values.

     New in version 3.5.

 -- Method: SSLSocket.pending ()

     Returns the number of already decrypted bytes available for read,
     pending on the connection.

 -- Attribute: SSLSocket.context

     The *note SSLContext: 1c6. object this SSL socket is tied to.  If
     the SSL socket was created using the top-level *note wrap_socket():
     7fc. function (rather than *note SSLContext.wrap_socket(): 7fb.),
     this is a custom context object created for this SSL socket.

     New in version 3.2.

 -- Attribute: SSLSocket.server_side

     A boolean which is ‘True’ for server-side sockets and ‘False’ for
     client-side sockets.

     New in version 3.2.

 -- Attribute: SSLSocket.server_hostname

     Hostname of the server: *note str: 25a. type, or ‘None’ for
     server-side socket or if the hostname was not specified in the
     constructor.

     New in version 3.2.

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc3280.html

   (2) https://tools.ietf.org/html/rfc5929.html

