This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: Lookahead Assertions,  Prev: Non-capturing and Named Groups,  Up: More Pattern Power

10.8.4.4 Lookahead Assertions
.............................

Another zero-width assertion is the lookahead assertion.  Lookahead
assertions are available in both positive and negative form, and look
like this:

‘(?=...)’

     Positive lookahead assertion.  This succeeds if the contained
     regular expression, represented here by ‘...’, successfully matches
     at the current location, and fails otherwise.  But, once the
     contained expression has been tried, the matching engine doesn’t
     advance at all; the rest of the pattern is tried right where the
     assertion started.

‘(?!...)’

     Negative lookahead assertion.  This is the opposite of the positive
     assertion; it succeeds if the contained expression `doesn’t' match
     at the current position in the string.

To make this concrete, let’s look at a case where a lookahead is useful.
Consider a simple pattern to match a filename and split it apart into a
base name and an extension, separated by a ‘.’.  For example, in
‘news.rc’, ‘news’ is the base name, and ‘rc’ is the filename’s
extension.

The pattern to match this is quite simple:

‘.*[.].*$’

Notice that the ‘.’ needs to be treated specially because it’s a
metacharacter, so it’s inside a character class to only match that
specific character.  Also notice the trailing ‘$’; this is added to
ensure that all the rest of the string must be included in the
extension.  This regular expression matches ‘foo.bar’ and ‘autoexec.bat’
and ‘sendmail.cf’ and ‘printers.conf’.

Now, consider complicating the problem a bit; what if you want to match
filenames where the extension is not ‘bat’?  Some incorrect attempts:

‘.*[.][^b].*$’ The first attempt above tries to exclude ‘bat’ by
requiring that the first character of the extension is not a ‘b’.  This
is wrong, because the pattern also doesn’t match ‘foo.bar’.

‘.*[.]([^b]..|.[^a].|..[^t])$’

The expression gets messier when you try to patch up the first solution
by requiring one of the following cases to match: the first character of
the extension isn’t ‘b’; the second character isn’t ‘a’; or the third
character isn’t ‘t’.  This accepts ‘foo.bar’ and rejects ‘autoexec.bat’,
but it requires a three-letter extension and won’t accept a filename
with a two-letter extension such as ‘sendmail.cf’.  We’ll complicate the
pattern again in an effort to fix it.

‘.*[.]([^b].?.?|.[^a]?.?|..?[^t]?)$’

In the third attempt, the second and third letters are all made optional
in order to allow matching extensions shorter than three characters,
such as ‘sendmail.cf’.

The pattern’s getting really complicated now, which makes it hard to
read and understand.  Worse, if the problem changes and you want to
exclude both ‘bat’ and ‘exe’ as extensions, the pattern would get even
more complicated and confusing.

A negative lookahead cuts through all this confusion:

‘.*[.](?!bat$)[^.]*$’ The negative lookahead means: if the expression
‘bat’ doesn’t match at this point, try the rest of the pattern; if
‘bat$’ does match, the whole pattern will fail.  The trailing ‘$’ is
required to ensure that something like ‘sample.batch’, where the
extension only starts with ‘bat’, will be allowed.  The ‘[^.]*’ makes
sure that the pattern works when there are multiple dots in the
filename.

Excluding another filename extension is now easy; simply add it as an
alternative inside the assertion.  The following pattern excludes
filenames that end in either ‘bat’ or ‘exe’:

‘.*[.](?!bat$|exe$)[^.]*$’


File: python.info,  Node: Modifying Strings,  Next: Common Problems,  Prev: More Pattern Power,  Up: Regular Expression HOWTO

10.8.5 Modifying Strings
------------------------

Up to this point, we’ve simply performed searches against a static
string.  Regular expressions are also commonly used to modify strings in
various ways, using the following pattern methods:

Method/Attribute       Purpose
                       
---------------------------------------------------------------------------
                       
‘split()’              Split the string into a list, splitting it
                       wherever the RE matches
                       
                       
‘sub()’                Find all substrings where the RE matches, and
                       replace them with a different string
                       
                       
‘subn()’               Does the same thing as ‘sub()’, but returns the
                       new string and the number of replacements
                       

* Menu:

* Splitting Strings:: 
* Search and Replace:: 


File: python.info,  Node: Splitting Strings,  Next: Search and Replace,  Up: Modifying Strings

10.8.5.1 Splitting Strings
..........................

The ‘split()’ method of a pattern splits a string apart wherever the RE
matches, returning a list of the pieces.  It’s similar to the ‘split()’
method of strings but provides much more generality in the delimiters
that you can split by; string ‘split()’ only supports splitting by
whitespace or by a fixed string.  As you’d expect, there’s a
module-level *note re.split(): 3ae. function, too.

 -- Method: .split (string[, maxsplit=0])

     Split `string' by the matches of the regular expression.  If
     capturing parentheses are used in the RE, then their contents will
     also be returned as part of the resulting list.  If `maxsplit' is
     nonzero, at most `maxsplit' splits are performed.

You can limit the number of splits made, by passing a value for
`maxsplit'.  When `maxsplit' is nonzero, at most `maxsplit' splits will
be made, and the remainder of the string is returned as the final
element of the list.  In the following example, the delimiter is any
sequence of non-alphanumeric characters.

     >>> p = re.compile(r'\W+')
     >>> p.split('This is a test, short and sweet, of split().')
     ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']
     >>> p.split('This is a test, short and sweet, of split().', 3)
     ['This', 'is', 'a', 'test, short and sweet, of split().']

Sometimes you’re not only interested in what the text between delimiters
is, but also need to know what the delimiter was.  If capturing
parentheses are used in the RE, then their values are also returned as
part of the list.  Compare the following calls:

     >>> p = re.compile(r'\W+')
     >>> p2 = re.compile(r'(\W+)')
     >>> p.split('This... is a test.')
     ['This', 'is', 'a', 'test', '']
     >>> p2.split('This... is a test.')
     ['This', '... ', 'is', ' ', 'a', ' ', 'test', '.', '']

The module-level function *note re.split(): 3ae. adds the RE to be used
as the first argument, but is otherwise the same.

     >>> re.split('[\W]+', 'Words, words, words.')
     ['Words', 'words', 'words', '']
     >>> re.split('([\W]+)', 'Words, words, words.')
     ['Words', ', ', 'words', ', ', 'words', '.', '']
     >>> re.split('[\W]+', 'Words, words, words.', 1)
     ['Words', 'words, words.']


File: python.info,  Node: Search and Replace,  Prev: Splitting Strings,  Up: Modifying Strings

10.8.5.2 Search and Replace
...........................

Another common task is to find all the matches for a pattern, and
replace them with a different string.  The ‘sub()’ method takes a
replacement value, which can be either a string or a function, and the
string to be processed.

 -- Method: .sub (replacement, string[, count=0])

     Returns the string obtained by replacing the leftmost
     non-overlapping occurrences of the RE in `string' by the
     replacement `replacement'.  If the pattern isn’t found, `string' is
     returned unchanged.

     The optional argument `count' is the maximum number of pattern
     occurrences to be replaced; `count' must be a non-negative integer.
     The default value of 0 means to replace all occurrences.

Here’s a simple example of using the ‘sub()’ method.  It replaces colour
names with the word ‘colour’:

     >>> p = re.compile( '(blue|white|red)')
     >>> p.sub( 'colour', 'blue socks and red shoes')
     'colour socks and colour shoes'
     >>> p.sub( 'colour', 'blue socks and red shoes', count=1)
     'colour socks and red shoes'

The ‘subn()’ method does the same work, but returns a 2-tuple containing
the new string value and the number of replacements that were performed:

     >>> p = re.compile( '(blue|white|red)')
     >>> p.subn( 'colour', 'blue socks and red shoes')
     ('colour socks and colour shoes', 2)
     >>> p.subn( 'colour', 'no colours at all')
     ('no colours at all', 0)

Empty matches are replaced only when they’re not adjacent to a previous
match.

     >>> p = re.compile('x*')
     >>> p.sub('-', 'abxd')
     '-a-b-d-'

If `replacement' is a string, any backslash escapes in it are processed.
That is, ‘\n’ is converted to a single newline character, ‘\r’ is
converted to a carriage return, and so forth.  Unknown escapes such as
‘\&’ are left alone.  Backreferences, such as ‘\6’, are replaced with
the substring matched by the corresponding group in the RE. This lets
you incorporate portions of the original text in the resulting
replacement string.

This example matches the word ‘section’ followed by a string enclosed in
‘{’, ‘}’, and changes ‘section’ to ‘subsection’:

     >>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)
     >>> p.sub(r'subsection{\1}','section{First} section{second}')
     'subsection{First} subsection{second}'

There’s also a syntax for referring to named groups as defined by the
‘(?P<name>...)’ syntax.  ‘\g<name>’ will use the substring matched by
the group named ‘name’, and ‘\g<number>’ uses the corresponding group
number.  ‘\g<2>’ is therefore equivalent to ‘\2’, but isn’t ambiguous in
a replacement string such as ‘\g<2>0’.  (‘\20’ would be interpreted as a
reference to group 20, not a reference to group 2 followed by the
literal character ‘'0'’.)  The following substitutions are all
equivalent, but use all three variations of the replacement string.

     >>> p = re.compile('section{ (?P<name> [^}]* ) }', re.VERBOSE)
     >>> p.sub(r'subsection{\1}','section{First}')
     'subsection{First}'
     >>> p.sub(r'subsection{\g<1>}','section{First}')
     'subsection{First}'
     >>> p.sub(r'subsection{\g<name>}','section{First}')
     'subsection{First}'

`replacement' can also be a function, which gives you even more control.
If `replacement' is a function, the function is called for every
non-overlapping occurrence of `pattern'.  On each call, the function is
passed a *note match object: 49a. argument for the match and can use
this information to compute the desired replacement string and return
it.

In the following example, the replacement function translates decimals
into hexadecimal:

     >>> def hexrepl(match):
     ...     "Return the hex string for a decimal number"
     ...     value = int(match.group())
     ...     return hex(value)
     ...
     >>> p = re.compile(r'\d+')
     >>> p.sub(hexrepl, 'Call 65490 for printing, 49152 for user code.')
     'Call 0xffd2 for printing, 0xc000 for user code.'

When using the module-level *note re.sub(): 2f5. function, the pattern
is passed as the first argument.  The pattern may be provided as an
object or as a string; if you need to specify regular expression flags,
you must either use a pattern object as the first parameter, or use
embedded modifiers in the pattern string, e.g.  ‘sub("(?i)b+", "x",
"bbbb BBBB")’ returns ‘'x x'’.


File: python.info,  Node: Common Problems,  Next: Feedback,  Prev: Modifying Strings,  Up: Regular Expression HOWTO

10.8.6 Common Problems
----------------------

Regular expressions are a powerful tool for some applications, but in
some ways their behaviour isn’t intuitive and at times they don’t behave
the way you may expect them to.  This section will point out some of the
most common pitfalls.

* Menu:

* Use String Methods:: 
* match() versus search(): match versus search. 
* Greedy versus Non-Greedy:: 
* Using re.VERBOSE: Using re VERBOSE. 


File: python.info,  Node: Use String Methods,  Next: match versus search,  Up: Common Problems

10.8.6.1 Use String Methods
...........................

Sometimes using the *note re: db. module is a mistake.  If you’re
matching a fixed string, or a single character class, and you’re not
using any *note re: db. features such as the ‘IGNORECASE’ flag, then the
full power of regular expressions may not be required.  Strings have
several methods for performing operations with fixed strings and they’re
usually much faster, because the implementation is a single small C loop
that’s been optimized for the purpose, instead of the large, more
generalized regular expression engine.

One example might be replacing a single fixed string with another one;
for example, you might replace ‘word’ with ‘deed’.  ‘re.sub()’ seems
like the function to use for this, but consider the ‘replace()’ method.
Note that ‘replace()’ will also replace ‘word’ inside words, turning
‘swordfish’ into ‘sdeedfish’, but the naive RE ‘word’ would have done
that, too.  (To avoid performing the substitution on parts of words, the
pattern would have to be ‘\bword\b’, in order to require that ‘word’
have a word boundary on either side.  This takes the job beyond
‘replace()’’s abilities.)

Another common task is deleting every occurrence of a single character
from a string or replacing it with another single character.  You might
do this with something like ‘re.sub('\n', ' ', S)’, but ‘translate()’ is
capable of doing both tasks and will be faster than any regular
expression operation can be.

In short, before turning to the *note re: db. module, consider whether
your problem can be solved with a faster and simpler string method.


File: python.info,  Node: match versus search,  Next: Greedy versus Non-Greedy,  Prev: Use String Methods,  Up: Common Problems

10.8.6.2 match() versus search()
................................

The ‘match()’ function only checks if the RE matches at the beginning of
the string while ‘search()’ will scan forward through the string for a
match.  It’s important to keep this distinction in mind.  Remember,
‘match()’ will only report a successful match which will start at 0; if
the match wouldn’t start at zero, ‘match()’ will `not' report it.

     >>> print(re.match('super', 'superstition').span())
     (0, 5)
     >>> print(re.match('super', 'insuperable'))
     None

On the other hand, ‘search()’ will scan forward through the string,
reporting the first match it finds.

     >>> print(re.search('super', 'superstition').span())
     (0, 5)
     >>> print(re.search('super', 'insuperable').span())
     (2, 7)

Sometimes you’ll be tempted to keep using *note re.match(): 811, and
just add ‘.*’ to the front of your RE. Resist this temptation and use
*note re.search(): 810. instead.  The regular expression compiler does
some analysis of REs in order to speed up the process of looking for a
match.  One such analysis figures out what the first character of a
match must be; for example, a pattern starting with ‘Crow’ must match
starting with a ‘'C'’.  The analysis lets the engine quickly scan
through the string looking for the starting character, only trying the
full match if a ‘'C'’ is found.

Adding ‘.*’ defeats this optimization, requiring scanning to the end of
the string and then backtracking to find a match for the rest of the RE.
Use *note re.search(): 810. instead.


File: python.info,  Node: Greedy versus Non-Greedy,  Next: Using re VERBOSE,  Prev: match versus search,  Up: Common Problems

10.8.6.3 Greedy versus Non-Greedy
.................................

When repeating a regular expression, as in ‘a*’, the resulting action is
to consume as much of the pattern as possible.  This fact often bites
you when you’re trying to match a pair of balanced delimiters, such as
the angle brackets surrounding an HTML tag.  The naive pattern for
matching a single HTML tag doesn’t work because of the greedy nature of
‘.*’.

     >>> s = '<html><head><title>Title</title>'
     >>> len(s)
     32
     >>> print(re.match('<.*>', s).span())
     (0, 32)
     >>> print(re.match('<.*>', s).group())
     <html><head><title>Title</title>

The RE matches the ‘'<'’ in ‘<html>’, and the ‘.*’ consumes the rest of
the string.  There’s still more left in the RE, though, and the ‘>’
can’t match at the end of the string, so the regular expression engine
has to backtrack character by character until it finds a match for the
‘>’.  The final match extends from the ‘'<'’ in ‘<html>’ to the ‘'>'’ in
‘</title>’, which isn’t what you want.

In this case, the solution is to use the non-greedy qualifiers ‘*?’,
‘+?’, ‘??’, or ‘{m,n}?’, which match as `little' text as possible.  In
the above example, the ‘'>'’ is tried immediately after the first ‘'<'’
matches, and when it fails, the engine advances a character at a time,
retrying the ‘'>'’ at every step.  This produces just the right result:

     >>> print(re.match('<.*?>', s).group())
     <html>

(Note that parsing HTML or XML with regular expressions is painful.
Quick-and-dirty patterns will handle common cases, but HTML and XML have
special cases that will break the obvious regular expression; by the
time you’ve written a regular expression that handles all of the
possible cases, the patterns will be `very' complicated.  Use an HTML or
XML parser module for such tasks.)


File: python.info,  Node: Using re VERBOSE,  Prev: Greedy versus Non-Greedy,  Up: Common Problems

10.8.6.4 Using re.VERBOSE
.........................

By now you’ve probably noticed that regular expressions are a very
compact notation, but they’re not terribly readable.  REs of moderate
complexity can become lengthy collections of backslashes, parentheses,
and metacharacters, making them difficult to read and understand.

For such REs, specifying the ‘re.VERBOSE’ flag when compiling the
regular expression can be helpful, because it allows you to format the
regular expression more clearly.

The ‘re.VERBOSE’ flag has several effects.  Whitespace in the regular
expression that `isn’t' inside a character class is ignored.  This means
that an expression such as ‘dog | cat’ is equivalent to the less
readable ‘dog|cat’, but ‘[a b]’ will still match the characters ‘'a'’,
‘'b'’, or a space.  In addition, you can also put comments inside a RE;
comments extend from a ‘#’ character to the next newline.  When used
with triple-quoted strings, this enables REs to be formatted more
neatly:

     pat = re.compile(r"""
      \s*                 # Skip leading whitespace
      (?P<header>[^:]+)   # Header name
      \s* :               # Whitespace, and a colon
      (?P<value>.*?)      # The header's value -- *? used to
                          # lose the following trailing whitespace
      \s*$                # Trailing whitespace to end-of-line
     """, re.VERBOSE)

This is far more readable than:

     pat = re.compile(r"\s*(?P<header>[^:]+)\s*:(?P<value>.*?)\s*$")


File: python.info,  Node: Feedback,  Prev: Common Problems,  Up: Regular Expression HOWTO

10.8.7 Feedback
---------------

Regular expressions are a complicated topic.  Did this document help you
understand them?  Were there parts that were unclear, or Problems you
encountered that weren’t covered here?  If so, please send suggestions
for improvements to the author.

The most complete book on regular expressions is almost certainly
Jeffrey Friedl’s Mastering Regular Expressions, published by O’Reilly.
Unfortunately, it exclusively concentrates on Perl and Java’s flavours
of regular expressions, and doesn’t contain any Python material at all,
so it won’t be useful as a reference for programming in Python.  (The
first edition covered Python’s now-removed ‘regex’ module, which won’t
help you much.)  Consider checking it out from your library.


File: python.info,  Node: Socket Programming HOWTO,  Next: Sorting HOW TO,  Prev: Regular Expression HOWTO,  Up: Python HOWTOs

10.9 Socket Programming HOWTO
=============================


Author: Gordon McMillan

Abstract
........

Sockets are used nearly everywhere, but are one of the most severely
misunderstood technologies around.  This is a 10,000 foot overview of
sockets.  It’s not really a tutorial - you’ll still have work to do in
getting things operational.  It doesn’t cover the fine points (and there
are a lot of them), but I hope it will give you enough background to
begin using them decently.

* Menu:

* Sockets:: 
* Creating a Socket:: 
* Using a Socket:: 
* Disconnecting:: 
* Non-blocking Sockets:: 


File: python.info,  Node: Sockets,  Next: Creating a Socket,  Up: Socket Programming HOWTO

10.9.1 Sockets
--------------

I’m only going to talk about INET (i.e.  IPv4) sockets, but they account
for at least 99% of the sockets in use.  And I’ll only talk about STREAM
(i.e.  TCP) sockets - unless you really know what you’re doing (in which
case this HOWTO isn’t for you!), you’ll get better behavior and
performance from a STREAM socket than anything else.  I will try to
clear up the mystery of what a socket is, as well as some hints on how
to work with blocking and non-blocking sockets.  But I’ll start by
talking about blocking sockets.  You’ll need to know how they work
before dealing with non-blocking sockets.

Part of the trouble with understanding these things is that "socket" can
mean a number of subtly different things, depending on context.  So
first, let’s make a distinction between a "client" socket - an endpoint
of a conversation, and a "server" socket, which is more like a
switchboard operator.  The client application (your browser, for
example) uses "client" sockets exclusively; the web server it’s talking
to uses both "server" sockets and "client" sockets.

* Menu:

* History:: 


File: python.info,  Node: History,  Up: Sockets

10.9.1.1 History
................

Of the various forms of IPC (Inter Process Communication), sockets are
by far the most popular.  On any given platform, there are likely to be
other forms of IPC that are faster, but for cross-platform
communication, sockets are about the only game in town.

They were invented in Berkeley as part of the BSD flavor of Unix.  They
spread like wildfire with the Internet.  With good reason — the
combination of sockets with INET makes talking to arbitrary machines
around the world unbelievably easy (at least compared to other schemes).


File: python.info,  Node: Creating a Socket,  Next: Using a Socket,  Prev: Sockets,  Up: Socket Programming HOWTO

10.9.2 Creating a Socket
------------------------

Roughly speaking, when you clicked on the link that brought you to this
page, your browser did something like the following:

     # create an INET, STREAMing socket
     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     # now connect to the web server on port 80 - the normal http port
     s.connect(("www.python.org", 80))

When the ‘connect’ completes, the socket ‘s’ can be used to send in a
request for the text of the page.  The same socket will read the reply,
and then be destroyed.  That’s right, destroyed.  Client sockets are
normally only used for one exchange (or a small set of sequential
exchanges).

What happens in the web server is a bit more complex.  First, the web
server creates a "server socket":

     # create an INET, STREAMing socket
     serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     # bind the socket to a public host, and a well-known port
     serversocket.bind((socket.gethostname(), 80))
     # become a server socket
     serversocket.listen(5)

A couple things to notice: we used ‘socket.gethostname()’ so that the
socket would be visible to the outside world.  If we had used
‘s.bind(('localhost', 80))’ or ‘s.bind(('127.0.0.1', 80))’ we would
still have a "server" socket, but one that was only visible within the
same machine.  ‘s.bind(('', 80))’ specifies that the socket is reachable
by any address the machine happens to have.

A second thing to note: low number ports are usually reserved for "well
known" services (HTTP, SNMP etc).  If you’re playing around, use a nice
high number (4 digits).

Finally, the argument to ‘listen’ tells the socket library that we want
it to queue up as many as 5 connect requests (the normal max) before
refusing outside connections.  If the rest of the code is written
properly, that should be plenty.

Now that we have a "server" socket, listening on port 80, we can enter
the mainloop of the web server:

     while True:
         # accept connections from outside
         (clientsocket, address) = serversocket.accept()
         # now do something with the clientsocket
         # in this case, we'll pretend this is a threaded server
         ct = client_thread(clientsocket)
         ct.run()

There’s actually 3 general ways in which this loop could work -
dispatching a thread to handle ‘clientsocket’, create a new process to
handle ‘clientsocket’, or restructure this app to use non-blocking
sockets, and mulitplex between our "server" socket and any active
‘clientsocket’s using ‘select’.  More about that later.  The important
thing to understand now is this: this is `all' a "server" socket does.
It doesn’t send any data.  It doesn’t receive any data.  It just
produces "client" sockets.  Each ‘clientsocket’ is created in response
to some `other' "client" socket doing a ‘connect()’ to the host and port
we’re bound to.  As soon as we’ve created that ‘clientsocket’, we go
back to listening for more connections.  The two "clients" are free to
chat it up - they are using some dynamically allocated port which will
be recycled when the conversation ends.

* Menu:

* IPC:: 


File: python.info,  Node: IPC,  Up: Creating a Socket

10.9.2.1 IPC
............

If you need fast IPC between two processes on one machine, you should
look into pipes or shared memory.  If you do decide to use AF_INET
sockets, bind the "server" socket to ‘'localhost'’.  On most platforms,
this will take a shortcut around a couple of layers of network code and
be quite a bit faster.

See also
........

The *note multiprocessing: b6. integrates cross-platform IPC into a
higher-level API.


File: python.info,  Node: Using a Socket,  Next: Disconnecting,  Prev: Creating a Socket,  Up: Socket Programming HOWTO

10.9.3 Using a Socket
---------------------

The first thing to note, is that the web browser’s "client" socket and
the web server’s "client" socket are identical beasts.  That is, this is
a "peer to peer" conversation.  Or to put it another way, `as the
designer, you will have to decide what the rules of etiquette are for a
conversation'.  Normally, the ‘connect’ing socket starts the
conversation, by sending in a request, or perhaps a signon.  But that’s
a design decision - it’s not a rule of sockets.

Now there are two sets of verbs to use for communication.  You can use
‘send’ and ‘recv’, or you can transform your client socket into a
file-like beast and use ‘read’ and ‘write’.  The latter is the way Java
presents its sockets.  I’m not going to talk about it here, except to
warn you that you need to use ‘flush’ on sockets.  These are buffered
"files", and a common mistake is to ‘write’ something, and then ‘read’
for a reply.  Without a ‘flush’ in there, you may wait forever for the
reply, because the request may still be in your output buffer.

Now we come to the major stumbling block of sockets - ‘send’ and ‘recv’
operate on the network buffers.  They do not necessarily handle all the
bytes you hand them (or expect from them), because their major focus is
handling the network buffers.  In general, they return when the
associated network buffers have been filled (‘send’) or emptied
(‘recv’).  They then tell you how many bytes they handled.  It is `your'
responsibility to call them again until your message has been completely
dealt with.

When a ‘recv’ returns 0 bytes, it means the other side has closed (or is
in the process of closing) the connection.  You will not receive any
more data on this connection.  Ever.  You may be able to send data
successfully; I’ll talk more about this later.

A protocol like HTTP uses a socket for only one transfer.  The client
sends a request, then reads a reply.  That’s it.  The socket is
discarded.  This means that a client can detect the end of the reply by
receiving 0 bytes.

But if you plan to reuse your socket for further transfers, you need to
realize that `there is no' EOT (End of Transfer) `on a socket.'  I
repeat: if a socket ‘send’ or ‘recv’ returns after handling 0 bytes, the
connection has been broken.  If the connection has `not' been broken,
you may wait on a ‘recv’ forever, because the socket will `not' tell you
that there’s nothing more to read (for now).  Now if you think about
that a bit, you’ll come to realize a fundamental truth of sockets:
`messages must either be fixed length' (yuck), `or be delimited'
(shrug), `or indicate how long they are' (much better), `or end by
shutting down the connection'.  The choice is entirely yours, (but some
ways are righter than others).

Assuming you don’t want to end the connection, the simplest solution is
a fixed length message:

     class MySocket:
         """demonstration class only
           - coded for clarity, not efficiency
         """

         def __init__(self, sock=None):
             if sock is None:
                 self.sock = socket.socket(
                                 socket.AF_INET, socket.SOCK_STREAM)
             else:
                 self.sock = sock

         def connect(self, host, port):
             self.sock.connect((host, port))

         def mysend(self, msg):
             totalsent = 0
             while totalsent < MSGLEN:
                 sent = self.sock.send(msg[totalsent:])
                 if sent == 0:
                     raise RuntimeError("socket connection broken")
                 totalsent = totalsent + sent

         def myreceive(self):
             chunks = []
             bytes_recd = 0
             while bytes_recd < MSGLEN:
                 chunk = self.sock.recv(min(MSGLEN - bytes_recd, 2048))
                 if chunk == b'':
                     raise RuntimeError("socket connection broken")
                 chunks.append(chunk)
                 bytes_recd = bytes_recd + len(chunk)
             return b''.join(chunks)

The sending code here is usable for almost any messaging scheme - in
Python you send strings, and you can use ‘len()’ to determine its length
(even if it has embedded ‘\0’ characters).  It’s mostly the receiving
code that gets more complex.  (And in C, it’s not much worse, except you
can’t use ‘strlen’ if the message has embedded ‘\0’s.)

The easiest enhancement is to make the first character of the message an
indicator of message type, and have the type determine the length.  Now
you have two ‘recv’s - the first to get (at least) that first character
so you can look up the length, and the second in a loop to get the rest.
If you decide to go the delimited route, you’ll be receiving in some
arbitrary chunk size, (4096 or 8192 is frequently a good match for
network buffer sizes), and scanning what you’ve received for a
delimiter.

One complication to be aware of: if your conversational protocol allows
multiple messages to be sent back to back (without some kind of reply),
and you pass ‘recv’ an arbitrary chunk size, you may end up reading the
start of a following message.  You’ll need to put that aside and hold
onto it, until it’s needed.

Prefixing the message with its length (say, as 5 numeric characters)
gets more complex, because (believe it or not), you may not get all 5
characters in one ‘recv’.  In playing around, you’ll get away with it;
but in high network loads, your code will very quickly break unless you
use two ‘recv’ loops - the first to determine the length, the second to
get the data part of the message.  Nasty.  This is also when you’ll
discover that ‘send’ does not always manage to get rid of everything in
one pass.  And despite having read this, you will eventually get bit by
it!

In the interests of space, building your character, (and preserving my
competitive position), these enhancements are left as an exercise for
the reader.  Lets move on to cleaning up.

* Menu:

* Binary Data:: 


File: python.info,  Node: Binary Data,  Up: Using a Socket

10.9.3.1 Binary Data
....................

It is perfectly possible to send binary data over a socket.  The major
problem is that not all machines use the same formats for binary data.
For example, a Motorola chip will represent a 16 bit integer with the
value 1 as the two hex bytes 00 01.  Intel and DEC, however, are
byte-reversed - that same 1 is 01 00.  Socket libraries have calls for
converting 16 and 32 bit integers - ‘ntohl, htonl, ntohs, htons’ where
"n" means `network' and "h" means `host', "s" means `short' and "l"
means `long'.  Where network order is host order, these do nothing, but
where the machine is byte-reversed, these swap the bytes around
appropriately.

In these days of 32 bit machines, the ascii representation of binary
data is frequently smaller than the binary representation.  That’s
because a surprising amount of the time, all those longs have the value
0, or maybe 1.  The string "0" would be two bytes, while binary is four.
Of course, this doesn’t fit well with fixed-length messages.  Decisions,
decisions.


File: python.info,  Node: Disconnecting,  Next: Non-blocking Sockets,  Prev: Using a Socket,  Up: Socket Programming HOWTO

10.9.4 Disconnecting
--------------------

Strictly speaking, you’re supposed to use ‘shutdown’ on a socket before
you ‘close’ it.  The ‘shutdown’ is an advisory to the socket at the
other end.  Depending on the argument you pass it, it can mean "I’m not
going to send anymore, but I’ll still listen", or "I’m not listening,
good riddance!".  Most socket libraries, however, are so used to
programmers neglecting to use this piece of etiquette that normally a
‘close’ is the same as ‘shutdown(); close()’.  So in most situations, an
explicit ‘shutdown’ is not needed.

One way to use ‘shutdown’ effectively is in an HTTP-like exchange.  The
client sends a request and then does a ‘shutdown(1)’.  This tells the
server "This client is done sending, but can still receive."  The server
can detect "EOF" by a receive of 0 bytes.  It can assume it has the
complete request.  The server sends a reply.  If the ‘send’ completes
successfully then, indeed, the client was still receiving.

Python takes the automatic shutdown a step further, and says that when a
socket is garbage collected, it will automatically do a ‘close’ if it’s
needed.  But relying on this is a very bad habit.  If your socket just
disappears without doing a ‘close’, the socket at the other end may hang
indefinitely, thinking you’re just being slow.  `Please' ‘close’ your
sockets when you’re done.

* Menu:

* When Sockets Die:: 


File: python.info,  Node: When Sockets Die,  Up: Disconnecting

10.9.4.1 When Sockets Die
.........................

Probably the worst thing about using blocking sockets is what happens
when the other side comes down hard (without doing a ‘close’).  Your
socket is likely to hang.  TCP is a reliable protocol, and it will wait
a long, long time before giving up on a connection.  If you’re using
threads, the entire thread is essentially dead.  There’s not much you
can do about it.  As long as you aren’t doing something dumb, like
holding a lock while doing a blocking read, the thread isn’t really
consuming much in the way of resources.  Do `not' try to kill the thread
- part of the reason that threads are more efficient than processes is
that they avoid the overhead associated with the automatic recycling of
resources.  In other words, if you do manage to kill the thread, your
whole process is likely to be screwed up.


File: python.info,  Node: Non-blocking Sockets,  Prev: Disconnecting,  Up: Socket Programming HOWTO

10.9.5 Non-blocking Sockets
---------------------------

If you’ve understood the preceding, you already know most of what you
need to know about the mechanics of using sockets.  You’ll still use the
same calls, in much the same ways.  It’s just that, if you do it right,
your app will be almost inside-out.

In Python, you use ‘socket.setblocking(0)’ to make it non-blocking.  In
C, it’s more complex, (for one thing, you’ll need to choose between the
BSD flavor ‘O_NONBLOCK’ and the almost indistinguishable Posix flavor
‘O_NDELAY’, which is completely different from ‘TCP_NODELAY’), but it’s
the exact same idea.  You do this after creating the socket, but before
using it.  (Actually, if you’re nuts, you can switch back and forth.)

The major mechanical difference is that ‘send’, ‘recv’, ‘connect’ and
‘accept’ can return without having done anything.  You have (of course)
a number of choices.  You can check return code and error codes and
generally drive yourself crazy.  If you don’t believe me, try it
sometime.  Your app will grow large, buggy and suck CPU. So let’s skip
the brain-dead solutions and do it right.

Use ‘select’.

In C, coding ‘select’ is fairly complex.  In Python, it’s a piece of
cake, but it’s close enough to the C version that if you understand
‘select’ in Python, you’ll have little trouble with it in C:

     ready_to_read, ready_to_write, in_error = \
                    select.select(
                       potential_readers,
                       potential_writers,
                       potential_errs,
                       timeout)

You pass ‘select’ three lists: the first contains all sockets that you
might want to try reading; the second all the sockets you might want to
try writing to, and the last (normally left empty) those that you want
to check for errors.  You should note that a socket can go into more
than one list.  The ‘select’ call is blocking, but you can give it a
timeout.  This is generally a sensible thing to do - give it a nice long
timeout (say a minute) unless you have good reason to do otherwise.

In return, you will get three lists.  They contain the sockets that are
actually readable, writable and in error.  Each of these lists is a
subset (possibly empty) of the corresponding list you passed in.

If a socket is in the output readable list, you can be
as-close-to-certain-as-we-ever-get-in-this-business that a ‘recv’ on
that socket will return `something'.  Same idea for the writable list.
You’ll be able to send `something'.  Maybe not all you want to, but
`something' is better than nothing.  (Actually, any reasonably healthy
socket will return as writable - it just means outbound network buffer
space is available.)

If you have a "server" socket, put it in the potential_readers list.  If
it comes out in the readable list, your ‘accept’ will (almost certainly)
work.  If you have created a new socket to ‘connect’ to someone else,
put it in the potential_writers list.  If it shows up in the writable
list, you have a decent chance that it has connected.

Actually, ‘select’ can be handy even with blocking sockets.  It’s one
way of determining whether you will block - the socket returns as
readable when there’s something in the buffers.  However, this still
doesn’t help with the problem of determining whether the other end is
done, or just busy with something else.

`Portability alert': On Unix, ‘select’ works both with the sockets and
files.  Don’t try this on Windows.  On Windows, ‘select’ works with
sockets only.  Also note that in C, many of the more advanced socket
options are done differently on Windows.  In fact, on Windows I usually
use threads (which work very, very well) with my sockets.


File: python.info,  Node: Sorting HOW TO,  Next: Unicode HOWTO,  Prev: Socket Programming HOWTO,  Up: Python HOWTOs

10.10 Sorting HOW TO
====================


Author: Andrew Dalke and Raymond Hettinger


Release: 0.1

Python lists have a built-in *note list.sort(): 84d. method that
modifies the list in-place.  There is also a *note sorted(): 84e.
built-in function that builds a new sorted list from an iterable.

In this document, we explore the various techniques for sorting data
using Python.

* Menu:

* Sorting Basics:: 
* Key Functions:: 
* Operator Module Functions:: 
* Ascending and Descending:: 
* Sort Stability and Complex Sorts:: 
* The Old Way Using Decorate-Sort-Undecorate:: 
* The Old Way Using the cmp Parameter:: 
* Odd and Ends:: 


File: python.info,  Node: Sorting Basics,  Next: Key Functions,  Up: Sorting HOW TO

10.10.1 Sorting Basics
----------------------

A simple ascending sort is very easy: just call the *note sorted(): 84e.
function.  It returns a new sorted list:

     >>> sorted([5, 2, 3, 1, 4])
     [1, 2, 3, 4, 5]

You can also use the *note list.sort(): 84d. method.  It modifies the
list in-place (and returns `None' to avoid confusion).  Usually it’s
less convenient than *note sorted(): 84e. - but if you don’t need the
original list, it’s slightly more efficient.

     >>> a = [5, 2, 3, 1, 4]
     >>> a.sort()
     >>> a
     [1, 2, 3, 4, 5]

Another difference is that the *note list.sort(): 84d. method is only
defined for lists.  In contrast, the *note sorted(): 84e. function
accepts any iterable.

     >>> sorted({1: 'D', 2: 'B', 3: 'B', 4: 'E', 5: 'A'})
     [1, 2, 3, 4, 5]


File: python.info,  Node: Key Functions,  Next: Operator Module Functions,  Prev: Sorting Basics,  Up: Sorting HOW TO

10.10.2 Key Functions
---------------------

Both *note list.sort(): 84d. and *note sorted(): 84e. have a `key'
parameter to specify a function to be called on each list element prior
to making comparisons.

For example, here’s a case-insensitive string comparison:

     >>> sorted("This is a test string from Andrew".split(), key=str.lower)
     ['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']

The value of the `key' parameter should be a function that takes a
single argument and returns a key to use for sorting purposes.  This
technique is fast because the key function is called exactly once for
each input record.

A common pattern is to sort complex objects using some of the object’s
indices as keys.  For example:

     >>> student_tuples = [
         ('john', 'A', 15),
         ('jane', 'B', 12),
         ('dave', 'B', 10),
     ]
     >>> sorted(student_tuples, key=lambda student: student[2])   # sort by age
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The same technique works for objects with named attributes.  For
example:

     >>> class Student:
             def __init__(self, name, grade, age):
                 self.name = name
                 self.grade = grade
                 self.age = age
             def __repr__(self):
                 return repr((self.name, self.grade, self.age))

     >>> student_objects = [
         Student('john', 'A', 15),
         Student('jane', 'B', 12),
         Student('dave', 'B', 10),
     ]
     >>> sorted(student_objects, key=lambda student: student.age)   # sort by age
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]


File: python.info,  Node: Operator Module Functions,  Next: Ascending and Descending,  Prev: Key Functions,  Up: Sorting HOW TO

10.10.3 Operator Module Functions
---------------------------------

The key-function patterns shown above are very common, so Python
provides convenience functions to make accessor functions easier and
faster.  The *note operator: c0. module has *note itemgetter(): 2d8,
*note attrgetter(): 2d7, and a *note methodcaller(): 2d9. function.

Using those functions, the above examples become simpler and faster:

     >>> from operator import itemgetter, attrgetter

     >>> sorted(student_tuples, key=itemgetter(2))
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

     >>> sorted(student_objects, key=attrgetter('age'))
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The operator module functions allow multiple levels of sorting.  For
example, to sort by `grade' then by `age':

     >>> sorted(student_tuples, key=itemgetter(1,2))
     [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]

     >>> sorted(student_objects, key=attrgetter('grade', 'age'))
     [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]


File: python.info,  Node: Ascending and Descending,  Next: Sort Stability and Complex Sorts,  Prev: Operator Module Functions,  Up: Sorting HOW TO

10.10.4 Ascending and Descending
--------------------------------

Both *note list.sort(): 84d. and *note sorted(): 84e. accept a `reverse'
parameter with a boolean value.  This is used to flag descending sorts.
For example, to get the student data in reverse `age' order:

     >>> sorted(student_tuples, key=itemgetter(2), reverse=True)
     [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]

     >>> sorted(student_objects, key=attrgetter('age'), reverse=True)
     [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]


File: python.info,  Node: Sort Stability and Complex Sorts,  Next: The Old Way Using Decorate-Sort-Undecorate,  Prev: Ascending and Descending,  Up: Sorting HOW TO

10.10.5 Sort Stability and Complex Sorts
----------------------------------------

Sorts are guaranteed to be stable(1).  That means that when multiple
records have the same key, their original order is preserved.

     >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]
     >>> sorted(data, key=itemgetter(0))
     [('blue', 1), ('blue', 2), ('red', 1), ('red', 2)]

Notice how the two records for `blue' retain their original order so
that ‘('blue', 1)’ is guaranteed to precede ‘('blue', 2)’.

This wonderful property lets you build complex sorts in a series of
sorting steps.  For example, to sort the student data by descending
`grade' and then ascending `age', do the `age' sort first and then sort
again using `grade':

     >>> s = sorted(student_objects, key=attrgetter('age'))     # sort on secondary key
     >>> sorted(s, key=attrgetter('grade'), reverse=True)       # now sort on primary key, descending
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The Timsort(2) algorithm used in Python does multiple sorts efficiently
because it can take advantage of any ordering already present in a
dataset.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Sorting_algorithm#Stability

   (2) https://en.wikipedia.org/wiki/Timsort


File: python.info,  Node: The Old Way Using Decorate-Sort-Undecorate,  Next: The Old Way Using the cmp Parameter,  Prev: Sort Stability and Complex Sorts,  Up: Sorting HOW TO

10.10.6 The Old Way Using Decorate-Sort-Undecorate
--------------------------------------------------

This idiom is called Decorate-Sort-Undecorate after its three steps:

   * First, the initial list is decorated with new values that control
     the sort order.

   * Second, the decorated list is sorted.

   * Finally, the decorations are removed, creating a list that contains
     only the initial values in the new order.

For example, to sort the student data by `grade' using the DSU approach:

     >>> decorated = [(student.grade, i, student) for i, student in enumerate(student_objects)]
     >>> decorated.sort()
     >>> [student for grade, i, student in decorated]               # undecorate
     [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]

This idiom works because tuples are compared lexicographically; the
first items are compared; if they are the same then the second items are
compared, and so on.

It is not strictly necessary in all cases to include the index `i' in
the decorated list, but including it gives two benefits:

   * The sort is stable – if two items have the same key, their order
     will be preserved in the sorted list.

   * The original items do not have to be comparable because the
     ordering of the decorated tuples will be determined by at most the
     first two items.  So for example the original list could contain
     complex numbers which cannot be sorted directly.

Another name for this idiom is Schwartzian transform(1), after Randal L.
Schwartz, who popularized it among Perl programmers.

Now that Python sorting provides key-functions, this technique is not
often needed.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Schwartzian_transform


File: python.info,  Node: The Old Way Using the cmp Parameter,  Next: Odd and Ends,  Prev: The Old Way Using Decorate-Sort-Undecorate,  Up: Sorting HOW TO

10.10.7 The Old Way Using the `cmp' Parameter
---------------------------------------------

Many constructs given in this HOWTO assume Python 2.4 or later.  Before
that, there was no *note sorted(): 84e. builtin and *note list.sort():
84d. took no keyword arguments.  Instead, all of the Py2.x versions
supported a `cmp' parameter to handle user specified comparison
functions.

In Py3.0, the `cmp' parameter was removed entirely (as part of a larger
effort to simplify and unify the language, eliminating the conflict
between rich comparisons and the ‘__cmp__()’ magic method).

In Py2.x, sort allowed an optional function which can be called for
doing the comparisons.  That function should take two arguments to be
compared and then return a negative value for less-than, return zero if
they are equal, or return a positive value for greater-than.  For
example, we can do:

     >>> def numeric_compare(x, y):
             return x - y
     >>> sorted([5, 2, 4, 1, 3], cmp=numeric_compare)
     [1, 2, 3, 4, 5]

Or you can reverse the order of comparison with:

     >>> def reverse_numeric(x, y):
             return y - x
     >>> sorted([5, 2, 4, 1, 3], cmp=reverse_numeric)
     [5, 4, 3, 2, 1]

When porting code from Python 2.x to 3.x, the situation can arise when
you have the user supplying a comparison function and you need to
convert that to a key function.  The following wrapper makes that easy
to do:

     def cmp_to_key(mycmp):
         'Convert a cmp= function into a key= function'
         class K:
             def __init__(self, obj, *args):
                 self.obj = obj
             def __lt__(self, other):
                 return mycmp(self.obj, other.obj) < 0
             def __gt__(self, other):
                 return mycmp(self.obj, other.obj) > 0
             def __eq__(self, other):
                 return mycmp(self.obj, other.obj) == 0
             def __le__(self, other):
                 return mycmp(self.obj, other.obj) <= 0
             def __ge__(self, other):
                 return mycmp(self.obj, other.obj) >= 0
             def __ne__(self, other):
                 return mycmp(self.obj, other.obj) != 0
         return K

To convert to a key function, just wrap the old comparison function:

     >>> sorted([5, 2, 4, 1, 3], key=cmp_to_key(reverse_numeric))
     [5, 4, 3, 2, 1]

In Python 3.2, the *note functools.cmp_to_key(): 7a0. function was added
to the *note functools: 84. module in the standard library.


File: python.info,  Node: Odd and Ends,  Prev: The Old Way Using the cmp Parameter,  Up: Sorting HOW TO

10.10.8 Odd and Ends
--------------------

   * For locale aware sorting, use *note locale.strxfrm(): 2935. for a
     key function or *note locale.strcoll(): 2933. for a comparison
     function.

   * The `reverse' parameter still maintains sort stability (so that
     records with equal keys retain the original order).  Interestingly,
     that effect can be simulated without the parameter by using the
     builtin *note reversed(): 24d. function twice:

          >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]
          >>> standard_way = sorted(data, key=itemgetter(0), reverse=True)
          >>> double_reversed = list(reversed(sorted(reversed(data), key=itemgetter(0))))
          >>> assert standard_way == double_reversed
          >>> standard_way
          [('red', 1), ('red', 2), ('blue', 1), ('blue', 2)]

   * The sort routines are guaranteed to use *note __lt__(): 899. when
     making comparisons between two objects.  So, it is easy to add a
     standard sort order to a class by defining an *note __lt__(): 899.
     method:

          >>> Student.__lt__ = lambda self, other: self.age < other.age
          >>> sorted(student_objects)
          [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

   * Key functions need not depend directly on the objects being sorted.
     A key function can also access external resources.  For instance,
     if the student grades are stored in a dictionary, they can be used
     to sort a separate list of student names:

          >>> students = ['dave', 'john', 'jane']
          >>> newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}
          >>> sorted(students, key=newgrades.__getitem__)
          ['jane', 'dave', 'john']


File: python.info,  Node: Unicode HOWTO,  Next: HOWTO Fetch Internet Resources Using The urllib Package,  Prev: Sorting HOW TO,  Up: Python HOWTOs

10.11 Unicode HOWTO
===================


Release: 1.12

This HOWTO discusses Python support for Unicode, and explains various
problems that people commonly encounter when trying to work with
Unicode.

* Menu:

* Introduction to Unicode:: 
* Python's Unicode Support:: 
* Reading and Writing Unicode Data:: 
* Acknowledgements: Acknowledgements<10>. 


File: python.info,  Node: Introduction to Unicode,  Next: Python's Unicode Support,  Up: Unicode HOWTO

10.11.1 Introduction to Unicode
-------------------------------

* Menu:

* History of Character Codes:: 
* Definitions:: 
* Encodings:: 
* References: References<3>. 


File: python.info,  Node: History of Character Codes,  Next: Definitions,  Up: Introduction to Unicode

10.11.1.1 History of Character Codes
....................................

In 1968, the American Standard Code for Information Interchange, better
known by its acronym ASCII, was standardized.  ASCII defined numeric
codes for various characters, with the numeric values running from 0 to
127.  For example, the lowercase letter ’a’ is assigned 97 as its code
value.

ASCII was an American-developed standard, so it only defined unaccented
characters.  There was an ’e’, but no ’é’ or ’Í’.  This meant that
languages which required accented characters couldn’t be faithfully
represented in ASCII. (Actually the missing accents matter for English,
too, which contains words such as ’naïve’ and ’café’, and some
publications have house styles which require spellings such as
’coöperate’.)

For a while people just wrote programs that didn’t display accents.  In
the mid-1980s an Apple II BASIC program written by a French speaker
might have lines like these:

     PRINT "MISE A JOUR TERMINEE"
     PRINT "PARAMETRES ENREGISTRES"

Those messages should contain accents (terminée, paramètre, enregistrés)
and they just look wrong to someone who can read French.

In the 1980s, almost all personal computers were 8-bit, meaning that
bytes could hold values ranging from 0 to 255.  ASCII codes only went up
to 127, so some machines assigned values between 128 and 255 to accented
characters.  Different machines had different codes, however, which led
to problems exchanging files.  Eventually various commonly used sets of
values for the 128–255 range emerged.  Some were true standards, defined
by the International Standards Organization, and some were `de facto'
conventions that were invented by one company or another and managed to
catch on.

255 characters aren’t very many.  For example, you can’t fit both the
accented characters used in Western Europe and the Cyrillic alphabet
used for Russian into the 128–255 range because there are more than 128
such characters.

You could write files using different codes (all your Russian files in a
coding system called KOI8, all your French files in a different coding
system called Latin1), but what if you wanted to write a French document
that quotes some Russian text?  In the 1980s people began to want to
solve this problem, and the Unicode standardization effort began.

Unicode started out using 16-bit characters instead of 8-bit characters.
16 bits means you have 2^16 = 65,536 distinct values available, making
it possible to represent many different characters from many different
alphabets; an initial goal was to have Unicode contain the alphabets for
every single human language.  It turns out that even 16 bits isn’t
enough to meet that goal, and the modern Unicode specification uses a
wider range of codes, 0 through 1,114,111 ( ‘0x10FFFF’ in base 16).

There’s a related ISO standard, ISO 10646.  Unicode and ISO 10646 were
originally separate efforts, but the specifications were merged with the
1.1 revision of Unicode.

(This discussion of Unicode’s history is highly simplified.  The precise
historical details aren’t necessary for understanding how to use Unicode
effectively, but if you’re curious, consult the Unicode consortium site
listed in the References or the Wikipedia entry for Unicode(1) for more
information.)

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Unicode#History


File: python.info,  Node: Definitions,  Next: Encodings,  Prev: History of Character Codes,  Up: Introduction to Unicode

10.11.1.2 Definitions
.....................

A `character' is the smallest possible component of a text.  ’A’, ’B’,
’C’, etc., are all different characters.  So are ’È’ and ’Í’.
Characters are abstractions, and vary depending on the language or
context you’re talking about.  For example, the symbol for ohms (Ω) is
usually drawn much like the capital letter omega (Ω) in the Greek
alphabet (they may even be the same in some fonts), but these are two
different characters that have different meanings.

The Unicode standard describes how characters are represented by `code
points'.  A code point is an integer value, usually denoted in base 16.
In the standard, a code point is written using the notation ‘U+12CA’ to
mean the character with value ‘0x12ca’ (4,810 decimal).  The Unicode
standard contains a lot of tables listing characters and their
corresponding code points:

     0061    'a'; LATIN SMALL LETTER A
     0062    'b'; LATIN SMALL LETTER B
     0063    'c'; LATIN SMALL LETTER C
     ...
     007B    '{'; LEFT CURLY BRACKET

Strictly, these definitions imply that it’s meaningless to say ’this is
character ‘U+12CA’’.  ‘U+12CA’ is a code point, which represents some
particular character; in this case, it represents the character
’ETHIOPIC SYLLABLE WI’.  In informal contexts, this distinction between
code points and characters will sometimes be forgotten.

A character is represented on a screen or on paper by a set of graphical
elements that’s called a `glyph'.  The glyph for an uppercase A, for
example, is two diagonal strokes and a horizontal stroke, though the
exact details will depend on the font being used.  Most Python code
doesn’t need to worry about glyphs; figuring out the correct glyph to
display is generally the job of a GUI toolkit or a terminal’s font
renderer.


File: python.info,  Node: Encodings,  Next: References<3>,  Prev: Definitions,  Up: Introduction to Unicode

10.11.1.3 Encodings
...................

To summarize the previous section: a Unicode string is a sequence of
code points, which are numbers from 0 through ‘0x10FFFF’ (1,114,111
decimal).  This sequence needs to be represented as a set of bytes
(meaning, values from 0 through 255) in memory.  The rules for
translating a Unicode string into a sequence of bytes are called an
`encoding'.

The first encoding you might think of is an array of 32-bit integers.
In this representation, the string "Python" would look like this:

        P           y           t           h           o           n
     0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00
        0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

This representation is straightforward but using it presents a number of
problems.

  1. It’s not portable; different processors order the bytes
     differently.

  2. It’s very wasteful of space.  In most texts, the majority of the
     code points are less than 127, or less than 255, so a lot of space
     is occupied by ‘0x00’ bytes.  The above string takes 24 bytes
     compared to the 6 bytes needed for an ASCII representation.
     Increased RAM usage doesn’t matter too much (desktop computers have
     gigabytes of RAM, and strings aren’t usually that large), but
     expanding our usage of disk and network bandwidth by a factor of 4
     is intolerable.

  3. It’s not compatible with existing C functions such as ‘strlen()’,
     so a new family of wide string functions would need to be used.

  4. Many Internet standards are defined in terms of textual data, and
     can’t handle content with embedded zero bytes.

Generally people don’t use this encoding, instead choosing other
encodings that are more efficient and convenient.  UTF-8 is probably the
most commonly supported encoding; it will be discussed below.

Encodings don’t have to handle every possible Unicode character, and
most encodings don’t.  The rules for converting a Unicode string into
the ASCII encoding, for example, are simple; for each code point:

  1. If the code point is < 128, each byte is the same as the value of
     the code point.

  2. If the code point is 128 or greater, the Unicode string can’t be
     represented in this encoding.  (Python raises a *note
     UnicodeEncodeError: 852. exception in this case.)

Latin-1, also known as ISO-8859-1, is a similar encoding.  Unicode code
points 0–255 are identical to the Latin-1 values, so converting to this
encoding simply requires converting code points to byte values; if a
code point larger than 255 is encountered, the string can’t be encoded
into Latin-1.

Encodings don’t have to be simple one-to-one mappings like Latin-1.
Consider IBM’s EBCDIC, which was used on IBM mainframes.  Letter values
weren’t in one block: ’a’ through ’i’ had values from 129 to 137, but
’j’ through ’r’ were 145 through 153.  If you wanted to use EBCDIC as an
encoding, you’d probably use some sort of lookup table to perform the
conversion, but this is largely an internal detail.

UTF-8 is one of the most commonly used encodings.  UTF stands for
"Unicode Transformation Format", and the ’8’ means that 8-bit numbers
are used in the encoding.  (There are also a UTF-16 and UTF-32
encodings, but they are less frequently used than UTF-8.)  UTF-8 uses
the following rules:

  1. If the code point is < 128, it’s represented by the corresponding
     byte value.

  2. If the code point is >= 128, it’s turned into a sequence of two,
     three, or four bytes, where each byte of the sequence is between
     128 and 255.

UTF-8 has several convenient properties:

  1. It can handle any Unicode code point.

  2. A Unicode string is turned into a string of bytes containing no
     embedded zero bytes.  This avoids byte-ordering issues, and means
     UTF-8 strings can be processed by C functions such as ‘strcpy()’
     and sent through protocols that can’t handle zero bytes.

  3. A string of ASCII text is also valid UTF-8 text.

  4. UTF-8 is fairly compact; the majority of commonly used characters
     can be represented with one or two bytes.

  5. If bytes are corrupted or lost, it’s possible to determine the
     start of the next UTF-8-encoded code point and resynchronize.  It’s
     also unlikely that random 8-bit data will look like valid UTF-8.


File: python.info,  Node: References<3>,  Prev: Encodings,  Up: Introduction to Unicode

10.11.1.4 References
....................

The Unicode Consortium site(1) has character charts, a glossary, and PDF
versions of the Unicode specification.  Be prepared for some difficult
reading.  A chronology(2) of the origin and development of Unicode is
also available on the site.

To help understand the standard, Jukka Korpela has written an
introductory guide(3) to reading the Unicode character tables.

Another good introductory article(4) was written by Joel Spolsky.  If
this introduction didn’t make things clear to you, you should try
reading this alternate article before continuing.

Wikipedia entries are often helpful; see the entries for "character
encoding(5)" and UTF-8(6), for example.

   ---------- Footnotes ----------

   (1) http://www.unicode.org

   (2) http://www.unicode.org/history/

   (3) http://www.cs.tut.fi/~jkorpela/unicode/guide.html

   (4) http://www.joelonsoftware.com/articles/Unicode.html

   (5) https://en.wikipedia.org/wiki/Character_encoding

   (6) https://en.wikipedia.org/wiki/UTF-8


File: python.info,  Node: Python's Unicode Support,  Next: Reading and Writing Unicode Data,  Prev: Introduction to Unicode,  Up: Unicode HOWTO

10.11.2 Python’s Unicode Support
--------------------------------

Now that you’ve learned the rudiments of Unicode, we can look at
Python’s Unicode features.

* Menu:

* The String Type:: 
* Converting to Bytes:: 
* Unicode Literals in Python Source Code:: 
* Unicode Properties:: 
* Unicode Regular Expressions:: 
* References: References<4>. 


File: python.info,  Node: The String Type,  Next: Converting to Bytes,  Up: Python's Unicode Support

10.11.2.1 The String Type
.........................

Since Python 3.0, the language features a *note str: 25a. type that
contain Unicode characters, meaning any string created using ‘"unicode
rocks!"’, ‘'unicode rocks!'’, or the triple-quoted string syntax is
stored as Unicode.

The default encoding for Python source code is UTF-8, so you can simply
include a Unicode character in a string literal:

     try:
         with open('/tmp/input.txt', 'r') as f:
             ...
     except OSError:
         # 'File not found' error message.
         print("Fichier non trouvé")

You can use a different encoding from UTF-8 by putting a
specially-formatted comment as the first or second line of the source
code:

     # -*- coding: <encoding name> -*-

Side note: Python 3 also supports using Unicode characters in
identifiers:

     répertoire = "/tmp/records.log"
     with open(répertoire, "w") as f:
         f.write("test\n")

If you can’t enter a particular character in your editor or want to keep
the source code ASCII-only for some reason, you can also use escape
sequences in string literals.  (Depending on your system, you may see
the actual capital-delta glyph instead of a u escape.)

     >>> "\N{GREEK CAPITAL LETTER DELTA}"  # Using the character name
     '\u0394'
     >>> "\u0394"                          # Using a 16-bit hex value
     '\u0394'
     >>> "\U00000394"                      # Using a 32-bit hex value
     '\u0394'

In addition, one can create a string using the *note decode(): 89e.
method of *note bytes: 1db.  This method takes an `encoding' argument,
such as ‘UTF-8’, and optionally an `errors' argument.

The `errors' argument specifies the response when the input string can’t
be converted according to the encoding’s rules.  Legal values for this
argument are ‘'strict'’ (raise a *note UnicodeDecodeError: 571.
exception), ‘'replace'’ (use ‘U+FFFD’, ‘REPLACEMENT CHARACTER’),
‘'ignore'’ (just leave the character out of the Unicode result), or
‘'backslashreplace'’ (inserts a ‘\xNN’ escape sequence).  The following
examples show the differences:

     >>> b'\x80abc'.decode("utf-8", "strict")  #doctest: +NORMALIZE_WHITESPACE
     Traceback (most recent call last):
         ...
     UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0:
       invalid start byte
     >>> b'\x80abc'.decode("utf-8", "replace")
     '\ufffdabc'
     >>> b'\x80abc'.decode("utf-8", "backslashreplace")
     '\\x80abc'
     >>> b'\x80abc'.decode("utf-8", "ignore")
     'abc'

Encodings are specified as strings containing the encoding’s name.
Python 3.2 comes with roughly 100 different encodings; see the Python
Library Reference at *note Standard Encodings: 228. for a list.  Some
encodings have multiple names; for example, ‘'latin-1'’, ‘'iso_8859_1'’
and ‘'8859’’ are all synonyms for the same encoding.

One-character Unicode strings can also be created with the *note chr():
de7. built-in function, which takes integers and returns a Unicode
string of length 1 that contains the corresponding code point.  The
reverse operation is the built-in *note ord(): de6. function that takes
a one-character Unicode string and returns the code point value:

     >>> chr(57344)
     '\ue000'
     >>> ord('\ue000')
     57344


File: python.info,  Node: Converting to Bytes,  Next: Unicode Literals in Python Source Code,  Prev: The String Type,  Up: Python's Unicode Support

10.11.2.2 Converting to Bytes
.............................

The opposite method of *note bytes.decode(): 89e. is *note str.encode():
89d, which returns a *note bytes: 1db. representation of the Unicode
string, encoded in the requested `encoding'.

The `errors' parameter is the same as the parameter of the *note
decode(): 89e. method but supports a few more possible handlers.  As
well as ‘'strict'’, ‘'ignore'’, and ‘'replace'’ (which in this case
inserts a question mark instead of the unencodable character), there is
also ‘'xmlcharrefreplace'’ (inserts an XML character reference),
‘backslashreplace’ (inserts a ‘\uNNNN’ escape sequence) and
‘namereplace’ (inserts a ‘\N{...}’ escape sequence).

The following example shows the different results:

     >>> u = chr(40960) + 'abcd' + chr(1972)
     >>> u.encode('utf-8')
     b'\xea\x80\x80abcd\xde\xb4'
     >>> u.encode('ascii')  #doctest: +NORMALIZE_WHITESPACE
     Traceback (most recent call last):
         ...
     UnicodeEncodeError: 'ascii' codec can't encode character '\ua000' in
       position 0: ordinal not in range(128)
     >>> u.encode('ascii', 'ignore')
     b'abcd'
     >>> u.encode('ascii', 'replace')
     b'?abcd?'
     >>> u.encode('ascii', 'xmlcharrefreplace')
     b'&#40960;abcd&#1972;'
     >>> u.encode('ascii', 'backslashreplace')
     b'\\ua000abcd\\u07b4'
     >>> u.encode('ascii', 'namereplace')
     b'\\N{YI SYLLABLE IT}abcd\\u07b4'

The low-level routines for registering and accessing the available
encodings are found in the *note codecs: 1c. module.  Implementing new
encodings also requires understanding the *note codecs: 1c. module.
However, the encoding and decoding functions returned by this module are
usually more low-level than is comfortable, and writing new encodings is
a specialized task, so the module won’t be covered in this HOWTO.


File: python.info,  Node: Unicode Literals in Python Source Code,  Next: Unicode Properties,  Prev: Converting to Bytes,  Up: Python's Unicode Support

10.11.2.3 Unicode Literals in Python Source Code
................................................

In Python source code, specific Unicode code points can be written using
the ‘\u’ escape sequence, which is followed by four hex digits giving
the code point.  The ‘\U’ escape sequence is similar, but expects eight
hex digits, not four:

     >>> s = "a\xac\u1234\u20ac\U00008000"
     ... #     ^^^^ two-digit hex escape
     ... #         ^^^^^^ four-digit Unicode escape
     ... #                     ^^^^^^^^^^ eight-digit Unicode escape
     >>> [ord(c) for c in s]
     [97, 172, 4660, 8364, 32768]

Using escape sequences for code points greater than 127 is fine in small
doses, but becomes an annoyance if you’re using many accented
characters, as you would in a program with messages in French or some
other accent-using language.  You can also assemble strings using the
*note chr(): de7. built-in function, but this is even more tedious.

Ideally, you’d want to be able to write literals in your language’s
natural encoding.  You could then edit Python source code with your
favorite editor which would display the accented characters naturally,
and have the right characters used at runtime.

Python supports writing source code in UTF-8 by default, but you can use
almost any encoding if you declare the encoding being used.  This is
done by including a special comment as either the first or second line
of the source file:

     #!/usr/bin/env python
     # -*- coding: latin-1 -*-

     u = 'abcdé'
     print(ord(u[-1]))

The syntax is inspired by Emacs’s notation for specifying variables
local to a file.  Emacs supports many different variables, but Python
only supports ’coding’.  The ‘-*-’ symbols indicate to Emacs that the
comment is special; they have no significance to Python but are a
convention.  Python looks for ‘coding: name’ or ‘coding=name’ in the
comment.

If you don’t include such a comment, the default encoding used will be
UTF-8 as already mentioned.  See also PEP 263(1) for more information.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0263


File: python.info,  Node: Unicode Properties,  Next: Unicode Regular Expressions,  Prev: Unicode Literals in Python Source Code,  Up: Python's Unicode Support

10.11.2.4 Unicode Properties
............................

The Unicode specification includes a database of information about code
points.  For each defined code point, the information includes the
character’s name, its category, the numeric value if applicable (Unicode
has characters representing the Roman numerals and fractions such as
one-third and four-fifths).  There are also properties related to the
code point’s use in bidirectional text and other display-related
properties.

The following program displays some information about several
characters, and prints the numeric value of one particular character:

     import unicodedata

     u = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)

     for i, c in enumerate(u):
         print(i, '%04x' % ord(c), unicodedata.category(c), end=" ")
         print(unicodedata.name(c))

     # Get numeric value of second character
     print(unicodedata.numeric(u[1]))

When run, this prints:

     0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE
     1 0bf2 No TAMIL NUMBER ONE THOUSAND
     2 0f84 Mn TIBETAN MARK HALANTA
     3 1770 Lo TAGBANWA LETTER SA
     4 33af So SQUARE RAD OVER S SQUARED
     1000.0

The category codes are abbreviations describing the nature of the
character.  These are grouped into categories such as "Letter",
"Number", "Punctuation", or "Symbol", which in turn are broken up into
subcategories.  To take the codes from the above output, ‘'Ll'’ means
’Letter, lowercase’, ‘'No'’ means "Number, other", ‘'Mn'’ is "Mark,
nonspacing", and ‘'So'’ is "Symbol, other".  See the General Category
Values section of the Unicode Character Database documentation(1) for a
list of category codes.

   ---------- Footnotes ----------

   (1) http://www.unicode.org/reports/tr44/#General_Category_Values


File: python.info,  Node: Unicode Regular Expressions,  Next: References<4>,  Prev: Unicode Properties,  Up: Python's Unicode Support

10.11.2.5 Unicode Regular Expressions
.....................................

The regular expressions supported by the *note re: db. module can be
provided either as bytes or strings.  Some of the special character
sequences such as ‘\d’ and ‘\w’ have different meanings depending on
whether the pattern is supplied as bytes or a string.  For example, ‘\d’
will match the characters ‘[0-9]’ in bytes but in strings will match any
character that’s in the ‘'Nd'’ category.

The string in this example has the number 57 written in both Thai and
Arabic numerals:

     import re
     p = re.compile('\d+')

     s = "Over \u0e55\u0e57 57 flavours"
     m = p.search(s)
     print(repr(m.group()))

When executed, ‘\d+’ will match the Thai numerals and print them out.
If you supply the *note re.ASCII: 3a1. flag to *note compile(): 110d,
‘\d+’ will match the substring "57" instead.

Similarly, ‘\w’ matches a wide variety of Unicode characters but only
‘[a-zA-Z0-9_]’ in bytes or if *note re.ASCII: 3a1. is supplied, and ‘\s’
will match either Unicode whitespace characters or ‘[ \t\n\r\f\v]’.


File: python.info,  Node: References<4>,  Prev: Unicode Regular Expressions,  Up: Python's Unicode Support

10.11.2.6 References
....................

Some good alternative discussions of Python’s Unicode support are:

   * Processing Text Files in Python 3(1), by Nick Coghlan.

   * Pragmatic Unicode(2), a PyCon 2012 presentation by Ned Batchelder.

The *note str: 25a. type is described in the Python library reference at
*note Text Sequence Type — str: bea.

The documentation for the *note unicodedata: 117. module.

The documentation for the *note codecs: 1c. module.

Marc-André Lemburg gave a presentation titled "Python and Unicode" (PDF
slides)(3) at EuroPython 2002.  The slides are an excellent overview of
the design of Python 2’s Unicode features (where the Unicode string type
is called ‘unicode’ and literals start with ‘u’).

   ---------- Footnotes ----------

   (1) 
http://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html

   (2) http://nedbatchelder.com/text/unipain.html

   (3) https://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf


File: python.info,  Node: Reading and Writing Unicode Data,  Next: Acknowledgements<10>,  Prev: Python's Unicode Support,  Up: Unicode HOWTO

10.11.3 Reading and Writing Unicode Data
----------------------------------------

Once you’ve written some code that works with Unicode data, the next
problem is input/output.  How do you get Unicode strings into your
program, and how do you convert Unicode into a form suitable for storage
or transmission?

It’s possible that you may not need to do anything depending on your
input sources and output destinations; you should check whether the
libraries used in your application support Unicode natively.  XML
parsers often return Unicode data, for example.  Many relational
databases also support Unicode-valued columns and can return Unicode
values from an SQL query.

Unicode data is usually converted to a particular encoding before it
gets written to disk or sent over a socket.  It’s possible to do all the
work yourself: open a file, read an 8-bit bytes object from it, and
convert the bytes with ‘bytes.decode(encoding)’.  However, the manual
approach is not recommended.

One problem is the multi-byte nature of encodings; one Unicode character
can be represented by several bytes.  If you want to read the file in
arbitrary-sized chunks (say, 1024 or 4096 bytes), you need to write
error-handling code to catch the case where only part of the bytes
encoding a single Unicode character are read at the end of a chunk.  One
solution would be to read the entire file into memory and then perform
the decoding, but that prevents you from working with files that are
extremely large; if you need to read a 2 GiB file, you need 2 GiB of
RAM. (More, really, since for at least a moment you’d need to have both
the encoded string and its Unicode version in memory.)

The solution would be to use the low-level decoding interface to catch
the case of partial coding sequences.  The work of implementing this has
already been done for you: the built-in *note open(): 1e8. function can
return a file-like object that assumes the file’s contents are in a
specified encoding and accepts Unicode parameters for methods such as
*note read(): 1966. and *note write(): 1969.  This works through *note
open(): 1e8.’s `encoding' and `errors' parameters which are interpreted
just like those in *note str.encode(): 89d. and *note bytes.decode():
89e.

Reading Unicode from a file is therefore simple:

     with open('unicode.txt', encoding='utf-8') as f:
         for line in f:
             print(repr(line))

It’s also possible to open files in update mode, allowing both reading
and writing:

     with open('test', encoding='utf-8', mode='w+') as f:
         f.write('\u4500 blah blah blah\n')
         f.seek(0)
         print(repr(f.readline()[:1]))

The Unicode character ‘U+FEFF’ is used as a byte-order mark (BOM), and
is often written as the first character of a file in order to assist
with autodetection of the file’s byte ordering.  Some encodings, such as
UTF-16, expect a BOM to be present at the start of a file; when such an
encoding is used, the BOM will be automatically written as the first
character and will be silently dropped when the file is read.  There are
variants of these encodings, such as ’utf-16-le’ and ’utf-16-be’ for
little-endian and big-endian encodings, that specify one particular byte
ordering and don’t skip the BOM.

In some areas, it is also convention to use a "BOM" at the start of
UTF-8 encoded files; the name is misleading since UTF-8 is not
byte-order dependent.  The mark simply announces that the file is
encoded in UTF-8.  Use the ’utf-8-sig’ codec to automatically skip the
mark if present for reading such files.

* Menu:

* Unicode filenames:: 
* Tips for Writing Unicode-aware Programs:: 
* References: References<5>. 


File: python.info,  Node: Unicode filenames,  Next: Tips for Writing Unicode-aware Programs,  Up: Reading and Writing Unicode Data

10.11.3.1 Unicode filenames
...........................

Most of the operating systems in common use today support filenames that
contain arbitrary Unicode characters.  Usually this is implemented by
converting the Unicode string into some encoding that varies depending
on the system.  For example, Mac OS X uses UTF-8 while Windows uses a
configurable encoding; on Windows, Python uses the name "mbcs" to refer
to whatever the currently configured encoding is.  On Unix systems,
there will only be a filesystem encoding if you’ve set the ‘LANG’ or
‘LC_CTYPE’ environment variables; if you haven’t, the default encoding
is UTF-8.

The *note sys.getfilesystemencoding(): 1758. function returns the
encoding to use on your current system, in case you want to do the
encoding manually, but there’s not much reason to bother.  When opening
a file for reading or writing, you can usually just provide the Unicode
string as the filename, and it will be automatically converted to the
right encoding for you:

     filename = 'filename\u4500abc'
     with open(filename, 'w') as f:
         f.write('blah\n')

Functions in the *note os: c2. module such as *note os.stat(): 1e2. will
also accept Unicode filenames.

The *note os.listdir(): 675. function returns filenames and raises an
issue: should it return the Unicode version of filenames, or should it
return bytes containing the encoded versions?  *note os.listdir(): 675.
will do both, depending on whether you provided the directory path as
bytes or a Unicode string.  If you pass a Unicode string as the path,
filenames will be decoded using the filesystem’s encoding and a list of
Unicode strings will be returned, while passing a byte path will return
the filenames as bytes.  For example, assuming the default filesystem
encoding is UTF-8, running the following program:

     fn = 'filename\u4500abc'
     f = open(fn, 'w')
     f.close()

     import os
     print(os.listdir(b'.'))
     print(os.listdir('.'))

will produce the following output:

     amk:~$ python t.py
     [b'filename\xe4\x94\x80abc', ...]
     ['filename\u4500abc', ...]

The first list contains UTF-8-encoded filenames, and the second list
contains the Unicode versions.

Note that on most occasions, the Unicode APIs should be used.  The bytes
APIs should only be used on systems where undecodable file names can be
present, i.e.  Unix systems.


File: python.info,  Node: Tips for Writing Unicode-aware Programs,  Next: References<5>,  Prev: Unicode filenames,  Up: Reading and Writing Unicode Data

10.11.3.2 Tips for Writing Unicode-aware Programs
.................................................

This section provides some suggestions on writing software that deals
with Unicode.

The most important tip is:

     Software should only work with Unicode strings internally, decoding
     the input data as soon as possible and encoding the output only at
     the end.

If you attempt to write processing functions that accept both Unicode
and byte strings, you will find your program vulnerable to bugs wherever
you combine the two different kinds of strings.  There is no automatic
encoding or decoding: if you do e.g.  ‘str + bytes’, a *note TypeError:
562. will be raised.

When using data coming from a web browser or some other untrusted
source, a common technique is to check for illegal characters in a
string before using the string in a generated command line or storing it
in a database.  If you’re doing this, be careful to check the decoded
string, not the encoded bytes data; some encodings may have interesting
properties, such as not being bijective or not being fully
ASCII-compatible.  This is especially true if the input data also
specifies the encoding, since the attacker can then choose a clever way
to hide malicious text in the encoded bytestream.

* Menu:

* Converting Between File Encodings:: 
* Files in an Unknown Encoding:: 


File: python.info,  Node: Converting Between File Encodings,  Next: Files in an Unknown Encoding,  Up: Tips for Writing Unicode-aware Programs

10.11.3.3 Converting Between File Encodings
...........................................

The *note StreamRecoder: 11eb. class can transparently convert between
encodings, taking a stream that returns data in encoding #1 and behaving
like a stream returning data in encoding #2.

For example, if you have an input file `f' that’s in Latin-1, you can
wrap it with a *note StreamRecoder: 11eb. to return bytes encoded in
UTF-8:

     new_f = codecs.StreamRecoder(f,
         # en/decoder: used by read() to encode its results and
         # by write() to decode its input.
         codecs.getencoder('utf-8'), codecs.getdecoder('utf-8'),

         # reader/writer: used to read and write to the stream.
         codecs.getreader('latin-1'), codecs.getwriter('latin-1') )


File: python.info,  Node: Files in an Unknown Encoding,  Prev: Converting Between File Encodings,  Up: Tips for Writing Unicode-aware Programs

10.11.3.4 Files in an Unknown Encoding
......................................

What can you do if you need to make a change to a file, but don’t know
the file’s encoding?  If you know the encoding is ASCII-compatible and
only want to examine or modify the ASCII parts, you can open the file
with the ‘surrogateescape’ error handler:

     with open(fname, 'r', encoding="ascii", errors="surrogateescape") as f:
         data = f.read()

     # make changes to the string 'data'

     with open(fname + '.new', 'w',
                encoding="ascii", errors="surrogateescape") as f:
         f.write(data)

The ‘surrogateescape’ error handler will decode any non-ASCII bytes as
code points in the Unicode Private Use Area ranging from U+DC80 to
U+DCFF. These private code points will then be turned back into the same
bytes when the ‘surrogateescape’ error handler is used when encoding the
data and writing it back out.


File: python.info,  Node: References<5>,  Prev: Tips for Writing Unicode-aware Programs,  Up: Reading and Writing Unicode Data

10.11.3.5 References
....................

One section of Mastering Python 3 Input/Output(1), a PyCon 2010 talk by
David Beazley, discusses text processing and binary data handling.

The PDF slides for Marc-André Lemburg’s presentation "Writing
Unicode-aware Applications in Python"(2) discuss questions of character
encodings as well as how to internationalize and localize an
application.  These slides cover Python 2.x only.

The Guts of Unicode in Python(3) is a PyCon 2013 talk by Benjamin
Peterson that discusses the internal Unicode representation in Python
3.3.

   ---------- Footnotes ----------

   (1) http://pyvideo.org/video/289/pycon-2010–mastering-python-3-i-o

   (2) 
https://downloads.egenix.com/python/LSM2005-Developing-Unicode-aware-applications-in-Python.pdf

   (3) http://pyvideo.org/video/1768/the-guts-of-unicode-in-python


File: python.info,  Node: Acknowledgements<10>,  Prev: Reading and Writing Unicode Data,  Up: Unicode HOWTO

10.11.4 Acknowledgements
------------------------

The initial draft of this document was written by Andrew Kuchling.  It
has since been revised further by Alexander Belopolsky, Georg Brandl,
Andrew Kuchling, and Ezio Melotti.

Thanks to the following people who have noted errors or offered
suggestions on this article: Éric Araujo, Nicholas Bastin, Nick Coghlan,
Marius Gedminas, Kent Johnson, Ken Krugler, Marc-André Lemburg, Martin
von Löwis, Terry J. Reedy, Chad Whitacre.


File: python.info,  Node: HOWTO Fetch Internet Resources Using The urllib Package,  Next: Argparse Tutorial,  Prev: Unicode HOWTO,  Up: Python HOWTOs

10.12 HOWTO Fetch Internet Resources Using The urllib Package
=============================================================


Author: Michael Foord(1)

     Note: There is a French translation of an earlier revision of this
     HOWTO, available at urllib2 - Le Manuel manquant(2).

* Menu:

* Introduction: Introduction<16>. 
* Fetching URLs:: 
* Handling Exceptions: Handling Exceptions<2>. 
* info and geturl:: 
* Openers and Handlers:: 
* Basic Authentication:: 
* Proxies:: 
* Sockets and Layers:: 
* Footnotes:: 

   ---------- Footnotes ----------

   (1) http://www.voidspace.org.uk/python/index.shtml

   (2) 
http://www.voidspace.org.uk/python/articles/urllib2_francais.shtml


File: python.info,  Node: Introduction<16>,  Next: Fetching URLs,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.1 Introduction
--------------------

Related Articles
................

You may also find useful the following article on fetching web resources
with Python:

   * Basic Authentication(1)

          A tutorial on `Basic Authentication', with examples in Python.

`urllib.request' is a Python module for fetching URLs (Uniform Resource
Locators).  It offers a very simple interface, in the form of the
`urlopen' function.  This is capable of fetching URLs using a variety of
different protocols.  It also offers a slightly more complex interface
for handling common situations - like basic authentication, cookies,
proxies and so on.  These are provided by objects called handlers and
openers.

urllib.request supports fetching URLs for many "URL schemes" (identified
by the string before the ":" in URL - for example "ftp" is the URL
scheme of "‘ftp://python.org/’") using their associated network
protocols (e.g.  FTP, HTTP). This tutorial focuses on the most common
case, HTTP.

For straightforward situations `urlopen' is very easy to use.  But as
soon as you encounter errors or non-trivial cases when opening HTTP
URLs, you will need some understanding of the HyperText Transfer
Protocol.  The most comprehensive and authoritative reference to HTTP is
RFC 2616(2).  This is a technical document and not intended to be easy
to read.  This HOWTO aims to illustrate using `urllib', with enough
detail about HTTP to help you through.  It is not intended to replace
the *note urllib.request: 11d. docs, but is supplementary to them.

   ---------- Footnotes ----------

   (1) http://www.voidspace.org.uk/python/articles/authentication.shtml

   (2) https://tools.ietf.org/html/rfc2616.html


File: python.info,  Node: Fetching URLs,  Next: Handling Exceptions<2>,  Prev: Introduction<16>,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.2 Fetching URLs
---------------------

The simplest way to use urllib.request is as follows:

     import urllib.request
     with urllib.request.urlopen('http://python.org/') as response:
        html = response.read()

If you wish to retrieve a resource via URL and store it in a temporary
location, you can do so via the *note urlretrieve(): 2564. function:

     import urllib.request
     local_filename, headers = urllib.request.urlretrieve('http://python.org/')
     html = open(local_filename)

Many uses of urllib will be that simple (note that instead of an ’http:’
URL we could have used a URL starting with ’ftp:’, ’file:’, etc.).
However, it’s the purpose of this tutorial to explain the more
complicated cases, concentrating on HTTP.

HTTP is based on requests and responses - the client makes requests and
servers send responses.  urllib.request mirrors this with a ‘Request’
object which represents the HTTP request you are making.  In its
simplest form you create a Request object that specifies the URL you
want to fetch.  Calling ‘urlopen’ with this Request object returns a
response object for the URL requested.  This response is a file-like
object, which means you can for example call ‘.read()’ on the response:

     import urllib.request

     req = urllib.request.Request('http://www.voidspace.org.uk')
     with urllib.request.urlopen(req) as response:
        the_page = response.read()

Note that urllib.request makes use of the same Request interface to
handle all URL schemes.  For example, you can make an FTP request like
so:

     req = urllib.request.Request('ftp://example.com/')

In the case of HTTP, there are two extra things that Request objects
allow you to do: First, you can pass data to be sent to the server.
Second, you can pass extra information ("metadata") `about' the data or
the about request itself, to the server - this information is sent as
HTTP "headers".  Let’s look at each of these in turn.

* Menu:

* Data:: 
* Headers:: 


File: python.info,  Node: Data,  Next: Headers,  Up: Fetching URLs

10.12.2.1 Data
..............

Sometimes you want to send data to a URL (often the URL will refer to a
CGI (Common Gateway Interface) script or other web application).  With
HTTP, this is often done using what’s known as a `POST' request.  This
is often what your browser does when you submit a HTML form that you
filled in on the web.  Not all POSTs have to come from forms: you can
use a POST to transmit arbitrary data to your own application.  In the
common case of HTML forms, the data needs to be encoded in a standard
way, and then passed to the Request object as the ‘data’ argument.  The
encoding is done using a function from the *note urllib.parse: 11c.
library.

     import urllib.parse
     import urllib.request

     url = 'http://www.someserver.com/cgi-bin/register.cgi'
     values = {'name' : 'Michael Foord',
               'location' : 'Northampton',
               'language' : 'Python' }

     data = urllib.parse.urlencode(values)
     data = data.encode('ascii') # data should be bytes
     req = urllib.request.Request(url, data)
     with urllib.request.urlopen(req) as response:
        the_page = response.read()

Note that other encodings are sometimes required (e.g.  for file upload
from HTML forms - see HTML Specification, Form Submission(1) for more
details).

If you do not pass the ‘data’ argument, urllib uses a `GET' request.
One way in which GET and POST requests differ is that POST requests
often have "side-effects": they change the state of the system in some
way (for example by placing an order with the website for a
hundredweight of tinned spam to be delivered to your door).  Though the
HTTP standard makes it clear that POSTs are intended to `always' cause
side-effects, and GET requests `never' to cause side-effects, nothing
prevents a GET request from having side-effects, nor a POST requests
from having no side-effects.  Data can also be passed in an HTTP GET
request by encoding it in the URL itself.

This is done as follows:

     >>> import urllib.request
     >>> import urllib.parse
     >>> data = {}
     >>> data['name'] = 'Somebody Here'
     >>> data['location'] = 'Northampton'
     >>> data['language'] = 'Python'
     >>> url_values = urllib.parse.urlencode(data)
     >>> print(url_values)  # The order may differ from below.  #doctest: +SKIP
     name=Somebody+Here&language=Python&location=Northampton
     >>> url = 'http://www.example.com/example.cgi'
     >>> full_url = url + '?' + url_values
     >>> data = urllib.request.urlopen(full_url)

Notice that the full URL is created by adding a ‘?’ to the URL, followed
by the encoded values.

   ---------- Footnotes ----------

   (1) http://www.w3.org/TR/REC-html40/interact/forms.html#h-17.13


File: python.info,  Node: Headers,  Prev: Data,  Up: Fetching URLs

10.12.2.2 Headers
.................

We’ll discuss here one particular HTTP header, to illustrate how to add
headers to your HTTP request.

Some websites (1) dislike being browsed by programs, or send different
versions to different browsers (2).  By default urllib identifies itself
as ‘Python-urllib/x.y’ (where ‘x’ and ‘y’ are the major and minor
version numbers of the Python release, e.g.  ‘Python-urllib/2.5’), which
may confuse the site, or just plain not work.  The way a browser
identifies itself is through the ‘User-Agent’ header (3).  When you
create a Request object you can pass a dictionary of headers in.  The
following example makes the same request as above, but identifies itself
as a version of Internet Explorer (4).

     import urllib.parse
     import urllib.request

     url = 'http://www.someserver.com/cgi-bin/register.cgi'
     user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'
     values = {'name' : 'Michael Foord',
               'location' : 'Northampton',
               'language' : 'Python' }
     headers = { 'User-Agent' : user_agent }

     data = urllib.parse.urlencode(values)
     data = data.encode('ascii')
     req = urllib.request.Request(url, data, headers)
     with urllib.request.urlopen(req) as response:
        the_page = response.read()

The response also has two useful methods.  See the section on *note info
and geturl: 3919. which comes after we have a look at what happens when
things go wrong.

   ---------- Footnotes ----------

   (1) Google for example.

   (2) Browser sniffing is a very bad practise for website design -
building sites using web standards is much more sensible.  Unfortunately
a lot of sites still send different versions to different browsers.

   (3) The user agent for MSIE 6 is `’Mozilla/4.0 (compatible; MSIE 6.0;
Windows NT 5.1; SV1; .NET CLR 1.1.4322)’'

   (4) For details of more HTTP request headers, see Quick Reference to
HTTP Headers (http://www.cs.tut.fi/~jkorpela/http.html).


File: python.info,  Node: Handling Exceptions<2>,  Next: info and geturl,  Prev: Fetching URLs,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.3 Handling Exceptions
---------------------------

`urlopen' raises ‘URLError’ when it cannot handle a response (though as
usual with Python APIs, built-in exceptions such as *note ValueError:
19c, *note TypeError: 562. etc.  may also be raised).

‘HTTPError’ is the subclass of ‘URLError’ raised in the specific case of
HTTP URLs.

The exception classes are exported from the *note urllib.error: 11b.
module.

* Menu:

* URLError:: 
* HTTPError:: 
* Wrapping it Up:: 


File: python.info,  Node: URLError,  Next: HTTPError,  Up: Handling Exceptions<2>

10.12.3.1 URLError
..................

Often, URLError is raised because there is no network connection (no
route to the specified server), or the specified server doesn’t exist.
In this case, the exception raised will have a ’reason’ attribute, which
is a tuple containing an error code and a text error message.

e.g.

     >>> req = urllib.request.Request('http://www.pretend_server.org')
     >>> try: urllib.request.urlopen(req)
     ... except urllib.error.URLError as e:
     ...    print(e.reason)      #doctest: +SKIP
     ...
     (4, 'getaddrinfo failed')


File: python.info,  Node: HTTPError,  Next: Wrapping it Up,  Prev: URLError,  Up: Handling Exceptions<2>

10.12.3.2 HTTPError
...................

Every HTTP response from the server contains a numeric "status code".
Sometimes the status code indicates that the server is unable to fulfil
the request.  The default handlers will handle some of these responses
for you (for example, if the response is a "redirection" that requests
the client fetch the document from a different URL, urllib will handle
that for you).  For those it can’t handle, urlopen will raise an
‘HTTPError’.  Typical errors include ’404’ (page not found), ’403’
(request forbidden), and ’401’ (authentication required).

See section 10 of RFC 2616 for a reference on all the HTTP error codes.

The ‘HTTPError’ instance raised will have an integer ’code’ attribute,
which corresponds to the error sent by the server.

* Menu:

* Error Codes:: 


File: python.info,  Node: Error Codes,  Up: HTTPError

10.12.3.3 Error Codes
.....................

Because the default handlers handle redirects (codes in the 300 range),
and codes in the 100-299 range indicate success, you will usually only
see error codes in the 400-599 range.

*note http.server.BaseHTTPRequestHandler.responses: 2584. is a useful
dictionary of response codes in that shows all the response codes used
by RFC 2616.  The dictionary is reproduced here for convenience

     # Table mapping response codes to messages; entries have the
     # form {code: (shortmessage, longmessage)}.
     responses = {
         100: ('Continue', 'Request received, please continue'),
         101: ('Switching Protocols',
               'Switching to new protocol; obey Upgrade header'),

         200: ('OK', 'Request fulfilled, document follows'),
         201: ('Created', 'Document created, URL follows'),
         202: ('Accepted',
               'Request accepted, processing continues off-line'),
         203: ('Non-Authoritative Information', 'Request fulfilled from cache'),
         204: ('No Content', 'Request fulfilled, nothing follows'),
         205: ('Reset Content', 'Clear input form for further input.'),
         206: ('Partial Content', 'Partial content follows.'),

         300: ('Multiple Choices',
               'Object has several resources -- see URI list'),
         301: ('Moved Permanently', 'Object moved permanently -- see URI list'),
         302: ('Found', 'Object moved temporarily -- see URI list'),
         303: ('See Other', 'Object moved -- see Method and URL list'),
         304: ('Not Modified',
               'Document has not changed since given time'),
         305: ('Use Proxy',
               'You must use proxy specified in Location to access this '
               'resource.'),
         307: ('Temporary Redirect',
               'Object moved temporarily -- see URI list'),

         400: ('Bad Request',
               'Bad request syntax or unsupported method'),
         401: ('Unauthorized',
               'No permission -- see authorization schemes'),
         402: ('Payment Required',
               'No payment -- see charging schemes'),
         403: ('Forbidden',
               'Request forbidden -- authorization will not help'),
         404: ('Not Found', 'Nothing matches the given URI'),
         405: ('Method Not Allowed',
               'Specified method is invalid for this server.'),
         406: ('Not Acceptable', 'URI not available in preferred format.'),
         407: ('Proxy Authentication Required', 'You must authenticate with '
               'this proxy before proceeding.'),
         408: ('Request Timeout', 'Request timed out; try again later.'),
         409: ('Conflict', 'Request conflict.'),
         410: ('Gone',
               'URI no longer exists and has been permanently removed.'),
         411: ('Length Required', 'Client must specify Content-Length.'),
         412: ('Precondition Failed', 'Precondition in headers is false.'),
         413: ('Request Entity Too Large', 'Entity is too large.'),
         414: ('Request-URI Too Long', 'URI is too long.'),
         415: ('Unsupported Media Type', 'Entity body in unsupported format.'),
         416: ('Requested Range Not Satisfiable',
               'Cannot satisfy request range.'),
         417: ('Expectation Failed',
               'Expect condition could not be satisfied.'),

         500: ('Internal Server Error', 'Server got itself in trouble'),
         501: ('Not Implemented',
               'Server does not support this operation'),
         502: ('Bad Gateway', 'Invalid responses from another server/proxy.'),
         503: ('Service Unavailable',
               'The server cannot process the request due to a high load'),
         504: ('Gateway Timeout',
               'The gateway server did not receive a timely response'),
         505: ('HTTP Version Not Supported', 'Cannot fulfill request.'),
         }

When an error is raised the server responds by returning an HTTP error
code `and' an error page.  You can use the ‘HTTPError’ instance as a
response on the page returned.  This means that as well as the code
attribute, it also has read, geturl, and info, methods as returned by
the ‘urllib.response’ module:

     >>> req = urllib.request.Request('http://www.python.org/fish.html')
     >>> try:
     ...     urllib.request.urlopen(req)
     ... except urllib.error.HTTPError as e:
     ...     print(e.code)
     ...     print(e.read())  #doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
     ...
     404
     b'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
       "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">\n\n\n<html
       ...
       <title>Page Not Found</title>\n
       ...


File: python.info,  Node: Wrapping it Up,  Prev: HTTPError,  Up: Handling Exceptions<2>

10.12.3.4 Wrapping it Up
........................

So if you want to be prepared for ‘HTTPError’ `or' ‘URLError’ there are
two basic approaches.  I prefer the second approach.

* Menu:

* Number 1:: 
* Number 2:: 


File: python.info,  Node: Number 1,  Next: Number 2,  Up: Wrapping it Up

10.12.3.5 Number 1
..................

     from urllib.request import Request, urlopen
     from urllib.error import URLError, HTTPError
     req = Request(someurl)
     try:
         response = urlopen(req)
     except HTTPError as e:
         print('The server couldn\'t fulfill the request.')
         print('Error code: ', e.code)
     except URLError as e:
         print('We failed to reach a server.')
         print('Reason: ', e.reason)
     else:
         # everything is fine

     Note: The ‘except HTTPError’ `must' come first, otherwise ‘except
     URLError’ will `also' catch an ‘HTTPError’.


File: python.info,  Node: Number 2,  Prev: Number 1,  Up: Wrapping it Up

10.12.3.6 Number 2
..................

     from urllib.request import Request, urlopen
     from urllib.error import  URLError
     req = Request(someurl)
     try:
         response = urlopen(req)
     except URLError as e:
         if hasattr(e, 'reason'):
             print('We failed to reach a server.')
             print('Reason: ', e.reason)
         elif hasattr(e, 'code'):
             print('The server couldn\'t fulfill the request.')
             print('Error code: ', e.code)
     else:
         # everything is fine


File: python.info,  Node: info and geturl,  Next: Openers and Handlers,  Prev: Handling Exceptions<2>,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.4 info and geturl
-----------------------

The response returned by urlopen (or the ‘HTTPError’ instance) has two
useful methods ‘info()’ and ‘geturl()’ and is defined in the module
*note urllib.response: 11e..

`geturl' - this returns the real URL of the page fetched.  This is
useful because ‘urlopen’ (or the opener object used) may have followed a
redirect.  The URL of the page fetched may not be the same as the URL
requested.

`info' - this returns a dictionary-like object that describes the page
fetched, particularly the headers sent by the server.  It is currently
an ‘http.client.HTTPMessage’ instance.

Typical headers include ’Content-length’, ’Content-type’, and so on.
See the Quick Reference to HTTP Headers(1) for a useful listing of HTTP
headers with brief explanations of their meaning and use.

   ---------- Footnotes ----------

   (1) http://www.cs.tut.fi/~jkorpela/http.html


File: python.info,  Node: Openers and Handlers,  Next: Basic Authentication,  Prev: info and geturl,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.5 Openers and Handlers
----------------------------

When you fetch a URL you use an opener (an instance of the perhaps
confusingly-named *note urllib.request.OpenerDirector: 24e8.).  Normally
we have been using the default opener - via ‘urlopen’ - but you can
create custom openers.  Openers use handlers.  All the "heavy lifting"
is done by the handlers.  Each handler knows how to open URLs for a
particular URL scheme (http, ftp, etc.), or how to handle an aspect of
URL opening, for example HTTP redirections or HTTP cookies.

You will want to create openers if you want to fetch URLs with specific
handlers installed, for example to get an opener that handles cookies,
or to get an opener that does not handle redirections.

To create an opener, instantiate an ‘OpenerDirector’, and then call
‘.add_handler(some_handler_instance)’ repeatedly.

Alternatively, you can use ‘build_opener’, which is a convenience
function for creating opener objects with a single function call.
‘build_opener’ adds several handlers by default, but provides a quick
way to add more and/or override the default handlers.

Other sorts of handlers you might want to can handle proxies,
authentication, and other common but slightly specialised situations.

‘install_opener’ can be used to make an ‘opener’ object the (global)
default opener.  This means that calls to ‘urlopen’ will use the opener
you have installed.

Opener objects have an ‘open’ method, which can be called directly to
fetch urls in the same way as the ‘urlopen’ function: there’s no need to
call ‘install_opener’, except as a convenience.


File: python.info,  Node: Basic Authentication,  Next: Proxies,  Prev: Openers and Handlers,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.6 Basic Authentication
----------------------------

To illustrate creating and installing a handler we will use the
‘HTTPBasicAuthHandler’.  For a more detailed discussion of this subject
– including an explanation of how Basic Authentication works - see the
Basic Authentication Tutorial(1).

When authentication is required, the server sends a header (as well as
the 401 error code) requesting authentication.  This specifies the
authentication scheme and a ’realm’.  The header looks like:
‘WWW-Authenticate: SCHEME realm="REALM"’.

e.g.

     WWW-Authenticate: Basic realm="cPanel Users"

The client should then retry the request with the appropriate name and
password for the realm included as a header in the request.  This is
’basic authentication’.  In order to simplify this process we can create
an instance of ‘HTTPBasicAuthHandler’ and an opener to use this handler.

The ‘HTTPBasicAuthHandler’ uses an object called a password manager to
handle the mapping of URLs and realms to passwords and usernames.  If
you know what the realm is (from the authentication header sent by the
server), then you can use a ‘HTTPPasswordMgr’.  Frequently one doesn’t
care what the realm is.  In that case, it is convenient to use
‘HTTPPasswordMgrWithDefaultRealm’.  This allows you to specify a default
username and password for a URL. This will be supplied in the absence of
you providing an alternative combination for a specific realm.  We
indicate this by providing ‘None’ as the realm argument to the
‘add_password’ method.

The top-level URL is the first URL that requires authentication.  URLs
"deeper" than the URL you pass to .add_password() will also match.

     # create a password manager
     password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()

     # Add the username and password.
     # If we knew the realm, we could use it instead of None.
     top_level_url = "http://example.com/foo/"
     password_mgr.add_password(None, top_level_url, username, password)

     handler = urllib.request.HTTPBasicAuthHandler(password_mgr)

     # create "opener" (OpenerDirector instance)
     opener = urllib.request.build_opener(handler)

     # use the opener to fetch a URL
     opener.open(a_url)

     # Install the opener.
     # Now all calls to urllib.request.urlopen use our opener.
     urllib.request.install_opener(opener)

     Note: In the above example we only supplied our
     ‘HTTPBasicAuthHandler’ to ‘build_opener’.  By default openers have
     the handlers for normal situations – ‘ProxyHandler’ (if a proxy
     setting such as an ‘http_proxy’ environment variable is set),
     ‘UnknownHandler’, ‘HTTPHandler’, ‘HTTPDefaultErrorHandler’,
     ‘HTTPRedirectHandler’, ‘FTPHandler’, ‘FileHandler’, ‘DataHandler’,
     ‘HTTPErrorProcessor’.

‘top_level_url’ is in fact `either' a full URL (including the ’http:’
scheme component and the hostname and optionally the port number) e.g.
"‘http://example.com/’" `or' an "authority" (i.e.  the hostname,
optionally including the port number) e.g.  "example.com" or
"example.com:8080" (the latter example includes a port number).  The
authority, if present, must NOT contain the "userinfo" component - for
example "joe:password@example.com" is not correct.

   ---------- Footnotes ----------

   (1) http://www.voidspace.org.uk/python/articles/authentication.shtml


File: python.info,  Node: Proxies,  Next: Sockets and Layers,  Prev: Basic Authentication,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.7 Proxies
---------------

`urllib' will auto-detect your proxy settings and use those.  This is
through the ‘ProxyHandler’, which is part of the normal handler chain
when a proxy setting is detected.  Normally that’s a good thing, but
there are occasions when it may not be helpful (1).  One way to do this
is to setup our own ‘ProxyHandler’, with no proxies defined.  This is
done using similar steps to setting up a Basic Authentication(2)
handler:

     >>> proxy_support = urllib.request.ProxyHandler({})
     >>> opener = urllib.request.build_opener(proxy_support)
     >>> urllib.request.install_opener(opener)

     Note: Currently ‘urllib.request’ `does not' support fetching of
     ‘https’ locations through a proxy.  However, this can be enabled by
     extending urllib.request as shown in the recipe (3).

   ---------- Footnotes ----------

   (1) In my case I have to use a proxy to access the internet at work.
If you attempt to fetch `localhost' URLs through this proxy it blocks
them.  IE is set to use the proxy, which urllib picks up on.  In order
to test scripts with a localhost server, I have to prevent urllib from
using the proxy.

   (2) http://www.voidspace.org.uk/python/articles/authentication.shtml

   (3) urllib opener for SSL proxy (CONNECT method): ASPN Cookbook
Recipe (http://code.activestate.com/recipes/456195/).


File: python.info,  Node: Sockets and Layers,  Next: Footnotes,  Prev: Proxies,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.8 Sockets and Layers
--------------------------

The Python support for fetching resources from the web is layered.
urllib uses the *note http.client: 93. library, which in turn uses the
socket library.

As of Python 2.3 you can specify how long a socket should wait for a
response before timing out.  This can be useful in applications which
have to fetch web pages.  By default the socket module has `no timeout'
and can hang.  Currently, the socket timeout is not exposed at the
http.client or urllib.request levels.  However, you can set the default
timeout globally for all sockets using

     import socket
     import urllib.request

     # timeout in seconds
     timeout = 10
     socket.setdefaulttimeout(timeout)

     # this call to urllib.request.urlopen now uses the default timeout
     # we have set in the socket module
     req = urllib.request.Request('http://www.voidspace.org.uk')
     response = urllib.request.urlopen(req)

__________________________________________________________________


File: python.info,  Node: Footnotes,  Prev: Sockets and Layers,  Up: HOWTO Fetch Internet Resources Using The urllib Package

10.12.9 Footnotes
-----------------

This document was reviewed and revised by John Lee.


File: python.info,  Node: Argparse Tutorial,  Next: An introduction to the ipaddress module,  Prev: HOWTO Fetch Internet Resources Using The urllib Package,  Up: Python HOWTOs

10.13 Argparse Tutorial
=======================


author: Tshepang Lekhonkhobe

This tutorial is intended to be a gentle introduction to *note argparse:
6, the recommended command-line parsing module in the Python standard
library.

     Note: There are two other modules that fulfill the same task,
     namely *note getopt: 86. (an equivalent for ‘getopt()’ from the C
     language) and the deprecated *note optparse: c1.  Note also that
     *note argparse: 6. is based on *note optparse: c1, and therefore
     very similar in terms of usage.

* Menu:

* Concepts:: 
* The basics:: 
* Introducing Positional arguments:: 
* Introducing Optional arguments:: 
* Combining Positional and Optional arguments:: 
* Getting a little more advanced:: 
* Conclusion:: 


File: python.info,  Node: Concepts,  Next: The basics,  Up: Argparse Tutorial

10.13.1 Concepts
----------------

Let’s show the sort of functionality that we are going to explore in
this introductory tutorial by making use of the ‘ls’ command:

     $ ls
     cpython  devguide  prog.py  pypy  rm-unused-function.patch
     $ ls pypy
     ctypes_configure  demo  dotviewer  include  lib_pypy  lib-python ...
     $ ls -l
     total 20
     drwxr-xr-x 19 wena wena 4096 Feb 18 18:51 cpython
     drwxr-xr-x  4 wena wena 4096 Feb  8 12:04 devguide
     -rwxr-xr-x  1 wena wena  535 Feb 19 00:05 prog.py
     drwxr-xr-x 14 wena wena 4096 Feb  7 00:59 pypy
     -rw-r--r--  1 wena wena  741 Feb 18 01:01 rm-unused-function.patch
     $ ls --help
     Usage: ls [OPTION]... [FILE]...
     List information about the FILEs (the current directory by default).
     Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.
     ...

A few concepts we can learn from the four commands:

   * The ‘ls’ command is useful when run without any options at all.  It
     defaults to displaying the contents of the current directory.

   * If we want beyond what it provides by default, we tell it a bit
     more.  In this case, we want it to display a different directory,
     ‘pypy’.  What we did is specify what is known as a positional
     argument.  It’s named so because the program should know what to do
     with the value, solely based on where it appears on the command
     line.  This concept is more relevant to a command like ‘cp’, whose
     most basic usage is ‘cp SRC DEST’.  The first position is `what you
     want copied,' and the second position is `where you want it copied
     to'.

   * Now, say we want to change behaviour of the program.  In our
     example, we display more info for each file instead of just showing
     the file names.  The ‘-l’ in that case is known as an optional
     argument.

   * That’s a snippet of the help text.  It’s very useful in that you
     can come across a program you have never used before, and can
     figure out how it works simply by reading its help text.


File: python.info,  Node: The basics,  Next: Introducing Positional arguments,  Prev: Concepts,  Up: Argparse Tutorial

10.13.2 The basics
------------------

Let us start with a very simple example which does (almost) nothing:

     import argparse
     parser = argparse.ArgumentParser()
     parser.parse_args()

Following is a result of running the code:

     $ python3 prog.py
     $ python3 prog.py --help
     usage: prog.py [-h]

     optional arguments:
       -h, --help  show this help message and exit
     $ python3 prog.py --verbose
     usage: prog.py [-h]
     prog.py: error: unrecognized arguments: --verbose
     $ python3 prog.py foo
     usage: prog.py [-h]
     prog.py: error: unrecognized arguments: foo

Here is what is happening:

   * Running the script without any options results in nothing displayed
     to stdout.  Not so useful.

   * The second one starts to display the usefulness of the *note
     argparse: 6. module.  We have done almost nothing, but already we
     get a nice help message.

   * The ‘--help’ option, which can also be shortened to ‘-h’, is the
     only option we get for free (i.e.  no need to specify it).
     Specifying anything else results in an error.  But even then, we do
     get a useful usage message, also for free.


File: python.info,  Node: Introducing Positional arguments,  Next: Introducing Optional arguments,  Prev: The basics,  Up: Argparse Tutorial

10.13.3 Introducing Positional arguments
----------------------------------------

An example:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("echo")
     args = parser.parse_args()
     print(args.echo)

And running the code:

     $ python3 prog.py
     usage: prog.py [-h] echo
     prog.py: error: the following arguments are required: echo
     $ python3 prog.py --help
     usage: prog.py [-h] echo

     positional arguments:
       echo

     optional arguments:
       -h, --help  show this help message and exit
     $ python3 prog.py foo
     foo

Here is what’s happening:

   * We’ve added the ‘add_argument()’ method, which is what we use to
     specify which command-line options the program is willing to
     accept.  In this case, I’ve named it ‘echo’ so that it’s in line
     with its function.

   * Calling our program now requires us to specify an option.

   * The ‘parse_args()’ method actually returns some data from the
     options specified, in this case, ‘echo’.

   * The variable is some form of ’magic’ that *note argparse: 6.
     performs for free (i.e.  no need to specify which variable that
     value is stored in).  You will also notice that its name matches
     the string argument given to the method, ‘echo’.

Note however that, although the help display looks nice and all, it
currently is not as helpful as it can be.  For example we see that we
got ‘echo’ as a positional argument, but we don’t know what it does,
other than by guessing or by reading the source code.  So, let’s make it
a bit more useful:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("echo", help="echo the string you use here")
     args = parser.parse_args()
     print(args.echo)

And we get:

     $ python3 prog.py -h
     usage: prog.py [-h] echo

     positional arguments:
       echo        echo the string you use here

     optional arguments:
       -h, --help  show this help message and exit

Now, how about doing something even more useful:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", help="display a square of a given number")
     args = parser.parse_args()
     print(args.square**2)

Following is a result of running the code:

     $ python3 prog.py 4
     Traceback (most recent call last):
       File "prog.py", line 5, in <module>
         print(args.square**2)
     TypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'

That didn’t go so well.  That’s because *note argparse: 6. treats the
options we give it as strings, unless we tell it otherwise.  So, let’s
tell *note argparse: 6. to treat that input as an integer:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", help="display a square of a given number",
                         type=int)
     args = parser.parse_args()
     print(args.square**2)

Following is a result of running the code:

     $ python3 prog.py 4
     16
     $ python3 prog.py four
     usage: prog.py [-h] square
     prog.py: error: argument square: invalid int value: 'four'

That went well.  The program now even helpfully quits on bad illegal
input before proceeding.


File: python.info,  Node: Introducing Optional arguments,  Next: Combining Positional and Optional arguments,  Prev: Introducing Positional arguments,  Up: Argparse Tutorial

10.13.4 Introducing Optional arguments
--------------------------------------

So far we, have been playing with positional arguments.  Let us have a
look on how to add optional ones:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("--verbosity", help="increase output verbosity")
     args = parser.parse_args()
     if args.verbosity:
         print("verbosity turned on")

And the output:

     $ python3 prog.py --verbosity 1
     verbosity turned on
     $ python3 prog.py
     $ python3 prog.py --help
     usage: prog.py [-h] [--verbosity VERBOSITY]

     optional arguments:
       -h, --help            show this help message and exit
       --verbosity VERBOSITY
                             increase output verbosity
     $ python3 prog.py --verbosity
     usage: prog.py [-h] [--verbosity VERBOSITY]
     prog.py: error: argument --verbosity: expected one argument

Here is what is happening:

   * The program is written so as to display something when
     ‘--verbosity’ is specified and display nothing when not.

   * To show that the option is actually optional, there is no error
     when running the program without it.  Note that by default, if an
     optional argument isn’t used, the relevant variable, in this case
     ‘args.verbosity’, is given ‘None’ as a value, which is the reason
     it fails the truth test of the *note if: a65. statement.

   * The help message is a bit different.

   * When using the ‘--verbosity’ option, one must also specify some
     value, any value.

The above example accepts arbitrary integer values for ‘--verbosity’,
but for our simple program, only two values are actually useful, ‘True’
or ‘False’.  Let’s modify the code accordingly:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("--verbose", help="increase output verbosity",
                         action="store_true")
     args = parser.parse_args()
     if args.verbose:
         print("verbosity turned on")

And the output:

     $ python3 prog.py --verbose
     verbosity turned on
     $ python3 prog.py --verbose 1
     usage: prog.py [-h] [--verbose]
     prog.py: error: unrecognized arguments: 1
     $ python3 prog.py --help
     usage: prog.py [-h] [--verbose]

     optional arguments:
       -h, --help  show this help message and exit
       --verbose   increase output verbosity

Here is what is happening:

   * The option is now more of a flag than something that requires a
     value.  We even changed the name of the option to match that idea.
     Note that we now specify a new keyword, ‘action’, and give it the
     value ‘"store_true"’.  This means that, if the option is specified,
     assign the value ‘True’ to ‘args.verbose’.  Not specifying it
     implies ‘False’.

   * It complains when you specify a value, in true spirit of what flags
     actually are.

   * Notice the different help text.

* Menu:

* Short options:: 


File: python.info,  Node: Short options,  Up: Introducing Optional arguments

10.13.4.1 Short options
.......................

If you are familiar with command line usage, you will notice that I
haven’t yet touched on the topic of short versions of the options.  It’s
quite simple:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("-v", "--verbose", help="increase output verbosity",
                         action="store_true")
     args = parser.parse_args()
     if args.verbose:
         print("verbosity turned on")

And here goes:

     $ python3 prog.py -v
     verbosity turned on
     $ python3 prog.py --help
     usage: prog.py [-h] [-v]

     optional arguments:
       -h, --help     show this help message and exit
       -v, --verbose  increase output verbosity

Note that the new ability is also reflected in the help text.


File: python.info,  Node: Combining Positional and Optional arguments,  Next: Getting a little more advanced,  Prev: Introducing Optional arguments,  Up: Argparse Tutorial

10.13.5 Combining Positional and Optional arguments
---------------------------------------------------

Our program keeps growing in complexity:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", type=int,
                         help="display a square of a given number")
     parser.add_argument("-v", "--verbose", action="store_true",
                         help="increase output verbosity")
     args = parser.parse_args()
     answer = args.square**2
     if args.verbose:
         print("the square of {} equals {}".format(args.square, answer))
     else:
         print(answer)

And now the output:

     $ python3 prog.py
     usage: prog.py [-h] [-v] square
     prog.py: error: the following arguments are required: square
     $ python3 prog.py 4
     16
     $ python3 prog.py 4 --verbose
     the square of 4 equals 16
     $ python3 prog.py --verbose 4
     the square of 4 equals 16

   * We’ve brought back a positional argument, hence the complaint.

   * Note that the order does not matter.

How about we give this program of ours back the ability to have multiple
verbosity values, and actually get to use them:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", type=int,
                         help="display a square of a given number")
     parser.add_argument("-v", "--verbosity", type=int,
                         help="increase output verbosity")
     args = parser.parse_args()
     answer = args.square**2
     if args.verbosity == 2:
         print("the square of {} equals {}".format(args.square, answer))
     elif args.verbosity == 1:
         print("{}^2 == {}".format(args.square, answer))
     else:
         print(answer)

And the output:

     $ python3 prog.py 4
     16
     $ python3 prog.py 4 -v
     usage: prog.py [-h] [-v VERBOSITY] square
     prog.py: error: argument -v/--verbosity: expected one argument
     $ python3 prog.py 4 -v 1
     4^2 == 16
     $ python3 prog.py 4 -v 2
     the square of 4 equals 16
     $ python3 prog.py 4 -v 3
     16

These all look good except the last one, which exposes a bug in our
program.  Let’s fix it by restricting the values the ‘--verbosity’
option can accept:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", type=int,
                         help="display a square of a given number")
     parser.add_argument("-v", "--verbosity", type=int, choices=[0, 1, 2],
                         help="increase output verbosity")
     args = parser.parse_args()
     answer = args.square**2
     if args.verbosity == 2:
         print("the square of {} equals {}".format(args.square, answer))
     elif args.verbosity == 1:
         print("{}^2 == {}".format(args.square, answer))
     else:
         print(answer)

And the output:

     $ python3 prog.py 4 -v 3
     usage: prog.py [-h] [-v {0,1,2}] square
     prog.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)
     $ python3 prog.py 4 -h
     usage: prog.py [-h] [-v {0,1,2}] square

     positional arguments:
       square                display a square of a given number

     optional arguments:
       -h, --help            show this help message and exit
       -v {0,1,2}, --verbosity {0,1,2}
                             increase output verbosity

Note that the change also reflects both in the error message as well as
the help string.

Now, let’s use a different approach of playing with verbosity, which is
pretty common.  It also matches the way the CPython executable handles
its own verbosity argument (check the output of ‘python --help’):

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", type=int,
                         help="display the square of a given number")
     parser.add_argument("-v", "--verbosity", action="count",
                         help="increase output verbosity")
     args = parser.parse_args()
     answer = args.square**2
     if args.verbosity == 2:
         print("the square of {} equals {}".format(args.square, answer))
     elif args.verbosity == 1:
         print("{}^2 == {}".format(args.square, answer))
     else:
         print(answer)

We have introduced another action, "count", to count the number of
occurrences of a specific optional arguments:

     $ python3 prog.py 4
     16
     $ python3 prog.py 4 -v
     4^2 == 16
     $ python3 prog.py 4 -vv
     the square of 4 equals 16
     $ python3 prog.py 4 --verbosity --verbosity
     the square of 4 equals 16
     $ python3 prog.py 4 -v 1
     usage: prog.py [-h] [-v] square
     prog.py: error: unrecognized arguments: 1
     $ python3 prog.py 4 -h
     usage: prog.py [-h] [-v] square

     positional arguments:
       square           display a square of a given number

     optional arguments:
       -h, --help       show this help message and exit
       -v, --verbosity  increase output verbosity
     $ python3 prog.py 4 -vvv
     16

   * Yes, it’s now more of a flag (similar to ‘action="store_true"’) in
     the previous version of our script.  That should explain the
     complaint.

   * It also behaves similar to "store_true" action.

   * Now here’s a demonstration of what the "count" action gives.
     You’ve probably seen this sort of usage before.

   * And, just like the "store_true" action, if you don’t specify the
     ‘-v’ flag, that flag is considered to have ‘None’ value.

   * As should be expected, specifying the long form of the flag, we
     should get the same output.

   * Sadly, our help output isn’t very informative on the new ability
     our script has acquired, but that can always be fixed by improving
     the documentation for our script (e.g.  via the ‘help’ keyword
     argument).

   * That last output exposes a bug in our program.

Let’s fix:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", type=int,
                         help="display a square of a given number")
     parser.add_argument("-v", "--verbosity", action="count",
                         help="increase output verbosity")
     args = parser.parse_args()
     answer = args.square**2

     # bugfix: replace == with >=
     if args.verbosity >= 2:
         print("the square of {} equals {}".format(args.square, answer))
     elif args.verbosity >= 1:
         print("{}^2 == {}".format(args.square, answer))
     else:
         print(answer)

And this is what it gives:

     $ python3 prog.py 4 -vvv
     the square of 4 equals 16
     $ python3 prog.py 4 -vvvv
     the square of 4 equals 16
     $ python3 prog.py 4
     Traceback (most recent call last):
       File "prog.py", line 11, in <module>
         if args.verbosity >= 2:
     TypeError: '>=' not supported between instances of 'NoneType' and 'int'

   * First output went well, and fixes the bug we had before.  That is,
     we want any value >= 2 to be as verbose as possible.

   * Third output not so good.

Let’s fix that bug:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("square", type=int,
                         help="display a square of a given number")
     parser.add_argument("-v", "--verbosity", action="count", default=0,
                         help="increase output verbosity")
     args = parser.parse_args()
     answer = args.square**2
     if args.verbosity >= 2:
         print("the square of {} equals {}".format(args.square, answer))
     elif args.verbosity >= 1:
         print("{}^2 == {}".format(args.square, answer))
     else:
         print(answer)

We’ve just introduced yet another keyword, ‘default’.  We’ve set it to
‘0’ in order to make it comparable to the other int values.  Remember
that by default, if an optional argument isn’t specified, it gets the
‘None’ value, and that cannot be compared to an int value (hence the
*note TypeError: 562. exception).

And:

     $ python3 prog.py 4
     16

You can go quite far just with what we’ve learned so far, and we have
only scratched the surface.  The *note argparse: 6. module is very
powerful, and we’ll explore a bit more of it before we end this
tutorial.


File: python.info,  Node: Getting a little more advanced,  Next: Conclusion,  Prev: Combining Positional and Optional arguments,  Up: Argparse Tutorial

10.13.6 Getting a little more advanced
--------------------------------------

What if we wanted to expand our tiny program to perform other powers,
not just squares:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("x", type=int, help="the base")
     parser.add_argument("y", type=int, help="the exponent")
     parser.add_argument("-v", "--verbosity", action="count", default=0)
     args = parser.parse_args()
     answer = args.x**args.y
     if args.verbosity >= 2:
         print("{} to the power {} equals {}".format(args.x, args.y, answer))
     elif args.verbosity >= 1:
         print("{}^{} == {}".format(args.x, args.y, answer))
     else:
         print(answer)

Output:

     $ python3 prog.py
     usage: prog.py [-h] [-v] x y
     prog.py: error: the following arguments are required: x, y
     $ python3 prog.py -h
     usage: prog.py [-h] [-v] x y

     positional arguments:
       x                the base
       y                the exponent

     optional arguments:
       -h, --help       show this help message and exit
       -v, --verbosity
     $ python3 prog.py 4 2 -v
     4^2 == 16

Notice that so far we’ve been using verbosity level to `change' the text
that gets displayed.  The following example instead uses verbosity level
to display `more' text instead:

     import argparse
     parser = argparse.ArgumentParser()
     parser.add_argument("x", type=int, help="the base")
     parser.add_argument("y", type=int, help="the exponent")
     parser.add_argument("-v", "--verbosity", action="count", default=0)
     args = parser.parse_args()
     answer = args.x**args.y
     if args.verbosity >= 2:
         print("Running '{}'".format(__file__))
     if args.verbosity >= 1:
         print("{}^{} == ".format(args.x, args.y), end="")
     print(answer)

Output:

     $ python3 prog.py 4 2
     16
     $ python3 prog.py 4 2 -v
     4^2 == 16
     $ python3 prog.py 4 2 -vv
     Running 'prog.py'
     4^2 == 16

* Menu:

* Conflicting options:: 


File: python.info,  Node: Conflicting options,  Up: Getting a little more advanced

10.13.6.1 Conflicting options
.............................

So far, we have been working with two methods of an *note
argparse.ArgumentParser: 22f. instance.  Let’s introduce a third one,
‘add_mutually_exclusive_group()’.  It allows for us to specify options
that conflict with each other.  Let’s also change the rest of the
program so that the new functionality makes more sense: we’ll introduce
the ‘--quiet’ option, which will be the opposite of the ‘--verbose’ one:

     import argparse

     parser = argparse.ArgumentParser()
     group = parser.add_mutually_exclusive_group()
     group.add_argument("-v", "--verbose", action="store_true")
     group.add_argument("-q", "--quiet", action="store_true")
     parser.add_argument("x", type=int, help="the base")
     parser.add_argument("y", type=int, help="the exponent")
     args = parser.parse_args()
     answer = args.x**args.y

     if args.quiet:
         print(answer)
     elif args.verbose:
         print("{} to the power {} equals {}".format(args.x, args.y, answer))
     else:
         print("{}^{} == {}".format(args.x, args.y, answer))

Our program is now simpler, and we’ve lost some functionality for the
sake of demonstration.  Anyways, here’s the output:

     $ python3 prog.py 4 2
     4^2 == 16
     $ python3 prog.py 4 2 -q
     16
     $ python3 prog.py 4 2 -v
     4 to the power 2 equals 16
     $ python3 prog.py 4 2 -vq
     usage: prog.py [-h] [-v | -q] x y
     prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose
     $ python3 prog.py 4 2 -v --quiet
     usage: prog.py [-h] [-v | -q] x y
     prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose

That should be easy to follow.  I’ve added that last output so you can
see the sort of flexibility you get, i.e.  mixing long form options with
short form ones.

Before we conclude, you probably want to tell your users the main
purpose of your program, just in case they don’t know:

     import argparse

     parser = argparse.ArgumentParser(description="calculate X to the power of Y")
     group = parser.add_mutually_exclusive_group()
     group.add_argument("-v", "--verbose", action="store_true")
     group.add_argument("-q", "--quiet", action="store_true")
     parser.add_argument("x", type=int, help="the base")
     parser.add_argument("y", type=int, help="the exponent")
     args = parser.parse_args()
     answer = args.x**args.y

     if args.quiet:
         print(answer)
     elif args.verbose:
         print("{} to the power {} equals {}".format(args.x, args.y, answer))
     else:
         print("{}^{} == {}".format(args.x, args.y, answer))

Note that slight difference in the usage text.  Note the ‘[-v | -q]’,
which tells us that we can either use ‘-v’ or ‘-q’, but not both at the
same time:

     $ python3 prog.py --help
     usage: prog.py [-h] [-v | -q] x y

     calculate X to the power of Y

     positional arguments:
       x              the base
       y              the exponent

     optional arguments:
       -h, --help     show this help message and exit
       -v, --verbose
       -q, --quiet


File: python.info,  Node: Conclusion,  Prev: Getting a little more advanced,  Up: Argparse Tutorial

10.13.7 Conclusion
------------------

The *note argparse: 6. module offers a lot more than shown here.  Its
docs are quite detailed and thorough, and full of examples.  Having gone
through this tutorial, you should easily digest them without feeling
overwhelmed.


File: python.info,  Node: An introduction to the ipaddress module,  Next: Argument Clinic How-To,  Prev: Argparse Tutorial,  Up: Python HOWTOs

10.14 An introduction to the ipaddress module
=============================================


author: Peter Moody


author: Nick Coghlan

Overview
........

This document aims to provide a gentle introduction to the *note
ipaddress: a0. module.  It is aimed primarily at users that aren’t
already familiar with IP networking terminology, but may also be useful
to network engineers wanting an overview of how *note ipaddress: a0.
represents IP network addressing concepts.

* Menu:

* Creating Address/Network/Interface objects:: 
* Inspecting Address/Network/Interface Objects:: 
* Networks as lists of Addresses:: 
* Comparisons: Comparisons<4>. 
* Using IP Addresses with other modules:: 
* Getting more detail when instance creation fails:: 


File: python.info,  Node: Creating Address/Network/Interface objects,  Next: Inspecting Address/Network/Interface Objects,  Up: An introduction to the ipaddress module

10.14.1 Creating Address/Network/Interface objects
--------------------------------------------------

Since *note ipaddress: a0. is a module for inspecting and manipulating
IP addresses, the first thing you’ll want to do is create some objects.
You can use *note ipaddress: a0. to create objects from strings and
integers.

* Menu:

* A Note on IP Versions:: 
* IP Host Addresses:: 
* Defining Networks:: 
* Host Interfaces:: 


File: python.info,  Node: A Note on IP Versions,  Next: IP Host Addresses,  Up: Creating Address/Network/Interface objects

10.14.1.1 A Note on IP Versions
...............................

For readers that aren’t particularly familiar with IP addressing, it’s
important to know that the Internet Protocol is currently in the process
of moving from version 4 of the protocol to version 6.  This transition
is occurring largely because version 4 of the protocol doesn’t provide
enough addresses to handle the needs of the whole world, especially
given the increasing number of devices with direct connections to the
internet.

Explaining the details of the differences between the two versions of
the protocol is beyond the scope of this introduction, but readers need
to at least be aware that these two versions exist, and it will
sometimes be necessary to force the use of one version or the other.


File: python.info,  Node: IP Host Addresses,  Next: Defining Networks,  Prev: A Note on IP Versions,  Up: Creating Address/Network/Interface objects

10.14.1.2 IP Host Addresses
...........................

Addresses, often referred to as "host addresses" are the most basic unit
when working with IP addressing.  The simplest way to create addresses
is to use the *note ipaddress.ip_address(): 27bc. factory function,
which automatically determines whether to create an IPv4 or IPv6 address
based on the passed in value:

     >>> ipaddress.ip_address('192.0.2.1')
     IPv4Address('192.0.2.1')
     >>> ipaddress.ip_address('2001:DB8::1')
     IPv6Address('2001:db8::1')

Addresses can also be created directly from integers.  Values that will
fit within 32 bits are assumed to be IPv4 addresses:

     >>> ipaddress.ip_address(3221225985)
     IPv4Address('192.0.2.1')
     >>> ipaddress.ip_address(42540766411282592856903984951653826561)
     IPv6Address('2001:db8::1')

To force the use of IPv4 or IPv6 addresses, the relevant classes can be
invoked directly.  This is particularly useful to force creation of IPv6
addresses for small integers:

     >>> ipaddress.ip_address(1)
     IPv4Address('0.0.0.1')
     >>> ipaddress.IPv4Address(1)
     IPv4Address('0.0.0.1')
     >>> ipaddress.IPv6Address(1)
     IPv6Address('::1')


File: python.info,  Node: Defining Networks,  Next: Host Interfaces,  Prev: IP Host Addresses,  Up: Creating Address/Network/Interface objects

10.14.1.3 Defining Networks
...........................

Host addresses are usually grouped together into IP networks, so *note
ipaddress: a0. provides a way to create, inspect and manipulate network
definitions.  IP network objects are constructed from strings that
define the range of host addresses that are part of that network.  The
simplest form for that information is a "network address/network prefix"
pair, where the prefix defines the number of leading bits that are
compared to determine whether or not an address is part of the network
and the network address defines the expected value of those bits.

As for addresses, a factory function is provided that determines the
correct IP version automatically:

     >>> ipaddress.ip_network('192.0.2.0/24')
     IPv4Network('192.0.2.0/24')
     >>> ipaddress.ip_network('2001:db8::0/96')
     IPv6Network('2001:db8::/96')

Network objects cannot have any host bits set.  The practical effect of
this is that ‘192.0.2.1/24’ does not describe a network.  Such
definitions are referred to as interface objects since the
ip-on-a-network notation is commonly used to describe network interfaces
of a computer on a given network and are described further in the next
section.

By default, attempting to create a network object with host bits set
will result in *note ValueError: 19c. being raised.  To request that the
additional bits instead be coerced to zero, the flag ‘strict=False’ can
be passed to the constructor:

     >>> ipaddress.ip_network('192.0.2.1/24')
     Traceback (most recent call last):
        ...
     ValueError: 192.0.2.1/24 has host bits set
     >>> ipaddress.ip_network('192.0.2.1/24', strict=False)
     IPv4Network('192.0.2.0/24')

While the string form offers significantly more flexibility, networks
can also be defined with integers, just like host addresses.  In this
case, the network is considered to contain only the single address
identified by the integer, so the network prefix includes the entire
network address:

     >>> ipaddress.ip_network(3221225984)
     IPv4Network('192.0.2.0/32')
     >>> ipaddress.ip_network(42540766411282592856903984951653826560)
     IPv6Network('2001:db8::/128')

As with addresses, creation of a particular kind of network can be
forced by calling the class constructor directly instead of using the
factory function.


File: python.info,  Node: Host Interfaces,  Prev: Defining Networks,  Up: Creating Address/Network/Interface objects

10.14.1.4 Host Interfaces
.........................

As mentioned just above, if you need to describe an address on a
particular network, neither the address nor the network classes are
sufficient.  Notation like ‘192.0.2.1/24’ is commonly used by network
engineers and the people who write tools for firewalls and routers as
shorthand for "the host ‘192.0.2.1’ on the network ‘192.0.2.0/24’",
Accordingly, *note ipaddress: a0. provides a set of hybrid classes that
associate an address with a particular network.  The interface for
creation is identical to that for defining network objects, except that
the address portion isn’t constrained to being a network address.

     >>> ipaddress.ip_interface('192.0.2.1/24')
     IPv4Interface('192.0.2.1/24')
     >>> ipaddress.ip_interface('2001:db8::1/96')
     IPv6Interface('2001:db8::1/96')

Integer inputs are accepted (as with networks), and use of a particular
IP version can be forced by calling the relevant constructor directly.


File: python.info,  Node: Inspecting Address/Network/Interface Objects,  Next: Networks as lists of Addresses,  Prev: Creating Address/Network/Interface objects,  Up: An introduction to the ipaddress module

10.14.2 Inspecting Address/Network/Interface Objects
----------------------------------------------------

You’ve gone to the trouble of creating an
IPv(4|6)(Address|Network|Interface) object, so you probably want to get
information about it.  *note ipaddress: a0. tries to make doing this
easy and intuitive.

Extracting the IP version:

     >>> addr4 = ipaddress.ip_address('192.0.2.1')
     >>> addr6 = ipaddress.ip_address('2001:db8::1')
     >>> addr6.version
     6
     >>> addr4.version
     4

Obtaining the network from an interface:

     >>> host4 = ipaddress.ip_interface('192.0.2.1/24')
     >>> host4.network
     IPv4Network('192.0.2.0/24')
     >>> host6 = ipaddress.ip_interface('2001:db8::1/96')
     >>> host6.network
     IPv6Network('2001:db8::/96')

Finding out how many individual addresses are in a network:

     >>> net4 = ipaddress.ip_network('192.0.2.0/24')
     >>> net4.num_addresses
     256
     >>> net6 = ipaddress.ip_network('2001:db8::0/96')
     >>> net6.num_addresses
     4294967296

Iterating through the "usable" addresses on a network:

     >>> net4 = ipaddress.ip_network('192.0.2.0/24')
     >>> for x in net4.hosts():
     ...     print(x)  # doctest: +ELLIPSIS
     192.0.2.1
     192.0.2.2
     192.0.2.3
     192.0.2.4
     ...
     192.0.2.252
     192.0.2.253
     192.0.2.254

Obtaining the netmask (i.e.  set bits corresponding to the network
prefix) or the hostmask (any bits that are not part of the netmask):

     >>> net4 = ipaddress.ip_network('192.0.2.0/24')
     >>> net4.netmask
     IPv4Address('255.255.255.0')
     >>> net4.hostmask
     IPv4Address('0.0.0.255')
     >>> net6 = ipaddress.ip_network('2001:db8::0/96')
     >>> net6.netmask
     IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff::')
     >>> net6.hostmask
     IPv6Address('::ffff:ffff')

Exploding or compressing the address:

     >>> addr6.exploded
     '2001:0db8:0000:0000:0000:0000:0000:0001'
     >>> addr6.compressed
     '2001:db8::1'
     >>> net6.exploded
     '2001:0db8:0000:0000:0000:0000:0000:0000/96'
     >>> net6.compressed
     '2001:db8::/96'

While IPv4 doesn’t support explosion or compression, the associated
objects still provide the relevant properties so that version neutral
code can easily ensure the most concise or most verbose form is used for
IPv6 addresses while still correctly handling IPv4 addresses.


File: python.info,  Node: Networks as lists of Addresses,  Next: Comparisons<4>,  Prev: Inspecting Address/Network/Interface Objects,  Up: An introduction to the ipaddress module

10.14.3 Networks as lists of Addresses
--------------------------------------

It’s sometimes useful to treat networks as lists.  This means it is
possible to index them like this:

     >>> net4[1]
     IPv4Address('192.0.2.1')
     >>> net4[-1]
     IPv4Address('192.0.2.255')
     >>> net6[1]
     IPv6Address('2001:db8::1')
     >>> net6[-1]
     IPv6Address('2001:db8::ffff:ffff')

It also means that network objects lend themselves to using the list
membership test syntax like this:

     if address in network:
         # do something

Containment testing is done efficiently based on the network prefix:

     >>> addr4 = ipaddress.ip_address('192.0.2.1')
     >>> addr4 in ipaddress.ip_network('192.0.2.0/24')
     True
     >>> addr4 in ipaddress.ip_network('192.0.3.0/24')
     False


File: python.info,  Node: Comparisons<4>,  Next: Using IP Addresses with other modules,  Prev: Networks as lists of Addresses,  Up: An introduction to the ipaddress module

10.14.4 Comparisons
-------------------

*note ipaddress: a0. provides some simple, hopefully intuitive ways to
compare objects, where it makes sense:

     >>> ipaddress.ip_address('192.0.2.1') < ipaddress.ip_address('192.0.2.2')
     True

A *note TypeError: 562. exception is raised if you try to compare
objects of different versions or different types.


File: python.info,  Node: Using IP Addresses with other modules,  Next: Getting more detail when instance creation fails,  Prev: Comparisons<4>,  Up: An introduction to the ipaddress module

10.14.5 Using IP Addresses with other modules
---------------------------------------------

Other modules that use IP addresses (such as *note socket: ed.) usually
won’t accept objects from this module directly.  Instead, they must be
coerced to an integer or string that the other module will accept:

     >>> addr4 = ipaddress.ip_address('192.0.2.1')
     >>> str(addr4)
     '192.0.2.1'
     >>> int(addr4)
     3221225985


File: python.info,  Node: Getting more detail when instance creation fails,  Prev: Using IP Addresses with other modules,  Up: An introduction to the ipaddress module

10.14.6 Getting more detail when instance creation fails
--------------------------------------------------------

When creating address/network/interface objects using the
version-agnostic factory functions, any errors will be reported as *note
ValueError: 19c. with a generic error message that simply says the
passed in value was not recognized as an object of that type.  The lack
of a specific error is because it’s necessary to know whether the value
is `supposed' to be IPv4 or IPv6 in order to provide more detail on why
it has been rejected.

To support use cases where it is useful to have access to this
additional detail, the individual class constructors actually raise the
*note ValueError: 19c. subclasses *note ipaddress.AddressValueError:
27c5. and *note ipaddress.NetmaskValueError: 27ea. to indicate exactly
which part of the definition failed to parse correctly.

The error messages are significantly more detailed when using the class
constructors directly.  For example:

     >>> ipaddress.ip_address("192.168.0.256")
     Traceback (most recent call last):
       ...
     ValueError: '192.168.0.256' does not appear to be an IPv4 or IPv6 address
     >>> ipaddress.IPv4Address("192.168.0.256")
     Traceback (most recent call last):
       ...
     ipaddress.AddressValueError: Octet 256 (> 255) not permitted in '192.168.0.256'

     >>> ipaddress.ip_network("192.168.0.1/64")
     Traceback (most recent call last):
       ...
     ValueError: '192.168.0.1/64' does not appear to be an IPv4 or IPv6 network
     >>> ipaddress.IPv4Network("192.168.0.1/64")
     Traceback (most recent call last):
       ...
     ipaddress.NetmaskValueError: '64' is not a valid netmask

However, both of the module specific exceptions have *note ValueError:
19c. as their parent class, so if you’re not concerned with the
particular type of error, you can still write code like the following:

     try:
         network = ipaddress.IPv4Network(address)
     except ValueError:
         print('address/netmask is invalid for IPv4:', address)


File: python.info,  Node: Argument Clinic How-To,  Prev: An introduction to the ipaddress module,  Up: Python HOWTOs

10.15 Argument Clinic How-To
============================


author: Larry Hastings

Abstract
........

Argument Clinic is a preprocessor for CPython C files.  Its purpose is
to automate all the boilerplate involved with writing argument parsing
code for "builtins".  This document shows you how to convert your first
C function to work with Argument Clinic, and then introduces some
advanced topics on Argument Clinic usage.

Currently Argument Clinic is considered internal-only for CPython.  Its
use is not supported for files outside CPython, and no guarantees are
made regarding backwards compatibility for future versions.  In other
words: if you maintain an external C extension for CPython, you’re
welcome to experiment with Argument Clinic in your own code.  But the
version of Argument Clinic that ships with CPython 3.5 `could' be
totally incompatible and break all your code.

* Menu:

* The Goals Of Argument Clinic:: 
* Basic Concepts And Usage:: 
* Converting Your First Function:: 
* Advanced Topics:: 


File: python.info,  Node: The Goals Of Argument Clinic,  Next: Basic Concepts And Usage,  Up: Argument Clinic How-To

10.15.1 The Goals Of Argument Clinic
------------------------------------

Argument Clinic’s primary goal is to take over responsibility for all
argument parsing code inside CPython.  This means that, when you convert
a function to work with Argument Clinic, that function should no longer
do any of its own argument parsing–the code generated by Argument Clinic
should be a "black box" to you, where CPython calls in at the top, and
your code gets called at the bottom, with ‘PyObject *args’ (and maybe
‘PyObject *kwargs’) magically converted into the C variables and types
you need.

In order for Argument Clinic to accomplish its primary goal, it must be
easy to use.  Currently, working with CPython’s argument parsing library
is a chore, requiring maintaining redundant information in a surprising
number of places.  When you use Argument Clinic, you don’t have to
repeat yourself.

Obviously, no one would want to use Argument Clinic unless it’s solving
their problem–and without creating new problems of its own.  So it’s
paramount that Argument Clinic generate correct code.  It’d be nice if
the code was faster, too, but at the very least it should not introduce
a major speed regression.  (Eventually Argument Clinic `should' make a
major speedup possible–we could rewrite its code generator to produce
tailor-made argument parsing code, rather than calling the
general-purpose CPython argument parsing library.  That would make for
the fastest argument parsing possible!)

Additionally, Argument Clinic must be flexible enough to work with any
approach to argument parsing.  Python has some functions with some very
strange parsing behaviors; Argument Clinic’s goal is to support all of
them.

Finally, the original motivation for Argument Clinic was to provide
introspection "signatures" for CPython builtins.  It used to be, the
introspection query functions would throw an exception if you passed in
a builtin.  With Argument Clinic, that’s a thing of the past!

One idea you should keep in mind, as you work with Argument Clinic: the
more information you give it, the better job it’ll be able to do.
Argument Clinic is admittedly relatively simple right now.  But as it
evolves it will get more sophisticated, and it should be able to do many
interesting and smart things with all the information you give it.


File: python.info,  Node: Basic Concepts And Usage,  Next: Converting Your First Function,  Prev: The Goals Of Argument Clinic,  Up: Argument Clinic How-To

10.15.2 Basic Concepts And Usage
--------------------------------

Argument Clinic ships with CPython; you’ll find it in
‘Tools/clinic/clinic.py’.  If you run that script, specifying a C file
as an argument:

     % python3 Tools/clinic/clinic.py foo.c

Argument Clinic will scan over the file looking for lines that look
exactly like this:

     /*[clinic input]

When it finds one, it reads everything up to a line that looks exactly
like this:

     [clinic start generated code]*/

Everything in between these two lines is input for Argument Clinic.  All
of these lines, including the beginning and ending comment lines, are
collectively called an Argument Clinic "block".

When Argument Clinic parses one of these blocks, it generates output.
This output is rewritten into the C file immediately after the block,
followed by a comment containing a checksum.  The Argument Clinic block
now looks like this:

     /*[clinic input]
     ... clinic input goes here ...
     [clinic start generated code]*/
     ... clinic output goes here ...
     /*[clinic end generated code: checksum=...]*/

If you run Argument Clinic on the same file a second time, Argument
Clinic will discard the old output and write out the new output with a
fresh checksum line.  However, if the input hasn’t changed, the output
won’t change either.

You should never modify the output portion of an Argument Clinic block.
Instead, change the input until it produces the output you want.
(That’s the purpose of the checksum–to detect if someone changed the
output, as these edits would be lost the next time Argument Clinic
writes out fresh output.)

For the sake of clarity, here’s the terminology we’ll use with Argument
Clinic:

   * The first line of the comment (‘/*[clinic input]’) is the `start
     line'.

   * The last line of the initial comment (‘[clinic start generated
     code]*/’) is the `end line'.

   * The last line (‘/*[clinic end generated code: checksum=...]*/’) is
     the `checksum line'.

   * In between the start line and the end line is the `input'.

   * In between the end line and the checksum line is the `output'.

   * All the text collectively, from the start line to the checksum line
     inclusively, is the `block'.  (A block that hasn’t been
     successfully processed by Argument Clinic yet doesn’t have output
     or a checksum line, but it’s still considered a block.)


File: python.info,  Node: Converting Your First Function,  Next: Advanced Topics,  Prev: Basic Concepts And Usage,  Up: Argument Clinic How-To

10.15.3 Converting Your First Function
--------------------------------------

The best way to get a sense of how Argument Clinic works is to convert a
function to work with it.  Here, then, are the bare minimum steps you’d
need to follow to convert a function to work with Argument Clinic.  Note
that for code you plan to check in to CPython, you really should take
the conversion farther, using some of the advanced concepts you’ll see
later on in the document (like "return converters" and "self
converters").  But we’ll keep it simple for this walkthrough so you can
learn.

Let’s dive in!

  0. Make sure you’re working with a freshly updated checkout of the
     CPython trunk.

  1. Find a Python builtin that calls either *note PyArg_ParseTuple():
     724. or *note PyArg_ParseTupleAndKeywords(): a57, and hasn’t been
     converted to work with Argument Clinic yet.  For my example I’m
     using ‘_pickle.Pickler.dump()’.

  2. If the call to the ‘PyArg_Parse’ function uses any of the following
     format units:

          O&
          O!
          es
          es#
          et
          et#

     or if it has multiple calls to *note PyArg_ParseTuple(): 724, you
     should choose a different function.  Argument Clinic `does' support
     all of these scenarios.  But these are advanced topics–let’s do
     something simpler for your first function.

     Also, if the function has multiple calls to *note
     PyArg_ParseTuple(): 724. or *note PyArg_ParseTupleAndKeywords():
     a57. where it supports different types for the same argument, or if
     the function uses something besides PyArg_Parse functions to parse
     its arguments, it probably isn’t suitable for conversion to
     Argument Clinic.  Argument Clinic doesn’t support generic functions
     or polymorphic parameters.

  3. Add the following boilerplate above the function, creating our
     block:

          /*[clinic input]
          [clinic start generated code]*/

  4. Cut the docstring and paste it in between the ‘[clinic]’ lines,
     removing all the junk that makes it a properly quoted C string.
     When you’re done you should have just the text, based at the left
     margin, with no line wider than 80 characters.  (Argument Clinic
     will preserve indents inside the docstring.)

     If the old docstring had a first line that looked like a function
     signature, throw that line away.  (The docstring doesn’t need it
     anymore–when you use ‘help()’ on your builtin in the future, the
     first line will be built automatically based on the function’s
     signature.)

     Sample:

          /*[clinic input]
          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

  5. If your docstring doesn’t have a "summary" line, Argument Clinic
     will complain.  So let’s make sure it has one.  The "summary" line
     should be a paragraph consisting of a single 80-column line at the
     beginning of the docstring.

     (Our example docstring consists solely of a summary line, so the
     sample code doesn’t have to change for this step.)

  6. Above the docstring, enter the name of the function, followed by a
     blank line.  This should be the Python name of the function, and
     should be the full dotted path to the function–it should start with
     the name of the module, include any sub-modules, and if the
     function is a method on a class it should include the class name
     too.

     Sample:

          /*[clinic input]
          _pickle.Pickler.dump

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

  7. If this is the first time that module or class has been used with
     Argument Clinic in this C file, you must declare the module and/or
     class.  Proper Argument Clinic hygiene prefers declaring these in a
     separate block somewhere near the top of the C file, in the same
     way that include files and statics go at the top.  (In our sample
     code we’ll just show the two blocks next to each other.)

     The name of the class and module should be the same as the one seen
     by Python.  Check the name defined in the *note PyModuleDef: 3344.
     or *note PyTypeObject: 3bc. as appropriate.

     When you declare a class, you must also specify two aspects of its
     type in C: the type declaration you’d use for a pointer to an
     instance of this class, and a pointer to the *note PyTypeObject:
     3bc. for this class.

     Sample:

          /*[clinic input]
          module _pickle
          class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
          [clinic start generated code]*/

          /*[clinic input]
          _pickle.Pickler.dump

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

  8. Declare each of the parameters to the function.  Each parameter
     should get its own line.  All the parameter lines should be
     indented from the function name and the docstring.

     The general form of these parameter lines is as follows:

          name_of_parameter: converter

     If the parameter has a default value, add that after the converter:

          name_of_parameter: converter = default_value

     Argument Clinic’s support for "default values" is quite
     sophisticated; please see *note the section below on default
     values: 3942. for more information.

     Add a blank line below the parameters.

     What’s a "converter"?  It establishes both the type of the variable
     used in C, and the method to convert the Python value into a C
     value at runtime.  For now you’re going to use what’s called a
     "legacy converter"–a convenience syntax intended to make porting
     old code into Argument Clinic easier.

     For each parameter, copy the "format unit" for that parameter from
     the ‘PyArg_Parse()’ format argument and specify `that' as its
     converter, as a quoted string.  ("format unit" is the formal name
     for the one-to-three character substring of the ‘format’ parameter
     that tells the argument parsing function what the type of the
     variable is and how to convert it.  For more on format units please
     see *note Parsing arguments and building values: 3311.)

     For multicharacter format units like ‘z#’, use the entire
     two-or-three character string.

     Sample:

           /*[clinic input]
           module _pickle
           class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
           [clinic start generated code]*/

           /*[clinic input]
           _pickle.Pickler.dump

              obj: 'O'

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

  9. If your function has ‘|’ in the format string, meaning some
     parameters have default values, you can ignore it.  Argument Clinic
     infers which parameters are optional based on whether or not they
     have default values.

     If your function has ‘$’ in the format string, meaning it takes
     keyword-only arguments, specify ‘*’ on a line by itself before the
     first keyword-only argument, indented the same as the parameter
     lines.

     (‘_pickle.Pickler.dump’ has neither, so our sample is unchanged.)

  10. If the existing C function calls *note PyArg_ParseTuple(): 724.
     (as opposed to *note PyArg_ParseTupleAndKeywords(): a57.), then all
     its arguments are positional-only.

     To mark all parameters as positional-only in Argument Clinic, add a
     ‘/’ on a line by itself after the last parameter, indented the same
     as the parameter lines.

     Currently this is all-or-nothing; either all parameters are
     positional-only, or none of them are.  (In the future Argument
     Clinic may relax this restriction.)

     Sample:

          /*[clinic input]
          module _pickle
          class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
          [clinic start generated code]*/

          /*[clinic input]
          _pickle.Pickler.dump

              obj: 'O'
              /

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

  11. It’s helpful to write a per-parameter docstring for each
     parameter.  But per-parameter docstrings are optional; you can skip
     this step if you prefer.

     Here’s how to add a per-parameter docstring.  The first line of the
     per-parameter docstring must be indented further than the parameter
     definition.  The left margin of this first line establishes the
     left margin for the whole per-parameter docstring; all the text you
     write will be outdented by this amount.  You can write as much text
     as you like, across multiple lines if you wish.

     Sample:

          /*[clinic input]
          module _pickle
          class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
          [clinic start generated code]*/

          /*[clinic input]
          _pickle.Pickler.dump

              obj: 'O'
                  The object to be pickled.
              /

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

  12. Save and close the file, then run ‘Tools/clinic/clinic.py’ on it.
     With luck everything worked and your block now has output!  Reopen
     the file in your text editor to see:

          /*[clinic input]
          module _pickle
          class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
          [clinic start generated code]*/
          /*[clinic end generated code: checksum=da39a3ee5e6b4b0d3255bfef95601890afd80709]*/

          /*[clinic input]
          _pickle.Pickler.dump

              obj: 'O'
                  The object to be pickled.
              /

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

          PyDoc_STRVAR(_pickle_Pickler_dump__doc__,
          "Write a pickled representation of obj to the open file.\n"
          "\n"
          ...
          static PyObject *
          _pickle_Pickler_dump_impl(PicklerObject *self, PyObject *obj)
          /*[clinic end generated code: checksum=3bd30745bf206a48f8b576a1da3d90f55a0a4187]*/

     Obviously, if Argument Clinic didn’t produce any output, it’s
     because it found an error in your input.  Keep fixing your errors
     and retrying until Argument Clinic processes your file without
     complaint.

  13. Double-check that the argument-parsing code Argument Clinic
     generated looks basically the same as the existing code.

     First, ensure both places use the same argument-parsing function.
     The existing code must call either *note PyArg_ParseTuple(): 724.
     or *note PyArg_ParseTupleAndKeywords(): a57.; ensure that the code
     generated by Argument Clinic calls the `exact' same function.

     Second, the format string passed in to *note PyArg_ParseTuple():
     724. or *note PyArg_ParseTupleAndKeywords(): a57. should be
     `exactly' the same as the hand-written one in the existing
     function, up to the colon or semi-colon.

     (Argument Clinic always generates its format strings with a ‘:’
     followed by the name of the function.  If the existing code’s
     format string ends with ‘;’, to provide usage help, this change is
     harmless–don’t worry about it.)

     Third, for parameters whose format units require two arguments
     (like a length variable, or an encoding string, or a pointer to a
     conversion function), ensure that the second argument is `exactly'
     the same between the two invocations.

     Fourth, inside the output portion of the block you’ll find a
     preprocessor macro defining the appropriate static *note
     PyMethodDef: a9d. structure for this builtin:

          #define __PICKLE_PICKLER_DUMP_METHODDEF    \
          {"dump", (PyCFunction)__pickle_Pickler_dump, METH_O, __pickle_Pickler_dump__doc__},

     This static structure should be `exactly' the same as the existing
     static *note PyMethodDef: a9d. structure for this builtin.

     If any of these items differ in `any way', adjust your Argument
     Clinic function specification and rerun ‘Tools/clinic/clinic.py’
     until they `are' the same.

  14. Notice that the last line of its output is the declaration of your
     "impl" function.  This is where the builtin’s implementation goes.
     Delete the existing prototype of the function you’re modifying, but
     leave the opening curly brace.  Now delete its argument parsing
     code and the declarations of all the variables it dumps the
     arguments into.  Notice how the Python arguments are now arguments
     to this impl function; if the implementation used different names
     for these variables, fix it.

     Let’s reiterate, just because it’s kind of weird.  Your code should
     now look like this:

          static return_type
          your_function_impl(...)
          /*[clinic end generated code: checksum=...]*/
          {
          ...

     Argument Clinic generated the checksum line and the function
     prototype just above it.  You should write the opening (and
     closing) curly braces for the function, and the implementation
     inside.

     Sample:

          /*[clinic input]
          module _pickle
          class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
          [clinic start generated code]*/
          /*[clinic end generated code: checksum=da39a3ee5e6b4b0d3255bfef95601890afd80709]*/

          /*[clinic input]
          _pickle.Pickler.dump

              obj: 'O'
                  The object to be pickled.
              /

          Write a pickled representation of obj to the open file.
          [clinic start generated code]*/

          PyDoc_STRVAR(__pickle_Pickler_dump__doc__,
          "Write a pickled representation of obj to the open file.\n"
          "\n"
          ...
          static PyObject *
          _pickle_Pickler_dump_impl(PicklerObject *self, PyObject *obj)
          /*[clinic end generated code: checksum=3bd30745bf206a48f8b576a1da3d90f55a0a4187]*/
          {
              /* Check whether the Pickler was initialized correctly (issue3664).
                 Developers often forget to call __init__() in their subclasses, which
                 would trigger a segfault without this check. */
              if (self->write == NULL) {
                  PyErr_Format(PicklingError,
                               "Pickler.__init__() was not called by %s.__init__()",
                               Py_TYPE(self)->tp_name);
                  return NULL;
              }

              if (_Pickler_ClearBuffer(self) < 0)
                  return NULL;

              ...

  15. Remember the macro with the *note PyMethodDef: a9d. structure for
     this function?  Find the existing *note PyMethodDef: a9d. structure
     for this function and replace it with a reference to the macro.
     (If the builtin is at module scope, this will probably be very near
     the end of the file; if the builtin is a class method, this will
     probably be below but relatively near to the implementation.)

     Note that the body of the macro contains a trailing comma.  So when
     you replace the existing static *note PyMethodDef: a9d. structure
     with the macro, `don’t' add a comma to the end.

     Sample:

          static struct PyMethodDef Pickler_methods[] = {
              __PICKLE_PICKLER_DUMP_METHODDEF
              __PICKLE_PICKLER_CLEAR_MEMO_METHODDEF
              {NULL, NULL}                /* sentinel */
          };

  16. Compile, then run the relevant portions of the regression-test
     suite.  This change should not introduce any new compile-time
     warnings or errors, and there should be no externally-visible
     change to Python’s behavior.

     Well, except for one difference: ‘inspect.signature()’ run on your
     function should now provide a valid signature!

     Congratulations, you’ve ported your first function to work with
     Argument Clinic!


File: python.info,  Node: Advanced Topics,  Prev: Converting Your First Function,  Up: Argument Clinic How-To

10.15.4 Advanced Topics
-----------------------

Now that you’ve had some experience working with Argument Clinic, it’s
time for some advanced topics.

* Menu:

* Symbolic default values:: 
* Renaming the C functions and variables generated by Argument Clinic:: 
* Converting functions using PyArg_UnpackTuple:: 
* Optional Groups:: 
* Using real Argument Clinic converters, instead of "legacy converters": Using real Argument Clinic converters instead of "legacy converters". 
* Py_buffer:: 
* Advanced converters:: 
* Parameter default values:: 
* The NULL default value:: 
* Expressions specified as default values:: 
* Using a return converter:: 
* Cloning existing functions:: 
* Calling Python code:: 
* Using a "self converter":: 
* Writing a custom converter:: 
* Writing a custom return converter:: 
* METH_O and METH_NOARGS:: 
* tp_new and tp_init functions:: 
* Changing and redirecting Clinic's output:: 
* The #ifdef trick:: 
* Using Argument Clinic in Python files:: 


File: python.info,  Node: Symbolic default values,  Next: Renaming the C functions and variables generated by Argument Clinic,  Up: Advanced Topics

10.15.4.1 Symbolic default values
.................................

The default value you provide for a parameter can’t be any arbitrary
expression.  Currently the following are explicitly supported:

   * Numeric constants (integer and float)

   * String constants

   * ‘True’, ‘False’, and ‘None’

   * Simple symbolic constants like ‘sys.maxsize’, which must start with
     the name of the module

In case you’re curious, this is implemented in ‘from_builtin()’ in
‘Lib/inspect.py’.

(In the future, this may need to get even more elaborate, to allow full
expressions like ‘CONSTANT - 1’.)


File: python.info,  Node: Renaming the C functions and variables generated by Argument Clinic,  Next: Converting functions using PyArg_UnpackTuple,  Prev: Symbolic default values,  Up: Advanced Topics

10.15.4.2 Renaming the C functions and variables generated by Argument Clinic
.............................................................................

Argument Clinic automatically names the functions it generates for you.
Occasionally this may cause a problem, if the generated name collides
with the name of an existing C function.  There’s an easy solution:
override the names used for the C functions.  Just add the keyword
‘"as"’ to your function declaration line, followed by the function name
you wish to use.  Argument Clinic will use that function name for the
base (generated) function, then add ‘"_impl"’ to the end and use that
for the name of the impl function.

For example, if we wanted to rename the C function names generated for
‘pickle.Pickler.dump’, it’d look like this:

     /*[clinic input]
     pickle.Pickler.dump as pickler_dumper

     ...

The base function would now be named ‘pickler_dumper()’, and the impl
function would now be named ‘pickler_dumper_impl()’.

Similarly, you may have a problem where you want to give a parameter a
specific Python name, but that name may be inconvenient in C. Argument
Clinic allows you to give a parameter different names in Python and in
C, using the same ‘"as"’ syntax:

     /*[clinic input]
     pickle.Pickler.dump

         obj: object
         file as file_obj: object
         protocol: object = NULL
         *
         fix_imports: bool = True

Here, the name used in Python (in the signature and the ‘keywords’
array) would be ‘file’, but the C variable would be named ‘file_obj’.

You can use this to rename the ‘self’ parameter too!


File: python.info,  Node: Converting functions using PyArg_UnpackTuple,  Next: Optional Groups,  Prev: Renaming the C functions and variables generated by Argument Clinic,  Up: Advanced Topics

10.15.4.3 Converting functions using PyArg_UnpackTuple
......................................................

To convert a function parsing its arguments with *note
PyArg_UnpackTuple(): aca, simply write out all the arguments, specifying
each as an ‘object’.  You may specify the ‘type’ argument to cast the
type as appropriate.  All arguments should be marked positional-only
(add a ‘/’ on a line by itself after the last argument).

Currently the generated code will use *note PyArg_ParseTuple(): 724, but
this will change soon.


File: python.info,  Node: Optional Groups,  Next: Using real Argument Clinic converters instead of "legacy converters",  Prev: Converting functions using PyArg_UnpackTuple,  Up: Advanced Topics

10.15.4.4 Optional Groups
.........................

Some legacy functions have a tricky approach to parsing their arguments:
they count the number of positional arguments, then use a ‘switch’
statement to call one of several different *note PyArg_ParseTuple():
724. calls depending on how many positional arguments there are.  (These
functions cannot accept keyword-only arguments.)  This approach was used
to simulate optional arguments back before *note
PyArg_ParseTupleAndKeywords(): a57. was created.

While functions using this approach can often be converted to use *note
PyArg_ParseTupleAndKeywords(): a57, optional arguments, and default
values, it’s not always possible.  Some of these legacy functions have
behaviors *note PyArg_ParseTupleAndKeywords(): a57. doesn’t directly
support.  The most obvious example is the builtin function ‘range()’,
which has an optional argument on the `left' side of its required
argument!  Another example is ‘curses.window.addch()’, which has a group
of two arguments that must always be specified together.  (The arguments
are called ‘x’ and ‘y’; if you call the function passing in ‘x’, you
must also pass in ‘y’–and if you don’t pass in ‘x’ you may not pass in
‘y’ either.)

In any case, the goal of Argument Clinic is to support argument parsing
for all existing CPython builtins without changing their semantics.
Therefore Argument Clinic supports this alternate approach to parsing,
using what are called `optional groups'.  Optional groups are groups of
arguments that must all be passed in together.  They can be to the left
or the right of the required arguments.  They can `only' be used with
positional-only parameters.

     Note: Optional groups are `only' intended for use when converting
     functions that make multiple calls to *note PyArg_ParseTuple():
     724.!  Functions that use `any' other approach for parsing
     arguments should `almost never' be converted to Argument Clinic
     using optional groups.  Functions using optional groups currently
     cannot have accurate sigantures in Python, because Python just
     doesn’t understand the concept.  Please avoid using optional groups
     wherever possible.

To specify an optional group, add a ‘[’ on a line by itself before the
parameters you wish to group together, and a ‘]’ on a line by itself
after these parameters.  As an example, here’s how ‘curses.window.addch’
uses optional groups to make the first two parameters and the last
parameter optional:

     /*[clinic input]

     curses.window.addch

         [
         x: int
           X-coordinate.
         y: int
           Y-coordinate.
         ]

         ch: object
           Character to add.

         [
         attr: long
           Attributes for the character.
         ]
         /

     ...

Notes:

   * For every optional group, one additional parameter will be passed
     into the impl function representing the group.  The parameter will
     be an int named ‘group_{direction}_{number}’, where ‘{direction}’
     is either ‘right’ or ‘left’ depending on whether the group is
     before or after the required parameters, and ‘{number}’ is a
     monotonically increasing number (starting at 1) indicating how far
     away the group is from the required parameters.  When the impl is
     called, this parameter will be set to zero if this group was
     unused, and set to non-zero if this group was used.  (By used or
     unused, I mean whether or not the parameters received arguments in
     this invocation.)

   * If there are no required arguments, the optional groups will behave
     as if they’re to the right of the required arguments.

   * In the case of ambiguity, the argument parsing code favors
     parameters on the left (before the required parameters).

   * Optional groups can only contain positional-only parameters.

   * Optional groups are `only' intended for legacy code.  Please do not
     use optional groups for new code.


File: python.info,  Node: Using real Argument Clinic converters instead of "legacy converters",  Next: Py_buffer,  Prev: Optional Groups,  Up: Advanced Topics

10.15.4.5 Using real Argument Clinic converters, instead of "legacy converters"
...............................................................................

To save time, and to minimize how much you need to learn to achieve your
first port to Argument Clinic, the walkthrough above tells you to use
"legacy converters".  "Legacy converters" are a convenience, designed
explicitly to make porting existing code to Argument Clinic easier.  And
to be clear, their use is acceptable when porting code for Python 3.4.

However, in the long term we probably want all our blocks to use
Argument Clinic’s real syntax for converters.  Why?  A couple reasons:

   * The proper converters are far easier to read and clearer in their
     intent.

   * There are some format units that are unsupported as "legacy
     converters", because they require arguments, and the legacy
     converter syntax doesn’t support specifying arguments.

   * In the future we may have a new argument parsing library that isn’t
     restricted to what *note PyArg_ParseTuple(): 724. supports; this
     flexibility won’t be available to parameters using legacy
     converters.

Therefore, if you don’t mind a little extra effort, please use the
normal converters instead of legacy converters.

In a nutshell, the syntax for Argument Clinic (non-legacy) converters
looks like a Python function call.  However, if there are no explicit
arguments to the function (all functions take their default values), you
may omit the parentheses.  Thus ‘bool’ and ‘bool()’ are exactly the same
converters.

All arguments to Argument Clinic converters are keyword-only.  All
Argument Clinic converters accept the following arguments:

     ‘c_default’

          The default value for this parameter when defined in C.
          Specifically, this will be the initializer for the variable
          declared in the "parse function".  See *note the section on
          default values: 3942. for how to use this.  Specified as a
          string.

     ‘annotation’

          The annotation value for this parameter.  Not currently
          supported, because PEP 8 mandates that the Python library may
          not use annotations.

In addition, some converters accept additional arguments.  Here is a
list of these arguments, along with their meanings:

     ‘accept’

          A set of Python types (and possibly pseudo-types); this
          restricts the allowable Python argument to values of these
          types.  (This is not a general-purpose facility; as a rule it
          only supports specific lists of types as shown in the legacy
          converter table.)

          To accept ‘None’, add ‘NoneType’ to this set.

     ‘bitwise’

          Only supported for unsigned integers.  The native integer
          value of this Python argument will be written to the parameter
          without any range checking, even for negative values.

     ‘converter’

          Only supported by the ‘object’ converter.  Specifies the name
          of a *note C "converter function": 347a. to use to convert
          this object to a native type.

     ‘encoding’

          Only supported for strings.  Specifies the encoding to use
          when converting this string from a Python str (Unicode) value
          into a C ‘char *’ value.

     ‘subclass_of’

          Only supported for the ‘object’ converter.  Requires that the
          Python value be a subclass of a Python type, as expressed in
          C.

     ‘type’

          Only supported for the ‘object’ and ‘self’ converters.
          Specifies the C type that will be used to declare the
          variable.  Default value is ‘"PyObject *"’.

     ‘zeroes’

          Only supported for strings.  If true, embedded NUL bytes
          (‘'\\0'’) are permitted inside the value.  The length of the
          string will be passed in to the impl function, just after the
          string parameter, as a parameter named
          ‘<parameter_name>_length’.

Please note, not every possible combination of arguments will work.
Usually these arguments are implemented by specific ‘PyArg_ParseTuple’
`format units', with specific behavior.  For example, currently you
cannot call ‘unsigned_short’ without also specifying ‘bitwise=True’.
Although it’s perfectly reasonable to think this would work, these
semantics don’t map to any existing format unit.  So Argument Clinic
doesn’t support it.  (Or, at least, not yet.)

Below is a table showing the mapping of legacy converters into real
Argument Clinic converters.  On the left is the legacy converter, on the
right is the text you’d replace it with.

‘'B'’         ‘unsigned_char(bitwise=True)’
              
              
‘'b'’         ‘unsigned_char’
              
              
‘'c'’         ‘char’
              
              
‘'C'’         ‘int(accept={str})’
              
              
‘'d'’         ‘double’
              
              
‘'D'’         ‘Py_complex’
              
              
‘'es'’        ‘str(encoding='name_of_encoding')’
              
              
‘'es#'’       ‘str(encoding='name_of_encoding', zeroes=True)’
              
              
‘'et'’        ‘str(encoding='name_of_encoding', accept={bytes, bytearray, str})’
              
              
‘'et#'’       ‘str(encoding='name_of_encoding', accept={bytes, bytearray, str}, zeroes=True)’
              
              
‘'f'’         ‘float’
              
              
‘'h'’         ‘short’
              
              
‘'H'’         ‘unsigned_short(bitwise=True)’
              
              
‘'i'’         ‘int’
              
              
‘'I'’         ‘unsigned_int(bitwise=True)’
              
              
‘'k'’         ‘unsigned_long(bitwise=True)’
              
              
‘'K'’         ‘unsigned_PY_LONG_LONG(bitwise=True)’
              
              
‘'l'’         ‘long’
              
              
‘'L'’         ‘PY_LONG_LONG’
              
              
‘'n'’         ‘Py_ssize_t’
              
              
‘'O'’         ‘object’
              
              
‘'O!'’        ‘object(subclass_of='&PySomething_Type')’
              
              
‘'O&'’        ‘object(converter='name_of_c_function')’
              
              
‘'p'’         ‘bool’
              
              
‘'S'’         ‘PyBytesObject’
              
              
‘'s'’         ‘str’
              
              
‘'s#'’        ‘str(zeroes=True)’
              
              
‘'s*'’        ‘Py_buffer(accept={buffer, str})’
              
              
‘'U'’         ‘unicode’
              
              
‘'u'’         ‘Py_UNICODE’
              
              
‘'u#'’        ‘Py_UNICODE(zeroes=True)’
              
              
‘'w*'’        ‘Py_buffer(accept={rwbuffer})’
              
              
‘'Y'’         ‘PyByteArrayObject’
              
              
‘'y'’         ‘str(accept={bytes})’
              
              
‘'y#'’        ‘str(accept={robuffer}, zeroes=True)’
              
              
‘'y*'’        ‘Py_buffer’
              
              
‘'Z'’         ‘Py_UNICODE(accept={str, NoneType})’
              
              
‘'Z#'’        ‘Py_UNICODE(accept={str, NoneType}, zeroes=True)’
              
              
‘'z'’         ‘str(accept={str, NoneType})’
              
              
‘'z#'’        ‘str(accept={str, NoneType}, zeroes=True)’
              
              
‘'z*'’        ‘Py_buffer(accept={buffer, str, NoneType})’
              

As an example, here’s our sample ‘pickle.Pickler.dump’ using the proper
converter:

     /*[clinic input]
     pickle.Pickler.dump

         obj: object
             The object to be pickled.
         /

     Write a pickled representation of obj to the open file.
     [clinic start generated code]*/

Argument Clinic will show you all the converters it has available.  For
each converter it’ll show you all the parameters it accepts, along with
the default value for each parameter.  Just run ‘Tools/clinic/clinic.py
--converters’ to see the full list.


File: python.info,  Node: Py_buffer,  Next: Advanced converters,  Prev: Using real Argument Clinic converters instead of "legacy converters",  Up: Advanced Topics

10.15.4.6 Py_buffer
...................

When using the ‘Py_buffer’ converter (or the ‘'s*'’, ‘'w*'’, ‘'*y'’, or
‘'z*'’ legacy converters), you `must' not call *note PyBuffer_Release():
9cb. on the provided buffer.  Argument Clinic generates code that does
it for you (in the parsing function).


File: python.info,  Node: Advanced converters,  Next: Parameter default values,  Prev: Py_buffer,  Up: Advanced Topics

10.15.4.7 Advanced converters
.............................

Remember those format units you skipped for your first time because they
were advanced?  Here’s how to handle those too.

The trick is, all those format units take arguments–either conversion
functions, or types, or strings specifying an encoding.  (But "legacy
converters" don’t support arguments.  That’s why we skipped them for
your first function.)  The argument you specified to the format unit is
now an argument to the converter; this argument is either ‘converter’
(for ‘O&’), ‘subclass_of’ (for ‘O!’), or ‘encoding’ (for all the format
units that start with ‘e’).

When using ‘subclass_of’, you may also want to use the other custom
argument for ‘object()’: ‘type’, which lets you set the type actually
used for the parameter.  For example, if you want to ensure that the
object is a subclass of ‘PyUnicode_Type’, you probably want to use the
converter ‘object(type='PyUnicodeObject *',
subclass_of='&PyUnicode_Type')’.

One possible problem with using Argument Clinic: it takes away some
possible flexibility for the format units starting with ‘e’.  When
writing a ‘PyArg_Parse’ call by hand, you could theoretically decide at
runtime what encoding string to pass in to *note PyArg_ParseTuple():
724.  But now this string must be hard-coded at
Argument-Clinic-preprocessing-time.  This limitation is deliberate; it
made supporting this format unit much easier, and may allow for future
optimizations.  This restriction doesn’t seem unreasonable; CPython
itself always passes in static hard-coded encoding strings for
parameters whose format units start with ‘e’.


File: python.info,  Node: Parameter default values,  Next: The NULL default value,  Prev: Advanced converters,  Up: Advanced Topics

10.15.4.8 Parameter default values
..................................

Default values for parameters can be any of a number of values.  At
their simplest, they can be string, int, or float literals:

     foo: str = "abc"
     bar: int = 123
     bat: float = 45.6

They can also use any of Python’s built-in constants:

     yep:  bool = True
     nope: bool = False
     nada: object = None

There’s also special support for a default value of ‘NULL’, and for
simple expressions, documented in the following sections.


File: python.info,  Node: The NULL default value,  Next: Expressions specified as default values,  Prev: Parameter default values,  Up: Advanced Topics

10.15.4.9 The ‘NULL’ default value
..................................

For string and object parameters, you can set them to ‘None’ to indicate
that there’s no default.  However, that means the C variable will be
initialized to ‘Py_None’.  For convenience’s sakes, there’s a special
value called ‘NULL’ for just this reason: from Python’s perspective it
behaves like a default value of ‘None’, but the C variable is
initialized with ‘NULL’.


File: python.info,  Node: Expressions specified as default values,  Next: Using a return converter,  Prev: The NULL default value,  Up: Advanced Topics

10.15.4.10 Expressions specified as default values
..................................................

The default value for a parameter can be more than just a literal value.
It can be an entire expression, using math operators and looking up
attributes on objects.  However, this support isn’t exactly simple,
because of some non-obvious semantics.

Consider the following example:

     foo: Py_ssize_t = sys.maxsize - 1

‘sys.maxsize’ can have different values on different platforms.
Therefore Argument Clinic can’t simply evaluate that expression locally
and hard-code it in C. So it stores the default in such a way that it
will get evaluated at runtime, when the user asks for the function’s
signature.

What namespace is available when the expression is evaluated?  It’s
evaluated in the context of the module the builtin came from.  So, if
your module has an attribute called "‘max_widgets’", you may simply use
it:

     foo: Py_ssize_t = max_widgets

If the symbol isn’t found in the current module, it fails over to
looking in ‘sys.modules’.  That’s how it can find ‘sys.maxsize’ for
example.  (Since you don’t know in advance what modules the user will
load into their interpreter, it’s best to restrict yourself to modules
that are preloaded by Python itself.)

Evaluating default values only at runtime means Argument Clinic can’t
compute the correct equivalent C default value.  So you need to tell it
explicitly.  When you use an expression, you must also specify the
equivalent expression in C, using the ‘c_default’ parameter to the
converter:

     foo: Py_ssize_t(c_default="PY_SSIZE_T_MAX - 1") = sys.maxsize - 1

Another complication: Argument Clinic can’t know in advance whether or
not the expression you supply is valid.  It parses it to make sure it
looks legal, but it can’t `actually' know.  You must be very careful
when using expressions to specify values that are guaranteed to be valid
at runtime!

Finally, because expressions must be representable as static C values,
there are many restrictions on legal expressions.  Here’s a list of
Python features you’re not permitted to use:

   * Function calls.

   * Inline if statements (‘3 if foo else 5’).

   * Automatic sequence unpacking (‘*[1, 2, 3]’).

   * List/set/dict comprehensions and generator expressions.

   * Tuple/list/set/dict literals.


File: python.info,  Node: Using a return converter,  Next: Cloning existing functions,  Prev: Expressions specified as default values,  Up: Advanced Topics

10.15.4.11 Using a return converter
...................................

By default the impl function Argument Clinic generates for you returns
‘PyObject *’.  But your C function often computes some C type, then
converts it into the ‘PyObject *’ at the last moment.  Argument Clinic
handles converting your inputs from Python types into native C types–why
not have it convert your return value from a native C type into a Python
type too?

That’s what a "return converter" does.  It changes your impl function to
return some C type, then adds code to the generated (non-impl) function
to handle converting that value into the appropriate ‘PyObject *’.

The syntax for return converters is similar to that of parameter
converters.  You specify the return converter like it was a return
annotation on the function itself.  Return converters behave much the
same as parameter converters; they take arguments, the arguments are all
keyword-only, and if you’re not changing any of the default arguments
you can omit the parentheses.

(If you use both ‘"as"’ `and' a return converter for your function, the
‘"as"’ should come before the return converter.)

There’s one additional complication when using return converters: how do
you indicate an error has occurred?  Normally, a function returns a
valid (non-‘NULL’) pointer for success, and ‘NULL’ for failure.  But if
you use an integer return converter, all integers are valid.  How can
Argument Clinic detect an error?  Its solution: each return converter
implicitly looks for a special value that indicates an error.  If you
return that value, and an error has been set (‘PyErr_Occurred()’ returns
a true value), then the generated code will propagate the error.
Otherwise it will encode the value you return like normal.

Currently Argument Clinic supports only a few return converters:

     bool
     int
     unsigned int
     long
     unsigned int
     size_t
     Py_ssize_t
     float
     double
     DecodeFSDefault

None of these take parameters.  For the first three, return -1 to
indicate error.  For ‘DecodeFSDefault’, the return type is ‘char *’;
return a NULL pointer to indicate an error.

(There’s also an experimental ‘NoneType’ converter, which lets you
return ‘Py_None’ on success or ‘NULL’ on failure, without having to
increment the reference count on ‘Py_None’.  I’m not sure it adds enough
clarity to be worth using.)

To see all the return converters Argument Clinic supports, along with
their parameters (if any), just run ‘Tools/clinic/clinic.py
--converters’ for the full list.


File: python.info,  Node: Cloning existing functions,  Next: Calling Python code,  Prev: Using a return converter,  Up: Advanced Topics

10.15.4.12 Cloning existing functions
.....................................

If you have a number of functions that look similar, you may be able to
use Clinic’s "clone" feature.  When you clone an existing function, you
reuse:

   * its parameters, including

        * their names,

        * their converters, with all parameters,

        * their default values,

        * their per-parameter docstrings,

        * their `kind' (whether they’re positional only, positional or
          keyword, or keyword only), and

   * its return converter.

The only thing not copied from the original function is its docstring;
the syntax allows you to specify a new docstring.

Here’s the syntax for cloning a function:

     /*[clinic input]
     module.class.new_function [as c_basename] = module.class.existing_function

     Docstring for new_function goes here.
     [clinic start generated code]*/

(The functions can be in different modules or classes.  I wrote
‘module.class’ in the sample just to illustrate that you must use the
full path to `both' functions.)

Sorry, there’s no syntax for partially-cloning a function, or cloning a
function then modifying it.  Cloning is an all-or nothing proposition.

Also, the function you are cloning from must have been previously
defined in the current file.


File: python.info,  Node: Calling Python code,  Next: Using a "self converter",  Prev: Cloning existing functions,  Up: Advanced Topics

10.15.4.13 Calling Python code
..............................

The rest of the advanced topics require you to write Python code which
lives inside your C file and modifies Argument Clinic’s runtime state.
This is simple: you simply define a Python block.

A Python block uses different delimiter lines than an Argument Clinic
function block.  It looks like this:

     /*[python input]
     # python code goes here
     [python start generated code]*/

All the code inside the Python block is executed at the time it’s
parsed.  All text written to stdout inside the block is redirected into
the "output" after the block.

As an example, here’s a Python block that adds a static integer variable
to the C code:

     /*[python input]
     print('static int __ignored_unused_variable__ = 0;')
     [python start generated code]*/
     static int __ignored_unused_variable__ = 0;
     /*[python checksum:...]*/


File: python.info,  Node: Using a "self converter",  Next: Writing a custom converter,  Prev: Calling Python code,  Up: Advanced Topics

10.15.4.14 Using a "self converter"
...................................

Argument Clinic automatically adds a "self" parameter for you using a
default converter.  It automatically sets the ‘type’ of this parameter
to the "pointer to an instance" you specified when you declared the
type.  However, you can override Argument Clinic’s converter and specify
one yourself.  Just add your own ‘self’ parameter as the first parameter
in a block, and ensure that its converter is an instance of
‘self_converter’ or a subclass thereof.

What’s the point?  This lets you override the type of ‘self’, or give it
a different default name.

How do you specify the custom type you want to cast ‘self’ to?  If you
only have one or two functions with the same type for ‘self’, you can
directly use Argument Clinic’s existing ‘self’ converter, passing in the
type you want to use as the ‘type’ parameter:

     /*[clinic input]

     _pickle.Pickler.dump

       self: self(type="PicklerObject *")
       obj: object
       /

     Write a pickled representation of the given object to the open file.
     [clinic start generated code]*/

On the other hand, if you have a lot of functions that will use the same
type for ‘self’, it’s best to create your own converter, subclassing
‘self_converter’ but overwriting the ‘type’ member:

     /*[python input]
     class PicklerObject_converter(self_converter):
         type = "PicklerObject *"
     [python start generated code]*/

     /*[clinic input]

     _pickle.Pickler.dump

       self: PicklerObject
       obj: object
       /

     Write a pickled representation of the given object to the open file.
     [clinic start generated code]*/


File: python.info,  Node: Writing a custom converter,  Next: Writing a custom return converter,  Prev: Using a "self converter",  Up: Advanced Topics

10.15.4.15 Writing a custom converter
.....................................

As we hinted at in the previous section...  you can write your own
converters!  A converter is simply a Python class that inherits from
‘CConverter’.  The main purpose of a custom converter is if you have a
parameter using the ‘O&’ format unit–parsing this parameter means
calling a *note PyArg_ParseTuple(): 724. "converter function".

Your converter class should be named ‘*something*_converter’.  If the
name follows this convention, then your converter class will be
automatically registered with Argument Clinic; its name will be the name
of your class with the ‘_converter’ suffix stripped off.  (This is
accomplished with a metaclass.)

You shouldn’t subclass ‘CConverter.__init__’.  Instead, you should write
a ‘converter_init()’ function.  ‘converter_init()’ always accepts a
‘self’ parameter; after that, all additional parameters `must' be
keyword-only.  Any arguments passed in to the converter in Argument
Clinic will be passed along to your ‘converter_init()’.

There are some additional members of ‘CConverter’ you may wish to
specify in your subclass.  Here’s the current list:

‘type’

     The C type to use for this variable.  ‘type’ should be a Python
     string specifying the type, e.g.  ‘int’.  If this is a pointer
     type, the type string should end with ‘' *'’.

‘default’

     The Python default value for this parameter, as a Python value.  Or
     the magic value ‘unspecified’ if there is no default.

‘py_default’

     ‘default’ as it should appear in Python code, as a string.  Or
     ‘None’ if there is no default.

‘c_default’

     ‘default’ as it should appear in C code, as a string.  Or ‘None’ if
     there is no default.

‘c_ignored_default’

     The default value used to initialize the C variable when there is
     no default, but not specifying a default may result in an
     "uninitialized variable" warning.  This can easily happen when
     using option groups–although properly-written code will never
     actually use this value, the variable does get passed in to the
     impl, and the C compiler will complain about the "use" of the
     uninitialized value.  This value should always be a non-empty
     string.

‘converter’

     The name of the C converter function, as a string.

‘impl_by_reference’

     A boolean value.  If true, Argument Clinic will add a ‘&’ in front
     of the name of the variable when passing it into the impl function.

‘parse_by_reference’

     A boolean value.  If true, Argument Clinic will add a ‘&’ in front
     of the name of the variable when passing it into *note
     PyArg_ParseTuple(): 724.

Here’s the simplest example of a custom converter, from
‘Modules/zlibmodule.c’:

     /*[python input]

     class capped_uint_converter(CConverter):
         type = 'unsigned int'
         converter = 'capped_uint_converter'

     [python start generated code]*/
     /*[python end generated code: output=da39a3ee5e6b4b0d input=35521e4e733823c7]*/

This block adds a converter to Argument Clinic named ‘capped_uint’.
Parameters declared as ‘capped_uint’ will be declared as type ‘unsigned
int’, and will be parsed by the ‘'O&'’ format unit, which will call the
‘capped_uint_converter’ converter function.  ‘capped_uint’ variables
automatically support default values.

More sophisticated custom converters can insert custom C code to handle
initialization and cleanup.  You can see more examples of custom
converters in the CPython source tree; grep the C files for the string
‘CConverter’.


File: python.info,  Node: Writing a custom return converter,  Next: METH_O and METH_NOARGS,  Prev: Writing a custom converter,  Up: Advanced Topics

10.15.4.16 Writing a custom return converter
............................................

Writing a custom return converter is much like writing a custom
converter.  Except it’s somewhat simpler, because return converters are
themselves much simpler.

Return converters must subclass ‘CReturnConverter’.  There are no
examples yet of custom return converters, because they are not widely
used yet.  If you wish to write your own return converter, please read
‘Tools/clinic/clinic.py’, specifically the implementation of
‘CReturnConverter’ and all its subclasses.


File: python.info,  Node: METH_O and METH_NOARGS,  Next: tp_new and tp_init functions,  Prev: Writing a custom return converter,  Up: Advanced Topics

10.15.4.17 METH_O and METH_NOARGS
.................................

To convert a function using ‘METH_O’, make sure the function’s single
argument is using the ‘object’ converter, and mark the arguments as
positional-only:

     /*[clinic input]
     meth_o_sample

          argument: object
          /
     [clinic start generated code]*/

To convert a function using ‘METH_NOARGS’, just don’t specify any
arguments.

You can still use a self converter, a return converter, and specify a
‘type’ argument to the object converter for ‘METH_O’.


File: python.info,  Node: tp_new and tp_init functions,  Next: Changing and redirecting Clinic's output,  Prev: METH_O and METH_NOARGS,  Up: Advanced Topics

10.15.4.18 tp_new and tp_init functions
.......................................

You can convert ‘tp_new’ and ‘tp_init’ functions.  Just name them
‘__new__’ or ‘__init__’ as appropriate.  Notes:

   * The function name generated for ‘__new__’ doesn’t end in ‘__new__’
     like it would by default.  It’s just the name of the class,
     converted into a valid C identifier.

   * No ‘PyMethodDef’ ‘#define’ is generated for these functions.

   * ‘__init__’ functions return ‘int’, not ‘PyObject *’.

   * Use the docstring as the class docstring.

   * Although ‘__new__’ and ‘__init__’ functions must always accept both
     the ‘args’ and ‘kwargs’ objects, when converting you may specify
     any signature for these functions that you like.  (If your function
     doesn’t support keywords, the parsing function generated will throw
     an exception if it receives any.)


File: python.info,  Node: Changing and redirecting Clinic's output,  Next: The #ifdef trick,  Prev: tp_new and tp_init functions,  Up: Advanced Topics

10.15.4.19 Changing and redirecting Clinic’s output
...................................................

It can be inconvenient to have Clinic’s output interspersed with your
conventional hand-edited C code.  Luckily, Clinic is configurable: you
can buffer up its output for printing later (or earlier!), or write its
output to a separate file.  You can also add a prefix or suffix to every
line of Clinic’s generated output.

While changing Clinic’s output in this manner can be a boon to
readability, it may result in Clinic code using types before they are
defined, or your code attempting to use Clinic-generated code befire it
is defined.  These problems can be easily solved by rearranging the
declarations in your file, or moving where Clinic’s generated code goes.
(This is why the default behavior of Clinic is to output everything into
the current block; while many people consider this hampers readability,
it will never require rearranging your code to fix definition-before-use
problems.)

Let’s start with defining some terminology:

`field'

     A field, in this context, is a subsection of Clinic’s output.  For
     example, the ‘#define’ for the ‘PyMethodDef’ structure is a field,
     called ‘methoddef_define’.  Clinic has seven different fields it
     can output per function definition:

          docstring_prototype
          docstring_definition
          methoddef_define
          impl_prototype
          parser_prototype
          parser_definition
          impl_definition

     All the names are of the form ‘"<a>_<b>"’, where ‘"<a>"’ is the
     semantic object represented (the parsing function, the impl
     function, the docstring, or the methoddef structure) and ‘"<b>"’
     represents what kind of statement the field is.  Field names that
     end in ‘"_prototype"’ represent forward declarations of that thing,
     without the actual body/data of the thing; field names that end in
     ‘"_definition"’ represent the actual definition of the thing, with
     the body/data of the thing.  (‘"methoddef"’ is special, it’s the
     only one that ends with ‘"_define"’, representing that it’s a
     preprocessor #define.)

`destination'

     A destination is a place Clinic can write output to.  There are
     five built-in destinations:

     ‘block’

          The default destination: printed in the output section of the
          current Clinic block.

     ‘buffer’

          A text buffer where you can save text for later.  Text sent
          here is appended to the end of any exsiting text.  It’s an
          error to have any text left in the buffer when Clinic finishes
          processing a file.

     ‘file’

          A separate "clinic file" that will be created automatically by
          Clinic.  The filename chosen for the file is
          ‘{basename}.clinic{extension}’, where ‘basename’ and
          ‘extension’ were assigned the output from ‘os.path.splitext()’
          run on the current file.  (Example: the ‘file’ destination for
          ‘_pickle.c’ would be written to ‘_pickle.clinic.c’.)

          `Important: When using a' ‘file’ `destination, you' `must
          check in' `the generated file!'

     ‘two-pass’

          A buffer like ‘buffer’.  However, a two-pass buffer can only
          be written once, and it prints out all text sent to it during
          all of processing, even from Clinic blocks `after' the

     ‘suppress’

          The text is suppressed–thrown away.

Clinic defines five new directives that let you reconfigure its output.

The first new directive is ‘dump’:

     dump <destination>

This dumps the current contents of the named destination into the output
of the current block, and empties it.  This only works with ‘buffer’ and
‘two-pass’ destinations.

The second new directive is ‘output’.  The most basic form of ‘output’
is like this:

     output <field> <destination>

This tells Clinic to output `field' to `destination'.  ‘output’ also
supports a special meta-destination, called ‘everything’, which tells
Clinic to output `all' fields to that `destination'.

‘output’ has a number of other functions:

     output push
     output pop
     output preset <preset>

‘output push’ and ‘output pop’ allow you to push and pop configurations
on an internal configuration stack, so that you can temporarily modify
the output configuration, then easily restore the previous
configuration.  Simply push before your change to save the current
configuration, then pop when you wish to restore the previous
configuration.

‘output preset’ sets Clinic’s output to one of several built-in preset
configurations, as follows:

     ‘block’

          Clinic’s original starting configuration.  Writes everything
          immediately after the input block.

          Suppress the ‘parser_prototype’ and ‘docstring_prototype’,
          write everything else to ‘block’.

     ‘file’

          Designed to write everything to the "clinic file" that it can.
          You then ‘#include’ this file near the top of your file.  You
          may need to rearrange your file to make this work, though
          usually this just means creating forward declarations for
          various ‘typedef’ and ‘PyTypeObject’ definitions.

          Suppress the ‘parser_prototype’ and ‘docstring_prototype’,
          write the ‘impl_definition’ to ‘block’, and write everything
          else to ‘file’.

          The default filename is ‘"{dirname}/clinic/{basename}.h"’.

     ‘buffer’

          Save up all most of the output from Clinic, to be written into
          your file near the end.  For Python files implementing modules
          or builtin types, it’s recommended that you dump the buffer
          just above the static structures for your module or builtin
          type; these are normally very near the end.  Using ‘buffer’
          may require even more editing than ‘file’, if your file has
          static ‘PyMethodDef’ arrays defined in the middle of the file.

          Suppress the ‘parser_prototype’, ‘impl_prototype’, and
          ‘docstring_prototype’, write the ‘impl_definition’ to ‘block’,
          and write everything else to ‘file’.

     ‘two-pass’

          Similar to the ‘buffer’ preset, but writes forward
          declarations to the ‘two-pass’ buffer, and definitions to the
          ‘buffer’.  This is similar to the ‘buffer’ preset, but may
          require less editing than ‘buffer’.  Dump the ‘two-pass’
          buffer near the top of your file, and dump the ‘buffer’ near
          the end just like you would when using the ‘buffer’ preset.

          Suppresses the ‘impl_prototype’, write the ‘impl_definition’
          to ‘block’, write ‘docstring_prototype’, ‘methoddef_define’,
          and ‘parser_prototype’ to ‘two-pass’, write everything else to
          ‘buffer’.

     ‘partial-buffer’

          Similar to the ‘buffer’ preset, but writes more things to
          ‘block’, only writing the really big chunks of generated code
          to ‘buffer’.  This avoids the definition-before-use problem of
          ‘buffer’ completely, at the small cost of having slightly more
          stuff in the block’s output.  Dump the ‘buffer’ near the end,
          just like you would when using the ‘buffer’ preset.

          Suppresses the ‘impl_prototype’, write the
          ‘docstring_definition’ and ‘parser_definition’ to ‘buffer’,
          write everything else to ‘block’.

The third new directive is ‘destination’:

     destination <name> <command> [...]

This performs an operation on the destination named ‘name’.

There are two defined subcommands: ‘new’ and ‘clear’.

The ‘new’ subcommand works like this:

     destination <name> new <type>

This creates a new destination with name ‘<name>’ and type ‘<type>’.

There are five destination types:

     ‘suppress’

          Throws the text away.

     ‘block’

          Writes the text to the current block.  This is what Clinic
          originally did.

     ‘buffer’

          A simple text buffer, like the "buffer" builtin destination
          above.

     ‘file’

          A text file.  The file destination takes an extra argument, a
          template to use for building the filename, like so:

               destination <name> new <type> <file_template>

          The template can use three strings internally that will be
          replaced by bits of the filename:

               {path}

                    The full path to the file, including directory and
                    full filename.

               {dirname}

                    The name of the directory the file is in.

               {basename}

                    Just the name of the file, not including the
                    directory.

               {basename_root}

                    Basename with the extension clipped off (everything
                    up to but not including the last ’.’).

               {basename_extension}

                    The last ’.’ and everything after it.  If the
                    basename does not contain a period, this will be the
                    empty string.

          If there are no periods in the filename, {basename} and
          {filename} are the same, and {extension} is empty.
          "{basename}{extension}" is always exactly the same as
          "{filename}"."

     ‘two-pass’

          A two-pass buffer, like the "two-pass" builtin destination
          above.

The ‘clear’ subcommand works like this:

     destination <name> clear

It removes all the accumulated text up to this point in the destination.
(I don’t know what you’d need this for, but I thought maybe it’d be
useful while someone’s experimenting.)

The fourth new directive is ‘set’:

     set line_prefix "string"
     set line_suffix "string"

‘set’ lets you set two internal variables in Clinic.  ‘line_prefix’ is a
string that will be prepended to every line of Clinic’s output;
‘line_suffix’ is a string that will be appended to every line of
Clinic’s output.

Both of these support two format strings:

     ‘{block comment start}’

          Turns into the string ‘/*’, the start-comment text sequence
          for C files.

     ‘{block comment end}’

          Turns into the string ‘*/’, the end-comment text sequence for
          C files.

The final new directive is one you shouldn’t need to use directly,
called ‘preserve’:

     preserve

This tells Clinic that the current contents of the output should be
kept, unmodifed.  This is used internally by Clinic when dumping output
into ‘file’ files; wrapping it in a Clinic block lets Clinic use its
existing checksum functionality to ensure the file was not modified by
hand before it gets overwritten.


File: python.info,  Node: The #ifdef trick,  Next: Using Argument Clinic in Python files,  Prev: Changing and redirecting Clinic's output,  Up: Advanced Topics

10.15.4.20 The #ifdef trick
...........................

If you’re converting a function that isn’t available on all platforms,
there’s a trick you can use to make life a little easier.  The existing
code probably looks like this:

     #ifdef HAVE_FUNCTIONNAME
     static module_functionname(...)
     {
     ...
     }
     #endif /* HAVE_FUNCTIONNAME */

And then in the ‘PyMethodDef’ structure at the bottom the existing code
will have:

     #ifdef HAVE_FUNCTIONNAME
     {'functionname', ... },
     #endif /* HAVE_FUNCTIONNAME */

In this scenario, you should enclose the body of your impl function
inside the ‘#ifdef’, like so:

     #ifdef HAVE_FUNCTIONNAME
     /*[clinic input]
     module.functionname
     ...
     [clinic start generated code]*/
     static module_functionname(...)
     {
     ...
     }
     #endif /* HAVE_FUNCTIONNAME */

Then, remove those three lines from the ‘PyMethodDef’ structure,
replacing them with the macro Argument Clinic generated:

     MODULE_FUNCTIONNAME_METHODDEF

(You can find the real name for this macro inside the generated code.
Or you can calculate it yourself: it’s the name of your function as
defined on the first line of your block, but with periods changed to
underscores, uppercased, and ‘"_METHODDEF"’ added to the end.)

Perhaps you’re wondering: what if ‘HAVE_FUNCTIONNAME’ isn’t defined?
The ‘MODULE_FUNCTIONNAME_METHODDEF’ macro won’t be defined either!

Here’s where Argument Clinic gets very clever.  It actually detects that
the Argument Clinic block might be deactivated by the ‘#ifdef’.  When
that happens, it generates a little extra code that looks like this:

     #ifndef MODULE_FUNCTIONNAME_METHODDEF
         #define MODULE_FUNCTIONNAME_METHODDEF
     #endif /* !defined(MODULE_FUNCTIONNAME_METHODDEF) */

That means the macro always works.  If the function is defined, this
turns into the correct structure, including the trailing comma.  If the
function is undefined, this turns into nothing.

However, this causes one ticklish problem: where should Argument Clinic
put this extra code when using the "block" output preset?  It can’t go
in the output block, because that could be decativated by the ‘#ifdef’.
(That’s the whole point!)

In this situation, Argument Clinic writes the extra code to the "buffer"
destination.  This may mean that you get a complaint from Argument
Clinic:

     Warning in file "Modules/posixmodule.c" on line 12357:
     Destination buffer 'buffer' not empty at end of file, emptying.

When this happens, just open your file, find the ‘dump buffer’ block
that Argument Clinic added to your file (it’ll be at the very bottom),
then move it above the ‘PyMethodDef’ structure where that macro is used.


File: python.info,  Node: Using Argument Clinic in Python files,  Prev: The #ifdef trick,  Up: Advanced Topics

10.15.4.21 Using Argument Clinic in Python files
................................................

It’s actually possible to use Argument Clinic to preprocess Python
files.  There’s no point to using Argument Clinic blocks, of course, as
the output wouldn’t make any sense to the Python interpreter.  But using
Argument Clinic to run Python blocks lets you use Python as a Python
preprocessor!

Since Python comments are different from C comments, Argument Clinic
blocks embedded in Python files look slightly different.  They look like
this:

     #/*[python input]
     #print("def foo(): pass")
     #[python start generated code]*/
     def foo(): pass
     #/*[python checksum:...]*/


File: python.info,  Node: Python Frequently Asked Questions,  Next: Glossary,  Prev: Python HOWTOs,  Up: Top

11 Python Frequently Asked Questions
************************************

* Menu:

* General Python FAQ:: 
* Programming FAQ:: 
* Design and History FAQ:: 
* Library and Extension FAQ:: 
* Extending/Embedding FAQ:: 
* Python on Windows FAQ:: 
* Graphic User Interface FAQ:: 
* "Why is Python Installed on my Computer?" FAQ:: 


File: python.info,  Node: General Python FAQ,  Next: Programming FAQ,  Up: Python Frequently Asked Questions

11.1 General Python FAQ
=======================

* Menu:

* General Information:: 
* Python in the real world:: 


File: python.info,  Node: General Information,  Next: Python in the real world,  Up: General Python FAQ

11.1.1 General Information
--------------------------

* Menu:

* What is Python?:: 
* What is the Python Software Foundation?:: 
* Are there copyright restrictions on the use of Python?:: 
* Why was Python created in the first place?:: 
* What is Python good for?:: 
* How does the Python version numbering scheme work?:: 
* How do I obtain a copy of the Python source?:: 
* How do I get documentation on Python?:: 
* I’ve never programmed before. Is there a Python tutorial?: I've never programmed before Is there a Python tutorial?. 
* Is there a newsgroup or mailing list devoted to Python?:: 
* How do I get a beta test version of Python?:: 
* How do I submit bug reports and patches for Python?:: 
* Are there any published articles about Python that I can reference?:: 
* Are there any books on Python?:: 
* Where in the world is www.python.org located?: Where in the world is www python org located?. 
* Why is it called Python?:: 
* Do I have to like "Monty Python's Flying Circus"?:: 


File: python.info,  Node: What is Python?,  Next: What is the Python Software Foundation?,  Up: General Information

11.1.1.1 What is Python?
........................

Python is an interpreted, interactive, object-oriented programming
language.  It incorporates modules, exceptions, dynamic typing, very
high level dynamic data types, and classes.  Python combines remarkable
power with very clear syntax.  It has interfaces to many system calls
and libraries, as well as to various window systems, and is extensible
in C or C++.  It is also usable as an extension language for
applications that need a programmable interface.  Finally, Python is
portable: it runs on many Unix variants, on the Mac, and on Windows 2000
and later.

To find out more, start with *note The Python Tutorial: bc4.  The
Beginner’s Guide to Python(1) links to other introductory tutorials and
resources for learning Python.

   ---------- Footnotes ----------

   (1) https://wiki.python.org/moin/BeginnersGuide


File: python.info,  Node: What is the Python Software Foundation?,  Next: Are there copyright restrictions on the use of Python?,  Prev: What is Python?,  Up: General Information

11.1.1.2 What is the Python Software Foundation?
................................................

The Python Software Foundation is an independent non-profit organization
that holds the copyright on Python versions 2.1 and newer.  The PSF’s
mission is to advance open source technology related to the Python
programming language and to publicize the use of Python.  The PSF’s home
page is at ‘https://www.python.org/psf/’.

Donations to the PSF are tax-exempt in the US. If you use Python and
find it helpful, please contribute via the PSF donation page(1).

   ---------- Footnotes ----------

   (1) https://www.python.org/psf/donations/


File: python.info,  Node: Are there copyright restrictions on the use of Python?,  Next: Why was Python created in the first place?,  Prev: What is the Python Software Foundation?,  Up: General Information

11.1.1.3 Are there copyright restrictions on the use of Python?
...............................................................

You can do anything you want with the source, as long as you leave the
copyrights in and display those copyrights in any documentation about
Python that you produce.  If you honor the copyright rules, it’s OK to
use Python for commercial use, to sell copies of Python in source or
binary form (modified or unmodified), or to sell products that
incorporate Python in some form.  We would still like to know about all
commercial use of Python, of course.

See the PSF license page(1) to find further explanations and a link to
the full text of the license.

The Python logo is trademarked, and in certain cases permission is
required to use it.  Consult the Trademark Usage Policy(2) for more
information.

   ---------- Footnotes ----------

   (1) https://www.python.org/psf/license/

   (2) https://www.python.org/psf/trademarks/


File: python.info,  Node: Why was Python created in the first place?,  Next: What is Python good for?,  Prev: Are there copyright restrictions on the use of Python?,  Up: General Information

11.1.1.4 Why was Python created in the first place?
...................................................

Here’s a `very' brief summary of what started it all, written by Guido
van Rossum:

     I had extensive experience with implementing an interpreted
     language in the ABC group at CWI, and from working with this group
     I had learned a lot about language design.  This is the origin of
     many Python features, including the use of indentation for
     statement grouping and the inclusion of very-high-level data types
     (although the details are all different in Python).

     I had a number of gripes about the ABC language, but also liked
     many of its features.  It was impossible to extend the ABC language
     (or its implementation) to remedy my complaints – in fact its lack
     of extensibility was one of its biggest problems.  I had some
     experience with using Modula-2+ and talked with the designers of
     Modula-3 and read the Modula-3 report.  Modula-3 is the origin of
     the syntax and semantics used for exceptions, and some other Python
     features.

     I was working in the Amoeba distributed operating system group at
     CWI. We needed a better way to do system administration than by
     writing either C programs or Bourne shell scripts, since Amoeba had
     its own system call interface which wasn’t easily accessible from
     the Bourne shell.  My experience with error handling in Amoeba made
     me acutely aware of the importance of exceptions as a programming
     language feature.

     It occurred to me that a scripting language with a syntax like ABC
     but with access to the Amoeba system calls would fill the need.  I
     realized that it would be foolish to write an Amoeba-specific
     language, so I decided that I needed a language that was generally
     extensible.

     During the 1989 Christmas holidays, I had a lot of time on my hand,
     so I decided to give it a try.  During the next year, while still
     mostly working on it in my own time, Python was used in the Amoeba
     project with increasing success, and the feedback from colleagues
     made me add many early improvements.

     In February 1991, after just over a year of development, I decided
     to post to USENET. The rest is in the ‘Misc/HISTORY’ file.


File: python.info,  Node: What is Python good for?,  Next: How does the Python version numbering scheme work?,  Prev: Why was Python created in the first place?,  Up: General Information

11.1.1.5 What is Python good for?
.................................

Python is a high-level general-purpose programming language that can be
applied to many different classes of problems.

The language comes with a large standard library that covers areas such
as string processing (regular expressions, Unicode, calculating
differences between files), Internet protocols (HTTP, FTP, SMTP,
XML-RPC, POP, IMAP, CGI programming), software engineering (unit
testing, logging, profiling, parsing Python code), and operating system
interfaces (system calls, filesystems, TCP/IP sockets).  Look at the
table of contents for *note The Python Standard Library: bc5. to get an
idea of what’s available.  A wide variety of third-party extensions are
also available.  Consult the Python Package Index(1) to find packages of
interest to you.

   ---------- Footnotes ----------

   (1) https://pypi.python.org/pypi


File: python.info,  Node: How does the Python version numbering scheme work?,  Next: How do I obtain a copy of the Python source?,  Prev: What is Python good for?,  Up: General Information

11.1.1.6 How does the Python version numbering scheme work?
...........................................................

Python versions are numbered A.B.C or A.B. A is the major version number
– it is only incremented for really major changes in the language.  B is
the minor version number, incremented for less earth-shattering changes.
C is the micro-level – it is incremented for each bugfix release.  See
PEP 6(1) for more information about bugfix releases.

Not all releases are bugfix releases.  In the run-up to a new major
release, a series of development releases are made, denoted as alpha,
beta, or release candidate.  Alphas are early releases in which
interfaces aren’t yet finalized; it’s not unexpected to see an interface
change between two alpha releases.  Betas are more stable, preserving
existing interfaces but possibly adding new modules, and release
candidates are frozen, making no changes except as needed to fix
critical bugs.

Alpha, beta and release candidate versions have an additional suffix.
The suffix for an alpha version is "aN" for some small number N, the
suffix for a beta version is "bN" for some small number N, and the
suffix for a release candidate version is "cN" for some small number N.
In other words, all versions labeled 2.0aN precede the versions labeled
2.0bN, which precede versions labeled 2.0cN, and `those' precede 2.0.

You may also find version numbers with a "+" suffix, e.g.  "2.2+".
These are unreleased versions, built directly from the Subversion trunk.
In practice, after a final minor release is made, the Subversion trunk
is incremented to the next minor version, which becomes the "a0"
version, e.g.  "2.4a0".

See also the documentation for *note sys.version: 2e3b, *note
sys.hexversion: 2e34, and *note sys.version_info: 75c.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0006


File: python.info,  Node: How do I obtain a copy of the Python source?,  Next: How do I get documentation on Python?,  Prev: How does the Python version numbering scheme work?,  Up: General Information

11.1.1.7 How do I obtain a copy of the Python source?
.....................................................

The latest Python source distribution is always available from
python.org, at ‘https://www.python.org/downloads/’.  The latest
development sources can be obtained via anonymous Mercurial access at
‘https://hg.python.org/cpython’.

The source distribution is a gzipped tar file containing the complete C
source, Sphinx-formatted documentation, Python library modules, example
programs, and several useful pieces of freely distributable software.
The source will compile and run out of the box on most UNIX platforms.

Consult the Getting Started section of the Python Developer’s Guide(1)
for more information on getting the source code and compiling it.

   ---------- Footnotes ----------

   (1) https://docs.python.org/devguide/setup.html


File: python.info,  Node: How do I get documentation on Python?,  Next: I've never programmed before Is there a Python tutorial?,  Prev: How do I obtain a copy of the Python source?,  Up: General Information

11.1.1.8 How do I get documentation on Python?
..............................................

The standard documentation for the current stable version of Python is
available at ‘https://docs.python.org/3/’.  PDF, plain text, and
downloadable HTML versions are also available at
‘https://docs.python.org/3/download.html’.

The documentation is written in reStructuredText and processed by the
Sphinx documentation tool(1).  The reStructuredText source for the
documentation is part of the Python source distribution.

   ---------- Footnotes ----------

   (1) http://sphinx-doc.org/


File: python.info,  Node: I've never programmed before Is there a Python tutorial?,  Next: Is there a newsgroup or mailing list devoted to Python?,  Prev: How do I get documentation on Python?,  Up: General Information

11.1.1.9 I’ve never programmed before. Is there a Python tutorial?
..................................................................

There are numerous tutorials and books available.  The standard
documentation includes *note The Python Tutorial: bc4.

Consult the Beginner’s Guide(1) to find information for beginning Python
programmers, including lists of tutorials.

   ---------- Footnotes ----------

   (1) https://wiki.python.org/moin/BeginnersGuide


File: python.info,  Node: Is there a newsgroup or mailing list devoted to Python?,  Next: How do I get a beta test version of Python?,  Prev: I've never programmed before Is there a Python tutorial?,  Up: General Information

11.1.1.10 Is there a newsgroup or mailing list devoted to Python?
.................................................................

There is a newsgroup, ‘comp.lang.python’, and a mailing list,
python-list(1).  The newsgroup and mailing list are gatewayed into each
other – if you can read news it’s unnecessary to subscribe to the
mailing list.  ‘comp.lang.python’ is high-traffic, receiving hundreds of
postings every day, and Usenet readers are often more able to cope with
this volume.

Announcements of new software releases and events can be found in
comp.lang.python.announce, a low-traffic moderated list that receives
about five postings per day.  It’s available as the python-announce
mailing list(2).

More info about other mailing lists and newsgroups can be found at
‘https://www.python.org/community/lists/’.

   ---------- Footnotes ----------

   (1) https://mail.python.org/mailman/listinfo/python-list

   (2) https://mail.python.org/mailman/listinfo/python-announce-list


File: python.info,  Node: How do I get a beta test version of Python?,  Next: How do I submit bug reports and patches for Python?,  Prev: Is there a newsgroup or mailing list devoted to Python?,  Up: General Information

11.1.1.11 How do I get a beta test version of Python?
.....................................................

Alpha and beta releases are available from
‘https://www.python.org/downloads/’.  All releases are announced on the
comp.lang.python and comp.lang.python.announce newsgroups and on the
Python home page at ‘https://www.python.org/’; an RSS feed of news is
available.

You can also access the development version of Python through Mercurial.
See ‘https://docs.python.org/devguide/faq.html’ for details.


File: python.info,  Node: How do I submit bug reports and patches for Python?,  Next: Are there any published articles about Python that I can reference?,  Prev: How do I get a beta test version of Python?,  Up: General Information

11.1.1.12 How do I submit bug reports and patches for Python?
.............................................................

To report a bug or submit a patch, please use the Roundup installation
at ‘https://bugs.python.org/’.

You must have a Roundup account to report bugs; this makes it possible
for us to contact you if we have follow-up questions.  It will also
enable Roundup to send you updates as we act on your bug.  If you had
previously used SourceForge to report bugs to Python, you can obtain
your Roundup password through Roundup’s password reset procedure(1).

For more information on how Python is developed, consult the Python
Developer’s Guide(2).

   ---------- Footnotes ----------

   (1) https://bugs.python.org/user?@template=forgotten

   (2) https://docs.python.org/devguide/


File: python.info,  Node: Are there any published articles about Python that I can reference?,  Next: Are there any books on Python?,  Prev: How do I submit bug reports and patches for Python?,  Up: General Information

11.1.1.13 Are there any published articles about Python that I can reference?
.............................................................................

It’s probably best to cite your favorite book about Python.

The very first article about Python was written in 1991 and is now quite
outdated.

     Guido van Rossum and Jelke de Boer, "Interactively Testing Remote
     Servers Using the Python Programming Language", CWI Quarterly,
     Volume 4, Issue 4 (December 1991), Amsterdam, pp 283-303.


File: python.info,  Node: Are there any books on Python?,  Next: Where in the world is www python org located?,  Prev: Are there any published articles about Python that I can reference?,  Up: General Information

11.1.1.14 Are there any books on Python?
........................................

Yes, there are many, and more are being published.  See the python.org
wiki at ‘https://wiki.python.org/moin/PythonBooks’ for a list.

You can also search online bookstores for "Python" and filter out the
Monty Python references; or perhaps search for "Python" and "language".


File: python.info,  Node: Where in the world is www python org located?,  Next: Why is it called Python?,  Prev: Are there any books on Python?,  Up: General Information

11.1.1.15 Where in the world is www.python.org located?
.......................................................

The Python project’s infrastructure is located all over the world.
www.python.org(1) is graciously hosted by Rackspace(2), with CDN caching
provided by Fastly(3).  Upfront Systems(4) hosts bugs.python.org(5).
Many other Python services like the Wiki(6) are hosted by Oregon State
University Open Source Lab(7).

   ---------- Footnotes ----------

   (1) https://www.python.org

   (2) http://www.rackspace.com

   (3) https://www.fastly.com

   (4) http://www.upfrontsystems.co.za/

   (5) https://bugs.python.org

   (6) https://wiki.python.org

   (7) https://osuosl.org


File: python.info,  Node: Why is it called Python?,  Next: Do I have to like "Monty Python's Flying Circus"?,  Prev: Where in the world is www python org located?,  Up: General Information

11.1.1.16 Why is it called Python?
..................................

When he began implementing Python, Guido van Rossum was also reading the
published scripts from "Monty Python’s Flying Circus"(1), a BBC comedy
series from the 1970s.  Van Rossum thought he needed a name that was
short, unique, and slightly mysterious, so he decided to call the
language Python.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Monty_Python


File: python.info,  Node: Do I have to like "Monty Python's Flying Circus"?,  Prev: Why is it called Python?,  Up: General Information

11.1.1.17 Do I have to like "Monty Python’s Flying Circus"?
...........................................................

No, but it helps.  :)


File: python.info,  Node: Python in the real world,  Prev: General Information,  Up: General Python FAQ

11.1.2 Python in the real world
-------------------------------

* Menu:

* How stable is Python?:: 
* How many people are using Python?:: 
* Have any significant projects been done in Python?:: 
* What new developments are expected for Python in the future?:: 
* Is it reasonable to propose incompatible changes to Python?:: 
* Is Python a good language for beginning programmers?:: 


File: python.info,  Node: How stable is Python?,  Next: How many people are using Python?,  Up: Python in the real world

11.1.2.1 How stable is Python?
..............................

Very stable.  New, stable releases have been coming out roughly every 6
to 18 months since 1991, and this seems likely to continue.  Currently
there are usually around 18 months between major releases.

The developers issue "bugfix" releases of older versions, so the
stability of existing releases gradually improves.  Bugfix releases,
indicated by a third component of the version number (e.g.  2.5.3,
2.6.2), are managed for stability; only fixes for known problems are
included in a bugfix release, and it’s guaranteed that interfaces will
remain the same throughout a series of bugfix releases.

The latest stable releases can always be found on the Python download
page(1).  There are two recommended production-ready versions at this
point in time, because at the moment there are two branches of stable
releases: 2.x and 3.x.  Python 3.x may be less useful than 2.x, since
currently there is more third party software available for Python 2 than
for Python 3.  Python 2 code will generally not run unchanged in Python
3.

   ---------- Footnotes ----------

   (1) https://www.python.org/downloads/


File: python.info,  Node: How many people are using Python?,  Next: Have any significant projects been done in Python?,  Prev: How stable is Python?,  Up: Python in the real world

11.1.2.2 How many people are using Python?
..........................................

There are probably tens of thousands of users, though it’s difficult to
obtain an exact count.

Python is available for free download, so there are no sales figures,
and it’s available from many different sites and packaged with many
Linux distributions, so download statistics don’t tell the whole story
either.

The comp.lang.python newsgroup is very active, but not all Python users
post to the group or even read it.


File: python.info,  Node: Have any significant projects been done in Python?,  Next: What new developments are expected for Python in the future?,  Prev: How many people are using Python?,  Up: Python in the real world

11.1.2.3 Have any significant projects been done in Python?
...........................................................

See ‘https://www.python.org/about/success’ for a list of projects that
use Python.  Consulting the proceedings for past Python conferences(1)
will reveal contributions from many different companies and
organizations.

High-profile Python projects include the Mailman mailing list manager(2)
and the Zope application server(3).  Several Linux distributions, most
notably Red Hat(4), have written part or all of their installer and
system administration software in Python.  Companies that use Python
internally include Google, Yahoo, and Lucasfilm Ltd.

   ---------- Footnotes ----------

   (1) https://www.python.org/community/workshops/

   (2) http://www.list.org

   (3) http://www.zope.org

   (4) https://www.redhat.com


File: python.info,  Node: What new developments are expected for Python in the future?,  Next: Is it reasonable to propose incompatible changes to Python?,  Prev: Have any significant projects been done in Python?,  Up: Python in the real world

11.1.2.4 What new developments are expected for Python in the future?
.....................................................................

See ‘https://www.python.org/dev/peps/’ for the Python Enhancement
Proposals (PEPs).  PEPs are design documents describing a suggested new
feature for Python, providing a concise technical specification and a
rationale.  Look for a PEP titled "Python X.Y Release Schedule", where
X.Y is a version that hasn’t been publicly released yet.

New development is discussed on the python-dev mailing list(1).

   ---------- Footnotes ----------

   (1) https://mail.python.org/mailman/listinfo/python-dev/


File: python.info,  Node: Is it reasonable to propose incompatible changes to Python?,  Next: Is Python a good language for beginning programmers?,  Prev: What new developments are expected for Python in the future?,  Up: Python in the real world

11.1.2.5 Is it reasonable to propose incompatible changes to Python?
....................................................................

In general, no.  There are already millions of lines of Python code
around the world, so any change in the language that invalidates more
than a very small fraction of existing programs has to be frowned upon.
Even if you can provide a conversion program, there’s still the problem
of updating all documentation; many books have been written about
Python, and we don’t want to invalidate them all at a single stroke.

Providing a gradual upgrade path is necessary if a feature has to be
changed.  PEP 5(1) describes the procedure followed for introducing
backward-incompatible changes while minimizing disruption for users.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0005


File: python.info,  Node: Is Python a good language for beginning programmers?,  Prev: Is it reasonable to propose incompatible changes to Python?,  Up: Python in the real world

11.1.2.6 Is Python a good language for beginning programmers?
.............................................................

Yes.

It is still common to start students with a procedural and statically
typed language such as Pascal, C, or a subset of C++ or Java.  Students
may be better served by learning Python as their first language.  Python
has a very simple and consistent syntax and a large standard library
and, most importantly, using Python in a beginning programming course
lets students concentrate on important programming skills such as
problem decomposition and data type design.  With Python, students can
be quickly introduced to basic concepts such as loops and procedures.
They can probably even work with user-defined objects in their very
first course.

For a student who has never programmed before, using a statically typed
language seems unnatural.  It presents additional complexity that the
student must master and slows the pace of the course.  The students are
trying to learn to think like a computer, decompose problems, design
consistent interfaces, and encapsulate data.  While learning to use a
statically typed language is important in the long term, it is not
necessarily the best topic to address in the students’ first programming
course.

Many other aspects of Python make it a good first language.  Like Java,
Python has a large standard library so that students can be assigned
programming projects very early in the course that `do' something.
Assignments aren’t restricted to the standard four-function calculator
and check balancing programs.  By using the standard library, students
can gain the satisfaction of working on realistic applications as they
learn the fundamentals of programming.  Using the standard library also
teaches students about code reuse.  Third-party modules such as PyGame
are also helpful in extending the students’ reach.

Python’s interactive interpreter enables students to test language
features while they’re programming.  They can keep a window with the
interpreter running while they enter their program’s source in another
window.  If they can’t remember the methods for a list, they can do
something like this:

     >>> L = []
     >>> dir(L) # doctest: +NORMALIZE_WHITESPACE
     ['__add__', '__class__', '__contains__', '__delattr__', '__delitem__',
     '__dir__', '__doc__', '__eq__', '__format__', '__ge__',
     '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__',
     '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__',
     '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__',
     '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__',
     '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear',
     'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove',
     'reverse', 'sort']
     >>> [d for d in dir(L) if '__' not in d]
     ['append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']

     >>> help(L.append)
     Help on built-in function append:
     <BLANKLINE>
     append(...)
         L.append(object) -> None -- append object to end
     <BLANKLINE>
     >>> L.append(1)
     >>> L
     [1]

With the interpreter, documentation is never far from the student as
he’s programming.

There are also good IDEs for Python.  IDLE is a cross-platform IDE for
Python that is written in Python using Tkinter.  PythonWin is a
Windows-specific IDE. Emacs users will be happy to know that there is a
very good Python mode for Emacs.  All of these programming environments
provide syntax highlighting, auto-indenting, and access to the
interactive interpreter while coding.  Consult the Python wiki(1) for a
full list of Python editing environments.

If you want to discuss Python’s use in education, you may be interested
in joining the edu-sig mailing list(2).

   ---------- Footnotes ----------

   (1) https://wiki.python.org/moin/PythonEditors

   (2) https://www.python.org/community/sigs/current/edu-sig


File: python.info,  Node: Programming FAQ,  Next: Design and History FAQ,  Prev: General Python FAQ,  Up: Python Frequently Asked Questions

11.2 Programming FAQ
====================

* Menu:

* General Questions:: 
* Core Language:: 
* Numbers and strings:: 
* Performance: Performance<4>. 
* Sequences (Tuples/Lists): Sequences Tuples/Lists. 
* Dictionaries: Dictionaries<2>. 
* Objects:: 
* Modules: Modules<3>. 


File: python.info,  Node: General Questions,  Next: Core Language,  Up: Programming FAQ

11.2.1 General Questions
------------------------

* Menu:

* Is there a source code level debugger with breakpoints, single-stepping, etc.?: Is there a source code level debugger with breakpoints single-stepping etc ?. 
* Is there a tool to help find bugs or perform static analysis?:: 
* How can I create a stand-alone binary from a Python script?:: 
* Are there coding standards or a style guide for Python programs?:: 


File: python.info,  Node: Is there a source code level debugger with breakpoints single-stepping etc ?,  Next: Is there a tool to help find bugs or perform static analysis?,  Up: General Questions

11.2.1.1 Is there a source code level debugger with breakpoints, single-stepping, etc.?
.......................................................................................

Yes.

The pdb module is a simple but adequate console-mode debugger for
Python.  It is part of the standard Python library, and is *note
documented in the Library Reference Manual: c7.  You can also write your
own debugger by using the code for pdb as an example.

The IDLE interactive development environment, which is part of the
standard Python distribution (normally available as Tools/scripts/idle),
includes a graphical debugger.

PythonWin is a Python IDE that includes a GUI debugger based on pdb.
The Pythonwin debugger colors breakpoints and has quite a few cool
features such as debugging non-Pythonwin programs.  Pythonwin is
available as part of the Python for Windows Extensions(1) project and as
a part of the ActivePython distribution (see
‘http://www.activestate.com/activepython’).

Boa Constructor(2) is an IDE and GUI builder that uses wxWidgets.  It
offers visual frame creation and manipulation, an object inspector, many
views on the source like object browsers, inheritance hierarchies, doc
string generated html documentation, an advanced debugger, integrated
help, and Zope support.

Eric(3) is an IDE built on PyQt and the Scintilla editing component.

Pydb is a version of the standard Python debugger pdb, modified for use
with DDD (Data Display Debugger), a popular graphical debugger front
end.  Pydb can be found at ‘http://bashdb.sourceforge.net/pydb/’ and DDD
can be found at ‘http://www.gnu.org/software/ddd’.

There are a number of commercial Python IDEs that include graphical
debuggers.  They include:

   * Wing IDE (‘http://wingware.com/’)

   * Komodo IDE (‘http://komodoide.com/’)

   * PyCharm (‘https://www.jetbrains.com/pycharm/’)

   ---------- Footnotes ----------

   (1) http://sourceforge.net/projects/pywin32/

   (2) http://boa-constructor.sourceforge.net/

   (3) http://eric-ide.python-projects.org/


File: python.info,  Node: Is there a tool to help find bugs or perform static analysis?,  Next: How can I create a stand-alone binary from a Python script?,  Prev: Is there a source code level debugger with breakpoints single-stepping etc ?,  Up: General Questions

11.2.1.2 Is there a tool to help find bugs or perform static analysis?
......................................................................

Yes.

PyChecker is a static analysis tool that finds bugs in Python source
code and warns about code complexity and style.  You can get PyChecker
from ‘http://pychecker.sourceforge.net/’.

Pylint(1) is another tool that checks if a module satisfies a coding
standard, and also makes it possible to write plug-ins to add a custom
feature.  In addition to the bug checking that PyChecker performs,
Pylint offers some additional features such as checking line length,
whether variable names are well-formed according to your coding
standard, whether declared interfaces are fully implemented, and more.
‘http://docs.pylint.org/’ provides a full list of Pylint’s features.

   ---------- Footnotes ----------

   (1) http://www.pylint.org/


File: python.info,  Node: How can I create a stand-alone binary from a Python script?,  Next: Are there coding standards or a style guide for Python programs?,  Prev: Is there a tool to help find bugs or perform static analysis?,  Up: General Questions

11.2.1.3 How can I create a stand-alone binary from a Python script?
....................................................................

You don’t need the ability to compile Python to C code if all you want
is a stand-alone program that users can download and run without having
to install the Python distribution first.  There are a number of tools
that determine the set of modules required by a program and bind these
modules together with a Python binary to produce a single executable.

One is to use the freeze tool, which is included in the Python source
tree as ‘Tools/freeze’.  It converts Python byte code to C arrays; a C
compiler you can embed all your modules into a new program, which is
then linked with the standard Python modules.

It works by scanning your source recursively for import statements (in
both forms) and looking for the modules in the standard Python path as
well as in the source directory (for built-in modules).  It then turns
the bytecode for modules written in Python into C code (array
initializers that can be turned into code objects using the marshal
module) and creates a custom-made config file that only contains those
built-in modules which are actually used in the program.  It then
compiles the generated C code and links it with the rest of the Python
interpreter to form a self-contained binary which acts exactly like your
script.

Obviously, freeze requires a C compiler.  There are several other
utilities which don’t.  One is Thomas Heller’s py2exe (Windows only) at

     ‘http://www.py2exe.org/’

Another tool is Anthony Tuininga’s cx_Freeze(1).

   ---------- Footnotes ----------

   (1) http://cx-freeze.sourceforge.net/


File: python.info,  Node: Are there coding standards or a style guide for Python programs?,  Prev: How can I create a stand-alone binary from a Python script?,  Up: General Questions

11.2.1.4 Are there coding standards or a style guide for Python programs?
.........................................................................

Yes.  The coding style required for standard library modules is
documented as PEP 8(1).

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0008


File: python.info,  Node: Core Language,  Next: Numbers and strings,  Prev: General Questions,  Up: Programming FAQ

11.2.2 Core Language
--------------------

* Menu:

* Why am I getting an UnboundLocalError when the variable has a value?:: 
* What are the rules for local and global variables in Python?:: 
* Why do lambdas defined in a loop with different values all return the same result?:: 
* How do I share global variables across modules?:: 
* What are the "best practices" for using import in a module?:: 
* Why are default values shared between objects?:: 
* How can I pass optional or keyword parameters from one function to another?:: 
* What is the difference between arguments and parameters?:: 
* Why did changing list 'y' also change list 'x'?:: 
* How do I write a function with output parameters (call by reference)?: How do I write a function with output parameters call by reference ?. 
* How do you make a higher order function in Python?:: 
* How do I copy an object in Python?:: 
* How can I find the methods or attributes of an object?:: 
* How can my code discover the name of an object?:: 
* What's up with the comma operator's precedence?:: 
* Is there an equivalent of C’s "?;" ternary operator?: Is there an equivalent of C's "? " ternary operator?. 
* Is it possible to write obfuscated one-liners in Python?:: 


File: python.info,  Node: Why am I getting an UnboundLocalError when the variable has a value?,  Next: What are the rules for local and global variables in Python?,  Up: Core Language

11.2.2.1 Why am I getting an UnboundLocalError when the variable has a value?
.............................................................................

It can be a surprise to get the UnboundLocalError in previously working
code when it is modified by adding an assignment statement somewhere in
the body of a function.

This code:

     >>> x = 10
     >>> def bar():
     ...     print(x)
     >>> bar()
     10

works, but this code:

     >>> x = 10
     >>> def foo():
     ...     print(x)
     ...     x += 1

results in an UnboundLocalError:

     >>> foo()
     Traceback (most recent call last):
       ...
     UnboundLocalError: local variable 'x' referenced before assignment

This is because when you make an assignment to a variable in a scope,
that variable becomes local to that scope and shadows any similarly
named variable in the outer scope.  Since the last statement in foo
assigns a new value to ‘x’, the compiler recognizes it as a local
variable.  Consequently when the earlier ‘print(x)’ attempts to print
the uninitialized local variable and an error results.

In the example above you can access the outer scope variable by
declaring it global:

     >>> x = 10
     >>> def foobar():
     ...     global x
     ...     print(x)
     ...     x += 1
     >>> foobar()
     10

This explicit declaration is required in order to remind you that
(unlike the superficially analogous situation with class and instance
variables) you are actually modifying the value of the variable in the
outer scope:

     >>> print(x)
     11

You can do a similar thing in a nested scope using the *note nonlocal:
8a6. keyword:

     >>> def foo():
     ...    x = 10
     ...    def bar():
     ...        nonlocal x
     ...        print(x)
     ...        x += 1
     ...    bar()
     ...    print(x)
     >>> foo()
     10
     11


File: python.info,  Node: What are the rules for local and global variables in Python?,  Next: Why do lambdas defined in a loop with different values all return the same result?,  Prev: Why am I getting an UnboundLocalError when the variable has a value?,  Up: Core Language

11.2.2.2 What are the rules for local and global variables in Python?
.....................................................................

In Python, variables that are only referenced inside a function are
implicitly global.  If a variable is assigned a value anywhere within
the function’s body, it’s assumed to be a local unless explicitly
declared as global.

Though a bit surprising at first, a moment’s consideration explains
this.  On one hand, requiring *note global: c0b. for assigned variables
provides a bar against unintended side-effects.  On the other hand, if
‘global’ was required for all global references, you’d be using ‘global’
all the time.  You’d have to declare as global every reference to a
built-in function or to a component of an imported module.  This clutter
would defeat the usefulness of the ‘global’ declaration for identifying
side-effects.


File: python.info,  Node: Why do lambdas defined in a loop with different values all return the same result?,  Next: How do I share global variables across modules?,  Prev: What are the rules for local and global variables in Python?,  Up: Core Language

11.2.2.3 Why do lambdas defined in a loop with different values all return the same result?
...........................................................................................

Assume you use a for loop to define a few different lambdas (or even
plain functions), e.g.:

     >>> squares = []
     >>> for x in range(5):
     ...    squares.append(lambda: x**2)

This gives you a list that contains 5 lambdas that calculate ‘x**2’.
You might expect that, when called, they would return, respectively,
‘0’, ‘1’, ‘4’, ‘9’, and ‘16’.  However, when you actually try you will
see that they all return ‘16’:

     >>> squares[2]()
     16
     >>> squares[4]()
     16

This happens because ‘x’ is not local to the lambdas, but is defined in
the outer scope, and it is accessed when the lambda is called — not when
it is defined.  At the end of the loop, the value of ‘x’ is ‘4’, so all
the functions now return ‘4**2’, i.e.  ‘16’.  You can also verify this
by changing the value of ‘x’ and see how the results of the lambdas
change:

     >>> x = 8
     >>> squares[2]()
     64

In order to avoid this, you need to save the values in variables local
to the lambdas, so that they don’t rely on the value of the global ‘x’:

     >>> squares = []
     >>> for x in range(5):
     ...    squares.append(lambda n=x: n**2)

Here, ‘n=x’ creates a new variable ‘n’ local to the lambda and computed
when the lambda is defined so that it has the same value that ‘x’ had at
that point in the loop.  This means that the value of ‘n’ will be ‘0’ in
the first lambda, ‘1’ in the second, ‘2’ in the third, and so on.
Therefore each lambda will now return the correct result:

     >>> squares[2]()
     4
     >>> squares[4]()
     16

Note that this behaviour is not peculiar to lambdas, but applies to
regular functions too.


File: python.info,  Node: How do I share global variables across modules?,  Next: What are the "best practices" for using import in a module?,  Prev: Why do lambdas defined in a loop with different values all return the same result?,  Up: Core Language

11.2.2.4 How do I share global variables across modules?
........................................................

The canonical way to share information across modules within a single
program is to create a special module (often called config or cfg).
Just import the config module in all modules of your application; the
module then becomes available as a global name.  Because there is only
one instance of each module, any changes made to the module object get
reflected everywhere.  For example:

config.py:

     x = 0   # Default value of the 'x' configuration setting

mod.py:

     import config
     config.x = 1

main.py:

     import config
     import mod
     print(config.x)

Note that using a module is also the basis for implementing the
Singleton design pattern, for the same reason.


File: python.info,  Node: What are the "best practices" for using import in a module?,  Next: Why are default values shared between objects?,  Prev: How do I share global variables across modules?,  Up: Core Language

11.2.2.5 What are the "best practices" for using import in a module?
....................................................................

In general, don’t use ‘from modulename import *’.  Doing so clutters the
importer’s namespace, and makes it much harder for linters to detect
undefined names.

Import modules at the top of a file.  Doing so makes it clear what other
modules your code requires and avoids questions of whether the module
name is in scope.  Using one import per line makes it easy to add and
delete module imports, but using multiple imports per line uses less
screen space.

It’s good practice if you import modules in the following order:

  1. standard library modules – e.g.  ‘sys’, ‘os’, ‘getopt’, ‘re’

  2. third-party library modules (anything installed in Python’s
     site-packages directory) – e.g.  mx.DateTime, ZODB, PIL.Image, etc.

  3. locally-developed modules

It is sometimes necessary to move imports to a function or class to
avoid problems with circular imports.  Gordon McMillan says:

     Circular imports are fine where both modules use the "import
     <module>" form of import.  They fail when the 2nd module wants to
     grab a name out of the first ("from module import name") and the
     import is at the top level.  That’s because names in the 1st are
     not yet available, because the first module is busy importing the
     2nd.

In this case, if the second module is only used in one function, then
the import can easily be moved into that function.  By the time the
import is called, the first module will have finished initializing, and
the second module can do its import.

It may also be necessary to move imports out of the top level of code if
some of the modules are platform-specific.  In that case, it may not
even be possible to import all of the modules at the top of the file.
In this case, importing the correct modules in the corresponding
platform-specific code is a good option.

Only move imports into a local scope, such as inside a function
definition, if it’s necessary to solve a problem such as avoiding a
circular import or are trying to reduce the initialization time of a
module.  This technique is especially helpful if many of the imports are
unnecessary depending on how the program executes.  You may also want to
move imports into a function if the modules are only ever used in that
function.  Note that loading a module the first time may be expensive
because of the one time initialization of the module, but loading a
module multiple times is virtually free, costing only a couple of
dictionary lookups.  Even if the module name has gone out of scope, the
module is probably available in *note sys.modules: e75.


File: python.info,  Node: Why are default values shared between objects?,  Next: How can I pass optional or keyword parameters from one function to another?,  Prev: What are the "best practices" for using import in a module?,  Up: Core Language

11.2.2.6 Why are default values shared between objects?
.......................................................

This type of bug commonly bites neophyte programmers.  Consider this
function:

     def foo(mydict={}):  # Danger: shared reference to one dict for all calls
         ... compute something ...
         mydict[key] = value
         return mydict

The first time you call this function, ‘mydict’ contains a single item.
The second time, ‘mydict’ contains two items because when ‘foo()’ begins
executing, ‘mydict’ starts out with an item already in it.

It is often expected that a function call creates new objects for
default values.  This is not what happens.  Default values are created
exactly once, when the function is defined.  If that object is changed,
like the dictionary in this example, subsequent calls to the function
will refer to this changed object.

By definition, immutable objects such as numbers, strings, tuples, and
‘None’, are safe from change.  Changes to mutable objects such as
dictionaries, lists, and class instances can lead to confusion.

Because of this feature, it is good programming practice to not use
mutable objects as default values.  Instead, use ‘None’ as the default
value and inside the function, check if the parameter is ‘None’ and
create a new list/dictionary/whatever if it is.  For example, don’t
write:

     def foo(mydict={}):
         ...

but:

     def foo(mydict=None):
         if mydict is None:
             mydict = {}  # create a new dict for local namespace

This feature can be useful.  When you have a function that’s
time-consuming to compute, a common technique is to cache the parameters
and the resulting value of each call to the function, and return the
cached value if the same value is requested again.  This is called
"memoizing", and can be implemented like this:

     # Callers will never provide a third parameter for this function.
     def expensive(arg1, arg2, _cache={}):
         if (arg1, arg2) in _cache:
             return _cache[(arg1, arg2)]

         # Calculate the value
         result = ... expensive computation ...
         _cache[(arg1, arg2)] = result           # Store result in the cache
         return result

You could use a global variable containing a dictionary instead of the
default value; it’s a matter of taste.


File: python.info,  Node: How can I pass optional or keyword parameters from one function to another?,  Next: What is the difference between arguments and parameters?,  Prev: Why are default values shared between objects?,  Up: Core Language

11.2.2.7 How can I pass optional or keyword parameters from one function to another?
....................................................................................

Collect the arguments using the ‘*’ and ‘**’ specifiers in the
function’s parameter list; this gives you the positional arguments as a
tuple and the keyword arguments as a dictionary.  You can then pass
these arguments when calling another function by using ‘*’ and ‘**’:

     def f(x, *args, **kwargs):
         ...
         kwargs['width'] = '14.3c'
         ...
         g(x, *args, **kwargs)


File: python.info,  Node: What is the difference between arguments and parameters?,  Next: Why did changing list 'y' also change list 'x'?,  Prev: How can I pass optional or keyword parameters from one function to another?,  Up: Core Language

11.2.2.8 What is the difference between arguments and parameters?
.................................................................

*note Parameters: ee6. are defined by the names that appear in a
function definition, whereas *note arguments: ee0. are the values
actually passed to a function when calling it.  Parameters define what
types of arguments a function can accept.  For example, given the
function definition:

     def func(foo, bar=None, **kwargs):
         pass

`foo', `bar' and `kwargs' are parameters of ‘func’.  However, when
calling ‘func’, for example:

     func(42, bar=314, extra=somevar)

the values ‘42’, ‘314’, and ‘somevar’ are arguments.


File: python.info,  Node: Why did changing list 'y' also change list 'x'?,  Next: How do I write a function with output parameters call by reference ?,  Prev: What is the difference between arguments and parameters?,  Up: Core Language

11.2.2.9 Why did changing list ’y’ also change list ’x’?
........................................................

If you wrote code like:

     >>> x = []
     >>> y = x
     >>> y.append(10)
     >>> y
     [10]
     >>> x
     [10]

you might be wondering why appending an element to ‘y’ changed ‘x’ too.

There are two factors that produce this result:

  1. Variables are simply names that refer to objects.  Doing ‘y = x’
     doesn’t create a copy of the list – it creates a new variable ‘y’
     that refers to the same object ‘x’ refers to.  This means that
     there is only one object (the list), and both ‘x’ and ‘y’ refer to
     it.

  2. Lists are *note mutable: bf0, which means that you can change their
     content.

After the call to ‘append()’, the content of the mutable object has
changed from ‘[]’ to ‘[10]’.  Since both the variables refer to the same
object, using either name accesses the modified value ‘[10]’.

If we instead assign an immutable object to ‘x’:

     >>> x = 5  # ints are immutable
     >>> y = x
     >>> x = x + 1  # 5 can't be mutated, we are creating a new object here
     >>> x
     6
     >>> y
     5

we can see that in this case ‘x’ and ‘y’ are not equal anymore.  This is
because integers are *note immutable: be9, and when we do ‘x = x + 1’ we
are not mutating the int ‘5’ by incrementing its value; instead, we are
creating a new object (the int ‘6’) and assigning it to ‘x’ (that is,
changing which object ‘x’ refers to).  After this assignment we have two
objects (the ints ‘6’ and ‘5’) and two variables that refer to them (‘x’
now refers to ‘6’ but ‘y’ still refers to ‘5’).

Some operations (for example ‘y.append(10)’ and ‘y.sort()’) mutate the
object, whereas superficially similar operations (for example ‘y = y +
[10]’ and ‘sorted(y)’) create a new object.  In general in Python (and
in all cases in the standard library) a method that mutates an object
will return ‘None’ to help avoid getting the two types of operations
confused.  So if you mistakenly write ‘y.sort()’ thinking it will give
you a sorted copy of ‘y’, you’ll instead end up with ‘None’, which will
likely cause your program to generate an easily diagnosed error.

However, there is one class of operations where the same operation
sometimes has different behaviors with different types: the augmented
assignment operators.  For example, ‘+=’ mutates lists but not tuples or
ints (‘a_list += [1, 2, 3]’ is equivalent to ‘a_list.extend([1, 2, 3])’
and mutates ‘a_list’, whereas ‘some_tuple += (1, 2, 3)’ and ‘some_int +=
1’ create new objects).

In other words:

   * If we have a mutable object (*note list: 25d, *note dict: 3b0,
     *note set: 7be, etc.), we can use some specific operations to
     mutate it and all the variables that refer to it will see the
     change.

   * If we have an immutable object (*note str: 25a, *note int: 227,
     *note tuple: 25c, etc.), all the variables that refer to it will
     always see the same value, but operations that transform that value
     into a new value always return a new object.

If you want to know if two variables refer to the same object or not,
you can use the *note is: dde. operator, or the built-in function *note
id(): a00.


File: python.info,  Node: How do I write a function with output parameters call by reference ?,  Next: How do you make a higher order function in Python?,  Prev: Why did changing list 'y' also change list 'x'?,  Up: Core Language

11.2.2.10 How do I write a function with output parameters (call by reference)?
...............................................................................

Remember that arguments are passed by assignment in Python.  Since
assignment just creates references to objects, there’s no alias between
an argument name in the caller and callee, and so no call-by-reference
per se.  You can achieve the desired effect in a number of ways.

  1. By returning a tuple of the results:

          def func2(a, b):
              a = 'new-value'        # a and b are local names
              b = b + 1              # assigned to new objects
              return a, b            # return new values

          x, y = 'old-value', 99
          x, y = func2(x, y)
          print(x, y)                # output: new-value 100

     This is almost always the clearest solution.

  2. By using global variables.  This isn’t thread-safe, and is not
     recommended.

  3. By passing a mutable (changeable in-place) object:

          def func1(a):
              a[0] = 'new-value'     # 'a' references a mutable list
              a[1] = a[1] + 1        # changes a shared object

          args = ['old-value', 99]
          func1(args)
          print(args[0], args[1])    # output: new-value 100

  4. By passing in a dictionary that gets mutated:

          def func3(args):
              args['a'] = 'new-value'     # args is a mutable dictionary
              args['b'] = args['b'] + 1   # change it in-place

          args = {'a':' old-value', 'b': 99}
          func3(args)
          print(args['a'], args['b'])

  5. Or bundle up values in a class instance:

          class callByRef:
              def __init__(self, **args):
                  for (key, value) in args.items():
                      setattr(self, key, value)

          def func4(args):
              args.a = 'new-value'        # args is a mutable callByRef
              args.b = args.b + 1         # change object in-place

          args = callByRef(a='old-value', b=99)
          func4(args)
          print(args.a, args.b)

     There’s almost never a good reason to get this complicated.

Your best choice is to return a tuple containing the multiple results.


File: python.info,  Node: How do you make a higher order function in Python?,  Next: How do I copy an object in Python?,  Prev: How do I write a function with output parameters call by reference ?,  Up: Core Language

11.2.2.11 How do you make a higher order function in Python?
............................................................

You have two choices: you can use nested scopes or you can use callable
objects.  For example, suppose you wanted to define ‘linear(a,b)’ which
returns a function ‘f(x)’ that computes the value ‘a*x+b’.  Using nested
scopes:

     def linear(a, b):
         def result(x):
             return a * x + b
         return result

Or using a callable object:

     class linear:

         def __init__(self, a, b):
             self.a, self.b = a, b

         def __call__(self, x):
             return self.a * x + self.b

In both cases,

     taxes = linear(0.3, 2)

gives a callable object where ‘taxes(10e6) == 0.3 * 10e6 + 2’.

The callable object approach has the disadvantage that it is a bit
slower and results in slightly longer code.  However, note that a
collection of callables can share their signature via inheritance:

     class exponential(linear):
         # __init__ inherited
         def __call__(self, x):
             return self.a * (x ** self.b)

Object can encapsulate state for several methods:

     class counter:

         value = 0

         def set(self, x):
             self.value = x

         def up(self):
             self.value = self.value + 1

         def down(self):
             self.value = self.value - 1

     count = counter()
     inc, dec, reset = count.up, count.down, count.set

Here ‘inc()’, ‘dec()’ and ‘reset()’ act like functions which share the
same counting variable.


File: python.info,  Node: How do I copy an object in Python?,  Next: How can I find the methods or attributes of an object?,  Prev: How do you make a higher order function in Python?,  Up: Core Language

11.2.2.12 How do I copy an object in Python?
............................................

In general, try *note copy.copy(): 136a. or *note copy.deepcopy(): 90e.
for the general case.  Not all objects can be copied, but most can.

Some objects can be copied more easily.  Dictionaries have a *note
copy(): 1087. method:

     newdict = olddict.copy()

Sequences can be copied by slicing:

     new_l = l[:]


File: python.info,  Node: How can I find the methods or attributes of an object?,  Next: How can my code discover the name of an object?,  Prev: How do I copy an object in Python?,  Up: Core Language

11.2.2.13 How can I find the methods or attributes of an object?
................................................................

For an instance x of a user-defined class, ‘dir(x)’ returns an
alphabetized list of the names containing the instance attributes and
methods and attributes defined by its class.


File: python.info,  Node: How can my code discover the name of an object?,  Next: What's up with the comma operator's precedence?,  Prev: How can I find the methods or attributes of an object?,  Up: Core Language

11.2.2.14 How can my code discover the name of an object?
.........................................................

Generally speaking, it can’t, because objects don’t really have names.
Essentially, assignment always binds a name to a value; The same is true
of ‘def’ and ‘class’ statements, but in that case the value is a
callable.  Consider the following code:

     class A:
         pass

     B = A

     a = B()
     b = a
     print(b)
     <__main__.A object at 0x16D07CC>
     print(a)
     <__main__.A object at 0x16D07CC>

Arguably the class has a name: even though it is bound to two names and
invoked through the name B the created instance is still reported as an
instance of class A. However, it is impossible to say whether the
instance’s name is a or b, since both names are bound to the same value.

Generally speaking it should not be necessary for your code to "know the
names" of particular values.  Unless you are deliberately writing
introspective programs, this is usually an indication that a change of
approach might be beneficial.

In comp.lang.python, Fredrik Lundh once gave an excellent analogy in
answer to this question:

     The same way as you get the name of that cat you found on your
     porch: the cat (object) itself cannot tell you its name, and it
     doesn’t really care – so the only way to find out what it’s called
     is to ask all your neighbours (namespaces) if it’s their cat
     (object)...

     ....and don’t be surprised if you’ll find that it’s known by many
     names, or no name at all!


File: python.info,  Node: What's up with the comma operator's precedence?,  Next: Is there an equivalent of C's "? " ternary operator?,  Prev: How can my code discover the name of an object?,  Up: Core Language

11.2.2.15 What’s up with the comma operator’s precedence?
.........................................................

Comma is not an operator in Python.  Consider this session:

     >>> "a" in "b", "a"
     (False, 'a')

Since the comma is not an operator, but a separator between expressions
the above is evaluated as if you had entered:

     ("a" in "b"), "a"

not:

     "a" in ("b", "a")

The same is true of the various assignment operators (‘=’, ‘+=’ etc).
They are not truly operators but syntactic delimiters in assignment
statements.


File: python.info,  Node: Is there an equivalent of C's "? " ternary operator?,  Next: Is it possible to write obfuscated one-liners in Python?,  Prev: What's up with the comma operator's precedence?,  Up: Core Language

11.2.2.16 Is there an equivalent of C’s "?:" ternary operator?
..............................................................

Yes, there is.  The syntax is as follows:

     [on_true] if [expression] else [on_false]

     x, y = 50, 25
     small = x if x < y else y

Before this syntax was introduced in Python 2.5, a common idiom was to
use logical operators:

     [expression] and [on_true] or [on_false]

However, this idiom is unsafe, as it can give wrong results when
`on_true' has a false boolean value.  Therefore, it is always better to
use the ‘... if ... else ...’ form.

