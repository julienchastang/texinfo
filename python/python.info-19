This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: SSL Contexts,  Next: Certificates,  Prev: SSL Sockets,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.8 SSL Contexts
.....................

New in version 3.2.

An SSL context holds various data longer-lived than single SSL
connections, such as SSL configuration options, certificate(s) and
private key(s).  It also manages a cache of SSL sessions for server-side
sockets, in order to speed up repeated connections from the same
clients.

 -- Class: ssl.SSLContext (protocol)

     Create a new SSL context.  You must pass `protocol' which must be
     one of the ‘PROTOCOL_*’ constants defined in this module.  *note
     PROTOCOL_SSLv23: 1e76. is currently recommended for maximum
     interoperability.

     See also
     ........

     *note create_default_context(): 4c1. lets the *note ssl: f1. module
     choose security settings for a given purpose.

*note SSLContext: 1c6. objects have the following methods and
attributes:

 -- Method: SSLContext.cert_store_stats ()

     Get statistics about quantities of loaded X.509 certificates, count
     of X.509 certificates flagged as CA certificates and certificate
     revocation lists as dictionary.

     Example for a context with one CA cert and one other cert:

          >>> context.cert_store_stats()
          {'crl': 0, 'x509_ca': 1, 'x509': 2}

     New in version 3.4.

 -- Method: SSLContext.load_cert_chain (certfile, keyfile=None,
          password=None)

     Load a private key and the corresponding certificate.  The
     `certfile' string must be the path to a single file in PEM format
     containing the certificate as well as any number of CA certificates
     needed to establish the certificate’s authenticity.  The `keyfile'
     string, if present, must point to a file containing the private key
     in.  Otherwise the private key will be taken from `certfile' as
     well.  See the discussion of *note Certificates: 1e72. for more
     information on how the certificate is stored in the `certfile'.

     The `password' argument may be a function to call to get the
     password for decrypting the private key.  It will only be called if
     the private key is encrypted and a password is necessary.  It will
     be called with no arguments, and it should return a string, bytes,
     or bytearray.  If the return value is a string it will be encoded
     as UTF-8 before using it to decrypt the key.  Alternatively a
     string, bytes, or bytearray value may be supplied directly as the
     `password' argument.  It will be ignored if the private key is not
     encrypted and no password is needed.

     If the `password' argument is not specified and a password is
     required, OpenSSL’s built-in password prompting mechanism will be
     used to interactively prompt the user for a password.

     An *note SSLError: 870. is raised if the private key doesn’t match
     with the certificate.

     Changed in version 3.3: New optional argument `password'.

 -- Method: SSLContext.load_default_certs (purpose=Purpose.SERVER_AUTH)

     Load a set of default "certification authority" (CA) certificates
     from default locations.  On Windows it loads CA certs from the ‘CA’
     and ‘ROOT’ system stores.  On other systems it calls *note
     SSLContext.set_default_verify_paths(): 4c3.  In the future the
     method may load CA certificates from other locations, too.

     The `purpose' flag specifies what kind of CA certificates are
     loaded.  The default settings *note Purpose.SERVER_AUTH: 4cc. loads
     certificates, that are flagged and trusted for TLS web server
     authentication (client side sockets).  *note Purpose.CLIENT_AUTH:
     4cd. loads CA certificates for client certificate verification on
     the server side.

     New in version 3.4.

 -- Method: SSLContext.load_verify_locations (cafile=None, capath=None,
          cadata=None)

     Load a set of "certification authority" (CA) certificates used to
     validate other peers’ certificates when *note verify_mode: 1e79. is
     other than *note CERT_NONE: 1e73.  At least one of `cafile' or
     `capath' must be specified.

     This method can also load certification revocation lists (CRLs) in
     PEM or DER format.  In order to make use of CRLs, *note
     SSLContext.verify_flags: 4c6. must be configured properly.

     The `cafile' string, if present, is the path to a file of
     concatenated CA certificates in PEM format.  See the discussion of
     *note Certificates: 1e72. for more information about how to arrange
     the certificates in this file.

     The `capath' string, if present, is the path to a directory
     containing several CA certificates in PEM format, following an
     OpenSSL specific layout(1).

     The `cadata' object, if present, is either an ASCII string of one
     or more PEM-encoded certificates or a *note bytes-like object: 36b.
     of DER-encoded certificates.  Like with `capath' extra lines around
     PEM-encoded certificates are ignored but at least one certificate
     must be present.

     Changed in version 3.4: New optional argument `cadata'

 -- Method: SSLContext.get_ca_certs (binary_form=False)

     Get a list of loaded "certification authority" (CA) certificates.
     If the ‘binary_form’ parameter is *note False: 60d. each list entry
     is a dict like the output of *note SSLSocket.getpeercert(): 4d1.
     Otherwise the method returns a list of DER-encoded certificates.
     The returned list does not contain certificates from `capath'
     unless a certificate was requested and loaded by a SSL connection.

          Note: Certificates in a capath directory aren’t loaded unless
          they have been used at least once.

     New in version 3.4.

 -- Method: SSLContext.set_default_verify_paths ()

     Load a set of default "certification authority" (CA) certificates
     from a filesystem path defined when building the OpenSSL library.
     Unfortunately, there’s no easy way to know whether this method
     succeeds: no error is returned if no certificates are to be found.
     When the OpenSSL library is provided as part of the operating
     system, though, it is likely to be configured properly.

 -- Method: SSLContext.set_ciphers (ciphers)

     Set the available ciphers for sockets created with this context.
     It should be a string in the OpenSSL cipher list format(2).  If no
     cipher can be selected (because compile-time options or other
     configuration forbids use of all the specified ciphers), an *note
     SSLError: 870. will be raised.

          Note: when connected, the *note SSLSocket.cipher(): 1e96.
          method of SSL sockets will give the currently selected cipher.

 -- Method: SSLContext.set_alpn_protocols (protocols)

     Specify which protocols the socket should advertise during the
     SSL/TLS handshake.  It should be a list of ASCII strings, like
     ‘['http/1.1', 'spdy/2']’, ordered by preference.  The selection of
     a protocol will happen during the handshake, and will play out
     according to RFC 7301(3).  After a successful handshake, the *note
     SSLSocket.selected_alpn_protocol(): 320. method will return the
     agreed-upon protocol.

     This method will raise *note NotImplementedError: 569. if *note
     HAS_ALPN: 321. is False.

     New in version 3.5.

 -- Method: SSLContext.set_npn_protocols (protocols)

     Specify which protocols the socket should advertise during the
     SSL/TLS handshake.  It should be a list of strings, like
     ‘['http/1.1', 'spdy/2']’, ordered by preference.  The selection of
     a protocol will happen during the handshake, and will play out
     according to the NPN draft specification(4).  After a successful
     handshake, the *note SSLSocket.selected_npn_protocol(): 1e97.
     method will return the agreed-upon protocol.

     This method will raise *note NotImplementedError: 569. if *note
     HAS_NPN: 1e8e. is False.

     New in version 3.3.

 -- Method: SSLContext.set_servername_callback (server_name_callback)

     Register a callback function that will be called after the TLS
     Client Hello handshake message has been received by the SSL/TLS
     server when the TLS client specifies a server name indication.  The
     server name indication mechanism is specified in RFC 6066(5)
     section 3 - Server Name Indication.

     Only one callback can be set per ‘SSLContext’.  If
     `server_name_callback' is ‘None’ then the callback is disabled.
     Calling this function a subsequent time will disable the previously
     registered callback.

     The callback function, `server_name_callback', will be called with
     three arguments; the first being the *note ssl.SSLSocket: 31b, the
     second is a string that represents the server name that the client
     is intending to communicate (or *note None: 19d. if the TLS Client
     Hello does not contain a server name) and the third argument is the
     original *note SSLContext: 1c6.  The server name argument is the
     IDNA decoded server name.

     A typical use of this callback is to change the *note
     ssl.SSLSocket: 31b.’s *note SSLSocket.context: 1e95. attribute to a
     new object of type *note SSLContext: 1c6. representing a
     certificate chain that matches the server name.

     Due to the early negotiation phase of the TLS connection, only
     limited methods and attributes are usable like *note
     SSLSocket.selected_alpn_protocol(): 320. and *note
     SSLSocket.context: 1e95.  *note SSLSocket.getpeercert(): 4d1, *note
     SSLSocket.getpeercert(): 4d1, *note SSLSocket.cipher(): 1e96. and
     ‘SSLSocket.compress()’ methods require that the TLS connection has
     progressed beyond the TLS Client Hello and therefore will not
     contain return meaningful values nor can they be called safely.

     The `server_name_callback' function must return ‘None’ to allow the
     TLS negotiation to continue.  If a TLS failure is required, a
     constant *note ALERT_DESCRIPTION_*: 1e91. can be returned.  Other
     return values will result in a TLS fatal error with *note
     ALERT_DESCRIPTION_INTERNAL_ERROR: 1e91.

     If there is an IDNA decoding error on the server name, the TLS
     connection will terminate with an *note
     ALERT_DESCRIPTION_INTERNAL_ERROR: 1e91. fatal TLS alert message to
     the client.

     If an exception is raised from the `server_name_callback' function
     the TLS connection will terminate with a fatal TLS alert message
     *note ALERT_DESCRIPTION_HANDSHAKE_FAILURE: 1e90.

     This method will raise *note NotImplementedError: 569. if the
     OpenSSL library had OPENSSL_NO_TLSEXT defined when it was built.

     New in version 3.4.

 -- Method: SSLContext.load_dh_params (dhfile)

     Load the key generation parameters for Diffie-Helman (DH) key
     exchange.  Using DH key exchange improves forward secrecy at the
     expense of computational resources (both on the server and on the
     client).  The `dhfile' parameter should be the path to a file
     containing DH parameters in PEM format.

     This setting doesn’t apply to client sockets.  You can also use the
     *note OP_SINGLE_DH_USE: 1e8a. option to further improve security.

     New in version 3.3.

 -- Method: SSLContext.set_ecdh_curve (curve_name)

     Set the curve name for Elliptic Curve-based Diffie-Hellman (ECDH)
     key exchange.  ECDH is significantly faster than regular DH while
     arguably as secure.  The `curve_name' parameter should be a string
     describing a well-known elliptic curve, for example ‘prime256v1’
     for a widely supported curve.

     This setting doesn’t apply to client sockets.  You can also use the
     *note OP_SINGLE_ECDH_USE: 1e8b. option to further improve security.

     This method is not available if *note HAS_ECDH: 1e8c. is False.

     New in version 3.3.

     See also
     ........

     SSL/TLS & Perfect Forward Secrecy(6)

          Vincent Bernat.

 -- Method: SSLContext.wrap_socket (sock, server_side=False,
          do_handshake_on_connect=True, suppress_ragged_eofs=True,
          server_hostname=None)

     Wrap an existing Python socket `sock' and return an *note
     SSLSocket: 31b. object.  `sock' must be a *note SOCK_STREAM: 8fb.
     socket; other socket types are unsupported.

     The returned SSL socket is tied to the context, its settings and
     certificates.  The parameters `server_side',
     `do_handshake_on_connect' and `suppress_ragged_eofs' have the same
     meaning as in the top-level *note wrap_socket(): 7fc. function.

     On client connections, the optional parameter `server_hostname'
     specifies the hostname of the service which we are connecting to.
     This allows a single server to host multiple SSL-based services
     with distinct certificates, quite similarly to HTTP virtual hosts.
     Specifying `server_hostname' will raise a *note ValueError: 19c. if
     `server_side' is true.

     Changed in version 3.5: Always allow a server_hostname to be
     passed, even if OpenSSL does not have SNI.

 -- Method: SSLContext.wrap_bio (incoming, outgoing, server_side=False,
          server_hostname=None)

     Create a new *note SSLObject: 31a. instance by wrapping the BIO
     objects `incoming' and `outgoing'.  The SSL routines will read
     input data from the incoming BIO and write data to the outgoing
     BIO.

     The `server_side' and `server_hostname' parameters have the same
     meaning as in *note SSLContext.wrap_socket(): 7fb.

 -- Method: SSLContext.session_stats ()

     Get statistics about the SSL sessions created or managed by this
     context.  A dictionary is returned which maps the names of each
     piece of information(7) to their numeric values.  For example, here
     is the total number of hits and misses in the session cache since
     the context was created:

          >>> stats = context.session_stats()
          >>> stats['hits'], stats['misses']
          (0, 0)

 -- Attribute: SSLContext.check_hostname

     Whether to match the peer cert’s hostname with *note
     match_hostname(): 32b. in *note SSLSocket.do_handshake(): 328.  The
     context’s *note verify_mode: 1e79. must be set to *note
     CERT_OPTIONAL: 1e74. or *note CERT_REQUIRED: 1e75, and you must
     pass `server_hostname' to *note wrap_socket(): 7fb. in order to
     match the hostname.

     Example:

          import socket, ssl

          context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
          context.verify_mode = ssl.CERT_REQUIRED
          context.check_hostname = True
          context.load_default_certs()

          s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
          ssl_sock = context.wrap_socket(s, server_hostname='www.verisign.com')
          ssl_sock.connect(('www.verisign.com', 443))

     New in version 3.4.

          Note: This features requires OpenSSL 0.9.8f or newer.

 -- Attribute: SSLContext.options

     An integer representing the set of SSL options enabled on this
     context.  The default value is *note OP_ALL: 1e86, but you can
     specify other options such as *note OP_NO_SSLv2: 7fd. by ORing them
     together.

          Note: With versions of OpenSSL older than 0.9.8m, it is only
          possible to set options, not to clear them.  Attempting to
          clear an option (by resetting the corresponding bits) will
          raise a ‘ValueError’.

 -- Attribute: SSLContext.protocol

     The protocol version chosen when constructing the context.  This
     attribute is read-only.

 -- Attribute: SSLContext.verify_flags

     The flags for certificate verification operations.  You can set
     flags like *note VERIFY_CRL_CHECK_LEAF: 4c8. by ORing them
     together.  By default OpenSSL does neither require nor verify
     certificate revocation lists (CRLs).  Available only with openssl
     version 0.9.8+.

     New in version 3.4.

 -- Attribute: SSLContext.verify_mode

     Whether to try to verify other peers’ certificates and how to
     behave if verification fails.  This attribute must be one of *note
     CERT_NONE: 1e73, *note CERT_OPTIONAL: 1e74. or *note CERT_REQUIRED:
     1e75.

   ---------- Footnotes ----------

   (1) 
http://www.openssl.org/docs/ssl/SSL_CTX_load_verify_locations.html

   (2) http://www.openssl.org/docs/apps/ciphers.html#CIPHER-LIST-FORMAT

   (3) https://tools.ietf.org/html/rfc7301.html

   (4) https://tools.ietf.org/html/draft-agl-tls-nextprotoneg

   (5) https://tools.ietf.org/html/rfc6066.html

   (6) 
http://vincent.bernat.im/en/blog/2011-ssl-perfect-forward-secrecy.html

   (7) http://www.openssl.org/docs/ssl/SSL_CTX_sess_number.html


File: python.info,  Node: Certificates,  Next: Examples<10>,  Prev: SSL Contexts,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.9 Certificates
.....................

Certificates in general are part of a public-key / private-key system.
In this system, each `principal', (which may be a machine, or a person,
or an organization) is assigned a unique two-part encryption key.  One
part of the key is public, and is called the `public key'; the other
part is kept secret, and is called the `private key'.  The two parts are
related, in that if you encrypt a message with one of the parts, you can
decrypt it with the other part, and `only' with the other part.

A certificate contains information about two principals.  It contains
the name of a `subject', and the subject’s public key.  It also contains
a statement by a second principal, the `issuer', that the subject is who
he claims to be, and that this is indeed the subject’s public key.  The
issuer’s statement is signed with the issuer’s private key, which only
the issuer knows.  However, anyone can verify the issuer’s statement by
finding the issuer’s public key, decrypting the statement with it, and
comparing it to the other information in the certificate.  The
certificate also contains information about the time period over which
it is valid.  This is expressed as two fields, called "notBefore" and
"notAfter".

In the Python use of certificates, a client or server can use a
certificate to prove who they are.  The other side of a network
connection can also be required to produce a certificate, and that
certificate can be validated to the satisfaction of the client or server
that requires such validation.  The connection attempt can be set to
raise an exception if the validation fails.  Validation is done
automatically, by the underlying OpenSSL framework; the application need
not concern itself with its mechanics.  But the application does usually
need to provide sets of certificates to allow this process to take
place.

Python uses files to contain certificates.  They should be formatted as
"PEM" (see RFC 1422(1)), which is a base-64 encoded form wrapped with a
header line and a footer line:

     -----BEGIN CERTIFICATE-----
     ... (certificate in base64 PEM encoding) ...
     -----END CERTIFICATE-----

* Menu:

* Certificate chains:: 
* CA certificates:: 
* Combined key and certificate:: 
* Self-signed certificates:: 

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc1422.html


File: python.info,  Node: Certificate chains,  Next: CA certificates,  Up: Certificates

5.18.2.10 Certificate chains
............................

The Python files which contain certificates can contain a sequence of
certificates, sometimes called a `certificate chain'.  This chain should
start with the specific certificate for the principal who "is" the
client or server, and then the certificate for the issuer of that
certificate, and then the certificate for the issuer of `that'
certificate, and so on up the chain till you get to a certificate which
is `self-signed', that is, a certificate which has the same subject and
issuer, sometimes called a `root certificate'.  The certificates should
just be concatenated together in the certificate file.  For example,
suppose we had a three certificate chain, from our server certificate to
the certificate of the certification authority that signed our server
certificate, to the root certificate of the agency which issued the
certification authority’s certificate:

     -----BEGIN CERTIFICATE-----
     ... (certificate for your server)...
     -----END CERTIFICATE-----
     -----BEGIN CERTIFICATE-----
     ... (the certificate for the CA)...
     -----END CERTIFICATE-----
     -----BEGIN CERTIFICATE-----
     ... (the root certificate for the CA's issuer)...
     -----END CERTIFICATE-----


File: python.info,  Node: CA certificates,  Next: Combined key and certificate,  Prev: Certificate chains,  Up: Certificates

5.18.2.11 CA certificates
.........................

If you are going to require validation of the other side of the
connection’s certificate, you need to provide a "CA certs" file, filled
with the certificate chains for each issuer you are willing to trust.
Again, this file just contains these chains concatenated together.  For
validation, Python will use the first chain it finds in the file which
matches.  The platform’s certificates file can be used by calling *note
SSLContext.load_default_certs(): 4cb, this is done automatically with
*note create_default_context(): 4c1.


File: python.info,  Node: Combined key and certificate,  Next: Self-signed certificates,  Prev: CA certificates,  Up: Certificates

5.18.2.12 Combined key and certificate
......................................

Often the private key is stored in the same file as the certificate; in
this case, only the ‘certfile’ parameter to *note
SSLContext.load_cert_chain(): 6cb. and *note wrap_socket(): 7fc. needs
to be passed.  If the private key is stored with the certificate, it
should come before the first certificate in the certificate chain:

     -----BEGIN RSA PRIVATE KEY-----
     ... (private key in base64 encoding) ...
     -----END RSA PRIVATE KEY-----
     -----BEGIN CERTIFICATE-----
     ... (certificate in base64 PEM encoding) ...
     -----END CERTIFICATE-----


File: python.info,  Node: Self-signed certificates,  Prev: Combined key and certificate,  Up: Certificates

5.18.2.13 Self-signed certificates
..................................

If you are going to create a server that provides SSL-encrypted
connection services, you will need to acquire a certificate for that
service.  There are many ways of acquiring appropriate certificates,
such as buying one from a certification authority.  Another common
practice is to generate a self-signed certificate.  The simplest way to
do this is with the OpenSSL package, using something like the following:

     % openssl req -new -x509 -days 365 -nodes -out cert.pem -keyout cert.pem
     Generating a 1024 bit RSA private key
     .......++++++
     .............................++++++
     writing new private key to 'cert.pem'
     -----
     You are about to be asked to enter information that will be incorporated
     into your certificate request.
     What you are about to enter is what is called a Distinguished Name or a DN.
     There are quite a few fields but you can leave some blank
     For some fields there will be a default value,
     If you enter '.', the field will be left blank.
     -----
     Country Name (2 letter code) [AU]:US
     State or Province Name (full name) [Some-State]:MyState
     Locality Name (eg, city) []:Some City
     Organization Name (eg, company) [Internet Widgits Pty Ltd]:My Organization, Inc.
     Organizational Unit Name (eg, section) []:My Group
     Common Name (eg, YOUR name) []:myserver.mygroup.myorganization.com
     Email Address []:ops@myserver.mygroup.myorganization.com
     %

The disadvantage of a self-signed certificate is that it is its own root
certificate, and no one else will have it in their cache of known (and
trusted) root certificates.


File: python.info,  Node: Examples<10>,  Next: Notes on non-blocking sockets,  Prev: Certificates,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.14 Examples
..................

* Menu:

* Testing for SSL support:: 
* Client-side operation:: 
* Server-side operation:: 


File: python.info,  Node: Testing for SSL support,  Next: Client-side operation,  Up: Examples<10>

5.18.2.15 Testing for SSL support
.................................

To test for the presence of SSL support in a Python installation, user
code should use the following idiom:

     try:
         import ssl
     except ImportError:
         pass
     else:
         ... # do something that requires SSL support


File: python.info,  Node: Client-side operation,  Next: Server-side operation,  Prev: Testing for SSL support,  Up: Examples<10>

5.18.2.16 Client-side operation
...............................

This example creates a SSL context with the recommended security
settings for client sockets, including automatic certificate
verification:

     >>> context = ssl.create_default_context()

If you prefer to tune security settings yourself, you might create a
context from scratch (but beware that you might not get the settings
right):

     >>> context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
     >>> context.verify_mode = ssl.CERT_REQUIRED
     >>> context.check_hostname = True
     >>> context.load_verify_locations("/etc/ssl/certs/ca-bundle.crt")

(this snippet assumes your operating system places a bundle of all CA
certificates in ‘/etc/ssl/certs/ca-bundle.crt’; if not, you’ll get an
error and have to adjust the location)

When you use the context to connect to a server, *note CERT_REQUIRED:
1e75. validates the server certificate: it ensures that the server
certificate was signed with one of the CA certificates, and checks the
signature for correctness:

     >>> conn = context.wrap_socket(socket.socket(socket.AF_INET),
     ...                            server_hostname="www.python.org")
     >>> conn.connect(("www.python.org", 443))

You may then fetch the certificate:

     >>> cert = conn.getpeercert()

Visual inspection shows that the certificate does identify the desired
service (that is, the HTTPS host ‘www.python.org’):

     >>> pprint.pprint(cert)
     {'OCSP': ('http://ocsp.digicert.com',),
      'caIssuers': ('http://cacerts.digicert.com/DigiCertSHA2ExtendedValidationServerCA.crt',),
      'crlDistributionPoints': ('http://crl3.digicert.com/sha2-ev-server-g1.crl',
                                'http://crl4.digicert.com/sha2-ev-server-g1.crl'),
      'issuer': ((('countryName', 'US'),),
                 (('organizationName', 'DigiCert Inc'),),
                 (('organizationalUnitName', 'www.digicert.com'),),
                 (('commonName', 'DigiCert SHA2 Extended Validation Server CA'),)),
      'notAfter': 'Sep  9 12:00:00 2016 GMT',
      'notBefore': 'Sep  5 00:00:00 2014 GMT',
      'serialNumber': '01BB6F00122B177F36CAB49CEA8B6B26',
      'subject': ((('businessCategory', 'Private Organization'),),
                  (('1.3.6.1.4.1.311.60.2.1.3', 'US'),),
                  (('1.3.6.1.4.1.311.60.2.1.2', 'Delaware'),),
                  (('serialNumber', '3359300'),),
                  (('streetAddress', '16 Allen Rd'),),
                  (('postalCode', '03894-4801'),),
                  (('countryName', 'US'),),
                  (('stateOrProvinceName', 'NH'),),
                  (('localityName', 'Wolfeboro,'),),
                  (('organizationName', 'Python Software Foundation'),),
                  (('commonName', 'www.python.org'),)),
      'subjectAltName': (('DNS', 'www.python.org'),
                         ('DNS', 'python.org'),
                         ('DNS', 'pypi.python.org'),
                         ('DNS', 'docs.python.org'),
                         ('DNS', 'testpypi.python.org'),
                         ('DNS', 'bugs.python.org'),
                         ('DNS', 'wiki.python.org'),
                         ('DNS', 'hg.python.org'),
                         ('DNS', 'mail.python.org'),
                         ('DNS', 'packaging.python.org'),
                         ('DNS', 'pythonhosted.org'),
                         ('DNS', 'www.pythonhosted.org'),
                         ('DNS', 'test.pythonhosted.org'),
                         ('DNS', 'us.pycon.org'),
                         ('DNS', 'id.python.org')),
      'version': 3}

Now the SSL channel is established and the certificate verified, you can
proceed to talk with the server:

     >>> conn.sendall(b"HEAD / HTTP/1.0\r\nHost: linuxfr.org\r\n\r\n")
     >>> pprint.pprint(conn.recv(1024).split(b"\r\n"))
     [b'HTTP/1.1 200 OK',
      b'Date: Sat, 18 Oct 2014 18:27:20 GMT',
      b'Server: nginx',
      b'Content-Type: text/html; charset=utf-8',
      b'X-Frame-Options: SAMEORIGIN',
      b'Content-Length: 45679',
      b'Accept-Ranges: bytes',
      b'Via: 1.1 varnish',
      b'Age: 2188',
      b'X-Served-By: cache-lcy1134-LCY',
      b'X-Cache: HIT',
      b'X-Cache-Hits: 11',
      b'Vary: Cookie',
      b'Strict-Transport-Security: max-age=63072000; includeSubDomains',
      b'Connection: close',
      b'',
      b'']

See the discussion of *note Security considerations: 1e6a. below.


File: python.info,  Node: Server-side operation,  Prev: Client-side operation,  Up: Examples<10>

5.18.2.17 Server-side operation
...............................

For server operation, typically you’ll need to have a server
certificate, and private key, each in a file.  You’ll first create a
context holding the key and the certificate, so that clients can check
your authenticity.  Then you’ll open a socket, bind it to a port, call
‘listen()’ on it, and start waiting for clients to connect:

     import socket, ssl

     context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)
     context.load_cert_chain(certfile="mycertfile", keyfile="mykeyfile")

     bindsocket = socket.socket()
     bindsocket.bind(('myaddr.mydomain.com', 10023))
     bindsocket.listen(5)

When a client connects, you’ll call ‘accept()’ on the socket to get the
new socket from the other end, and use the context’s *note
SSLContext.wrap_socket(): 7fb. method to create a server-side SSL socket
for the connection:

     while True:
         newsocket, fromaddr = bindsocket.accept()
         connstream = context.wrap_socket(newsocket, server_side=True)
         try:
             deal_with_client(connstream)
         finally:
             connstream.shutdown(socket.SHUT_RDWR)
             connstream.close()

Then you’ll read data from the ‘connstream’ and do something with it
till you are finished with the client (or the client is finished with
you):

     def deal_with_client(connstream):
         data = connstream.recv(1024)
         # empty data means the client is finished with us
         while data:
             if not do_something(connstream, data):
                 # we'll assume do_something returns False
                 # when we're finished with client
                 break
             data = connstream.recv(1024)
         # finished with client

And go back to listening for new client connections (of course, a real
server would probably handle each client connection in a separate
thread, or put the sockets in *note non-blocking mode: 1e6d. and use an
event loop).


File: python.info,  Node: Notes on non-blocking sockets,  Next: Memory BIO Support<2>,  Prev: Examples<10>,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.18 Notes on non-blocking sockets
.......................................

SSL sockets behave slightly different than regular sockets in
non-blocking mode.  When working with non-blocking sockets, there are
thus several things you need to be aware of:

   - Most *note SSLSocket: 31b. methods will raise either *note
     SSLWantWriteError: 325. or *note SSLWantReadError: 324. instead of
     *note BlockingIOError: 5b5. if an I/O operation would block.  *note
     SSLWantReadError: 324. will be raised if a read operation on the
     underlying socket is necessary, and *note SSLWantWriteError: 325.
     for a write operation on the underlying socket.  Note that attempts
     to `write' to an SSL socket may require `reading' from the
     underlying socket first, and attempts to `read' from the SSL socket
     may require a prior `write' to the underlying socket.

     Changed in version 3.5: In earlier Python versions, the
     ‘SSLSocket.send()’ method returned zero instead of raising *note
     SSLWantWriteError: 325. or *note SSLWantReadError: 324.

   - Calling *note select(): 209. tells you that the OS-level socket can
     be read from (or written to), but it does not imply that there is
     sufficient data at the upper SSL layer.  For example, only part of
     an SSL frame might have arrived.  Therefore, you must be ready to
     handle ‘SSLSocket.recv()’ and ‘SSLSocket.send()’ failures, and
     retry after another call to *note select(): 209.

   - Conversely, since the SSL layer has its own framing, a SSL socket
     may still have data available for reading without *note select():
     209. being aware of it.  Therefore, you should first call
     ‘SSLSocket.recv()’ to drain any potentially available data, and
     then only block on a *note select(): 209. call if still necessary.

     (of course, similar provisions apply when using other primitives
     such as *note poll(): 1eaa, or those in the *note selectors: e4.
     module)

   - The SSL handshake itself will be non-blocking: the *note
     SSLSocket.do_handshake(): 328. method has to be retried until it
     returns successfully.  Here is a synopsis using *note select():
     209. to wait for the socket’s readiness:

          while True:
              try:
                  sock.do_handshake()
                  break
              except ssl.SSLWantReadError:
                  select.select([sock], [], [])
              except ssl.SSLWantWriteError:
                  select.select([], [sock], [])

See also
........

The *note asyncio: a. module supports *note non-blocking SSL sockets:
1e6d. and provides a higher level API. It polls for events using the
*note selectors: e4. module and handles *note SSLWantWriteError: 325,
*note SSLWantReadError: 324. and *note BlockingIOError: 5b5. exceptions.
It runs the SSL handshake asynchronously as well.


File: python.info,  Node: Memory BIO Support<2>,  Next: Security considerations,  Prev: Notes on non-blocking sockets,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.19 Memory BIO Support
............................

New in version 3.5.

Ever since the SSL module was introduced in Python 2.6, the *note
SSLSocket: 31b. class has provided two related but distinct areas of
functionality:

   - SSL protocol handling

   - Network IO

The network IO API is identical to that provided by *note socket.socket:
20a, from which *note SSLSocket: 31b. also inherits.  This allows an SSL
socket to be used as a drop-in replacement for a regular socket, making
it very easy to add SSL support to an existing application.

Combining SSL protocol handling and network IO usually works well, but
there are some cases where it doesn’t.  An example is async IO
frameworks that want to use a different IO multiplexing model than the
"select/poll on a file descriptor" (readiness based) model that is
assumed by *note socket.socket: 20a. and by the internal OpenSSL socket
IO routines.  This is mostly relevant for platforms like Windows where
this model is not efficient.  For this purpose, a reduced scope variant
of *note SSLSocket: 31b. called *note SSLObject: 31a. is provided.

 -- Class: ssl.SSLObject

     A reduced-scope variant of *note SSLSocket: 31b. representing an
     SSL protocol instance that does not contain any network IO methods.
     This class is typically used by framework authors that want to
     implement asynchronous IO for SSL through memory buffers.

     This class implements an interface on top of a low-level SSL object
     as implemented by OpenSSL. This object captures the state of an SSL
     connection but does not provide any network IO itself.  IO needs to
     be performed through separate "BIO" objects which are OpenSSL’s IO
     abstraction layer.

     An *note SSLObject: 31a. instance can be created using the *note
     wrap_bio(): 31d. method.  This method will create the *note
     SSLObject: 31a. instance and bind it to a pair of BIOs.  The
     `incoming' BIO is used to pass data from Python to the SSL protocol
     instance, while the `outgoing' BIO is used to pass data the other
     way around.

     The following methods are available:

        - *note context: 1e95.

        - *note server_side: 1e99.

        - *note server_hostname: 1e9a.

        - *note read(): 329.

        - *note write(): 32a.

        - *note getpeercert(): 4d1.

        - *note selected_npn_protocol(): 1e97.

        - *note cipher(): 1e96.

        - *note shared_ciphers(): 327.

        - *note compression(): 6cf.

        - *note pending(): 1e98.

        - *note do_handshake(): 328.

        - *note unwrap(): 1e93.

        - *note get_channel_binding(): 6ce.

     When compared to *note SSLSocket: 31b, this object lacks the
     following features:

        - Any form of network IO incluging methods such as ‘recv()’ and
          ‘send()’.

        - There is no `do_handshake_on_connect' machinery.  You must
          always manually call *note do_handshake(): 328. to start the
          handshake.

        - There is no handling of `suppress_ragged_eofs'.  All
          end-of-file conditions that are in violation of the protocol
          are reported via the *note SSLEOFError: 1e6f. exception.

        - The method *note unwrap(): 1e93. call does not return
          anything, unlike for an SSL socket where it returns the
          underlying socket.

        - The `server_name_callback' callback passed to *note
          SSLContext.set_servername_callback(): 4d0. will get an *note
          SSLObject: 31a. instance instead of a *note SSLSocket: 31b.
          instance as its first parameter.

     Some notes related to the use of *note SSLObject: 31a.:

        - All IO on an *note SSLObject: 31a. is *note non-blocking:
          1e6d.  This means that for example *note read(): 329. will
          raise an *note SSLWantReadError: 324. if it needs more data
          than the incoming BIO has available.

        - There is no module-level ‘wrap_bio()’ call like there is for
          *note wrap_socket(): 7fb.  An *note SSLObject: 31a. is always
          created via an *note SSLContext: 1c6.

An SSLObject communicates with the outside world using memory buffers.
The class *note MemoryBIO: 31c. provides a memory buffer that can be
used for this purpose.  It wraps an OpenSSL memory BIO (Basic IO)
object:

 -- Class: ssl.MemoryBIO

     A memory buffer that can be used to pass data between Python and an
     SSL protocol instance.

      -- Attribute: pending

          Return the number of bytes currently in the memory buffer.

      -- Attribute: eof

          A boolean indicating whether the memory BIO is current at the
          end-of-file position.

      -- Method: read (n=-1)

          Read up to `n' bytes from the memory buffer.  If `n' is not
          specified or negative, all bytes are returned.

      -- Method: write (buf)

          Write the bytes from `buf' to the memory BIO. The `buf'
          argument must be an object supporting the buffer protocol.

          The return value is the number of bytes written, which is
          always equal to the length of `buf'.

      -- Method: write_eof ()

          Write an EOF marker to the memory BIO. After this method has
          been called, it is illegal to call *note write(): 1eaf.  The
          attribute *note eof: 1ead. will become true after all data
          currently in the buffer has been read.


File: python.info,  Node: Security considerations,  Prev: Memory BIO Support<2>,  Up: ssl --- TLS/SSL wrapper for socket objects

5.18.2.20 Security considerations
.................................

* Menu:

* Best defaults:: 
* Manual settings:: 
* Multi-processing:: 


File: python.info,  Node: Best defaults,  Next: Manual settings,  Up: Security considerations

5.18.2.21 Best defaults
.......................

For `client use', if you don’t have any special requirements for your
security policy, it is highly recommended that you use the *note
create_default_context(): 4c1. function to create your SSL context.  It
will load the system’s trusted CA certificates, enable certificate
validation and hostname checking, and try to choose reasonably secure
protocol and cipher settings.

For example, here is how you would use the *note smtplib.SMTP: 6b9.
class to create a trusted, secure connection to a SMTP server:

     >>> import ssl, smtplib
     >>> smtp = smtplib.SMTP("mail.python.org", port=587)
     >>> context = ssl.create_default_context()
     >>> smtp.starttls(context=context)
     (220, b'2.0.0 Ready to start TLS')

If a client certificate is needed for the connection, it can be added
with *note SSLContext.load_cert_chain(): 6cb.

By contrast, if you create the SSL context by calling the *note
SSLContext: 1c6. constructor yourself, it will not have certificate
validation nor hostname checking enabled by default.  If you do so,
please read the paragraphs below to achieve a good security level.


File: python.info,  Node: Manual settings,  Next: Multi-processing,  Prev: Best defaults,  Up: Security considerations

5.18.2.22 Manual settings
.........................

* Menu:

* Verifying certificates:: 
* Protocol versions:: 
* Cipher selection:: 


File: python.info,  Node: Verifying certificates,  Next: Protocol versions,  Up: Manual settings

5.18.2.23 Verifying certificates
................................

When calling the *note SSLContext: 1c6. constructor directly, *note
CERT_NONE: 1e73. is the default.  Since it does not authenticate the
other peer, it can be insecure, especially in client mode where most of
time you would like to ensure the authenticity of the server you’re
talking to.  Therefore, when in client mode, it is highly recommended to
use *note CERT_REQUIRED: 1e75.  However, it is in itself not sufficient;
you also have to check that the server certificate, which can be
obtained by calling *note SSLSocket.getpeercert(): 4d1, matches the
desired service.  For many protocols and applications, the service can
be identified by the hostname; in this case, the *note match_hostname():
32b. function can be used.  This common check is automatically performed
when *note SSLContext.check_hostname: 1e94. is enabled.

In server mode, if you want to authenticate your clients using the SSL
layer (rather than using a higher-level authentication mechanism),
you’ll also have to specify *note CERT_REQUIRED: 1e75. and similarly
check the client certificate.

          Note: In client mode, *note CERT_OPTIONAL: 1e74. and *note
          CERT_REQUIRED: 1e75. are equivalent unless anonymous ciphers
          are enabled (they are disabled by default).


File: python.info,  Node: Protocol versions,  Next: Cipher selection,  Prev: Verifying certificates,  Up: Manual settings

5.18.2.24 Protocol versions
...........................

SSL versions 2 and 3 are considered insecure and are therefore dangerous
to use.  If you want maximum compatibility between clients and servers,
it is recommended to use *note PROTOCOL_SSLv23: 1e76. as the protocol
version and then disable SSLv2 and SSLv3 explicitly using the *note
SSLContext.options: 1e9e. attribute:

     context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
     context.options |= ssl.OP_NO_SSLv2
     context.options |= ssl.OP_NO_SSLv3

The SSL context created above will only allow TLSv1 and later (if
supported by your system) connections.


File: python.info,  Node: Cipher selection,  Prev: Protocol versions,  Up: Manual settings

5.18.2.25 Cipher selection
..........................

If you have advanced security requirements, fine-tuning of the ciphers
enabled when negotiating a SSL session is possible through the *note
SSLContext.set_ciphers(): 1e9c. method.  Starting from Python 3.2.3, the
ssl module disables certain weak ciphers by default, but you may want to
further restrict the cipher choice.  Be sure to read OpenSSL’s
documentation about the cipher list format(1).  If you want to check
which ciphers are enabled by a given cipher list, use the ‘openssl
ciphers’ command on your system.

   ---------- Footnotes ----------

   (1) http://www.openssl.org/docs/apps/ciphers.html#CIPHER-LIST-FORMAT


File: python.info,  Node: Multi-processing,  Prev: Manual settings,  Up: Security considerations

5.18.2.26 Multi-processing
..........................

If using this module as part of a multi-processed application (using,
for example the *note multiprocessing: b6. or *note concurrent.futures:
22. modules), be aware that OpenSSL’s internal random number generator
does not properly handle forked processes.  Applications must change the
PRNG state of the parent process if they use any SSL feature with *note
os.fork(): 57b.  Any successful call of *note RAND_add(): 1e7c, *note
RAND_bytes(): 6c9. or *note RAND_pseudo_bytes(): 6ca. is sufficient.

See also
........

Class *note socket.socket: 20a.

     Documentation of underlying *note socket: ed. class

SSL/TLS Strong Encryption: An Introduction(1)

     Intro from the Apache webserver documentation

RFC 1422: Privacy Enhancement for Internet Electronic Mail: Part II: Certificate-Based Key Management(2)

     Steve Kent

RFC 1750: Randomness Recommendations for Security(3)

     D. Eastlake et.  al.

RFC 3280: Internet X.509 Public Key Infrastructure Certificate and CRL Profile(4)

     Housley et.  al.

RFC 4366: Transport Layer Security (TLS) Extensions(5)

     Blake-Wilson et.  al.

RFC 5246: The Transport Layer Security (TLS) Protocol Version 1.2(6)

     T. Dierks et.  al.

RFC 6066: Transport Layer Security (TLS) Extensions(7)

     D. Eastlake

IANA TLS: Transport Layer Security (TLS) Parameters(8)

     IANA

   ---------- Footnotes ----------

   (1) https://httpd.apache.org/docs/trunk/en/ssl/ssl_intro.html

   (2) https://www.ietf.org/rfc/rfc1422

   (3) https://www.ietf.org/rfc/rfc1750

   (4) https://www.ietf.org/rfc/rfc3280

   (5) https://www.ietf.org/rfc/rfc4366

   (6) https://tools.ietf.org/html/rfc5246

   (7) https://tools.ietf.org/html/rfc6066

   (8) http://www.iana.org/assignments/tls-parameters/tls-parameters.xml


File: python.info,  Node: select --- Waiting for I/O completion,  Next: selectors -- High-level I/O multiplexing,  Prev: ssl --- TLS/SSL wrapper for socket objects,  Up: Interprocess Communication and Networking

5.18.3 ‘select’ — Waiting for I/O completion
--------------------------------------------

This module provides access to the ‘select()’ and ‘poll()’ functions
available in most operating systems, ‘devpoll()’ available on Solaris
and derivatives, ‘epoll()’ available on Linux 2.5+ and ‘kqueue()’
available on most BSD. Note that on Windows, it only works for sockets;
on other operating systems, it also works for other file types (in
particular, on Unix, it works on pipes).  It cannot be used on regular
files to determine whether a file has grown since it was last read.

     Note: The *note selectors: e4. module allows high-level and
     efficient I/O multiplexing, built upon the *note select: e3. module
     primitives.  Users are encouraged to use the *note selectors: e4.
     module instead, unless they want precise control over the OS-level
     primitives used.

The module defines the following:

 -- Exception: select.error

     A deprecated alias of *note OSError: 4b6.

     Changed in version 3.3: Following PEP 3151(1), this class was made
     an alias of *note OSError: 4b6.

 -- Function: select.devpoll ()

     (Only supported on Solaris and derivatives.)  Returns a ‘/dev/poll’
     polling object; see section *note /dev/poll Polling Objects: 1eba.
     below for the methods supported by devpoll objects.

     ‘devpoll()’ objects are linked to the number of file descriptors
     allowed at the time of instantiation.  If your program reduces this
     value, ‘devpoll()’ will fail.  If your program increases this
     value, ‘devpoll()’ may return an incomplete list of active file
     descriptors.

     The new file descriptor is *note non-inheritable: 3ea.

     New in version 3.3.

     Changed in version 3.4: The new file descriptor is now
     non-inheritable.

 -- Function: select.epoll (sizehint=-1, flags=0)

     (Only supported on Linux 2.5.44 and newer.)  Return an edge polling
     object, which can be used as Edge or Level Triggered interface for
     I/O events.  `sizehint' is deprecated and completely ignored.
     `flags' can be set to ‘EPOLL_CLOEXEC’, which causes the epoll
     descriptor to be closed automatically when *note os.execve(): 674.
     is called.

     See the *note Edge and Level Trigger Polling (epoll) Objects: 1ebb.
     section below for the methods supported by epolling objects.

     ‘epoll’ objects support the context management protocol: when used
     in a *note with: 29d. statement, the new file descriptor is
     automatically closed at the end of the block.

     The new file descriptor is *note non-inheritable: 3ea.

     Changed in version 3.3: Added the `flags' parameter.

     Changed in version 3.4: Support for the *note with: 29d. statement
     was added.  The new file descriptor is now non-inheritable.

 -- Function: select.poll ()

     (Not supported by all operating systems.)  Returns a polling
     object, which supports registering and unregistering file
     descriptors, and then polling them for I/O events; see section
     *note Polling Objects: 1ebc. below for the methods supported by
     polling objects.

 -- Function: select.kqueue ()

     (Only supported on BSD.) Returns a kernel queue object; see section
     *note Kqueue Objects: 1ebe. below for the methods supported by
     kqueue objects.

     The new file descriptor is *note non-inheritable: 3ea.

     Changed in version 3.4: The new file descriptor is now
     non-inheritable.

 -- Function: select.kevent (ident, filter=KQ_FILTER_READ,
          flags=KQ_EV_ADD, fflags=0, data=0, udata=0)

     (Only supported on BSD.) Returns a kernel event object; see section
     *note Kevent Objects: 1ec0. below for the methods supported by
     kevent objects.

 -- Function: select.select (rlist, wlist, xlist[, timeout])

     This is a straightforward interface to the Unix ‘select()’ system
     call.  The first three arguments are sequences of ’waitable
     objects’: either integers representing file descriptors or objects
     with a parameterless method named *note fileno(): 187a. returning
     such an integer:

        * `rlist': wait until ready for reading

        * `wlist': wait until ready for writing

        * `xlist': wait for an "exceptional condition" (see the manual
          page for what your system considers such a condition)

     Empty sequences are allowed, but acceptance of three empty
     sequences is platform-dependent.  (It is known to work on Unix but
     not on Windows.)  The optional `timeout' argument specifies a
     time-out as a floating point number in seconds.  When the `timeout'
     argument is omitted the function blocks until at least one file
     descriptor is ready.  A time-out value of zero specifies a poll and
     never blocks.

     The return value is a triple of lists of objects that are ready:
     subsets of the first three arguments.  When the time-out is reached
     without a file descriptor becoming ready, three empty lists are
     returned.

     Among the acceptable object types in the sequences are Python *note
     file objects: 78b. (e.g.  ‘sys.stdin’, or objects returned by *note
     open(): 1e8. or *note os.popen(): 7d7.), socket objects returned by
     *note socket.socket(): 20a.  You may also define a `wrapper' class
     yourself, as long as it has an appropriate *note fileno(): 187a.
     method (that really returns a file descriptor, not just a random
     integer).

          Note: 
          File objects on Windows are not acceptable, but sockets are.
          On Windows, the underlying ‘select()’ function is provided by
          the WinSock library, and does not handle file descriptors that
          don’t originate from WinSock.

     Changed in version 3.5: The function is now retried with a
     recomputed timeout when interrupted by a signal, except if the
     signal handler raises an exception (see PEP 475(2) for the
     rationale), instead of raising *note InterruptedError: 1e7.

 -- Attribute: select.PIPE_BUF

     The minimum number of bytes which can be written without blocking
     to a pipe when the pipe has been reported as ready for writing by
     *note select(): 209, *note poll(): 1eaa. or another interface in
     this module.  This doesn’t apply to other kind of file-like objects
     such as sockets.

     This value is guaranteed by POSIX to be at least 512.
     Availability: Unix.

     New in version 3.2.

* Menu:

* /dev/poll Polling Objects:: 
* Edge and Level Trigger Polling (epoll) Objects: Edge and Level Trigger Polling epoll Objects. 
* Polling Objects:: 
* Kqueue Objects:: 
* Kevent Objects:: 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3151

   (2) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: /dev/poll Polling Objects,  Next: Edge and Level Trigger Polling epoll Objects,  Up: select --- Waiting for I/O completion

5.18.3.1 ‘/dev/poll’ Polling Objects
....................................

Solaris and derivatives have ‘/dev/poll’.  While ‘select()’ is O(highest
file descriptor) and ‘poll()’ is O(number of file descriptors),
‘/dev/poll’ is O(active file descriptors).

‘/dev/poll’ behaviour is very close to the standard ‘poll()’ object.

 -- Method: devpoll.close ()

     Close the file descriptor of the polling object.

     New in version 3.4.

 -- Attribute: devpoll.closed

     ‘True’ if the polling object is closed.

     New in version 3.4.

 -- Method: devpoll.fileno ()

     Return the file descriptor number of the polling object.

     New in version 3.4.

 -- Method: devpoll.register (fd[, eventmask])

     Register a file descriptor with the polling object.  Future calls
     to the *note poll(): 1eaa. method will then check whether the file
     descriptor has any pending I/O events.  `fd' can be either an
     integer, or an object with a *note fileno(): 187a. method that
     returns an integer.  File objects implement ‘fileno()’, so they can
     also be used as the argument.

     `eventmask' is an optional bitmask describing the type of events
     you want to check for.  The constants are the same that with
     ‘poll()’ object.  The default value is a combination of the
     constants ‘POLLIN’, ‘POLLPRI’, and ‘POLLOUT’.

          Warning: Registering a file descriptor that’s already
          registered is not an error, but the result is undefined.  The
          appropriate action is to unregister or modify it first.  This
          is an important difference compared with ‘poll()’.

 -- Method: devpoll.modify (fd[, eventmask])

     This method does an *note unregister(): 1ec4. followed by a *note
     register(): 1ec2.  It is (a bit) more efficient that doing the same
     explicitly.

 -- Method: devpoll.unregister (fd)

     Remove a file descriptor being tracked by a polling object.  Just
     like the *note register(): 1ec2. method, `fd' can be an integer or
     an object with a *note fileno(): 187a. method that returns an
     integer.

     Attempting to remove a file descriptor that was never registered is
     safely ignored.

 -- Method: devpoll.poll ([timeout])

     Polls the set of registered file descriptors, and returns a
     possibly-empty list containing ‘(fd, event)’ 2-tuples for the
     descriptors that have events or errors to report.  `fd' is the file
     descriptor, and `event' is a bitmask with bits set for the reported
     events for that descriptor — ‘POLLIN’ for waiting input, ‘POLLOUT’
     to indicate that the descriptor can be written to, and so forth.
     An empty list indicates that the call timed out and no file
     descriptors had any events to report.  If `timeout' is given, it
     specifies the length of time in milliseconds which the system will
     wait for events before returning.  If `timeout' is omitted, -1, or
     *note None: 19d, the call will block until there is an event for
     this poll object.

     Changed in version 3.5: The function is now retried with a
     recomputed timeout when interrupted by a signal, except if the
     signal handler raises an exception (see PEP 475(1) for the
     rationale), instead of raising *note InterruptedError: 1e7.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Edge and Level Trigger Polling epoll Objects,  Next: Polling Objects,  Prev: /dev/poll Polling Objects,  Up: select --- Waiting for I/O completion

5.18.3.2 Edge and Level Trigger Polling (epoll) Objects
.......................................................

     ‘http://linux.die.net/man/4/epoll’

     `eventmask'

     Constant                    Meaning
                                 
     --------------------------------------------------------------------------------
                                 
     ‘EPOLLIN’                   Available for read
                                 
                                 
     ‘EPOLLOUT’                  Available for write
                                 
                                 
     ‘EPOLLPRI’                  Urgent data for read
                                 
                                 
     ‘EPOLLERR’                  Error condition happened on the assoc.  fd
                                 
                                 
     ‘EPOLLHUP’                  Hang up happened on the assoc.  fd
                                 
                                 
     ‘EPOLLET’                   Set Edge Trigger behavior, the default is Level
                                 Trigger behavior
                                 
                                 
     ‘EPOLLONESHOT’              Set one-shot behavior.  After one event is pulled
                                 out, the fd is internally disabled
                                 
                                 
     ‘EPOLLRDNORM’               Equivalent to ‘EPOLLIN’
                                 
                                 
     ‘EPOLLRDBAND’               Priority data band can be read.
                                 
                                 
     ‘EPOLLWRNORM’               Equivalent to ‘EPOLLOUT’
                                 
                                 
     ‘EPOLLWRBAND’               Priority data may be written.
                                 
                                 
     ‘EPOLLMSG’                  Ignored.
                                 

 -- Method: epoll.close ()

     Close the control file descriptor of the epoll object.

 -- Attribute: epoll.closed

     ‘True’ if the epoll object is closed.

 -- Method: epoll.fileno ()

     Return the file descriptor number of the control fd.

 -- Method: epoll.fromfd (fd)

     Create an epoll object from a given file descriptor.

 -- Method: epoll.register (fd[, eventmask])

     Register a fd descriptor with the epoll object.

 -- Method: epoll.modify (fd, eventmask)

     Modify a registered file descriptor.

 -- Method: epoll.unregister (fd)

     Remove a registered file descriptor from the epoll object.

 -- Method: epoll.poll (timeout=-1, maxevents=-1)

     Wait for events.  timeout in seconds (float)

     Changed in version 3.5: The function is now retried with a
     recomputed timeout when interrupted by a signal, except if the
     signal handler raises an exception (see PEP 475(1) for the
     rationale), instead of raising *note InterruptedError: 1e7.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Polling Objects,  Next: Kqueue Objects,  Prev: Edge and Level Trigger Polling epoll Objects,  Up: select --- Waiting for I/O completion

5.18.3.3 Polling Objects
........................

The ‘poll()’ system call, supported on most Unix systems, provides
better scalability for network servers that service many, many clients
at the same time.  ‘poll()’ scales better because the system call only
requires listing the file descriptors of interest, while ‘select()’
builds a bitmap, turns on bits for the fds of interest, and then
afterward the whole bitmap has to be linearly scanned again.  ‘select()’
is O(highest file descriptor), while ‘poll()’ is O(number of file
descriptors).

 -- Method: poll.register (fd[, eventmask])

     Register a file descriptor with the polling object.  Future calls
     to the *note poll(): 1eaa. method will then check whether the file
     descriptor has any pending I/O events.  `fd' can be either an
     integer, or an object with a *note fileno(): 187a. method that
     returns an integer.  File objects implement ‘fileno()’, so they can
     also be used as the argument.

     `eventmask' is an optional bitmask describing the type of events
     you want to check for, and can be a combination of the constants
     ‘POLLIN’, ‘POLLPRI’, and ‘POLLOUT’, described in the table below.
     If not specified, the default value used will check for all 3 types
     of events.

     Constant                Meaning
                             
     -----------------------------------------------------------------------
                             
     ‘POLLIN’                There is data to read
                             
                             
     ‘POLLPRI’               There is urgent data to read
                             
                             
     ‘POLLOUT’               Ready for output: writing will not block
                             
                             
     ‘POLLERR’               Error condition of some sort
                             
                             
     ‘POLLHUP’               Hung up
                             
                             
     ‘POLLNVAL’              Invalid request: descriptor not open
                             

     Registering a file descriptor that’s already registered is not an
     error, and has the same effect as registering the descriptor
     exactly once.

 -- Method: poll.modify (fd, eventmask)

     Modifies an already registered fd.  This has the same effect as
     ‘register(fd, eventmask)’.  Attempting to modify a file descriptor
     that was never registered causes an *note OSError: 4b6. exception
     with errno ‘ENOENT’ to be raised.

 -- Method: poll.unregister (fd)

     Remove a file descriptor being tracked by a polling object.  Just
     like the *note register(): 1ecd. method, `fd' can be an integer or
     an object with a *note fileno(): 187a. method that returns an
     integer.

     Attempting to remove a file descriptor that was never registered
     causes a *note KeyError: 1a7. exception to be raised.

 -- Method: poll.poll ([timeout])

     Polls the set of registered file descriptors, and returns a
     possibly-empty list containing ‘(fd, event)’ 2-tuples for the
     descriptors that have events or errors to report.  `fd' is the file
     descriptor, and `event' is a bitmask with bits set for the reported
     events for that descriptor — ‘POLLIN’ for waiting input, ‘POLLOUT’
     to indicate that the descriptor can be written to, and so forth.
     An empty list indicates that the call timed out and no file
     descriptors had any events to report.  If `timeout' is given, it
     specifies the length of time in milliseconds which the system will
     wait for events before returning.  If `timeout' is omitted,
     negative, or *note None: 19d, the call will block until there is an
     event for this poll object.

     Changed in version 3.5: The function is now retried with a
     recomputed timeout when interrupted by a signal, except if the
     signal handler raises an exception (see PEP 475(1) for the
     rationale), instead of raising *note InterruptedError: 1e7.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Kqueue Objects,  Next: Kevent Objects,  Prev: Polling Objects,  Up: select --- Waiting for I/O completion

5.18.3.4 Kqueue Objects
.......................

 -- Method: kqueue.close ()

     Close the control file descriptor of the kqueue object.

 -- Attribute: kqueue.closed

     ‘True’ if the kqueue object is closed.

 -- Method: kqueue.fileno ()

     Return the file descriptor number of the control fd.

 -- Method: kqueue.fromfd (fd)

     Create a kqueue object from a given file descriptor.

 -- Method: kqueue.control (changelist, max_events[, timeout=None]) ->
          eventlist

     Low level interface to kevent

        - changelist must be an iterable of kevent object or None

        - max_events must be 0 or a positive integer

        - timeout in seconds (floats possible)

     Changed in version 3.5: The function is now retried with a
     recomputed timeout when interrupted by a signal, except if the
     signal handler raises an exception (see PEP 475(1) for the
     rationale), instead of raising *note InterruptedError: 1e7.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Kevent Objects,  Prev: Kqueue Objects,  Up: select --- Waiting for I/O completion

5.18.3.5 Kevent Objects
.......................

‘http://www.freebsd.org/cgi/man.cgi?query=kqueue&sektion=2’

 -- Attribute: kevent.ident

     Value used to identify the event.  The interpretation depends on
     the filter but it’s usually the file descriptor.  In the
     constructor ident can either be an int or an object with a *note
     fileno(): 187a. method.  kevent stores the integer internally.

 -- Attribute: kevent.filter

     Name of the kernel filter.

     Constant                        Meaning
                                     
     ----------------------------------------------------------------------------------
                                     
     ‘KQ_FILTER_READ’                Takes a descriptor and returns whenever there
                                     is data available to read
                                     
                                     
     ‘KQ_FILTER_WRITE’               Takes a descriptor and returns whenever there
                                     is data available to write
                                     
                                     
     ‘KQ_FILTER_AIO’                 AIO requests
                                     
                                     
     ‘KQ_FILTER_VNODE’               Returns when one or more of the requested
                                     events watched in `fflag' occurs
                                     
                                     
     ‘KQ_FILTER_PROC’                Watch for events on a process id
                                     
                                     
     ‘KQ_FILTER_NETDEV’              Watch for events on a network device [not
                                     available on Mac OS X]
                                     
                                     
     ‘KQ_FILTER_SIGNAL’              Returns whenever the watched signal is
                                     delivered to the process
                                     
                                     
     ‘KQ_FILTER_TIMER’               Establishes an arbitrary timer
                                     

 -- Attribute: kevent.flags

     Filter action.

     Constant                        Meaning
                                     
     ----------------------------------------------------------------------------------
                                     
     ‘KQ_EV_ADD’                     Adds or modifies an event
                                     
                                     
     ‘KQ_EV_DELETE’                  Removes an event from the queue
                                     
                                     
     ‘KQ_EV_ENABLE’                  Permitscontrol() to returns the event
                                     
                                     
     ‘KQ_EV_DISABLE’                 Disablesevent
                                     
                                     
     ‘KQ_EV_ONESHOT’                 Removes event after first occurrence
                                     
                                     
     ‘KQ_EV_CLEAR’                   Reset the state after an event is retrieved
                                     
                                     
     ‘KQ_EV_SYSFLAGS’                internal event
                                     
                                     
     ‘KQ_EV_FLAG1’                   internal event
                                     
                                     
     ‘KQ_EV_EOF’                     Filter specific EOF condition
                                     
                                     
     ‘KQ_EV_ERROR’                   See return values
                                     

 -- Attribute: kevent.fflags

     Filter specific flags.

     ‘KQ_FILTER_READ’ and ‘KQ_FILTER_WRITE’ filter flags:

     Constant                         Meaning
                                      
     ----------------------------------------------------------------------------------
                                      
     ‘KQ_NOTE_LOWAT’                  low water mark of a socket buffer
                                      

     ‘KQ_FILTER_VNODE’ filter flags:

     Constant                         Meaning
                                      
     ----------------------------------------------------------------------------------
                                      
     ‘KQ_NOTE_DELETE’                 `unlink()' was called
                                      
                                      
     ‘KQ_NOTE_WRITE’                  a write occurred
                                      
                                      
     ‘KQ_NOTE_EXTEND’                 the file was extended
                                      
                                      
     ‘KQ_NOTE_ATTRIB’                 an attribute was changed
                                      
                                      
     ‘KQ_NOTE_LINK’                   the link count has changed
                                      
                                      
     ‘KQ_NOTE_RENAME’                 the file was renamed
                                      
                                      
     ‘KQ_NOTE_REVOKE’                 access to the file was revoked
                                      

     ‘KQ_FILTER_PROC’ filter flags:

     Constant                         Meaning
                                      
     ----------------------------------------------------------------------------------
                                      
     ‘KQ_NOTE_EXIT’                   the process has exited
                                      
                                      
     ‘KQ_NOTE_FORK’                   the process has called `fork()'
                                      
                                      
     ‘KQ_NOTE_EXEC’                   the process has executed a new process
                                      
                                      
     ‘KQ_NOTE_PCTRLMASK’              internal filter flag
                                      
                                      
     ‘KQ_NOTE_PDATAMASK’              internal filter flag
                                      
                                      
     ‘KQ_NOTE_TRACK’                  follow a process across `fork()'
                                      
                                      
     ‘KQ_NOTE_CHILD’                  returned on the child process for `NOTE_TRACK'
                                      
                                      
     ‘KQ_NOTE_TRACKERR’               unable to attach to a child
                                      

     ‘KQ_FILTER_NETDEV’ filter flags (not available on Mac OS X):

     Constant                         Meaning
                                      
     ----------------------------------------------------------------------------------
                                      
     ‘KQ_NOTE_LINKUP’                 link is up
                                      
                                      
     ‘KQ_NOTE_LINKDOWN’               link is down
                                      
                                      
     ‘KQ_NOTE_LINKINV’                link state is invalid
                                      

 -- Attribute: kevent.data

     Filter specific data.

 -- Attribute: kevent.udata

     User defined value.


File: python.info,  Node: selectors -- High-level I/O multiplexing,  Next: asyncio -- Asynchronous I/O event loop coroutines and tasks,  Prev: select --- Waiting for I/O completion,  Up: Interprocess Communication and Networking

5.18.4 ‘selectors’ – High-level I/O multiplexing
------------------------------------------------

New in version 3.4.

* Menu:

* Introduction: Introduction<9>. 
* Classes: Classes<3>. 
* Examples: Examples<11>. 


File: python.info,  Node: Introduction<9>,  Next: Classes<3>,  Up: selectors -- High-level I/O multiplexing

5.18.4.1 Introduction
.....................

This module allows high-level and efficient I/O multiplexing, built upon
the *note select: e3. module primitives.  Users are encouraged to use
this module instead, unless they want precise control over the OS-level
primitives used.

It defines a *note BaseSelector: 1edf. abstract base class, along with
several concrete implementations (*note KqueueSelector: 1ee0, *note
EpollSelector: 1ee1...), that can be used to wait for I/O readiness
notification on multiple file objects.  In the following, "file object"
refers to any object with a ‘fileno()’ method, or a raw file descriptor.
See *note file object: 78b.

*note DefaultSelector: 1ee2. is an alias to the most efficient
implementation available on the current platform: this should be the
default choice for most users.

     Note: The type of file objects supported depends on the platform:
     on Windows, sockets are supported, but not pipes, whereas on Unix,
     both are supported (some other types may be supported as well, such
     as fifos or special file devices).

See also
........

*note select: e3.

     Low-level I/O multiplexing module.


File: python.info,  Node: Classes<3>,  Next: Examples<11>,  Prev: Introduction<9>,  Up: selectors -- High-level I/O multiplexing

5.18.4.2 Classes
................

Classes hierarchy:

     BaseSelector
     +-- SelectSelector
     +-- PollSelector
     +-- EpollSelector
     +-- DevpollSelector
     +-- KqueueSelector

In the following, `events' is a bitwise mask indicating which I/O events
should be waited for on a given file object.  It can be a combination of
the modules constants below:

     Constant                    Meaning
                                 
     --------------------------------------------------------------------------------
                                 
     ‘EVENT_READ’                Available for read
                                 
                                 
     ‘EVENT_WRITE’               Available for write
                                 

 -- Class: selectors.SelectorKey

     A *note SelectorKey: 1ee4. is a *note namedtuple: 229. used to
     associate a file object to its underlying file decriptor, selected
     event mask and attached data.  It is returned by several *note
     BaseSelector: 1edf. methods.

      -- Attribute: fileobj

          File object registered.

      -- Attribute: fd

          Underlying file descriptor.

      -- Attribute: events

          Events that must be waited for on this file object.

      -- Attribute: data

          Optional opaque data associated to this file object: for
          example, this could be used to store a per-client session ID.

 -- Class: selectors.BaseSelector

     A *note BaseSelector: 1edf. is used to wait for I/O event readiness
     on multiple file objects.  It supports file stream registration,
     unregistration, and a method to wait for I/O events on those
     streams, with an optional timeout.  It’s an abstract base class, so
     cannot be instantiated.  Use *note DefaultSelector: 1ee2. instead,
     or one of *note SelectSelector: 1ee9, *note KqueueSelector: 1ee0.
     etc.  if you want to specifically use an implementation, and your
     platform supports it.  *note BaseSelector: 1edf. and its concrete
     implementations support the *note context manager: 165. protocol.

      -- Method: abstractmethod register (fileobj, events, data=None)

          Register a file object for selection, monitoring it for I/O
          events.

          `fileobj' is the file object to monitor.  It may either be an
          integer file descriptor or an object with a ‘fileno()’ method.
          `events' is a bitwise mask of events to monitor.  `data' is an
          opaque object.

          This returns a new *note SelectorKey: 1ee4. instance, or
          raises a *note ValueError: 19c. in case of invalid event mask
          or file descriptor, or *note KeyError: 1a7. if the file object
          is already registered.

      -- Method: abstractmethod unregister (fileobj)

          Unregister a file object from selection, removing it from
          monitoring.  A file object shall be unregistered prior to
          being closed.

          `fileobj' must be a file object previously registered.

          This returns the associated *note SelectorKey: 1ee4. instance,
          or raises a *note KeyError: 1a7. if `fileobj' is not
          registered.  It will raise *note ValueError: 19c. if `fileobj'
          is invalid (e.g.  it has no ‘fileno()’ method or its
          ‘fileno()’ method has an invalid return value).

      -- Method: modify (fileobj, events, data=None)

          Change a registered file object’s monitored events or attached
          data.

          This is equivalent to ‘BaseSelector.unregister(fileobj)()’
          followed by ‘BaseSelector.register(fileobj, events, data)()’,
          except that it can be implemented more efficiently.

          This returns a new *note SelectorKey: 1ee4. instance, or
          raises a *note ValueError: 19c. in case of invalid event mask
          or file descriptor, or *note KeyError: 1a7. if the file object
          is not registered.

      -- Method: abstractmethod select (timeout=None)

          Wait until some registered file objects become ready, or the
          timeout expires.

          If ‘timeout > 0’, this specifies the maximum wait time, in
          seconds.  If ‘timeout <= 0’, the call won’t block, and will
          report the currently ready file objects.  If `timeout' is
          ‘None’, the call will block until a monitored file object
          becomes ready.

          This returns a list of ‘(key, events)’ tuples, one for each
          ready file object.

          `key' is the *note SelectorKey: 1ee4. instance corresponding
          to a ready file object.  `events' is a bitmask of events ready
          on this file object.

               Note: This method can return before any file object
               becomes ready or the timeout has elapsed if the current
               process receives a signal: in this case, an empty list
               will be returned.

          Changed in version 3.5: The selector is now retried with a
          recomputed timeout when interrupted by a signal if the signal
          handler did not raise an exception (see PEP 475(1) for the
          rationale), instead of returning an empty list of events
          before the timeout.

      -- Method: close ()

          Close the selector.

          This must be called to make sure that any underlying resource
          is freed.  The selector shall not be used once it has been
          closed.

      -- Method: get_key (fileobj)

          Return the key associated with a registered file object.

          This returns the *note SelectorKey: 1ee4. instance associated
          to this file object, or raises *note KeyError: 1a7. if the
          file object is not registered.

      -- Method: abstractmethod get_map ()

          Return a mapping of file objects to selector keys.

          This returns a *note Mapping: 12ee. instance mapping
          registered file objects to their associated *note SelectorKey:
          1ee4. instance.

 -- Class: selectors.DefaultSelector

     The default selector class, using the most efficient implementation
     available on the current platform.  This should be the default
     choice for most users.

 -- Class: selectors.SelectSelector

     *note select.select(): 209.-based selector.

 -- Class: selectors.PollSelector

     *note select.poll(): 1eaa.-based selector.

 -- Class: selectors.EpollSelector

     *note select.epoll(): 4a6.-based selector.

      -- Method: fileno ()

          This returns the file descriptor used by the underlying *note
          select.epoll(): 4a6. object.

 -- Class: selectors.DevpollSelector

     *note select.devpoll(): 4a8.-based selector.

      -- Method: fileno ()

          This returns the file descriptor used by the underlying *note
          select.devpoll(): 4a8. object.

     New in version 3.5.

 -- Class: selectors.KqueueSelector

     *note select.kqueue(): 1ebd.-based selector.

      -- Method: fileno ()

          This returns the file descriptor used by the underlying *note
          select.kqueue(): 1ebd. object.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Examples<11>,  Prev: Classes<3>,  Up: selectors -- High-level I/O multiplexing

5.18.4.3 Examples
.................

Here is a simple echo server implementation:

     import selectors
     import socket

     sel = selectors.DefaultSelector()

     def accept(sock, mask):
         conn, addr = sock.accept()  # Should be ready
         print('accepted', conn, 'from', addr)
         conn.setblocking(False)
         sel.register(conn, selectors.EVENT_READ, read)

     def read(conn, mask):
         data = conn.recv(1000)  # Should be ready
         if data:
             print('echoing', repr(data), 'to', conn)
             conn.send(data)  # Hope it won't block
         else:
             print('closing', conn)
             sel.unregister(conn)
             conn.close()

     sock = socket.socket()
     sock.bind(('localhost', 1234))
     sock.listen(100)
     sock.setblocking(False)
     sel.register(sock, selectors.EVENT_READ, accept)

     while True:
         events = sel.select()
         for key, mask in events:
             callback = key.data
             callback(key.fileobj, mask)


File: python.info,  Node: asyncio -- Asynchronous I/O event loop coroutines and tasks,  Next: asyncore --- Asynchronous socket handler,  Prev: selectors -- High-level I/O multiplexing,  Up: Interprocess Communication and Networking

5.18.5 ‘asyncio’ – Asynchronous I/O, event loop, coroutines and tasks
---------------------------------------------------------------------

     Note: The asyncio package has been included in the standard library
     on a *note provisional basis: 59d.  Backwards incompatible changes
     (up to and including removal of the module) may occur if deemed
     necessary by the core developers.

New in version 3.4.

`Source code:' Lib/asyncio/(1)

__________________________________________________________________

This module provides infrastructure for writing single-threaded
concurrent code using coroutines, multiplexing I/O access over sockets
and other resources, running network clients and servers, and other
related primitives.  Here is a more detailed list of the package
contents:

   * a pluggable *note event loop: 1d3. with various system-specific
     implementations;

   * *note transport: 1ef8. and *note protocol: 1ef9. abstractions
     (similar to those in Twisted(2));

   * concrete support for TCP, UDP, SSL, subprocess pipes, delayed
     calls, and others (some may be system-dependent);

   * a *note Future: e50. class that mimics the one in the *note
     concurrent.futures: 22. module, but adapted for use with the event
     loop;

   * coroutines and tasks based on ‘yield from’ ( PEP 380(3)), to help
     write concurrent code in a sequential fashion;

   * cancellation support for *note Future: e50.s and coroutines;

   * *note synchronization primitives: 1efa. for use between coroutines
     in a single thread, mimicking those in the *note threading: 106.
     module;

   * an interface for passing work off to a threadpool, for times when
     you absolutely, positively have to use a library that makes
     blocking I/O calls.

Asynchronous programming is more complex than classical "sequential"
programming: see the *note Develop with asyncio: 1efb. page which lists
common traps and explains how to avoid them.  *note Enable the debug
mode: d1d. during development to detect common issues.

Table of contents:

* Menu:

* Base Event Loop:: 
* Event loops:: 
* Tasks and coroutines:: 
* Transports and protocols (callback based API): Transports and protocols callback based API. 
* Streams (coroutine based API): Streams coroutine based API. 
* Subprocess:: 
* Synchronization primitives: Synchronization primitives<2>. 
* Queues:: 
* Develop with asyncio:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/asyncio/

   (2) https://twistedmatrix.com/trac/

   (3) https://www.python.org/dev/peps/pep-0380


File: python.info,  Node: Base Event Loop,  Next: Event loops,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.1 Base Event Loop
........................

The event loop is the central execution device provided by *note
asyncio: a.  It provides multiple facilities, including:

   * Registering, executing and cancelling delayed calls (timeouts).

   * Creating client and server *note transports: 1ef8. for various
     kinds of communication.

   * Launching subprocesses and the associated *note transports: 1ef8.
     for communication with an external program.

   * Delegating costly function calls to a pool of threads.

 -- Class: asyncio.BaseEventLoop

     Base class of event loops.

     This class is *note not thread safe: 1eff.

* Menu:

* Run an event loop:: 
* Calls: Calls<2>. 
* Delayed calls:: 
* Tasks:: 
* Creating connections:: 
* Creating listening connections:: 
* Watch file descriptors:: 
* Low-level socket operations:: 
* Resolve host name:: 
* Connect pipes:: 
* UNIX signals:: 
* Executor:: 
* Error Handling API:: 
* Debug mode:: 
* Server:: 
* Handle:: 
* Event loop examples:: 


File: python.info,  Node: Run an event loop,  Next: Calls<2>,  Up: Base Event Loop

5.18.5.2 Run an event loop
..........................

 -- Method: BaseEventLoop.run_forever ()

     Run until *note stop(): 1f02. is called.  If *note stop(): 1f02. is
     called before *note run_forever(): 1f01. is called, this polls the
     I/O selector once with a timeout of zero, runs all callbacks
     scheduled in response to I/O events (and those that were already
     scheduled), and then exits.  If *note stop(): 1f02. is called while
     *note run_forever(): 1f01. is running, this will run the current
     batch of callbacks and then exit.  Note that callbacks scheduled by
     callbacks will not run in that case; they will run the next time
     *note run_forever(): 1f01. is called.

     Changed in version 3.5.1.

 -- Method: BaseEventLoop.run_until_complete (future)

     Run until the *note Future: e50. is done.

     If the argument is a *note coroutine object: 1f03, it is wrapped by
     *note ensure_future(): 23c.

     Return the Future’s result, or raise its exception.

 -- Method: BaseEventLoop.is_running ()

     Returns running status of event loop.

 -- Method: BaseEventLoop.stop ()

     Stop running the event loop.

     This causes *note run_forever(): 1f01. to exit at the next suitable
     opportunity (see there for more details).

     Changed in version 3.5.1.

 -- Method: BaseEventLoop.is_closed ()

     Returns ‘True’ if the event loop was closed.

     New in version 3.4.2.

 -- Method: BaseEventLoop.close ()

     Close the event loop.  The loop must not be running.  Pending
     callbacks will be lost.

     This clears the queues and shuts down the executor, but does not
     wait for the executor to finish.

     This is idempotent and irreversible.  No other methods should be
     called after this one.


File: python.info,  Node: Calls<2>,  Next: Delayed calls,  Prev: Run an event loop,  Up: Base Event Loop

5.18.5.3 Calls
..............

Most *note asyncio: a. functions don’t accept keywords.  If you want to
pass keywords to your callback, use *note functools.partial(): 3b7.  For
example, ‘loop.call_soon(functools.partial(print, "Hello", flush=True))’
will call ‘print("Hello", flush=True)’.

     Note: *note functools.partial(): 3b7. is better than ‘lambda’
     functions, because *note asyncio: a. can inspect *note
     functools.partial(): 3b7. object to display parameters in debug
     mode, whereas ‘lambda’ functions have a poor representation.

 -- Method: BaseEventLoop.call_soon (callback, *args)

     Arrange for a callback to be called as soon as possible.  The
     callback is called after *note call_soon(): 1f08. returns, when
     control returns to the event loop.

     This operates as a FIFO queue, callbacks are called in the order in
     which they are registered.  Each callback will be called exactly
     once.

     Any positional arguments after the callback will be passed to the
     callback when it is called.

     An instance of *note asyncio.Handle: 1f09. is returned, which can
     be used to cancel the callback.

     *note Use functools.partial to pass keywords to the callback: 1f06.

 -- Method: BaseEventLoop.call_soon_threadsafe (callback, *args)

     Like *note call_soon(): 1f08, but thread safe.

     See the *note concurrency and multithreading: 1eff. section of the
     documentation.


File: python.info,  Node: Delayed calls,  Next: Tasks,  Prev: Calls<2>,  Up: Base Event Loop

5.18.5.4 Delayed calls
......................

The event loop has its own internal clock for computing timeouts.  Which
clock is used depends on the (platform-specific) event loop
implementation; ideally it is a monotonic clock.  This will generally be
a different clock than *note time.time(): 6a5.

     Note: Timeouts (relative `delay' or absolute `when') should not
     exceed one day.

 -- Method: BaseEventLoop.call_later (delay, callback, *args)

     Arrange for the `callback' to be called after the given `delay'
     seconds (either an int or float).

     An instance of *note asyncio.Handle: 1f09. is returned, which can
     be used to cancel the callback.

     `callback' will be called exactly once per call to *note
     call_later(): 1f0d.  If two callbacks are scheduled for exactly the
     same time, it is undefined which will be called first.

     The optional positional `args' will be passed to the callback when
     it is called.  If you want the callback to be called with some
     named arguments, use a closure or *note functools.partial(): 3b7.

     *note Use functools.partial to pass keywords to the callback: 1f06.

 -- Method: BaseEventLoop.call_at (when, callback, *args)

     Arrange for the `callback' to be called at the given absolute
     timestamp `when' (an int or float), using the same time reference
     as *note BaseEventLoop.time(): 1f0f.

     This method’s behavior is the same as *note call_later(): 1f0d.

     An instance of *note asyncio.Handle: 1f09. is returned, which can
     be used to cancel the callback.

     *note Use functools.partial to pass keywords to the callback: 1f06.

 -- Method: BaseEventLoop.time ()

     Return the current time, as a *note float: 57a. value, according to
     the event loop’s internal clock.

See also
........

The *note asyncio.sleep(): 1f10. function.


File: python.info,  Node: Tasks,  Next: Creating connections,  Prev: Delayed calls,  Up: Base Event Loop

5.18.5.5 Tasks
..............

 -- Method: BaseEventLoop.create_task (coro)

     Schedule the execution of a *note coroutine object: 1f03.: wrap it
     in a future.  Return a *note Task: 237. object.

     Third-party event loops can use their own subclass of *note Task:
     237. for interoperability.  In this case, the result type is a
     subclass of *note Task: 237.

     This method was added in Python 3.4.2.  Use the *note async(): 23b.
     function to support also older Python versions.

     New in version 3.4.2.

 -- Method: BaseEventLoop.set_task_factory (factory)

     Set a task factory that will be used by *note
     BaseEventLoop.create_task(): 236.

     If `factory' is ‘None’ the default task factory will be set.

     If `factory' is a `callable', it should have a signature matching
     ‘(loop, coro)’, where `loop' will be a reference to the active
     event loop, `coro' will be a coroutine object.  The callable must
     return an *note asyncio.Future: e50. compatible object.

     New in version 3.4.4.

 -- Method: BaseEventLoop.get_task_factory ()

     Return a task factory, or ‘None’ if the default one is in use.

     New in version 3.4.4.


File: python.info,  Node: Creating connections,  Next: Creating listening connections,  Prev: Tasks,  Up: Base Event Loop

5.18.5.6 Creating connections
.............................

 -- Method: coroutine BaseEventLoop.create_connection (protocol_factory,
          host=None, port=None, *, ssl=None, family=0, proto=0, flags=0,
          sock=None, local_addr=None, server_hostname=None)

     Create a streaming transport connection to a given Internet `host'
     and `port': socket family *note AF_INET: 1e1a. or *note AF_INET6:
     1e1b. depending on `host' (or `family' if specified), socket type
     *note SOCK_STREAM: 8fb.  `protocol_factory' must be a callable
     returning a *note protocol: 1ef9. instance.

     This method is a *note coroutine: 1f03. which will try to establish
     the connection in the background.  When successful, the coroutine
     returns a ‘(transport, protocol)’ pair.

     The chronological synopsis of the underlying operation is as
     follows:

       1. The connection is established, and a *note transport: 1ef8. is
          created to represent it.

       2. `protocol_factory' is called without arguments and must return
          a *note protocol: 1ef9. instance.

       3. The protocol instance is tied to the transport, and its
          ‘connection_made()’ method is called.

       4. The coroutine returns successfully with the ‘(transport,
          protocol)’ pair.

     The created transport is an implementation-dependent bidirectional
     stream.

          Note: `protocol_factory' can be any kind of callable, not
          necessarily a class.  For example, if you want to use a
          pre-created protocol instance, you can pass ‘lambda:
          my_protocol’.

     Options that change how the connection is created:

        * `ssl': if given and not false, a SSL/TLS transport is created
          (by default a plain TCP transport is created).  If `ssl' is a
          *note ssl.SSLContext: 1c6. object, this context is used to
          create the transport; if `ssl' is *note True: 9ff, a context
          with some unspecified default settings is used.

          See also
          ........

          *note SSL/TLS security considerations: 1e6a.

        * `server_hostname', is only for use together with `ssl', and
          sets or overrides the hostname that the target server’s
          certificate will be matched against.  By default the value of
          the `host' argument is used.  If `host' is empty, there is no
          default and you must pass a value for `server_hostname'.  If
          `server_hostname' is an empty string, hostname matching is
          disabled (which is a serious security risk, allowing for
          man-in-the-middle-attacks).

        * `family', `proto', `flags' are the optional address family,
          protocol and flags to be passed through to getaddrinfo() for
          `host' resolution.  If given, these should all be integers
          from the corresponding *note socket: ed. module constants.

        * `sock', if given, should be an existing, already connected
          *note socket.socket: 20a. object to be used by the transport.
          If `sock' is given, none of `host', `port', `family', `proto',
          `flags' and `local_addr' should be specified.

        * `local_addr', if given, is a ‘(local_host, local_port)’ tuple
          used to bind the socket to locally.  The `local_host' and
          `local_port' are looked up using getaddrinfo(), similarly to
          `host' and `port'.

     Changed in version 3.5: On Windows with *note ProactorEventLoop:
     1f14, SSL/TLS is now supported.

     See also
     ........

     The *note open_connection(): 1f15. function can be used to get a
     pair of (*note StreamReader: 1f16, *note StreamWriter: 1f17.)
     instead of a protocol.

 -- Method: coroutine BaseEventLoop.create_datagram_endpoint
          (protocol_factory, local_addr=None, remote_addr=None, *,
          family=0, proto=0, flags=0, reuse_address=None,
          reuse_port=None, allow_broadcast=None, sock=None)

     Create datagram connection: socket family *note AF_INET: 1e1a. or
     *note AF_INET6: 1e1b. depending on `host' (or `family' if
     specified), socket type *note SOCK_DGRAM: 8fa.  `protocol_factory'
     must be a callable returning a *note protocol: 1ef9. instance.

     This method is a *note coroutine: 1f03. which will try to establish
     the connection in the background.  When successful, the coroutine
     returns a ‘(transport, protocol)’ pair.

     Options changing how the connection is created:

        * `local_addr', if given, is a ‘(local_host, local_port)’ tuple
          used to bind the socket to locally.  The `local_host' and
          `local_port' are looked up using *note getaddrinfo(): 1f19.

        * `remote_addr', if given, is a ‘(remote_host, remote_port)’
          tuple used to connect the socket to a remote address.  The
          `remote_host' and `remote_port' are looked up using *note
          getaddrinfo(): 1f19.

        * `family', `proto', `flags' are the optional address family,
          protocol and flags to be passed through to *note
          getaddrinfo(): 1f19. for `host' resolution.  If given, these
          should all be integers from the corresponding *note socket:
          ed. module constants.

        * `reuse_address' tells the kernel to reuse a local socket in
          TIME_WAIT state, without waiting for its natural timeout to
          expire.  If not specified will automatically be set to True on
          UNIX.

        * `reuse_port' tells the kernel to allow this endpoint to be
          bound to the same port as other existing endpoints are bound
          to, so long as they all set this flag when being created.
          This option is not supported on Windows and some UNIX’s.  If
          the ‘SO_REUSEPORT’ constant is not defined then this
          capability is unsupported.

        * `allow_broadcast' tells the kernel to allow this endpoint to
          send messages to the broadcast address.

        * `sock' can optionally be specified in order to use a
          preexisting, already connected, *note socket.socket: 20a.
          object to be used by the transport.  If specified,
          `local_addr' and `remote_addr' should be omitted (must be
          *note None: 19d.).

     On Windows with *note ProactorEventLoop: 1f14, this method is not
     supported.

     See *note UDP echo client protocol: 1f1a. and *note UDP echo server
     protocol: 1f1b. examples.

 -- Method: coroutine BaseEventLoop.create_unix_connection
          (protocol_factory, path, *, ssl=None, sock=None,
          server_hostname=None)

     Create UNIX connection: socket family *note AF_UNIX: 1e19, socket
     type *note SOCK_STREAM: 8fb.  The *note AF_UNIX: 1e19. socket
     family is used to communicate between processes on the same machine
     efficiently.

     This method is a *note coroutine: 1f03. which will try to establish
     the connection in the background.  When successful, the coroutine
     returns a ‘(transport, protocol)’ pair.

     See the *note BaseEventLoop.create_connection(): 1f13. method for
     parameters.

     Availability: UNIX.


File: python.info,  Node: Creating listening connections,  Next: Watch file descriptors,  Prev: Creating connections,  Up: Base Event Loop

5.18.5.7 Creating listening connections
.......................................

 -- Method: coroutine BaseEventLoop.create_server (protocol_factory,
          host=None, port=None, *, family=socket.AF_UNSPEC,
          flags=socket.AI_PASSIVE, sock=None, backlog=100, ssl=None,
          reuse_address=None, reuse_port=None)

     Create a TCP server (socket type *note SOCK_STREAM: 8fb.) bound to
     `host' and `port'.

     Return a *note Server: 1f1e. object, its *note sockets: 1f1f.
     attribute contains created sockets.  Use the *note Server.close():
     1f20. method to stop the server: close listening sockets.

     Parameters:

        * The `host' parameter can be a string, in that case the TCP
          server is bound to `host' and `port'.  The `host' parameter
          can also be a sequence of strings and in that case the TCP
          server is bound to all hosts of the sequence.  If `host' is an
          empty string or ‘None’, all interfaces are assumed and a list
          of multiple sockets will be returned (most likely one for IPv4
          and another one for IPv6).

        * `family' can be set to either *note socket.AF_INET: 1e1a. or
          *note AF_INET6: 1e1b. to force the socket to use IPv4 or IPv6.
          If not set it will be determined from host (defaults to
          ‘socket.AF_UNSPEC’).

        * `flags' is a bitmask for *note getaddrinfo(): 1f19.

        * `sock' can optionally be specified in order to use a
          preexisting socket object.  If specified, `host' and `port'
          should be omitted (must be *note None: 19d.).

        * `backlog' is the maximum number of queued connections passed
          to *note listen(): 316. (defaults to 100).

        * `ssl' can be set to an *note SSLContext: 1c6. to enable SSL
          over the accepted connections.

        * `reuse_address' tells the kernel to reuse a local socket in
          TIME_WAIT state, without waiting for its natural timeout to
          expire.  If not specified will automatically be set to True on
          UNIX.

        * `reuse_port' tells the kernel to allow this endpoint to be
          bound to the same port as other existing endpoints are bound
          to, so long as they all set this flag when being created.
          This option is not supported on Windows.

     This method is a *note coroutine: 1f03.

     Changed in version 3.5: On Windows with *note ProactorEventLoop:
     1f14, SSL/TLS is now supported.

     See also
     ........

     The function *note start_server(): 1f21. creates a (*note
     StreamReader: 1f16, *note StreamWriter: 1f17.) pair and calls back
     a function with this pair.

     Changed in version 3.5.1: The `host' parameter can now be a
     sequence of strings.

 -- Method: coroutine BaseEventLoop.create_unix_server
          (protocol_factory, path=None, *, sock=None, backlog=100,
          ssl=None)

     Similar to *note BaseEventLoop.create_server(): 245, but specific
     to the socket family *note AF_UNIX: 1e19.

     This method is a *note coroutine: 1f03.

     Availability: UNIX.


File: python.info,  Node: Watch file descriptors,  Next: Low-level socket operations,  Prev: Creating listening connections,  Up: Base Event Loop

5.18.5.8 Watch file descriptors
...............................

On Windows with *note SelectorEventLoop: 1f24, only socket handles are
supported (ex: pipe file descriptors are not supported).

On Windows with *note ProactorEventLoop: 1f14, these methods are not
supported.

 -- Method: BaseEventLoop.add_reader (fd, callback, *args)

     Start watching the file descriptor for read availability and then
     call the `callback' with specified arguments.

     *note Use functools.partial to pass keywords to the callback: 1f06.

 -- Method: BaseEventLoop.remove_reader (fd)

     Stop watching the file descriptor for read availability.

 -- Method: BaseEventLoop.add_writer (fd, callback, *args)

     Start watching the file descriptor for write availability and then
     call the `callback' with specified arguments.

     *note Use functools.partial to pass keywords to the callback: 1f06.

 -- Method: BaseEventLoop.remove_writer (fd)

     Stop watching the file descriptor for write availability.

The *note watch a file descriptor for read events: 1f29. example uses
the low-level *note BaseEventLoop.add_reader(): 1f25. method to register
the file descriptor of a socket.


File: python.info,  Node: Low-level socket operations,  Next: Resolve host name,  Prev: Watch file descriptors,  Up: Base Event Loop

5.18.5.9 Low-level socket operations
....................................

 -- Method: coroutine BaseEventLoop.sock_recv (sock, nbytes)

     Receive data from the socket.  The return value is a bytes object
     representing the data received.  The maximum amount of data to be
     received at once is specified by `nbytes'.

     With *note SelectorEventLoop: 1f24. event loop, the socket `sock'
     must be non-blocking.

     This method is a *note coroutine: 1f03.

     See also
     ........

     The *note socket.socket.recv(): 20d. method.

 -- Method: coroutine BaseEventLoop.sock_sendall (sock, data)

     Send data to the socket.  The socket must be connected to a remote
     socket.  This method continues to send data from `data' until
     either all data has been sent or an error occurs.  ‘None’ is
     returned on success.  On error, an exception is raised, and there
     is no way to determine how much data, if any, was successfully
     processed by the receiving end of the connection.

     With *note SelectorEventLoop: 1f24. event loop, the socket `sock'
     must be non-blocking.

     This method is a *note coroutine: 1f03.

     See also
     ........

     The *note socket.socket.sendall(): 211. method.

 -- Method: coroutine BaseEventLoop.sock_connect (sock, address)

     Connect to a remote socket at `address'.

     The `address' must be already resolved to avoid the trap of hanging
     the entire event loop when the address requires doing a DNS lookup.
     For example, it must be an IP address, not a hostname, for *note
     AF_INET: 1e1a. and *note AF_INET6: 1e1b. address families.  Use
     *note getaddrinfo(): 1f19. to resolve the hostname asynchronously.

     With *note SelectorEventLoop: 1f24. event loop, the socket `sock'
     must be non-blocking.

     This method is a *note coroutine: 1f03.

     See also
     ........

     The *note BaseEventLoop.create_connection(): 1f13. method, the
     *note open_connection(): 1f15. function and the *note
     socket.socket.connect(): 20c. method.

 -- Method: coroutine BaseEventLoop.sock_accept (sock)

     Accept a connection.  The socket must be bound to an address and
     listening for connections.  The return value is a pair ‘(conn,
     address)’ where `conn' is a `new' socket object usable to send and
     receive data on the connection, and `address' is the address bound
     to the socket on the other end of the connection.

     The socket `sock' must be non-blocking.

     This method is a *note coroutine: 1f03.

     See also
     ........

     The *note BaseEventLoop.create_server(): 245. method, the *note
     start_server(): 1f21. function and the *note
     socket.socket.accept(): 20b. method.


File: python.info,  Node: Resolve host name,  Next: Connect pipes,  Prev: Low-level socket operations,  Up: Base Event Loop

5.18.5.10 Resolve host name
...........................

 -- Method: coroutine BaseEventLoop.getaddrinfo (host, port, *,
          family=0, type=0, proto=0, flags=0)

     This method is a *note coroutine: 1f03, similar to *note
     socket.getaddrinfo(): 1e24. function but non-blocking.

 -- Method: coroutine BaseEventLoop.getnameinfo (sockaddr, flags=0)

     This method is a *note coroutine: 1f03, similar to *note
     socket.getnameinfo(): 1e25. function but non-blocking.


File: python.info,  Node: Connect pipes,  Next: UNIX signals,  Prev: Resolve host name,  Up: Base Event Loop

5.18.5.11 Connect pipes
.......................

On Windows with *note SelectorEventLoop: 1f24, these methods are not
supported.  Use *note ProactorEventLoop: 1f14. to support pipes on
Windows.

 -- Method: coroutine BaseEventLoop.connect_read_pipe (protocol_factory,
          pipe)

     Register read pipe in eventloop.

     `protocol_factory' should instantiate object with *note Protocol:
     1f33. interface.  `pipe' is a *note file-like object: 78b.  Return
     pair ‘(transport, protocol)’, where `transport' supports the *note
     ReadTransport: 1f34. interface.

     With *note SelectorEventLoop: 1f24. event loop, the `pipe' is set
     to non-blocking mode.

     This method is a *note coroutine: 1f03.

 -- Method: coroutine BaseEventLoop.connect_write_pipe
          (protocol_factory, pipe)

     Register write pipe in eventloop.

     `protocol_factory' should instantiate object with ‘BaseProtocol’
     interface.  `pipe' is *note file-like object: 78b.  Return pair
     ‘(transport, protocol)’, where `transport' supports *note
     WriteTransport: 1f36. interface.

     With *note SelectorEventLoop: 1f24. event loop, the `pipe' is set
     to non-blocking mode.

     This method is a *note coroutine: 1f03.

See also
........

The *note BaseEventLoop.subprocess_exec(): 1f37. and *note
BaseEventLoop.subprocess_shell(): 1f38. methods.


File: python.info,  Node: UNIX signals,  Next: Executor,  Prev: Connect pipes,  Up: Base Event Loop

5.18.5.12 UNIX signals
......................

Availability: UNIX only.

 -- Method: BaseEventLoop.add_signal_handler (signum, callback, *args)

     Add a handler for a signal.

     Raise *note ValueError: 19c. if the signal number is invalid or
     uncatchable.  Raise *note RuntimeError: 193. if there is a problem
     setting up the handler.

     *note Use functools.partial to pass keywords to the callback: 1f06.

 -- Method: BaseEventLoop.remove_signal_handler (sig)

     Remove a handler for a signal.

     Return ‘True’ if a signal handler was removed, ‘False’ if not.

See also
........

The *note signal: e8. module.


File: python.info,  Node: Executor,  Next: Error Handling API,  Prev: UNIX signals,  Up: Base Event Loop

5.18.5.13 Executor
..................

Call a function in an *note Executor: 1d8d. (pool of threads or pool of
processes).  By default, an event loop uses a thread pool executor
(*note ThreadPoolExecutor: 26a.).

 -- Method: coroutine BaseEventLoop.run_in_executor (executor, func,
          *args)

     Arrange for a `func' to be called in the specified executor.

     The `executor' argument should be an *note Executor: 1d8d.
     instance.  The default executor is used if `executor' is ‘None’.

     *note Use functools.partial to pass keywords to the *func*: 1f06.

     This method is a *note coroutine: 1f03.

 -- Method: BaseEventLoop.set_default_executor (executor)

     Set the default executor used by *note run_in_executor(): 1f3d.


File: python.info,  Node: Error Handling API,  Next: Debug mode,  Prev: Executor,  Up: Base Event Loop

5.18.5.14 Error Handling API
............................

Allows customizing how exceptions are handled in the event loop.

 -- Method: BaseEventLoop.set_exception_handler (handler)

     Set `handler' as the new event loop exception handler.

     If `handler' is ‘None’, the default exception handler will be set.

     If `handler' is a callable object, it should have a matching
     signature to ‘(loop, context)’, where ‘loop’ will be a reference to
     the active event loop, ‘context’ will be a ‘dict’ object (see *note
     call_exception_handler(): 1f41. documentation for details about
     context).

 -- Method: BaseEventLoop.default_exception_handler (context)

     Default exception handler.

     This is called when an exception occurs and no exception handler is
     set, and can be called by a custom exception handler that wants to
     defer to the default behavior.

     `context' parameter has the same meaning as in *note
     call_exception_handler(): 1f41.

 -- Method: BaseEventLoop.call_exception_handler (context)

     Call the current event loop exception handler.

     `context' is a ‘dict’ object containing the following keys (new
     keys may be introduced later):

        * ’message’: Error message;

        * ’exception’ (optional): Exception object;

        * ’future’ (optional): *note asyncio.Future: e50. instance;

        * ’handle’ (optional): *note asyncio.Handle: 1f09. instance;

        * ’protocol’ (optional): *note Protocol: 1ef9. instance;

        * ’transport’ (optional): *note Transport: 1ef8. instance;

        * ’socket’ (optional): *note socket.socket: 20a. instance.

          Note: Note: this method should not be overloaded in subclassed
          event loops.  For any custom exception handling, use *note
          set_exception_handler(): 1f40. method.


File: python.info,  Node: Debug mode,  Next: Server,  Prev: Error Handling API,  Up: Base Event Loop

5.18.5.15 Debug mode
....................

 -- Method: BaseEventLoop.get_debug ()

     Get the debug mode (*note bool: a72.) of the event loop.

     The default value is ‘True’ if the environment variable *note
     PYTHONASYNCIODEBUG: d1c. is set to a non-empty string, ‘False’
     otherwise.

     New in version 3.4.2.

 -- Method: BaseEventLoop.set_debug (enabled: bool)

     Set the debug mode of the event loop.

     New in version 3.4.2.

See also
........

The *note debug mode of asyncio: d1d.


File: python.info,  Node: Server,  Next: Handle,  Prev: Debug mode,  Up: Base Event Loop

5.18.5.16 Server
................

 -- Class: asyncio.Server

     Server listening on sockets.

     Object created by the *note BaseEventLoop.create_server(): 245.
     method and the *note start_server(): 1f21. function.  Don’t
     instantiate the class directly.

      -- Method: close ()

          Stop serving: close listening sockets and set the *note
          sockets: 1f1f. attribute to ‘None’.

          The sockets that represent existing incoming client
          connections are left open.

          The server is closed asynchronously, use the *note
          wait_closed(): 1f45. coroutine to wait until the server is
          closed.

      -- Method: coroutine wait_closed ()

          Wait until the *note close(): 1f20. method completes.

          This method is a *note coroutine: 1f03.

      -- Attribute: sockets

          List of *note socket.socket: 20a. objects the server is
          listening to, or ‘None’ if the server is closed.


File: python.info,  Node: Handle,  Next: Event loop examples,  Prev: Server,  Up: Base Event Loop

5.18.5.17 Handle
................

 -- Class: asyncio.Handle

     A callback wrapper object returned by *note
     BaseEventLoop.call_soon(): 1f08, *note
     BaseEventLoop.call_soon_threadsafe(): 1f0a, *note
     BaseEventLoop.call_later(): 1f0d, and *note
     BaseEventLoop.call_at(): 1f0e.

      -- Method: cancel ()

          Cancel the call.  If the callback is already canceled or
          executed, this method has no effect.


File: python.info,  Node: Event loop examples,  Prev: Handle,  Up: Base Event Loop

5.18.5.18 Event loop examples
.............................

* Menu:

* Hello World with call_soon(): Hello World with call_soon. 
* Display the current date with call_later(): Display the current date with call_later. 
* Watch a file descriptor for read events:: 
* Set signal handlers for SIGINT and SIGTERM:: 


File: python.info,  Node: Hello World with call_soon,  Next: Display the current date with call_later,  Up: Event loop examples

5.18.5.19 Hello World with call_soon()
......................................

Example using the *note BaseEventLoop.call_soon(): 1f08. method to
schedule a callback.  The callback displays ‘"Hello World"’ and then
stops the event loop:

     import asyncio

     def hello_world(loop):
         print('Hello World')
         loop.stop()

     loop = asyncio.get_event_loop()

     # Schedule a call to hello_world()
     loop.call_soon(hello_world, loop)

     # Blocking call interrupted by loop.stop()
     loop.run_forever()
     loop.close()

See also
........

The *note Hello World coroutine: 1f4b. example uses a *note coroutine:
1f03.


File: python.info,  Node: Display the current date with call_later,  Next: Watch a file descriptor for read events,  Prev: Hello World with call_soon,  Up: Event loop examples

5.18.5.20 Display the current date with call_later()
....................................................

Example of callback displaying the current date every second.  The
callback uses the *note BaseEventLoop.call_later(): 1f0d. method to
reschedule itself during 5 seconds, and then stops the event loop:

     import asyncio
     import datetime

     def display_date(end_time, loop):
         print(datetime.datetime.now())
         if (loop.time() + 1.0) < end_time:
             loop.call_later(1, display_date, end_time, loop)
         else:
             loop.stop()

     loop = asyncio.get_event_loop()

     # Schedule the first call to display_date()
     end_time = loop.time() + 5.0
     loop.call_soon(display_date, end_time, loop)

     # Blocking call interrupted by loop.stop()
     loop.run_forever()
     loop.close()

See also
........

The *note coroutine displaying the current date: 1f4e. example uses a
*note coroutine: 1f03.


File: python.info,  Node: Watch a file descriptor for read events,  Next: Set signal handlers for SIGINT and SIGTERM,  Prev: Display the current date with call_later,  Up: Event loop examples

5.18.5.21 Watch a file descriptor for read events
.................................................

Wait until a file descriptor received some data using the *note
BaseEventLoop.add_reader(): 1f25. method and then close the event loop:

     import asyncio
     try:
         from socket import socketpair
     except ImportError:
         from asyncio.windows_utils import socketpair

     # Create a pair of connected file descriptors
     rsock, wsock = socketpair()
     loop = asyncio.get_event_loop()

     def reader():
         data = rsock.recv(100)
         print("Received:", data.decode())
         # We are done: unregister the file descriptor
         loop.remove_reader(rsock)
         # Stop the event loop
         loop.stop()

     # Register the file descriptor for read event
     loop.add_reader(rsock, reader)

     # Simulate the reception of data from the network
     loop.call_soon(wsock.send, 'abc'.encode())

     # Run the event loop
     loop.run_forever()

     # We are done, close sockets and the event loop
     rsock.close()
     wsock.close()
     loop.close()

See also
........

The *note register an open socket to wait for data using a protocol:
1f50. example uses a low-level protocol created by the *note
BaseEventLoop.create_connection(): 1f13. method.

The *note register an open socket to wait for data using streams: 1f51.
example uses high-level streams created by the *note open_connection():
1f15. function in a coroutine.


File: python.info,  Node: Set signal handlers for SIGINT and SIGTERM,  Prev: Watch a file descriptor for read events,  Up: Event loop examples

5.18.5.22 Set signal handlers for SIGINT and SIGTERM
....................................................

Register handlers for signals ‘SIGINT’ and ‘SIGTERM’ using the *note
BaseEventLoop.add_signal_handler(): 1f3a. method:

     import asyncio
     import functools
     import os
     import signal

     def ask_exit(signame):
         print("got signal %s: exit" % signame)
         loop.stop()

     loop = asyncio.get_event_loop()
     for signame in ('SIGINT', 'SIGTERM'):
         loop.add_signal_handler(getattr(signal, signame),
                                 functools.partial(ask_exit, signame))

     print("Event loop running forever, press Ctrl+C to interrupt.")
     print("pid %s: send SIGINT or SIGTERM to exit." % os.getpid())
     try:
         loop.run_forever()
     finally:
         loop.close()

This example only works on UNIX.


File: python.info,  Node: Event loops,  Next: Tasks and coroutines,  Prev: Base Event Loop,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.23 Event loops
.....................

* Menu:

* Event loop functions:: 
* Available event loops:: 
* Platform support:: 
* Event loop policies and the default policy:: 
* Event loop policy interface:: 
* Access to the global loop policy:: 


File: python.info,  Node: Event loop functions,  Next: Available event loops,  Up: Event loops

5.18.5.24 Event loop functions
..............................

The following functions are convenient shortcuts to accessing the
methods of the global policy.  Note that this provides access to the
default policy, unless an alternative policy was set by calling *note
set_event_loop_policy(): 1f56. earlier in the execution of the process.

 -- Function: asyncio.get_event_loop ()

     Equivalent to calling ‘get_event_loop_policy().get_event_loop()’.

 -- Function: asyncio.set_event_loop (loop)

     Equivalent to calling
     ‘get_event_loop_policy().set_event_loop(loop)’.

 -- Function: asyncio.new_event_loop ()

     Equivalent to calling ‘get_event_loop_policy().new_event_loop()’.


File: python.info,  Node: Available event loops,  Next: Platform support,  Prev: Event loop functions,  Up: Event loops

5.18.5.25 Available event loops
...............................

asyncio currently provides two implementations of event loops: *note
SelectorEventLoop: 1f24. and *note ProactorEventLoop: 1f14.

 -- Class: asyncio.SelectorEventLoop

     Event loop based on the *note selectors: e4. module.  Subclass of
     *note BaseEventLoop: 1efe.

     Use the most efficient selector available on the platform.

     On Windows, only sockets are supported (ex: pipes are not
     supported): see the MSDN documentation of select(1).

 -- Class: asyncio.ProactorEventLoop

     Proactor event loop for Windows using "I/O Completion Ports" aka
     IOCP. Subclass of *note BaseEventLoop: 1efe.

     Availability: Windows.

     See also
     ........

     MSDN documentation on I/O Completion Ports(2).

Example to use a *note ProactorEventLoop: 1f14. on Windows:

     import asyncio, sys

     if sys.platform == 'win32':
         loop = asyncio.ProactorEventLoop()
         asyncio.set_event_loop(loop)

   ---------- Footnotes ----------

   (1) 
https://msdn.microsoft.com/en-us/library/windows/desktop/ms740141%28v=vs.85%29.aspx

   (2) 
https://msdn.microsoft.com/en-us/library/windows/desktop/aa365198%28v=vs.85%29.aspx


File: python.info,  Node: Platform support,  Next: Event loop policies and the default policy,  Prev: Available event loops,  Up: Event loops

5.18.5.26 Platform support
..........................

The *note asyncio: a. module has been designed to be portable, but each
platform still has subtle differences and may not support all *note
asyncio: a. features.

* Menu:

* Windows: Windows<7>. 
* Mac OS X:: 


File: python.info,  Node: Windows<7>,  Next: Mac OS X,  Up: Platform support

5.18.5.27 Windows
.................

Common limits of Windows event loops:

   - *note create_unix_connection(): 1f1c. and *note
     create_unix_server(): 1f22. are not supported: the socket family
     *note socket.AF_UNIX: 1e19. is specific to UNIX

   - *note add_signal_handler(): 1f3a. and *note
     remove_signal_handler(): 1f3b. are not supported

   - ‘EventLoopPolicy.set_child_watcher()’ is not supported.  *note
     ProactorEventLoop: 1f14. supports subprocesses.  It has only one
     implementation to watch child processes, there is no need to
     configure it.

*note SelectorEventLoop: 1f24. specific limits:

   - *note SelectSelector: 1ee9. is used which only supports sockets and
     is limited to 512 sockets.

   - *note add_reader(): 1f25. and *note add_writer(): 1f27. only accept
     file descriptors of sockets

   - Pipes are not supported (ex: *note connect_read_pipe(): 1f32, *note
     connect_write_pipe(): 1f35.)

   - *note Subprocesses: 1f5f. are not supported (ex: *note
     subprocess_exec(): 1f37, *note subprocess_shell(): 1f38.)

*note ProactorEventLoop: 1f14. specific limits:

   - *note create_datagram_endpoint(): 1f18. (UDP) is not supported

   - *note add_reader(): 1f25. and *note add_writer(): 1f27. are not
     supported

The resolution of the monotonic clock on Windows is usually around 15.6
msec.  The best resolution is 0.5 msec.  The resolution depends on the
hardware (availability of HPET(1)) and on the Windows configuration.
See *note asyncio delayed calls: 1f0b.

Changed in version 3.5: *note ProactorEventLoop: 1f14. now supports SSL.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/High_Precision_Event_Timer


File: python.info,  Node: Mac OS X,  Prev: Windows<7>,  Up: Platform support

5.18.5.28 Mac OS X
..................

Character devices like PTY are only well supported since Mavericks (Mac
OS 10.9).  They are not supported at all on Mac OS 10.5 and older.

On Mac OS 10.6, 10.7 and 10.8, the default event loop is *note
SelectorEventLoop: 1f24. which uses *note selectors.KqueueSelector:
1ee0.  *note selectors.KqueueSelector: 1ee0. does not support character
devices on these versions.  The *note SelectorEventLoop: 1f24. can be
used with *note SelectSelector: 1ee9. or *note PollSelector: 1ef1. to
support character devices on these versions of Mac OS X. Example:

     import asyncio
     import selectors

     selector = selectors.SelectSelector()
     loop = asyncio.SelectorEventLoop(selector)
     asyncio.set_event_loop(loop)


File: python.info,  Node: Event loop policies and the default policy,  Next: Event loop policy interface,  Prev: Platform support,  Up: Event loops

5.18.5.29 Event loop policies and the default policy
....................................................

Event loop management is abstracted with a `policy' pattern, to provide
maximal flexibility for custom platforms and frameworks.  Throughout the
execution of a process, a single global policy object manages the event
loops available to the process based on the calling context.  A policy
is an object implementing the *note AbstractEventLoopPolicy: 1f62.
interface.

For most users of *note asyncio: a, policies never have to be dealt with
explicitly, since the default global policy is sufficient.

The default policy defines context as the current thread, and manages an
event loop per thread that interacts with *note asyncio: a.  The
module-level functions *note get_event_loop(): 1f57. and *note
set_event_loop(): 1f58. provide convenient access to event loops managed
by the default policy.


File: python.info,  Node: Event loop policy interface,  Next: Access to the global loop policy,  Prev: Event loop policies and the default policy,  Up: Event loops

5.18.5.30 Event loop policy interface
.....................................

An event loop policy must implement the following interface:

 -- Class: asyncio.AbstractEventLoopPolicy

     Event loop policy.

      -- Method: get_event_loop ()

          Get the event loop for the current context.

          Returns an event loop object implementing the *note
          BaseEventLoop: 1efe. interface.

          Raises an exception in case no event loop has been set for the
          current context and the current policy does not specify to
          create one.  It must never return ‘None’.

      -- Method: set_event_loop (loop)

          Set the event loop for the current context to `loop'.

      -- Method: new_event_loop ()

          Create and return a new event loop object according to this
          policy’s rules.

          If there’s need to set this loop as the event loop for the
          current context, *note set_event_loop(): 1f58. must be called
          explicitly.


File: python.info,  Node: Access to the global loop policy,  Prev: Event loop policy interface,  Up: Event loops

5.18.5.31 Access to the global loop policy
..........................................

 -- Function: asyncio.get_event_loop_policy ()

     Get the current event loop policy.

 -- Function: asyncio.set_event_loop_policy (policy)

     Set the current event loop policy.  If `policy' is ‘None’, the
     default policy is restored.


File: python.info,  Node: Tasks and coroutines,  Next: Transports and protocols callback based API,  Prev: Event loops,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.32 Tasks and coroutines
..............................

* Menu:

* Coroutines: Coroutines<3>. 
* InvalidStateError:: 
* TimeoutError:: 
* Future:: 
* Task:: 
* Task functions:: 


File: python.info,  Node: Coroutines<3>,  Next: InvalidStateError,  Up: Tasks and coroutines

5.18.5.33 Coroutines
....................

Coroutines used with *note asyncio: a. may be implemented using the
*note async def: 1ce. statement, or by using *note generators: 5c0.  The
*note async def: 1ce. type of coroutine was added in Python 3.5, and is
recommended if there is no need to support older Python versions.

Generator-based coroutines should be decorated with *note
@asyncio.coroutine: e4e, although this is not strictly enforced.  The
decorator enables compatibility with *note async def: 1ce. coroutines,
and also serves as documentation.  Generator-based coroutines use the
‘yield from’ syntax introduced in PEP 380(1), instead of the original
‘yield’ syntax.

The word "coroutine", like the word "generator", is used for two
different (though related) concepts:

   - The function that defines a coroutine (a function definition using
     *note async def: 1ce. or decorated with ‘@asyncio.coroutine’).  If
     disambiguation is needed we will call this a `coroutine function'
     (*note iscoroutinefunction(): 1f6c. returns ‘True’).

   - The object obtained by calling a coroutine function.  This object
     represents a computation or an I/O operation (usually a
     combination) that will complete eventually.  If disambiguation is
     needed we will call it a `coroutine object' (*note iscoroutine():
     1f6d. returns ‘True’).

Things a coroutine can do:

   - ‘result = await future’ or ‘result = yield from future’ – suspends
     the coroutine until the future is done, then returns the future’s
     result, or raises an exception, which will be propagated.  (If the
     future is cancelled, it will raise a ‘CancelledError’ exception.)
     Note that tasks are futures, and everything said about futures also
     applies to tasks.

   - ‘result = await coroutine’ or ‘result = yield from coroutine’ –
     wait for another coroutine to produce a result (or raise an
     exception, which will be propagated).  The ‘coroutine’ expression
     must be a `call' to another coroutine.

   - ‘return expression’ – produce a result to the coroutine that is
     waiting for this one using *note await: 1cf. or ‘yield from’.

   - ‘raise exception’ – raise an exception in the coroutine that is
     waiting for this one using *note await: 1cf. or ‘yield from’.

Calling a coroutine does not start its code running – the coroutine
object returned by the call doesn’t do anything until you schedule its
execution.  There are two basic ways to start it running: call ‘await
coroutine’ or ‘yield from coroutine’ from another coroutine (assuming
the other coroutine is already running!), or schedule its execution
using the *note ensure_future(): 23c. function or the *note
BaseEventLoop.create_task(): 236. method.

Coroutines (and tasks) can only run when the event loop is running.

 -- Function: @asyncio.coroutine

     Decorator to mark generator-based coroutines.  This enables the
     generator use ‘yield from’ to call *note async def: 1ce.
     coroutines, and also enables the generator to be called by *note
     async def: 1ce. coroutines, for instance using an *note await: 1cf.
     expression.

     There is no need to decorate *note async def: 1ce. coroutines
     themselves.

     If the generator is not yielded from before it is destroyed, an
     error message is logged.  See *note Detect coroutines never
     scheduled: 1f6e.

     Note: In this documentation, some methods are documented as
     coroutines, even if they are plain Python functions returning a
     *note Future: e50.  This is intentional to have a freedom of
     tweaking the implementation of these functions in the future.  If
     such a function is needed to be used in a callback-style code, wrap
     its result with *note ensure_future(): 23c.

* Menu:

* Example; Hello World coroutine: Example Hello World coroutine. 
* Example; Coroutine displaying the current date: Example Coroutine displaying the current date. 
* Example; Chain coroutines: Example Chain coroutines. 

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0380


File: python.info,  Node: Example Hello World coroutine,  Next: Example Coroutine displaying the current date,  Up: Coroutines<3>

5.18.5.34 Example: Hello World coroutine
........................................

Example of coroutine displaying ‘"Hello World"’:

     import asyncio

     async def hello_world():
         print("Hello World!")

     loop = asyncio.get_event_loop()
     # Blocking call which returns when the hello_world() coroutine is done
     loop.run_until_complete(hello_world())
     loop.close()

See also
........

The *note Hello World with call_soon(): 1f4a. example uses the *note
BaseEventLoop.call_soon(): 1f08. method to schedule a callback.


File: python.info,  Node: Example Coroutine displaying the current date,  Next: Example Chain coroutines,  Prev: Example Hello World coroutine,  Up: Coroutines<3>

5.18.5.35 Example: Coroutine displaying the current date
........................................................

Example of coroutine displaying the current date every second during 5
seconds using the *note sleep(): 1f10. function:

     import asyncio
     import datetime

     async def display_date(loop):
         end_time = loop.time() + 5.0
         while True:
             print(datetime.datetime.now())
             if (loop.time() + 1.0) >= end_time:
                 break
             await asyncio.sleep(1)

     loop = asyncio.get_event_loop()
     # Blocking call which returns when the display_date() coroutine is done
     loop.run_until_complete(display_date(loop))
     loop.close()

The same coroutine implemented using a generator:

     @asyncio.coroutine
     def display_date(loop):
         end_time = loop.time() + 5.0
         while True:
             print(datetime.datetime.now())
             if (loop.time() + 1.0) >= end_time:
                 break
             yield from asyncio.sleep(1)

See also
........

The *note display the current date with call_later(): 1f4d. example uses
a callback with the *note BaseEventLoop.call_later(): 1f0d. method.


File: python.info,  Node: Example Chain coroutines,  Prev: Example Coroutine displaying the current date,  Up: Coroutines<3>

5.18.5.36 Example: Chain coroutines
...................................

Example chaining coroutines:

     import asyncio

     async def compute(x, y):
         print("Compute %s + %s ..." % (x, y))
         await asyncio.sleep(1.0)
         return x + y

     async def print_sum(x, y):
         result = await compute(x, y)
         print("%s + %s = %s" % (x, y, result))

     loop = asyncio.get_event_loop()
     loop.run_until_complete(print_sum(1, 2))
     loop.close()

‘compute()’ is chained to ‘print_sum()’: ‘print_sum()’ coroutine waits
until ‘compute()’ is completed before returning its result.

Sequence diagram of the example:

 [image src="tulip_coro.png" ]

The "Task" is created by the *note BaseEventLoop.run_until_complete():
242. method when it gets a coroutine object instead of a task.

The diagram shows the control flow, it does not describe exactly how
things work internally.  For example, the sleep coroutine creates an
internal future which uses *note BaseEventLoop.call_later(): 1f0d. to
wake up the task in 1 second.


File: python.info,  Node: InvalidStateError,  Next: TimeoutError,  Prev: Coroutines<3>,  Up: Tasks and coroutines

5.18.5.37 InvalidStateError
...........................

 -- Exception: asyncio.InvalidStateError

     The operation is not allowed in this state.


File: python.info,  Node: TimeoutError,  Next: Future,  Prev: InvalidStateError,  Up: Tasks and coroutines

5.18.5.38 TimeoutError
......................

 -- Exception: asyncio.TimeoutError

     The operation exceeded the given deadline.

     Note: This exception is different from the builtin *note
     TimeoutError: 5ba. exception!


File: python.info,  Node: Future,  Next: Task,  Prev: TimeoutError,  Up: Tasks and coroutines

5.18.5.39 Future
................

 -- Class: asyncio.Future (*, loop=None)

     This class is `almost' compatible with *note
     concurrent.futures.Future: 76f.

     Differences:

        - *note result(): 1f77. and *note exception(): 1f78. do not take
          a timeout argument and raise an exception when the future
          isn’t done yet.

        - Callbacks registered with *note add_done_callback(): 1f79. are
          always called via the event loop’s *note
          call_soon_threadsafe(): 1f0a.

        - This class is not compatible with the *note wait(): 1d9f. and
          *note as_completed(): 1d9e. functions in the *note
          concurrent.futures: 22. package.

     This class is *note not thread safe: 1eff.

      -- Method: cancel ()

          Cancel the future and schedule callbacks.

          If the future is already done or cancelled, return ‘False’.
          Otherwise, change the future’s state to cancelled, schedule
          the callbacks and return ‘True’.

      -- Method: cancelled ()

          Return ‘True’ if the future was cancelled.

      -- Method: done ()

          Return True if the future is done.

          Done means either that a result / exception are available, or
          that the future was cancelled.

      -- Method: result ()

          Return the result this future represents.

          If the future has been cancelled, raises ‘CancelledError’.  If
          the future’s result isn’t yet available, raises *note
          InvalidStateError: 1f73.  If the future is done and has an
          exception set, this exception is raised.

      -- Method: exception ()

          Return the exception that was set on this future.

          The exception (or ‘None’ if no exception was set) is returned
          only if the future is done.  If the future has been cancelled,
          raises ‘CancelledError’.  If the future isn’t done yet, raises
          *note InvalidStateError: 1f73.

      -- Method: add_done_callback (fn)

          Add a callback to be run when the future becomes done.

          The callback is called with a single argument - the future
          object.  If the future is already done when this is called,
          the callback is scheduled with *note call_soon(): 1f08.

          *note Use functools.partial to pass parameters to the
          callback: 1f06.  For example,
          ‘fut.add_done_callback(functools.partial(print, "Future:",
          flush=True))’ will call ‘print("Future:", fut, flush=True)’.

      -- Method: remove_done_callback (fn)

          Remove all instances of a callback from the "call when done"
          list.

          Returns the number of callbacks removed.

      -- Method: set_result (result)

          Mark the future done and set its result.

          If the future is already done when this method is called,
          raises *note InvalidStateError: 1f73.

      -- Method: set_exception (exception)

          Mark the future done and set an exception.

          If the future is already done when this method is called,
          raises *note InvalidStateError: 1f73.

* Menu:

* Example; Future with run_until_complete(): Example Future with run_until_complete. 
* Example; Future with run_forever(): Example Future with run_forever. 


File: python.info,  Node: Example Future with run_until_complete,  Next: Example Future with run_forever,  Up: Future

5.18.5.40 Example: Future with run_until_complete()
...................................................

Example combining a *note Future: e50. and a *note coroutine function:
1f03.:

     import asyncio

     @asyncio.coroutine
     def slow_operation(future):
         yield from asyncio.sleep(1)
         future.set_result('Future is done!')

     loop = asyncio.get_event_loop()
     future = asyncio.Future()
     asyncio.ensure_future(slow_operation(future))
     loop.run_until_complete(future)
     print(future.result())
     loop.close()

The coroutine function is responsible for the computation (which takes 1
second) and it stores the result into the future.  The *note
run_until_complete(): 242. method waits for the completion of the
future.

     Note: The *note run_until_complete(): 242. method uses internally
     the *note add_done_callback(): 1f79. method to be notified when the
     future is done.


File: python.info,  Node: Example Future with run_forever,  Prev: Example Future with run_until_complete,  Up: Future

5.18.5.41 Example: Future with run_forever()
............................................

The previous example can be written differently using the *note
Future.add_done_callback(): 1f79. method to describe explicitly the
control flow:

     import asyncio

     @asyncio.coroutine
     def slow_operation(future):
         yield from asyncio.sleep(1)
         future.set_result('Future is done!')

     def got_result(future):
         print(future.result())
         loop.stop()

     loop = asyncio.get_event_loop()
     future = asyncio.Future()
     asyncio.ensure_future(slow_operation(future))
     future.add_done_callback(got_result)
     try:
         loop.run_forever()
     finally:
         loop.close()

In this example, the future is used to link ‘slow_operation()’ to
‘got_result()’: when ‘slow_operation()’ is done, ‘got_result()’ is
called with the result.


File: python.info,  Node: Task,  Next: Task functions,  Prev: Future,  Up: Tasks and coroutines

5.18.5.42 Task
..............

 -- Class: asyncio.Task (coro, *, loop=None)

     Schedule the execution of a *note coroutine: 1f03.: wrap it in a
     future.  A task is a subclass of *note Future: e50.

     A task is responsible for executing a coroutine object in an event
     loop.  If the wrapped coroutine yields from a future, the task
     suspends the execution of the wrapped coroutine and waits for the
     completition of the future.  When the future is done, the execution
     of the wrapped coroutine restarts with the result or the exception
     of the future.

     Event loops use cooperative scheduling: an event loop only runs one
     task at a time.  Other tasks may run in parallel if other event
     loops are running in different threads.  While a task waits for the
     completion of a future, the event loop executes a new task.

     The cancellation of a task is different from the cancelation of a
     future.  Calling *note cancel(): 1f83. will throw a *note
     CancelledError: 1d9a. to the wrapped coroutine.  *note cancelled():
     1f7b. only returns ‘True’ if the wrapped coroutine did not catch
     the *note CancelledError: 1d9a. exception, or raised a *note
     CancelledError: 1d9a. exception.

     If a pending task is destroyed, the execution of its wrapped *note
     coroutine: 1f03. did not complete.  It is probably a bug and a
     warning is logged: see *note Pending task destroyed: 1f84.

     Don’t directly create *note Task: 237. instances: use the *note
     ensure_future(): 23c. function or the *note
     BaseEventLoop.create_task(): 236. method.

     This class is *note not thread safe: 1eff.

      -- Class Method: all_tasks (loop=None)

          Return a set of all tasks for an event loop.

          By default all tasks for the current event loop are returned.

      -- Class Method: current_task (loop=None)

          Return the currently running task in an event loop or ‘None’.

          By default the current task for the current event loop is
          returned.

          ‘None’ is returned when called not in the context of a *note
          Task: 237.

      -- Method: cancel ()

          Request that this task cancel itself.

          This arranges for a *note CancelledError: 1d9a. to be thrown
          into the wrapped coroutine on the next cycle through the event
          loop.  The coroutine then has a chance to clean up or even
          deny the request using try/except/finally.

          Unlike *note Future.cancel(): 1f7a, this does not guarantee
          that the task will be cancelled: the exception might be caught
          and acted upon, delaying cancellation of the task or
          preventing cancellation completely.  The task may also return
          a value or raise a different exception.

          Immediately after this method is called, *note cancelled():
          1f7b. will not return ‘True’ (unless the task was already
          cancelled).  A task will be marked as cancelled when the
          wrapped coroutine terminates with a *note CancelledError:
          1d9a. exception (even if *note cancel(): 1f83. was not
          called).

      -- Method: get_stack (*, limit=None)

          Return the list of stack frames for this task’s coroutine.

          If the coroutine is not done, this returns the stack where it
          is suspended.  If the coroutine has completed successfully or
          was cancelled, this returns an empty list.  If the coroutine
          was terminated by an exception, this returns the list of
          traceback frames.

          The frames are always ordered from oldest to newest.

          The optional limit gives the maximum number of frames to
          return; by default all available frames are returned.  Its
          meaning differs depending on whether a stack or a traceback is
          returned: the newest frames of a stack are returned, but the
          oldest frames of a traceback are returned.  (This matches the
          behavior of the traceback module.)

          For reasons beyond our control, only one stack frame is
          returned for a suspended coroutine.

      -- Method: print_stack (*, limit=None, file=None)

          Print the stack or traceback for this task’s coroutine.

          This produces output similar to that of the traceback module,
          for the frames retrieved by get_stack().  The limit argument
          is passed to get_stack().  The file argument is an I/O stream
          to which the output is written; by default output is written
          to sys.stderr.

* Menu:

* Example; Parallel execution of tasks: Example Parallel execution of tasks. 


File: python.info,  Node: Example Parallel execution of tasks,  Up: Task

5.18.5.43 Example: Parallel execution of tasks
..............................................

Example executing 3 tasks (A, B, C) in parallel:

     import asyncio

     @asyncio.coroutine
     def factorial(name, number):
         f = 1
         for i in range(2, number+1):
             print("Task %s: Compute factorial(%s)..." % (name, i))
             yield from asyncio.sleep(1)
             f *= i
         print("Task %s: factorial(%s) = %s" % (name, number, f))

     loop = asyncio.get_event_loop()
     tasks = [
         asyncio.ensure_future(factorial("A", 2)),
         asyncio.ensure_future(factorial("B", 3)),
         asyncio.ensure_future(factorial("C", 4))]
     loop.run_until_complete(asyncio.wait(tasks))
     loop.close()

Output:

     Task A: Compute factorial(2)...
     Task B: Compute factorial(2)...
     Task C: Compute factorial(2)...
     Task A: factorial(2) = 2
     Task B: Compute factorial(3)...
     Task C: Compute factorial(3)...
     Task B: factorial(3) = 6
     Task C: Compute factorial(4)...
     Task C: factorial(4) = 24

A task is automatically scheduled for execution when it is created.  The
event loop stops when all tasks are done.


File: python.info,  Node: Task functions,  Prev: Task,  Up: Tasks and coroutines

5.18.5.44 Task functions
........................

     Note: In the functions below, the optional `loop' argument allows
     explicitly setting the event loop object used by the underlying
     task or coroutine.  If it’s not provided, the default event loop is
     used.

 -- Function: asyncio.as_completed (fs, *, loop=None, timeout=None)

     Return an iterator whose values, when waited for, are *note Future:
     e50. instances.

     Raises *note asyncio.TimeoutError: 1f75. if the timeout occurs
     before all Futures are done.

     Example:

          for f in as_completed(fs):
              result = yield from f  # The 'yield from' may raise
              # Use result

          Note: The futures ‘f’ are not necessarily members of fs.

 -- Function: asyncio.ensure_future (coro_or_future, *, loop=None)

     Schedule the execution of a *note coroutine object: 1f03.: wrap it
     in a future.  Return a *note Task: 237. object.

     If the argument is a *note Future: e50, it is returned directly.

     New in version 3.4.4.

     Changed in version 3.5.1: The function accepts any *note awaitable:
     1ca. object.

     See also
     ........

     The *note BaseEventLoop.create_task(): 236. method.

 -- Function: asyncio.async (coro_or_future, *, loop=None)

     A deprecated alias to *note ensure_future(): 23c.

     Deprecated since version 3.4.4.

 -- Function: asyncio.gather (*coros_or_futures, loop=None,
          return_exceptions=False)

     Return a future aggregating results from the given coroutine
     objects or futures.

     All futures must share the same event loop.  If all the tasks are
     done successfully, the returned future’s result is the list of
     results (in the order of the original sequence, not necessarily the
     order of results arrival).  If `return_exceptions' is True,
     exceptions in the tasks are treated the same as successful results,
     and gathered in the result list; otherwise, the first raised
     exception will be immediately propagated to the returned future.

     Cancellation: if the outer Future is cancelled, all children (that
     have not completed yet) are also cancelled.  If any child is
     cancelled, this is treated as if it raised *note CancelledError:
     1d9a. – the outer Future is `not' cancelled in this case.  (This is
     to prevent the cancellation of one child to cause other children to
     be cancelled.)

 -- Function: asyncio.iscoroutine (obj)

     Return ‘True’ if `obj' is a *note coroutine object: 1f03, which may
     be based on a generator or an *note async def: 1ce. coroutine.

 -- Function: asyncio.iscoroutinefunction (func)

     Return ‘True’ if `func' is determined to be a *note coroutine
     function: 1f03, which may be a decorated generator function or an
     *note async def: 1ce. function.

 -- Function: asyncio.run_coroutine_threadsafe (coro, loop)

     Submit a *note coroutine object: 1f03. to a given event loop.

     Return a *note concurrent.futures.Future: 76f. to access the
     result.

     This function is meant to be called from a different thread than
     the one where the event loop is running.  Usage:

          # Create a coroutine
          coro = asyncio.sleep(1, result=3)
          # Submit the coroutine to a given loop
          future = asyncio.run_coroutine_threadsafe(coro, loop)
          # Wait for the result with an optional timeout argument
          assert future.result(timeout) == 3

     If an exception is raised in the coroutine, the returned future
     will be notified.  It can also be used to cancel the task in the
     event loop:

          try:
              result = future.result(timeout)
          except asyncio.TimeoutError:
              print('The coroutine took too long, cancelling the task...')
              future.cancel()
          except Exception as exc:
              print('The coroutine raised an exception: {!r}'.format(exc))
          else:
              print('The coroutine returned: {!r}'.format(result))

     See the *note concurrency and multithreading: 1eff. section of the
     documentation.

          Note: Unlike other functions from the module, *note
          run_coroutine_threadsafe(): 243. requires the `loop' argument
          to be passed explicitely.

     New in version 3.5.1.

 -- Function: coroutine asyncio.sleep (delay, result=None, *, loop=None)

     Create a *note coroutine: 1f03. that completes after a given time
     (in seconds).  If `result' is provided, it is produced to the
     caller when the coroutine completes.

     The resolution of the sleep depends on the *note granularity of the
     event loop: 1f0b.

     This function is a *note coroutine: 1f03.

 -- Function: asyncio.shield (arg, *, loop=None)

     Wait for a future, shielding it from cancellation.

     The statement:

          res = yield from shield(something())

     is exactly equivalent to the statement:

          res = yield from something()

     `except' that if the coroutine containing it is cancelled, the task
     running in ‘something()’ is not cancelled.  From the point of view
     of ‘something()’, the cancellation did not happen.  But its caller
     is still cancelled, so the yield-from expression still raises *note
     CancelledError: 1d9a.  Note: If ‘something()’ is cancelled by other
     means this will still cancel ‘shield()’.

     If you want to completely ignore cancellation (not recommended) you
     can combine ‘shield()’ with a try/except clause, as follows:

          try:
              res = yield from shield(something())
          except CancelledError:
              res = None

 -- Function: asyncio.timeout (timeout, *, loop=None)

     Return a context manager that cancels a block on `timeout'
     expiring:

          with timeout(1.5):
              yield from inner()

       1. If ‘inner()’ is executed faster than in ‘1.5’ seconds nothing
          happens.

       2. Otherwise ‘inner()’ is cancelled internally but *note
          asyncio.TimeoutError: 1f75. is raised outside of context
          manager scope.

     Passing ‘None’ as `timeout' argument disables the manager logic.

 -- Function: coroutine asyncio.wait (futures, *, loop=None,
          timeout=None, return_when=ALL_COMPLETED)

     Wait for the Futures and coroutine objects given by the sequence
     `futures' to complete.  Coroutines will be wrapped in Tasks.
     Returns two sets of *note Future: e50.: (done, pending).

     The sequence `futures' must not be empty.

     `timeout' can be used to control the maximum number of seconds to
     wait before returning.  `timeout' can be an int or float.  If
     `timeout' is not specified or ‘None’, there is no limit to the wait
     time.

     `return_when' indicates when this function should return.  It must
     be one of the following constants of the *note concurrent.futures:
     22. module:

     Constant                          Description
                                       
     -------------------------------------------------------------------------------
                                       
     ‘FIRST_COMPLETED’                 The function will return when any future
                                       finishes or is cancelled.
                                       
                                       
     ‘FIRST_EXCEPTION’                 The function will return when any future
                                       finishes by raising an exception.  If no
                                       future raises an exception then it is
                                       equivalent to ‘ALL_COMPLETED’.
                                       
                                       
     ‘ALL_COMPLETED’                   The function will return when all futures
                                       finish or are cancelled.
                                       

     This function is a *note coroutine: 1f03.

     Usage:

          done, pending = yield from asyncio.wait(fs)

          Note: This does not raise *note asyncio.TimeoutError: 1f75.!
          Futures that aren’t done when the timeout occurs are returned
          in the second set.

 -- Function: coroutine asyncio.wait_for (fut, timeout, *, loop=None)

     Wait for the single *note Future: e50. or *note coroutine object:
     1f03. to complete with timeout.  If `timeout' is ‘None’, block
     until the future completes.

     Coroutine will be wrapped in *note Task: 237.

     Returns result of the Future or coroutine.  When a timeout occurs,
     it cancels the task and raises *note asyncio.TimeoutError: 1f75.
     To avoid the task cancellation, wrap it in *note shield(): 1f8c.

     If the wait is cancelled, the future `fut' is also cancelled.

     This function is a *note coroutine: 1f03, usage:

          result = yield from asyncio.wait_for(fut, 60.0)

     Changed in version 3.4.3: If the wait is cancelled, the future
     `fut' is now also cancelled.


File: python.info,  Node: Transports and protocols callback based API,  Next: Streams coroutine based API,  Prev: Tasks and coroutines,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.45 Transports and protocols (callback based API)
.......................................................

* Menu:

* Transports:: 
* Protocols:: 
* Protocol examples:: 


File: python.info,  Node: Transports,  Next: Protocols,  Up: Transports and protocols callback based API

5.18.5.46 Transports
....................

Transports are classes provided by *note asyncio: a. in order to
abstract various kinds of communication channels.  You generally won’t
instantiate a transport yourself; instead, you will call a *note
BaseEventLoop: 1efe. method which will create the transport and try to
initiate the underlying communication channel, calling you back when it
succeeds.

Once the communication channel is established, a transport is always
paired with a *note protocol: 1ef9. instance.  The protocol can then
call the transport’s methods for various purposes.

*note asyncio: a. currently implements transports for TCP, UDP, SSL, and
subprocess pipes.  The methods available on a transport depend on the
transport’s kind.

The transport classes are *note not thread safe: 1eff.

* Menu:

* BaseTransport:: 
* ReadTransport:: 
* WriteTransport:: 
* DatagramTransport:: 
* BaseSubprocessTransport:: 


File: python.info,  Node: BaseTransport,  Next: ReadTransport,  Up: Transports

5.18.5.47 BaseTransport
.......................

 -- Class: asyncio.BaseTransport

     Base class for transports.

      -- Method: close (self)

          Close the transport.  If the transport has a buffer for
          outgoing data, buffered data will be flushed asynchronously.
          No more data will be received.  After all buffered data is
          flushed, the protocol’s ‘connection_lost()’ method will be
          called with *note None: 19d. as its argument.

      -- Method: is_closing (self)

          Return ‘True’ if the transport is closing or is closed.

          New in version 3.5.1.

      -- Method: get_extra_info (name, default=None)

          Return optional transport information.  `name' is a string
          representing the piece of transport-specific information to
          get, `default' is the value to return if the information
          doesn’t exist.

          This method allows transport implementations to easily expose
          channel-specific information.

             * socket:

                  - ‘'peername'’: the remote address to which the socket
                    is connected, result of *note
                    socket.socket.getpeername(): 1e58. (‘None’ on error)

                  - ‘'socket'’: *note socket.socket: 20a. instance

                  - ‘'sockname'’: the socket’s own address, result of
                    *note socket.socket.getsockname(): 1e59.

             * SSL socket:

                  - ‘'compression'’: the compression algorithm being
                    used as a string, or ‘None’ if the connection isn’t
                    compressed; result of *note
                    ssl.SSLSocket.compression(): 6cf.

                  - ‘'cipher'’: a three-value tuple containing the name
                    of the cipher being used, the version of the SSL
                    protocol that defines its use, and the number of
                    secret bits being used; result of *note
                    ssl.SSLSocket.cipher(): 1e96.

                  - ‘'peercert'’: peer certificate; result of *note
                    ssl.SSLSocket.getpeercert(): 4d1.

                  - ‘'sslcontext'’: *note ssl.SSLContext: 1c6. instance

                  - ‘'ssl_object'’: *note ssl.SSLObject: 31a. or *note
                    ssl.SSLSocket: 31b. instance

             * pipe:

                  - ‘'pipe'’: pipe object

             * subprocess:

                  - ‘'subprocess'’: *note subprocess.Popen: 7d8.
                    instance

     Changed in version 3.5.1: ‘'ssl_object'’ info was added to SSL
     sockets.


File: python.info,  Node: ReadTransport,  Next: WriteTransport,  Prev: BaseTransport,  Up: Transports

5.18.5.48 ReadTransport
.......................

 -- Class: asyncio.ReadTransport

     Interface for read-only transports.

      -- Method: pause_reading ()

          Pause the receiving end of the transport.  No data will be
          passed to the protocol’s ‘data_received()’ method until *note
          resume_reading(): 1f98. is called.

      -- Method: resume_reading ()

          Resume the receiving end.  The protocol’s ‘data_received()’
          method will be called once again if some data is available for
          reading.


File: python.info,  Node: WriteTransport,  Next: DatagramTransport,  Prev: ReadTransport,  Up: Transports

5.18.5.49 WriteTransport
........................

 -- Class: asyncio.WriteTransport

     Interface for write-only transports.

      -- Method: abort ()

          Close the transport immediately, without waiting for pending
          operations to complete.  Buffered data will be lost.  No more
          data will be received.  The protocol’s ‘connection_lost()’
          method will eventually be called with *note None: 19d. as its
          argument.

      -- Method: can_write_eof ()

          Return *note True: 9ff. if the transport supports *note
          write_eof(): 1f9c, *note False: 60d. if not.

      -- Method: get_write_buffer_size ()

          Return the current size of the output buffer used by the
          transport.

      -- Method: get_write_buffer_limits ()

          Get the `high'- and `low'-water limits for write flow control.
          Return a tuple ‘(low, high)’ where `low' and `high' are
          positive number of bytes.

          Use *note set_write_buffer_limits(): 1f9e. to set the limits.

          New in version 3.4.2.

      -- Method: set_write_buffer_limits (high=None, low=None)

          Set the `high'- and `low'-water limits for write flow control.

          These two values control when call the protocol’s
          ‘pause_writing()’ and ‘resume_writing()’ methods are called.
          If specified, the low-water limit must be less than or equal
          to the high-water limit.  Neither `high' nor `low' can be
          negative.

          The defaults are implementation-specific.  If only the
          high-water limit is given, the low-water limit defaults to an
          implementation-specific value less than or equal to the
          high-water limit.  Setting `high' to zero forces `low' to zero
          as well, and causes ‘pause_writing()’ to be called whenever
          the buffer becomes non-empty.  Setting `low' to zero causes
          ‘resume_writing()’ to be called only once the buffer is empty.
          Use of zero for either limit is generally sub-optimal as it
          reduces opportunities for doing I/O and computation
          concurrently.

          Use *note get_write_buffer_limits(): 23a. to get the limits.

      -- Method: write (data)

          Write some `data' bytes to the transport.

          This method does not block; it buffers the data and arranges
          for it to be sent out asynchronously.

      -- Method: writelines (list_of_data)

          Write a list (or any iterable) of data bytes to the transport.
          This is functionally equivalent to calling *note write():
          1f9f. on each element yielded by the iterable, but may be
          implemented more efficiently.

      -- Method: write_eof ()

          Close the write end of the transport after flushing buffered
          data.  Data may still be received.

          This method can raise *note NotImplementedError: 569. if the
          transport (e.g.  SSL) doesn’t support half-closes.


File: python.info,  Node: DatagramTransport,  Next: BaseSubprocessTransport,  Prev: WriteTransport,  Up: Transports

5.18.5.50 DatagramTransport
...........................

 -- Method: DatagramTransport.sendto (data, addr=None)

     Send the `data' bytes to the remote peer given by `addr' (a
     transport-dependent target address).  If `addr' is *note None: 19d,
     the data is sent to the target address given on transport creation.

     This method does not block; it buffers the data and arranges for it
     to be sent out asynchronously.

 -- Method: DatagramTransport.abort ()

     Close the transport immediately, without waiting for pending
     operations to complete.  Buffered data will be lost.  No more data
     will be received.  The protocol’s ‘connection_lost()’ method will
     eventually be called with *note None: 19d. as its argument.


File: python.info,  Node: BaseSubprocessTransport,  Prev: DatagramTransport,  Up: Transports

5.18.5.51 BaseSubprocessTransport
.................................

 -- Class: asyncio.BaseSubprocessTransport

      -- Method: get_pid ()

          Return the subprocess process id as an integer.

      -- Method: get_pipe_transport (fd)

          Return the transport for the communication pipe corresponding
          to the integer file descriptor `fd':

             * ‘0’: readable streaming transport of the standard input
               (`stdin'), or *note None: 19d. if the subprocess was not
               created with ‘stdin=PIPE’

             * ‘1’: writable streaming transport of the standard output
               (`stdout'), or *note None: 19d. if the subprocess was not
               created with ‘stdout=PIPE’

             * ‘2’: writable streaming transport of the standard error
               (`stderr'), or *note None: 19d. if the subprocess was not
               created with ‘stderr=PIPE’

             * other `fd': *note None: 19d.

      -- Method: get_returncode ()

          Return the subprocess returncode as an integer or *note None:
          19d. if it hasn’t returned, similarly to the *note
          subprocess.Popen.returncode: 1dce. attribute.

      -- Method: kill (self)

          Kill the subprocess, as in *note subprocess.Popen.kill():
          1dd2.

          On POSIX systems, the function sends SIGKILL to the
          subprocess.  On Windows, this method is an alias for *note
          terminate(): 1faa.

      -- Method: send_signal (signal)

          Send the `signal' number to the subprocess, as in *note
          subprocess.Popen.send_signal(): 1dd0.

      -- Method: terminate ()

          Ask the subprocess to stop, as in *note
          subprocess.Popen.terminate(): 1dd1.  This method is an alias
          for the *note close(): 1fac. method.

          On POSIX systems, this method sends SIGTERM to the subprocess.
          On Windows, the Windows API function TerminateProcess() is
          called to stop the subprocess.

      -- Method: close ()

          Ask the subprocess to stop by calling the *note terminate():
          1faa. method if the subprocess hasn’t returned yet, and close
          transports of all pipes (`stdin', `stdout' and `stderr').


File: python.info,  Node: Protocols,  Next: Protocol examples,  Prev: Transports,  Up: Transports and protocols callback based API

5.18.5.52 Protocols
...................

*note asyncio: a. provides base classes that you can subclass to
implement your network protocols.  Those classes are used in conjunction
with *note transports: 1ef8. (see below): the protocol parses incoming
data and asks for the writing of outgoing data, while the transport is
responsible for the actual I/O and buffering.

When subclassing a protocol class, it is recommended you override
certain methods.  Those methods are callbacks: they will be called by
the transport on certain events (for example when some data is
received); you shouldn’t call them yourself, unless you are implementing
a transport.

     Note: All callbacks have default implementations, which are empty.
     Therefore, you only need to implement the callbacks for the events
     in which you are interested.

* Menu:

* Protocol classes:: 
* Connection callbacks:: 
* Streaming protocols:: 
* Datagram protocols:: 
* Flow control callbacks:: 
* Coroutines and protocols:: 


File: python.info,  Node: Protocol classes,  Next: Connection callbacks,  Up: Protocols

5.18.5.53 Protocol classes
..........................

 -- Class: asyncio.Protocol

     The base class for implementing streaming protocols (for use with
     e.g.  TCP and SSL transports).

 -- Class: asyncio.DatagramProtocol

     The base class for implementing datagram protocols (for use with
     e.g.  UDP transports).

 -- Class: asyncio.SubprocessProtocol

     The base class for implementing protocols communicating with child
     processes (through a set of unidirectional pipes).


File: python.info,  Node: Connection callbacks,  Next: Streaming protocols,  Prev: Protocol classes,  Up: Protocols

5.18.5.54 Connection callbacks
..............................

These callbacks may be called on *note Protocol: 1f33, *note
DatagramProtocol: 1faf. and *note SubprocessProtocol: 1fb0. instances:

 -- Method: BaseProtocol.connection_made (transport)

     Called when a connection is made.

     The `transport' argument is the transport representing the
     connection.  You are responsible for storing it somewhere (e.g.  as
     an attribute) if you need to.

 -- Method: BaseProtocol.connection_lost (exc)

     Called when the connection is lost or closed.

     The argument is either an exception object or *note None: 19d.  The
     latter means a regular EOF is received, or the connection was
     aborted or closed by this side of the connection.

*note connection_made(): 1fb2. and *note connection_lost(): 1fb3. are
called exactly once per successful connection.  All other callbacks will
be called between those two methods, which allows for easier resource
management in your protocol implementation.

The following callbacks may be called only on *note SubprocessProtocol:
1fb0. instances:

 -- Method: SubprocessProtocol.pipe_data_received (fd, data)

     Called when the child process writes data into its stdout or stderr
     pipe.  `fd' is the integer file descriptor of the pipe.  `data' is
     a non-empty bytes object containing the data.

 -- Method: SubprocessProtocol.pipe_connection_lost (fd, exc)

     Called when one of the pipes communicating with the child process
     is closed.  `fd' is the integer file descriptor that was closed.

 -- Method: SubprocessProtocol.process_exited ()

     Called when the child process has exited.


File: python.info,  Node: Streaming protocols,  Next: Datagram protocols,  Prev: Connection callbacks,  Up: Protocols

5.18.5.55 Streaming protocols
.............................

The following callbacks are called on *note Protocol: 1f33. instances:

 -- Method: Protocol.data_received (data)

     Called when some data is received.  `data' is a non-empty bytes
     object containing the incoming data.

          Note: Whether the data is buffered, chunked or reassembled
          depends on the transport.  In general, you shouldn’t rely on
          specific semantics and instead make your parsing generic and
          flexible enough.  However, data is always received in the
          correct order.

 -- Method: Protocol.eof_received ()

     Calls when the other end signals it won’t send any more data (for
     example by calling ‘write_eof()’, if the other end also uses
     asyncio).

     This method may return a false value (including None), in which
     case the transport will close itself.  Conversely, if this method
     returns a true value, closing the transport is up to the protocol.
     Since the default implementation returns None, it implicitly closes
     the connection.

          Note: Some transports such as SSL don’t support half-closed
          connections, in which case returning true from this method
          will not prevent closing the connection.

‘data_received()’ can be called an arbitrary number of times during a
connection.  However, ‘eof_received()’ is called at most once and, if
called, ‘data_received()’ won’t be called after it.

State machine:

     start -> *note connection_made(): 1fb2. [-> *note data_received():
     1fb8. *] [-> *note eof_received(): 1fb9. ?]  -> *note
     connection_lost(): 1fb3. -> end


File: python.info,  Node: Datagram protocols,  Next: Flow control callbacks,  Prev: Streaming protocols,  Up: Protocols

5.18.5.56 Datagram protocols
............................

The following callbacks are called on *note DatagramProtocol: 1faf.
instances.

 -- Method: DatagramProtocol.datagram_received (data, addr)

     Called when a datagram is received.  `data' is a bytes object
     containing the incoming data.  `addr' is the address of the peer
     sending the data; the exact format depends on the transport.

 -- Method: DatagramProtocol.error_received (exc)

     Called when a previous send or receive operation raises an *note
     OSError: 4b6.  `exc' is the *note OSError: 4b6. instance.

     This method is called in rare conditions, when the transport (e.g.
     UDP) detects that a datagram couldn’t be delivered to its
     recipient.  In many conditions though, undeliverable datagrams will
     be silently dropped.


File: python.info,  Node: Flow control callbacks,  Next: Coroutines and protocols,  Prev: Datagram protocols,  Up: Protocols

5.18.5.57 Flow control callbacks
................................

These callbacks may be called on *note Protocol: 1f33, *note
DatagramProtocol: 1faf. and *note SubprocessProtocol: 1fb0. instances:

 -- Method: BaseProtocol.pause_writing ()

     Called when the transport’s buffer goes over the high-water mark.

 -- Method: BaseProtocol.resume_writing ()

     Called when the transport’s buffer drains below the low-water mark.

‘pause_writing()’ and ‘resume_writing()’ calls are paired –
‘pause_writing()’ is called once when the buffer goes strictly over the
high-water mark (even if subsequent writes increases the buffer size
even more), and eventually ‘resume_writing()’ is called once when the
buffer size reaches the low-water mark.

     Note: If the buffer size equals the high-water mark,
     ‘pause_writing()’ is not called – it must go strictly over.
     Conversely, ‘resume_writing()’ is called when the buffer size is
     equal or lower than the low-water mark.  These end conditions are
     important to ensure that things go as expected when either mark is
     zero.

     Note: On BSD systems (OS X, FreeBSD, etc.)  flow control is not
     supported for *note DatagramProtocol: 1faf, because send failures
     caused by writing too many packets cannot be detected easily.  The
     socket always appears ’ready’ and excess packets are dropped; an
     *note OSError: 4b6. with errno set to *note errno.ENOBUFS: 1bfc.
     may or may not be raised; if it is raised, it will be reported to
     *note DatagramProtocol.error_received(): 1fbc. but otherwise
     ignored.


File: python.info,  Node: Coroutines and protocols,  Prev: Flow control callbacks,  Up: Protocols

5.18.5.58 Coroutines and protocols
..................................

Coroutines can be scheduled in a protocol method using *note
ensure_future(): 23c, but there is no guarantee made about the execution
order.  Protocols are not aware of coroutines created in protocol
methods and so will not wait for them.

To have a reliable execution order, use *note stream objects: 1fc1. in a
coroutine with ‘yield from’.  For example, the *note
StreamWriter.drain(): 1fc2. coroutine can be used to wait until the
write buffer is flushed.


File: python.info,  Node: Protocol examples,  Prev: Protocols,  Up: Transports and protocols callback based API

5.18.5.59 Protocol examples
...........................

* Menu:

* TCP echo client protocol:: 
* TCP echo server protocol:: 
* UDP echo client protocol:: 
* UDP echo server protocol:: 
* Register an open socket to wait for data using a protocol:: 


File: python.info,  Node: TCP echo client protocol,  Next: TCP echo server protocol,  Up: Protocol examples

5.18.5.60 TCP echo client protocol
..................................

TCP echo client using the *note BaseEventLoop.create_connection(): 1f13.
method, send data and wait until the connection is closed:

     import asyncio

     class EchoClientProtocol(asyncio.Protocol):
         def __init__(self, message, loop):
             self.message = message
             self.loop = loop

         def connection_made(self, transport):
             transport.write(self.message.encode())
             print('Data sent: {!r}'.format(self.message))

         def data_received(self, data):
             print('Data received: {!r}'.format(data.decode()))

         def connection_lost(self, exc):
             print('The server closed the connection')
             print('Stop the event loop')
             self.loop.stop()

     loop = asyncio.get_event_loop()
     message = 'Hello World!'
     coro = loop.create_connection(lambda: EchoClientProtocol(message, loop),
                                   '127.0.0.1', 8888)
     loop.run_until_complete(coro)
     loop.run_forever()
     loop.close()

The event loop is running twice.  The *note run_until_complete(): 242.
method is preferred in this short example to raise an exception if the
server is not listening, instead of having to write a short coroutine to
handle the exception and stop the running loop.  At *note
run_until_complete(): 242. exit, the loop is no longer running, so there
is no need to stop the loop in case of an error.

See also
........

The *note TCP echo client using streams: 1fc6. example uses the *note
asyncio.open_connection(): 1f15. function.


File: python.info,  Node: TCP echo server protocol,  Next: UDP echo client protocol,  Prev: TCP echo client protocol,  Up: Protocol examples

5.18.5.61 TCP echo server protocol
..................................

TCP echo server using the *note BaseEventLoop.create_server(): 245.
method, send back received data and close the connection:

     import asyncio

     class EchoServerClientProtocol(asyncio.Protocol):
         def connection_made(self, transport):
             peername = transport.get_extra_info('peername')
             print('Connection from {}'.format(peername))
             self.transport = transport

         def data_received(self, data):
             message = data.decode()
             print('Data received: {!r}'.format(message))

             print('Send: {!r}'.format(message))
             self.transport.write(data)

             print('Close the client socket')
             self.transport.close()

     loop = asyncio.get_event_loop()
     # Each client connection will create a new protocol instance
     coro = loop.create_server(EchoServerClientProtocol, '127.0.0.1', 8888)
     server = loop.run_until_complete(coro)

     # Serve requests until Ctrl+C is pressed
     print('Serving on {}'.format(server.sockets[0].getsockname()))
     try:
         loop.run_forever()
     except KeyboardInterrupt:
         pass

     # Close the server
     server.close()
     loop.run_until_complete(server.wait_closed())
     loop.close()

‘Transport.close()’ can be called immediately after *note
WriteTransport.write(): 1f9f. even if data are not sent yet on the
socket: both methods are asynchronous.  ‘yield from’ is not needed
because these transport methods are not coroutines.

See also
........

The *note TCP echo server using streams: 1fc9. example uses the *note
asyncio.start_server(): 1f21. function.


File: python.info,  Node: UDP echo client protocol,  Next: UDP echo server protocol,  Prev: TCP echo server protocol,  Up: Protocol examples

5.18.5.62 UDP echo client protocol
..................................

UDP echo client using the *note
BaseEventLoop.create_datagram_endpoint(): 1f18. method, send data and
close the transport when we received the answer:

     import asyncio

     class EchoClientProtocol:
         def __init__(self, message, loop):
             self.message = message
             self.loop = loop
             self.transport = None

         def connection_made(self, transport):
             self.transport = transport
             print('Send:', self.message)
             self.transport.sendto(self.message.encode())

         def datagram_received(self, data, addr):
             print("Received:", data.decode())

             print("Close the socket")
             self.transport.close()

         def error_received(self, exc):
             print('Error received:', exc)

         def connection_lost(self, exc):
             print("Socket closed, stop the event loop")
             loop = asyncio.get_event_loop()
             loop.stop()

     loop = asyncio.get_event_loop()
     message = "Hello World!"
     connect = loop.create_datagram_endpoint(
         lambda: EchoClientProtocol(message, loop),
         remote_addr=('127.0.0.1', 9999))
     transport, protocol = loop.run_until_complete(connect)
     loop.run_forever()
     transport.close()
     loop.close()


File: python.info,  Node: UDP echo server protocol,  Next: Register an open socket to wait for data using a protocol,  Prev: UDP echo client protocol,  Up: Protocol examples

5.18.5.63 UDP echo server protocol
..................................

UDP echo server using the *note
BaseEventLoop.create_datagram_endpoint(): 1f18. method, send back
received data:

     import asyncio

     class EchoServerProtocol:
         def connection_made(self, transport):
             self.transport = transport

         def datagram_received(self, data, addr):
             message = data.decode()
             print('Received %r from %s' % (message, addr))
             print('Send %r to %s' % (message, addr))
             self.transport.sendto(data, addr)

     loop = asyncio.get_event_loop()
     print("Starting UDP server")
     # One protocol instance will be created to serve all client requests
     listen = loop.create_datagram_endpoint(
         EchoServerProtocol, local_addr=('127.0.0.1', 9999))
     transport, protocol = loop.run_until_complete(listen)

     try:
         loop.run_forever()
     except KeyboardInterrupt:
         pass

     transport.close()
     loop.close()


File: python.info,  Node: Register an open socket to wait for data using a protocol,  Prev: UDP echo server protocol,  Up: Protocol examples

5.18.5.64 Register an open socket to wait for data using a protocol
...................................................................

Wait until a socket receives data using the *note
BaseEventLoop.create_connection(): 1f13. method with a protocol, and
then close the event loop

     import asyncio
     try:
         from socket import socketpair
     except ImportError:
         from asyncio.windows_utils import socketpair

     # Create a pair of connected sockets
     rsock, wsock = socketpair()
     loop = asyncio.get_event_loop()

     class MyProtocol(asyncio.Protocol):
         transport = None

         def connection_made(self, transport):
             self.transport = transport

         def data_received(self, data):
             print("Received:", data.decode())

             # We are done: close the transport (it will call connection_lost())
             self.transport.close()

         def connection_lost(self, exc):
             # The socket has been closed, stop the event loop
             loop.stop()

     # Register the socket to wait for data
     connect_coro = loop.create_connection(MyProtocol, sock=rsock)
     transport, protocol = loop.run_until_complete(connect_coro)

     # Simulate the reception of data from the network
     loop.call_soon(wsock.send, 'abc'.encode())

     # Run the event loop
     loop.run_forever()

     # We are done, close sockets and the event loop
     rsock.close()
     wsock.close()
     loop.close()

See also
........

The *note watch a file descriptor for read events: 1f29. example uses
the low-level *note BaseEventLoop.add_reader(): 1f25. method to register
the file descriptor of a socket.

The *note register an open socket to wait for data using streams: 1f51.
example uses high-level streams created by the *note open_connection():
1f15. function in a coroutine.


File: python.info,  Node: Streams coroutine based API,  Next: Subprocess,  Prev: Transports and protocols callback based API,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.65 Streams (coroutine based API)
.......................................

* Menu:

* Stream functions:: 
* StreamReader:: 
* StreamWriter:: 
* StreamReaderProtocol:: 
* IncompleteReadError:: 
* Stream examples:: 


File: python.info,  Node: Stream functions,  Next: StreamReader,  Up: Streams coroutine based API

5.18.5.66 Stream functions
..........................

     Note: The top-level functions in this module are meant as
     convenience wrappers only; there’s really nothing special there,
     and if they don’t do exactly what you want, feel free to copy their
     code.

 -- Function: coroutine asyncio.open_connection (host=None, port=None,
          *, loop=None, limit=None, **kwds)

     A wrapper for *note create_connection(): 1f13. returning a (reader,
     writer) pair.

     The reader returned is a *note StreamReader: 1f16. instance; the
     writer is a *note StreamWriter: 1f17. instance.

     The arguments are all the usual arguments to *note
     BaseEventLoop.create_connection(): 1f13. except `protocol_factory';
     most common are positional host and port, with various optional
     keyword arguments following.

     Additional optional keyword arguments are `loop' (to set the event
     loop instance to use) and `limit' (to set the buffer limit passed
     to the *note StreamReader: 1f16.).

     This function is a *note coroutine: 1f03.

 -- Function: coroutine asyncio.start_server (client_connected_cb,
          host=None, port=None, *, loop=None, limit=None, **kwds)

     Start a socket server, with a callback for each client connected.
     The return value is the same as *note create_server(): 245.

     The `client_connected_cb' parameter is called with two parameters:
     `client_reader', `client_writer'.  `client_reader' is a *note
     StreamReader: 1f16. object, while `client_writer' is a *note
     StreamWriter: 1f17. object.  The `client_connected_cb' parameter
     can either be a plain callback function or a *note coroutine
     function: 1f03.; if it is a coroutine function, it will be
     automatically converted into a *note Task: 237.

     The rest of the arguments are all the usual arguments to *note
     create_server(): 245. except `protocol_factory'; most common are
     positional `host' and `port', with various optional keyword
     arguments following.

     Additional optional keyword arguments are `loop' (to set the event
     loop instance to use) and `limit' (to set the buffer limit passed
     to the *note StreamReader: 1f16.).

     This function is a *note coroutine: 1f03.

 -- Function: coroutine asyncio.open_unix_connection (path=None, *,
          loop=None, limit=None, **kwds)

     A wrapper for *note create_unix_connection(): 1f1c. returning a
     (reader, writer) pair.

     See *note open_connection(): 1f15. for information about return
     value and other details.

     This function is a *note coroutine: 1f03.

     Availability: UNIX.

 -- Function: coroutine asyncio.start_unix_server (client_connected_cb,
          path=None, *, loop=None, limit=None, **kwds)

     Start a UNIX Domain Socket server, with a callback for each client
     connected.

     See *note start_server(): 1f21. for information about return value
     and other details.

     This function is a *note coroutine: 1f03.

     Availability: UNIX.


File: python.info,  Node: StreamReader,  Next: StreamWriter,  Prev: Stream functions,  Up: Streams coroutine based API

5.18.5.67 StreamReader
......................

 -- Class: asyncio.StreamReader (limit=None, loop=None)

     This class is *note not thread safe: 1eff.

      -- Method: exception ()

          Get the exception.

      -- Method: feed_eof ()

          Acknowledge the EOF.

      -- Method: feed_data (data)

          Feed `data' bytes in the internal buffer.  Any operations
          waiting for the data will be resumed.

      -- Method: set_exception (exc)

          Set the exception.

      -- Method: set_transport (transport)

          Set the transport.

      -- Method: coroutine read (n=-1)

          Read up to `n' bytes.  If `n' is not provided, or set to ‘-1’,
          read until EOF and return all read bytes.

          If the EOF was received and the internal buffer is empty,
          return an empty ‘bytes’ object.

          This method is a *note coroutine: 1f03.

      -- Method: coroutine readline ()

          Read one line, where "line" is a sequence of bytes ending with
          ‘\n’.

          If EOF is received, and ‘\n’ was not found, the method will
          return the partial read bytes.

          If the EOF was received and the internal buffer is empty,
          return an empty ‘bytes’ object.

          This method is a *note coroutine: 1f03.

      -- Method: coroutine readexactly (n)

          Read exactly `n' bytes.  Raise an *note IncompleteReadError:
          1fdb. if the end of the stream is reached before `n' can be
          read, the *note IncompleteReadError.partial: 1fdc. attribute
          of the exception contains the partial read bytes.

          This method is a *note coroutine: 1f03.

      -- Method: at_eof ()

          Return ‘True’ if the buffer is empty and *note feed_eof():
          1fd4. was called.


File: python.info,  Node: StreamWriter,  Next: StreamReaderProtocol,  Prev: StreamReader,  Up: Streams coroutine based API

5.18.5.68 StreamWriter
......................

 -- Class: asyncio.StreamWriter (transport, protocol, reader, loop)

     Wraps a Transport.

     This exposes *note write(): 1fdf, *note writelines(): 1fe0, *note
     can_write_eof(): 1fe1, *note write_eof(): 1fe2, *note
     get_extra_info(): 1fe3. and *note close(): 1fe4.  It adds *note
     drain(): 1fc2. which returns an optional *note Future: e50. on
     which you can wait for flow control.  It also adds a transport
     attribute which references the ‘Transport’ directly.

     This class is *note not thread safe: 1eff.

      -- Attribute: transport

          Transport.

      -- Method: can_write_eof ()

          Return *note True: 9ff. if the transport supports *note
          write_eof(): 1fe2, *note False: 60d. if not.  See *note
          WriteTransport.can_write_eof(): 1f9b.

      -- Method: close ()

          Close the transport: see *note BaseTransport.close(): 1f94.

      -- Method: coroutine drain ()

          Let the write buffer of the underlying transport a chance to
          be flushed.

          The intended use is to write:

               w.write(data)
               yield from w.drain()

          When the size of the transport buffer reaches the high-water
          limit (the protocol is paused), block until the size of the
          buffer is drained down to the low-water limit and the protocol
          is resumed.  When there is nothing to wait for, the yield-from
          continues immediately.

          Yielding from *note drain(): 1fc2. gives the opportunity for
          the loop to schedule the write operation and flush the buffer.
          It should especially be used when a possibly large amount of
          data is written to the transport, and the coroutine does not
          yield-from between calls to *note write(): 1fdf.

          This method is a *note coroutine: 1f03.

      -- Method: get_extra_info (name, default=None)

          Return optional transport information: see *note
          BaseTransport.get_extra_info(): 1f95.

      -- Method: write (data)

          Write some `data' bytes to the transport: see *note
          WriteTransport.write(): 1f9f.

      -- Method: writelines (data)

          Write a list (or any iterable) of data bytes to the transport:
          see *note WriteTransport.writelines(): 1fa0.

      -- Method: write_eof ()

          Close the write end of the transport after flushing buffered
          data: see *note WriteTransport.write_eof(): 1f9c.


File: python.info,  Node: StreamReaderProtocol,  Next: IncompleteReadError,  Prev: StreamWriter,  Up: Streams coroutine based API

5.18.5.69 StreamReaderProtocol
..............................

 -- Class: asyncio.StreamReaderProtocol (stream_reader,
          client_connected_cb=None, loop=None)

     Trivial helper class to adapt between *note Protocol: 1f33. and
     *note StreamReader: 1f16.  Subclass of *note Protocol: 1f33.

     `stream_reader' is a *note StreamReader: 1f16. instance,
     `client_connected_cb' is an optional function called with
     (stream_reader, stream_writer) when a connection is made, `loop' is
     the event loop instance to use.

     (This is a helper class instead of making *note StreamReader: 1f16.
     itself a *note Protocol: 1f33. subclass, because the *note
     StreamReader: 1f16. has other potential uses, and to prevent the
     user of the *note StreamReader: 1f16. from accidentally calling
     inappropriate methods of the protocol.)


File: python.info,  Node: IncompleteReadError,  Next: Stream examples,  Prev: StreamReaderProtocol,  Up: Streams coroutine based API

5.18.5.70 IncompleteReadError
.............................

 -- Exception: asyncio.IncompleteReadError

          Incomplete read error, subclass of *note EOFError: 8d8.

      -- Attribute: expected

          Total number of expected bytes (*note int: 227.).

      -- Attribute: partial

          Read bytes string before the end of stream was reached (*note
          bytes: 1db.).


File: python.info,  Node: Stream examples,  Prev: IncompleteReadError,  Up: Streams coroutine based API

5.18.5.71 Stream examples
.........................

* Menu:

* TCP echo client using streams:: 
* TCP echo server using streams:: 
* Get HTTP headers:: 
* Register an open socket to wait for data using streams:: 


File: python.info,  Node: TCP echo client using streams,  Next: TCP echo server using streams,  Up: Stream examples

5.18.5.72 TCP echo client using streams
.......................................

TCP echo client using the *note asyncio.open_connection(): 1f15.
function:

     import asyncio

     @asyncio.coroutine
     def tcp_echo_client(message, loop):
         reader, writer = yield from asyncio.open_connection('127.0.0.1', 8888,
                                                             loop=loop)

         print('Send: %r' % message)
         writer.write(message.encode())

         data = yield from reader.read(100)
         print('Received: %r' % data.decode())

         print('Close the socket')
         writer.close()

     message = 'Hello World!'
     loop = asyncio.get_event_loop()
     loop.run_until_complete(tcp_echo_client(message, loop))
     loop.close()

See also
........

The *note TCP echo client protocol: 1fc4. example uses the *note
BaseEventLoop.create_connection(): 1f13. method.


File: python.info,  Node: TCP echo server using streams,  Next: Get HTTP headers,  Prev: TCP echo client using streams,  Up: Stream examples

5.18.5.73 TCP echo server using streams
.......................................

TCP echo server using the *note asyncio.start_server(): 1f21. function:

     import asyncio

     @asyncio.coroutine
     def handle_echo(reader, writer):
         data = yield from reader.read(100)
         message = data.decode()
         addr = writer.get_extra_info('peername')
         print("Received %r from %r" % (message, addr))

         print("Send: %r" % message)
         writer.write(data)
         yield from writer.drain()

         print("Close the client socket")
         writer.close()

     loop = asyncio.get_event_loop()
     coro = asyncio.start_server(handle_echo, '127.0.0.1', 8888, loop=loop)
     server = loop.run_until_complete(coro)

     # Serve requests until Ctrl+C is pressed
     print('Serving on {}'.format(server.sockets[0].getsockname()))
     try:
         loop.run_forever()
     except KeyboardInterrupt:
         pass

     # Close the server
     server.close()
     loop.run_until_complete(server.wait_closed())
     loop.close()

See also
........

The *note TCP echo server protocol: 1fc7. example uses the *note
BaseEventLoop.create_server(): 245. method.


File: python.info,  Node: Get HTTP headers,  Next: Register an open socket to wait for data using streams,  Prev: TCP echo server using streams,  Up: Stream examples

5.18.5.74 Get HTTP headers
..........................

Simple example querying HTTP headers of the URL passed on the command
line:

     import asyncio
     import urllib.parse
     import sys

     @asyncio.coroutine
     def print_http_headers(url):
         url = urllib.parse.urlsplit(url)
         if url.scheme == 'https':
             connect = asyncio.open_connection(url.hostname, 443, ssl=True)
         else:
             connect = asyncio.open_connection(url.hostname, 80)
         reader, writer = yield from connect
         query = ('HEAD {path} HTTP/1.0\r\n'
                  'Host: {hostname}\r\n'
                  '\r\n').format(path=url.path or '/', hostname=url.hostname)
         writer.write(query.encode('latin-1'))
         while True:
             line = yield from reader.readline()
             if not line:
                 break
             line = line.decode('latin1').rstrip()
             if line:
                 print('HTTP header> %s' % line)

         # Ignore the body, close the socket
         writer.close()

     url = sys.argv[1]
     loop = asyncio.get_event_loop()
     task = asyncio.ensure_future(print_http_headers(url))
     loop.run_until_complete(task)
     loop.close()

Usage:

     python example.py http://example.com/path/page.html

or with HTTPS:

     python example.py https://example.com/path/page.html


File: python.info,  Node: Register an open socket to wait for data using streams,  Prev: Get HTTP headers,  Up: Stream examples

5.18.5.75 Register an open socket to wait for data using streams
................................................................

Coroutine waiting until a socket receives data using the *note
open_connection(): 1f15. function:

     import asyncio
     try:
         from socket import socketpair
     except ImportError:
         from asyncio.windows_utils import socketpair

     @asyncio.coroutine
     def wait_for_data(loop):
         # Create a pair of connected sockets
         rsock, wsock = socketpair()

         # Register the open socket to wait for data
         reader, writer = yield from asyncio.open_connection(sock=rsock, loop=loop)

         # Simulate the reception of data from the network
         loop.call_soon(wsock.send, 'abc'.encode())

         # Wait for data
         data = yield from reader.read(100)

         # Got data, we are done: close the socket
         print("Received:", data.decode())
         writer.close()

         # Close the second socket
         wsock.close()

     loop = asyncio.get_event_loop()
     loop.run_until_complete(wait_for_data(loop))
     loop.close()

See also
........

The *note register an open socket to wait for data using a protocol:
1f50. example uses a low-level protocol created by the *note
BaseEventLoop.create_connection(): 1f13. method.

The *note watch a file descriptor for read events: 1f29. example uses
the low-level *note BaseEventLoop.add_reader(): 1f25. method to register
the file descriptor of a socket.


File: python.info,  Node: Subprocess,  Next: Synchronization primitives<2>,  Prev: Streams coroutine based API,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.76 Subprocess
....................

* Menu:

* Windows event loop:: 
* Create a subprocess; high-level API using Process: Create a subprocess high-level API using Process. 
* Create a subprocess; low-level API using subprocess.Popen: Create a subprocess low-level API using subprocess Popen. 
* Constants: Constants<8>. 
* Process:: 
* Subprocess and threads:: 
* Subprocess examples:: 


File: python.info,  Node: Windows event loop,  Next: Create a subprocess high-level API using Process,  Up: Subprocess

5.18.5.77 Windows event loop
............................

On Windows, the default event loop is *note SelectorEventLoop: 1f24.
which does not support subprocesses.  *note ProactorEventLoop: 1f14.
should be used instead.  Example to use it on Windows:

     import asyncio, sys

     if sys.platform == 'win32':
         loop = asyncio.ProactorEventLoop()
         asyncio.set_event_loop(loop)

See also
........

*note Available event loops: 1f5a. and *note Platform support: 1f5c.


File: python.info,  Node: Create a subprocess high-level API using Process,  Next: Create a subprocess low-level API using subprocess Popen,  Prev: Windows event loop,  Up: Subprocess

5.18.5.78 Create a subprocess: high-level API using Process
...........................................................

 -- Function: coroutine asyncio.create_subprocess_exec (*args,
          stdin=None, stdout=None, stderr=None, loop=None, limit=None,
          **kwds)

     Create a subprocess.

     The `limit' parameter sets the buffer limit passed to the *note
     StreamReader: 1f16.  See *note BaseEventLoop.subprocess_exec():
     1f37. for other parameters.

     Return a *note Process: 1ff3. instance.

     This function is a *note coroutine: 1f03.

 -- Function: coroutine asyncio.create_subprocess_shell (cmd,
          stdin=None, stdout=None, stderr=None, loop=None, limit=None,
          **kwds)

     Run the shell command `cmd'.

     The `limit' parameter sets the buffer limit passed to the *note
     StreamReader: 1f16.  See *note BaseEventLoop.subprocess_shell():
     1f38. for other parameters.

     Return a *note Process: 1ff3. instance.

     It is the application’s responsibility to ensure that all
     whitespace and metacharacters are quoted appropriately to avoid
     shell injection(1) vulnerabilities.  The *note shlex.quote(): 6aa.
     function can be used to properly escape whitespace and shell
     metacharacters in strings that are going to be used to construct
     shell commands.

     This function is a *note coroutine: 1f03.

Use the *note BaseEventLoop.connect_read_pipe(): 1f32. and *note
BaseEventLoop.connect_write_pipe(): 1f35. methods to connect pipes.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Shell_injection#Shell_injection


File: python.info,  Node: Create a subprocess low-level API using subprocess Popen,  Next: Constants<8>,  Prev: Create a subprocess high-level API using Process,  Up: Subprocess

5.18.5.79 Create a subprocess: low-level API using subprocess.Popen
...................................................................

Run subprocesses asynchronously using the *note subprocess: f7. module.

 -- Method: coroutine BaseEventLoop.subprocess_exec (protocol_factory,
          *args, stdin=subprocess.PIPE, stdout=subprocess.PIPE,
          stderr=subprocess.PIPE, **kwargs)

     Create a subprocess from one or more string arguments (character
     strings or bytes strings encoded to the *note filesystem encoding:
     1851.), where the first string specifies the program to execute,
     and the remaining strings specify the program’s arguments.  (Thus,
     together the string arguments form the ‘sys.argv’ value of the
     program, assuming it is a Python script.)  This is similar to the
     standard library *note subprocess.Popen: 7d8. class called with
     shell=False and the list of strings passed as the first argument;
     however, where *note Popen: 7d8. takes a single argument which is
     list of strings, *note subprocess_exec(): 1f37. takes multiple
     string arguments.

     The `protocol_factory' must instanciate a subclass of the *note
     asyncio.SubprocessProtocol: 1fb0. class.

     Other parameters:

        * `stdin': Either a file-like object representing the pipe to be
          connected to the subprocess’s standard input stream using
          *note connect_write_pipe(): 1f35, or the constant *note
          subprocess.PIPE: 1daa. (the default).  By default a new pipe
          will be created and connected.

        * `stdout': Either a file-like object representing the pipe to
          be connected to the subprocess’s standard output stream using
          *note connect_read_pipe(): 1f32, or the constant *note
          subprocess.PIPE: 1daa. (the default).  By default a new pipe
          will be created and connected.

        * `stderr': Either a file-like object representing the pipe to
          be connected to the subprocess’s standard error stream using
          *note connect_read_pipe(): 1f32, or one of the constants *note
          subprocess.PIPE: 1daa. (the default) or *note
          subprocess.STDOUT: 1db2.  By default a new pipe will be
          created and connected.  When *note subprocess.STDOUT: 1db2. is
          specified, the subprocess’s standard error stream will be
          connected to the same pipe as the standard output stream.

        * All other keyword arguments are passed to *note
          subprocess.Popen: 7d8. without interpretation, except for
          `bufsize', `universal_newlines' and `shell', which should not
          be specified at all.

     Returns a pair of ‘(transport, protocol)’, where `transport' is an
     instance of *note BaseSubprocessTransport: 1fa5.

     This method is a *note coroutine: 1f03.

     See the constructor of the *note subprocess.Popen: 7d8. class for
     parameters.

 -- Method: coroutine BaseEventLoop.subprocess_shell (protocol_factory,
          cmd, *, stdin=subprocess.PIPE, stdout=subprocess.PIPE,
          stderr=subprocess.PIPE, **kwargs)

     Create a subprocess from `cmd', which is a character string or a
     bytes string encoded to the *note filesystem encoding: 1851, using
     the platform’s "shell" syntax.  This is similar to the standard
     library *note subprocess.Popen: 7d8. class called with
     ‘shell=True’.

     The `protocol_factory' must instanciate a subclass of the *note
     asyncio.SubprocessProtocol: 1fb0. class.

     See *note subprocess_exec(): 1f37. for more details about the
     remaining arguments.

     Returns a pair of ‘(transport, protocol)’, where `transport' is an
     instance of *note BaseSubprocessTransport: 1fa5.

     It is the application’s responsibility to ensure that all
     whitespace and metacharacters are quoted appropriately to avoid
     shell injection(1) vulnerabilities.  The *note shlex.quote(): 6aa.
     function can be used to properly escape whitespace and shell
     metacharacters in strings that are going to be used to construct
     shell commands.

     This method is a *note coroutine: 1f03.

See also
........

The *note BaseEventLoop.connect_read_pipe(): 1f32. and *note
BaseEventLoop.connect_write_pipe(): 1f35. methods.

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Shell_injection#Shell_injection


File: python.info,  Node: Constants<8>,  Next: Process,  Prev: Create a subprocess low-level API using subprocess Popen,  Up: Subprocess

5.18.5.80 Constants
...................

 -- Data: asyncio.subprocess.PIPE

     Special value that can be used as the `stdin', `stdout' or `stderr'
     argument to *note create_subprocess_shell(): 1ff4. and *note
     create_subprocess_exec(): 1dcf. and indicates that a pipe to the
     standard stream should be opened.

 -- Data: asyncio.subprocess.STDOUT

     Special value that can be used as the `stderr' argument to *note
     create_subprocess_shell(): 1ff4. and *note
     create_subprocess_exec(): 1dcf. and indicates that standard error
     should go into the same handle as standard output.

 -- Data: asyncio.subprocess.DEVNULL

     Special value that can be used as the `stdin', `stdout' or `stderr'
     argument to *note create_subprocess_shell(): 1ff4. and *note
     create_subprocess_exec(): 1dcf. and indicates that the special file
     *note os.devnull: bb9. will be used.


File: python.info,  Node: Process,  Next: Subprocess and threads,  Prev: Constants<8>,  Up: Subprocess

5.18.5.81 Process
.................

 -- Class: asyncio.subprocess.Process

     A subprocess created by the *note create_subprocess_exec(): 1dcf.
     or the *note create_subprocess_shell(): 1ff4. function.

     The API of the *note Process: 1ff3. class was designed to be close
     to the API of the *note subprocess.Popen: 7d8. class, but there are
     some differences:

        * There is no explicit *note poll(): 1dcd. method

        * The *note communicate(): 1dab. and *note wait(): 551. methods
          don’t take a `timeout' parameter: use the *note wait_for():
          1f8e. function

        * The `universal_newlines' parameter is not supported (only
          bytes strings are supported)

        * The *note wait(): 1ffb. method of the *note Process: 1ff3.
          class is asynchronous whereas the *note wait(): 551. method of
          the *note Popen: 7d8. class is implemented as a busy loop.

     This class is *note not thread safe: 1eff.  See also the *note
     Subprocess and threads: 1ffc. section.

      -- Method: coroutine wait ()

          Wait for child process to terminate.  Set and return *note
          returncode: 1ffd. attribute.

          This method is a *note coroutine: 1f03.

               Note: This will deadlock when using ‘stdout=PIPE’ or
               ‘stderr=PIPE’ and the child process generates enough
               output to a pipe such that it blocks waiting for the OS
               pipe buffer to accept more data.  Use the *note
               communicate(): 1ffe. method when using pipes to avoid
               that.

      -- Method: coroutine communicate (input=None)

          Interact with process: Send data to stdin.  Read data from
          stdout and stderr, until end-of-file is reached.  Wait for
          process to terminate.  The optional `input' argument should be
          data to be sent to the child process, or ‘None’, if no data
          should be sent to the child.  The type of `input' must be
          bytes.

          *note communicate(): 1ffe. returns a tuple ‘(stdout_data,
          stderr_data)’.

          If a *note BrokenPipeError: 5bb. or *note
          ConnectionResetError: 5be. exception is raised when writing
          `input' into stdin, the exception is ignored.  It occurs when
          the process exits before all data are written into stdin.

          Note that if you want to send data to the process’s stdin, you
          need to create the Process object with ‘stdin=PIPE’.
          Similarly, to get anything other than ‘None’ in the result
          tuple, you need to give ‘stdout=PIPE’ and/or ‘stderr=PIPE’
          too.

          This method is a *note coroutine: 1f03.

               Note: The data read is buffered in memory, so do not use
               this method if the data size is large or unlimited.

          Changed in version 3.4.2: The method now ignores *note
          BrokenPipeError: 5bb. and *note ConnectionResetError: 5be.

      -- Method: send_signal (signal)

          Sends the signal `signal' to the child process.

               Note: On Windows, ‘SIGTERM’ is an alias for *note
               terminate(): 2000.  ‘CTRL_C_EVENT’ and ‘CTRL_BREAK_EVENT’
               can be sent to processes started with a `creationflags'
               parameter which includes ‘CREATE_NEW_PROCESS_GROUP’.

      -- Method: terminate ()

          Stop the child.  On Posix OSs the method sends
          ‘signal.SIGTERM’ to the child.  On Windows the Win32 API
          function ‘TerminateProcess()’ is called to stop the child.

      -- Method: kill ()

          Kills the child.  On Posix OSs the function sends ‘SIGKILL’ to
          the child.  On Windows *note kill(): 2001. is an alias for
          *note terminate(): 2000.

      -- Attribute: stdin

          Standard input stream (*note StreamWriter: 1f17.), ‘None’ if
          the process was created with ‘stdin=None’.

      -- Attribute: stdout

          Standard output stream (*note StreamReader: 1f16.), ‘None’ if
          the process was created with ‘stdout=None’.

      -- Attribute: stderr

          Standard error stream (*note StreamReader: 1f16.), ‘None’ if
          the process was created with ‘stderr=None’.

          Warning: Use the *note communicate(): 1ffe. method rather than
          *note .stdin.write: 2002, *note .stdout.read: 2003. or *note
          .stderr.read: 2004. to avoid deadlocks due to streams pausing
          reading or writing and blocking the child process.

      -- Attribute: pid

          The identifier of the process.

          Note that for processes created by the *note
          create_subprocess_shell(): 1ff4. function, this attribute is
          the process identifier of the spawned shell.

      -- Attribute: returncode

          Return code of the process when it exited.  A ‘None’ value
          indicates that the process has not terminated yet.

          A negative value ‘-N’ indicates that the child was terminated
          by signal ‘N’ (Unix only).


File: python.info,  Node: Subprocess and threads,  Next: Subprocess examples,  Prev: Process,  Up: Subprocess

5.18.5.82 Subprocess and threads
................................

asyncio supports running subprocesses from different threads, but there
are limits:

   * An event loop must run in the main thread

   * The child watcher must be instantiated in the main thread, before
     executing subprocesses from other threads.  Call the
     ‘get_child_watcher()’ function in the main thread to instantiate
     the child watcher.

The *note asyncio.subprocess.Process: 1ff3. class is not thread safe.

See also
........

The *note Concurrency and multithreading in asyncio: 1eff. section.


File: python.info,  Node: Subprocess examples,  Prev: Subprocess and threads,  Up: Subprocess

5.18.5.83 Subprocess examples
.............................

* Menu:

* Subprocess using transport and protocol:: 
* Subprocess using streams:: 


File: python.info,  Node: Subprocess using transport and protocol,  Next: Subprocess using streams,  Up: Subprocess examples

5.18.5.84 Subprocess using transport and protocol
.................................................

Example of a subprocess protocol using to get the output of a subprocess
and to wait for the subprocess exit.  The subprocess is created by the
*note BaseEventLoop.subprocess_exec(): 1f37. method:

     import asyncio
     import sys

     class DateProtocol(asyncio.SubprocessProtocol):
         def __init__(self, exit_future):
             self.exit_future = exit_future
             self.output = bytearray()

         def pipe_data_received(self, fd, data):
             self.output.extend(data)

         def process_exited(self):
             self.exit_future.set_result(True)

     @asyncio.coroutine
     def get_date(loop):
         code = 'import datetime; print(datetime.datetime.now())'
         exit_future = asyncio.Future(loop=loop)

         # Create the subprocess controlled by the protocol DateProtocol,
         # redirect the standard output into a pipe
         create = loop.subprocess_exec(lambda: DateProtocol(exit_future),
                                       sys.executable, '-c', code,
                                       stdin=None, stderr=None)
         transport, protocol = yield from create

         # Wait for the subprocess exit using the process_exited() method
         # of the protocol
         yield from exit_future

         # Close the stdout pipe
         transport.close()

         # Read the output which was collected by the pipe_data_received()
         # method of the protocol
         data = bytes(protocol.output)
         return data.decode('ascii').rstrip()

     if sys.platform == "win32":
         loop = asyncio.ProactorEventLoop()
         asyncio.set_event_loop(loop)
     else:
         loop = asyncio.get_event_loop()

     date = loop.run_until_complete(get_date(loop))
     print("Current date: %s" % date)
     loop.close()


File: python.info,  Node: Subprocess using streams,  Prev: Subprocess using transport and protocol,  Up: Subprocess examples

5.18.5.85 Subprocess using streams
..................................

Example using the *note Process: 1ff3. class to control the subprocess
and the *note StreamReader: 1f16. class to read from the standard
output.  The subprocess is created by the *note
create_subprocess_exec(): 1dcf. function:

     import asyncio.subprocess
     import sys

     @asyncio.coroutine
     def get_date():
         code = 'import datetime; print(datetime.datetime.now())'

         # Create the subprocess, redirect the standard output into a pipe
         create = asyncio.create_subprocess_exec(sys.executable, '-c', code,
                                                 stdout=asyncio.subprocess.PIPE)
         proc = yield from create

         # Read one line of output
         data = yield from proc.stdout.readline()
         line = data.decode('ascii').rstrip()

         # Wait for the subprocess exit
         yield from proc.wait()
         return line

     if sys.platform == "win32":
         loop = asyncio.ProactorEventLoop()
         asyncio.set_event_loop(loop)
     else:
         loop = asyncio.get_event_loop()

     date = loop.run_until_complete(get_date())
     print("Current date: %s" % date)
     loop.close()


File: python.info,  Node: Synchronization primitives<2>,  Next: Queues,  Prev: Subprocess,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.86 Synchronization primitives
....................................

Locks:

   * *note Lock: 200c.

   * *note Event: 200d.

   * *note Condition: 200e.

Semaphores:

   * *note Semaphore: 200f.

   * *note BoundedSemaphore: 2010.

asyncio lock API was designed to be close to classes of the *note
threading: 106. module (*note Lock: 1ccd, *note Event: 6e7, *note
Condition: 6e4, *note Semaphore: 6e5, *note BoundedSemaphore: 6e6.), but
it has no `timeout' parameter.  The *note asyncio.wait_for(): 1f8e.
function can be used to cancel a task after a timeout.

* Menu:

* Locks:: 
* Semaphores:: 


File: python.info,  Node: Locks,  Next: Semaphores,  Up: Synchronization primitives<2>

5.18.5.87 Locks
...............

* Menu:

* Lock:: 
* Event:: 
* Condition:: 


File: python.info,  Node: Lock,  Next: Event,  Up: Locks

5.18.5.88 Lock
..............

 -- Class: asyncio.Lock (*, loop=None)

     Primitive lock objects.

     A primitive lock is a synchronization primitive that is not owned
     by a particular coroutine when locked.  A primitive lock is in one
     of two states, ’locked’ or ’unlocked’.

     It is created in the unlocked state.  It has two basic methods,
     *note acquire(): 2013. and *note release(): 2014.  When the state
     is unlocked, acquire() changes the state to locked and returns
     immediately.  When the state is locked, acquire() blocks until a
     call to release() in another coroutine changes it to unlocked, then
     the acquire() call resets it to locked and returns.  The release()
     method should only be called in the locked state; it changes the
     state to unlocked and returns immediately.  If an attempt is made
     to release an unlocked lock, a *note RuntimeError: 193. will be
     raised.

     When more than one coroutine is blocked in acquire() waiting for
     the state to turn to unlocked, only one coroutine proceeds when a
     release() call resets the state to unlocked; first coroutine which
     is blocked in acquire() is being processed.

     *note acquire(): 2013. is a coroutine and should be called with
     ‘yield from’.

     Locks also support the context management protocol.  ‘(yield from
     lock)’ should be used as context manager expression.

     This class is *note not thread safe: 1eff.

     Usage:

          lock = Lock()
          ...
          yield from lock
          try:
              ...
          finally:
              lock.release()

     Context manager usage:

          lock = Lock()
          ...
          with (yield from lock):
               ...

     Lock objects can be tested for locking state:

          if not lock.locked():
             yield from lock
          else:
             # lock is acquired
              ...

      -- Method: locked ()

          Return ‘True’ if the lock is acquired.

      -- Method: coroutine acquire ()

          Acquire a lock.

          This method blocks until the lock is unlocked, then sets it to
          locked and returns ‘True’.

          This method is a *note coroutine: 1f03.

      -- Method: release ()

          Release a lock.

          When the lock is locked, reset it to unlocked, and return.  If
          any other coroutines are blocked waiting for the lock to
          become unlocked, allow exactly one of them to proceed.

          When invoked on an unlocked lock, a *note RuntimeError: 193.
          is raised.

          There is no return value.


File: python.info,  Node: Event,  Next: Condition,  Prev: Lock,  Up: Locks

5.18.5.89 Event
...............

 -- Class: asyncio.Event (*, loop=None)

     An Event implementation, asynchronous equivalent to *note
     threading.Event: 6e7.

     Class implementing event objects.  An event manages a flag that can
     be set to true with the *note set(): 7be. method and reset to false
     with the *note clear(): 2017. method.  The *note wait(): 238.
     method blocks until the flag is true.  The flag is initially false.

     This class is *note not thread safe: 1eff.

      -- Method: clear ()

          Reset the internal flag to false.  Subsequently, coroutines
          calling *note wait(): 238. will block until *note set(): 7be.
          is called to set the internal flag to true again.

      -- Method: is_set ()

          Return ‘True’ if and only if the internal flag is true.

      -- Method: set ()

          Set the internal flag to true.  All coroutines waiting for it
          to become true are awakened.  Coroutine that call *note
          wait(): 238. once the flag is true will not block at all.

      -- Method: coroutine wait ()

          Block until the internal flag is true.

          If the internal flag is true on entry, return ‘True’
          immediately.  Otherwise, block until another coroutine calls
          *note set(): 7be. to set the flag to true, then return ‘True’.

          This method is a *note coroutine: 1f03.


File: python.info,  Node: Condition,  Prev: Event,  Up: Locks

5.18.5.90 Condition
...................

 -- Class: asyncio.Condition (lock=None, *, loop=None)

     A Condition implementation, asynchronous equivalent to *note
     threading.Condition: 6e4.

     This class implements condition variable objects.  A condition
     variable allows one or more coroutines to wait until they are
     notified by another coroutine.

     If the `lock' argument is given and not ‘None’, it must be a *note
     Lock: 200c. object, and it is used as the underlying lock.
     Otherwise, a new *note Lock: 200c. object is created and used as
     the underlying lock.

     This class is *note not thread safe: 1eff.

      -- Method: coroutine acquire ()

          Acquire the underlying lock.

          This method blocks until the lock is unlocked, then sets it to
          locked and returns ‘True’.

          This method is a *note coroutine: 1f03.

      -- Method: notify (n=1)

          By default, wake up one coroutine waiting on this condition,
          if any.  If the calling coroutine has not acquired the lock
          when this method is called, a *note RuntimeError: 193. is
          raised.

          This method wakes up at most `n' of the coroutines waiting for
          the condition variable; it is a no-op if no coroutines are
          waiting.

               Note: An awakened coroutine does not actually return from
               its *note wait(): 238. call until it can reacquire the
               lock.  Since *note notify(): 201d. does not release the
               lock, its caller should.

      -- Method: locked ()

          Return ‘True’ if the underlying lock is acquired.

      -- Method: notify_all ()

          Wake up all coroutines waiting on this condition.  This method
          acts like *note notify(): 201d, but wakes up all waiting
          coroutines instead of one.  If the calling coroutine has not
          acquired the lock when this method is called, a *note
          RuntimeError: 193. is raised.

      -- Method: release ()

          Release the underlying lock.

          When the lock is locked, reset it to unlocked, and return.  If
          any other coroutines are blocked waiting for the lock to
          become unlocked, allow exactly one of them to proceed.

          When invoked on an unlocked lock, a *note RuntimeError: 193.
          is raised.

          There is no return value.

      -- Method: coroutine wait ()

          Wait until notified.

          If the calling coroutine has not acquired the lock when this
          method is called, a *note RuntimeError: 193. is raised.

          This method releases the underlying lock, and then blocks
          until it is awakened by a *note notify(): 201d. or *note
          notify_all(): 201f. call for the same condition variable in
          another coroutine.  Once awakened, it re-acquires the lock and
          returns ‘True’.

          This method is a *note coroutine: 1f03.

      -- Method: coroutine wait_for (predicate)

          Wait until a predicate becomes true.

          The predicate should be a callable which result will be
          interpreted as a boolean value.  The final predicate value is
          the return value.

          This method is a *note coroutine: 1f03.


File: python.info,  Node: Semaphores,  Prev: Locks,  Up: Synchronization primitives<2>

5.18.5.91 Semaphores
....................

* Menu:

* Semaphore:: 
* BoundedSemaphore:: 


File: python.info,  Node: Semaphore,  Next: BoundedSemaphore,  Up: Semaphores

5.18.5.92 Semaphore
...................

 -- Class: asyncio.Semaphore (value=1, *, loop=None)

     A Semaphore implementation.

     A semaphore manages an internal counter which is decremented by
     each *note acquire(): 2025. call and incremented by each *note
     release(): 2026. call.  The counter can never go below zero; when
     *note acquire(): 2025. finds that it is zero, it blocks, waiting
     until some other coroutine calls *note release(): 2026.

     Semaphores also support the context management protocol.

     The optional argument gives the initial value for the internal
     counter; it defaults to ‘1’.  If the value given is less than ‘0’,
     *note ValueError: 19c. is raised.

     This class is *note not thread safe: 1eff.

      -- Method: coroutine acquire ()

          Acquire a semaphore.

          If the internal counter is larger than zero on entry,
          decrement it by one and return ‘True’ immediately.  If it is
          zero on entry, block, waiting until some other coroutine has
          called *note release(): 2026. to make it larger than ‘0’, and
          then return ‘True’.

          This method is a *note coroutine: 1f03.

      -- Method: locked ()

          Returns ‘True’ if semaphore can not be acquired immediately.

      -- Method: release ()

          Release a semaphore, incrementing the internal counter by one.
          When it was zero on entry and another coroutine is waiting for
          it to become larger than zero again, wake up that coroutine.


File: python.info,  Node: BoundedSemaphore,  Prev: Semaphore,  Up: Semaphores

5.18.5.93 BoundedSemaphore
..........................

 -- Class: asyncio.BoundedSemaphore (value=1, *, loop=None)

     A bounded semaphore implementation.  Inherit from *note Semaphore:
     200f.

     This raises *note ValueError: 19c. in *note release(): 2026. if it
     would increase the value above the initial value.


File: python.info,  Node: Queues,  Next: Develop with asyncio,  Prev: Synchronization primitives<2>,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.94 Queues
................

Queues:

   * *note Queue: 241.

   * *note PriorityQueue: 202b.

   * *note LifoQueue: 202c.

asyncio queue API was designed to be close to classes of the *note
queue: d8. module (*note Queue: cc5, *note PriorityQueue: 1df8, *note
LifoQueue: 1df7.), but it has no `timeout' parameter.  The *note
asyncio.wait_for(): 1f8e. function can be used to cancel a task after a
timeout.

* Menu:

* Queue:: 
* PriorityQueue:: 
* LifoQueue:: 


File: python.info,  Node: Queue,  Next: PriorityQueue,  Up: Queues

5.18.5.95 Queue
...............

 -- Class: asyncio.Queue (maxsize=0, *, loop=None)

     A queue, useful for coordinating producer and consumer coroutines.

     If `maxsize' is less than or equal to zero, the queue size is
     infinite.  If it is an integer greater than ‘0’, then ‘yield from
     put()’ will block when the queue reaches `maxsize', until an item
     is removed by *note get(): 202e.

     Unlike the standard library *note queue: d8, you can reliably know
     this Queue’s size with *note qsize(): 202f, since your
     single-threaded asyncio application won’t be interrupted between
     calling *note qsize(): 202f. and doing an operation on the Queue.

     This class is *note not thread safe: 1eff.

     Changed in version 3.4.4: New *note join(): 23f. and *note
     task_done(): 240. methods.

      -- Method: empty ()

          Return ‘True’ if the queue is empty, ‘False’ otherwise.

      -- Method: full ()

          Return ‘True’ if there are *note maxsize: 2032. items in the
          queue.

               Note: If the Queue was initialized with ‘maxsize=0’ (the
               default), then *note full(): 2031. is never ‘True’.

      -- Method: coroutine get ()

          Remove and return an item from the queue.  If queue is empty,
          wait until an item is available.

          This method is a *note coroutine: 1f03.

          See also
          ........

          The *note empty(): 2030. method.

      -- Method: get_nowait ()

          Remove and return an item from the queue.

          Return an item if one is immediately available, else raise
          *note QueueEmpty: 2034.

      -- Method: coroutine join ()

          Block until all items in the queue have been gotten and
          processed.

          The count of unfinished tasks goes up whenever an item is
          added to the queue.  The count goes down whenever a consumer
          thread calls *note task_done(): 240. to indicate that the item
          was retrieved and all work on it is complete.  When the count
          of unfinished tasks drops to zero, *note join(): 23f.
          unblocks.

          This method is a *note coroutine: 1f03.

          New in version 3.4.4.

      -- Method: coroutine put (item)

          Put an item into the queue.  If the queue is full, wait until
          a free slot is available before adding item.

          This method is a *note coroutine: 1f03.

          See also
          ........

          The *note full(): 2031. method.

      -- Method: put_nowait (item)

          Put an item into the queue without blocking.

          If no free slot is immediately available, raise *note
          QueueFull: 2037.

      -- Method: qsize ()

          Number of items in the queue.

      -- Method: task_done ()

          Indicate that a formerly enqueued task is complete.

          Used by queue consumers.  For each *note get(): 202e. used to
          fetch a task, a subsequent call to *note task_done(): 240.
          tells the queue that the processing on the task is complete.

          If a *note join(): 23f. is currently blocking, it will resume
          when all items have been processed (meaning that a *note
          task_done(): 240. call was received for every item that had
          been *note put(): 2035. into the queue).

          Raises *note ValueError: 19c. if called more times than there
          were items placed in the queue.

          New in version 3.4.4.

      -- Attribute: maxsize

          Number of items allowed in the queue.


File: python.info,  Node: PriorityQueue,  Next: LifoQueue,  Prev: Queue,  Up: Queues

5.18.5.96 PriorityQueue
.......................

 -- Class: asyncio.PriorityQueue

     A subclass of *note Queue: 241.; retrieves entries in priority
     order (lowest first).

     Entries are typically tuples of the form: (priority number, data).


File: python.info,  Node: LifoQueue,  Prev: PriorityQueue,  Up: Queues

5.18.5.97 LifoQueue
...................

 -- Class: asyncio.LifoQueue

     A subclass of *note Queue: 241. that retrieves most recently added
     entries first.

* Menu:

* Exceptions: Exceptions<8>. 


File: python.info,  Node: Exceptions<8>,  Up: LifoQueue

5.18.5.98 Exceptions
....................

 -- Exception: asyncio.QueueEmpty

     Exception raised when the *note get_nowait(): 2033. method is
     called on a *note Queue: 241. object which is empty.

 -- Exception: asyncio.QueueFull

     Exception raised when the *note put_nowait(): 2036. method is
     called on a *note Queue: 241. object which is full.


File: python.info,  Node: Develop with asyncio,  Prev: Queues,  Up: asyncio -- Asynchronous I/O event loop coroutines and tasks

5.18.5.99 Develop with asyncio
..............................

Asynchronous programming is different than classical "sequential"
programming.  This page lists common traps and explains how to avoid
them.

* Menu:

* Debug mode of asyncio:: 
* Cancellation:: 
* Concurrency and multithreading:: 
* Handle blocking functions correctly:: 
* Logging: Logging<3>. 
* Detect coroutine objects never scheduled:: 
* Detect exceptions never consumed:: 
* Chain coroutines correctly:: 
* Pending task destroyed:: 
* Close transports and event loops:: 


File: python.info,  Node: Debug mode of asyncio,  Next: Cancellation,  Up: Develop with asyncio

5.18.5.100 Debug mode of asyncio
................................

The implementation of *note asyncio: a. has been written for
performance.  In order to ease the development of asynchronous code, you
may wish to enable `debug mode'.

To enable all debug checks for an application:

   * Enable the asyncio debug mode globally by setting the environment
     variable *note PYTHONASYNCIODEBUG: d1c. to ‘1’, or by calling *note
     BaseEventLoop.set_debug(): 233.

   * Set the log level of the *note asyncio logger: 203e. to
     ‘logging.DEBUG’.  For example, call
     ‘logging.basicConfig(level=logging.DEBUG)’ at startup.

   * Configure the *note warnings: 123. module to display *note
     ResourceWarning: 166. warnings.  For example, use the ‘-Wdefault’
     command line option of Python to display them.

Examples debug checks:

   * Log *note coroutines defined but never "yielded from": 1f6e.

   * *note call_soon(): 1f08. and *note call_at(): 1f0e. methods raise
     an exception if they are called from the wrong thread.

   * Log the execution time of the selector

   * Log callbacks taking more than 100 ms to be executed.  The
     ‘BaseEventLoop.slow_callback_duration’ attribute is the minimum
     duration in seconds of "slow" callbacks.

   * *note ResourceWarning: 166. warnings are emitted when transports
     and event loops are *note not closed explicitly: 203f.

See also
........

The *note BaseEventLoop.set_debug(): 233. method and the *note asyncio
logger: 203e.


File: python.info,  Node: Cancellation,  Next: Concurrency and multithreading,  Prev: Debug mode of asyncio,  Up: Develop with asyncio

5.18.5.101 Cancellation
.......................

Cancellation of tasks is not common in classic programming.  In
asynchronous programming, not only it is something common, but you have
to prepare your code to handle it.

Futures and tasks can be cancelled explicitly with their *note
Future.cancel(): 1f7a. method.  The *note wait_for(): 1f8e. function
cancels the waited task when the timeout occurs.  There are many other
cases where a task can be cancelled indirectly.

Don’t call *note set_result(): 1f7e. or *note set_exception(): 1f7f.
method of *note Future: e50. if the future is cancelled: it would fail
with an exception.  For example, write:

     if not fut.cancelled():
         fut.set_result('done')

Don’t schedule directly a call to the *note set_result(): 1f7e. or the
*note set_exception(): 1f7f. method of a future with *note
BaseEventLoop.call_soon(): 1f08.: the future can be cancelled before its
method is called.

If you wait for a future, you should check early if the future was
cancelled to avoid useless operations.  Example:

     @coroutine
     def slow_operation(fut):
         if fut.cancelled():
             return
         # ... slow computation ...
         yield from fut
         # ...

The *note shield(): 1f8c. function can also be used to ignore
cancellation.


File: python.info,  Node: Concurrency and multithreading,  Next: Handle blocking functions correctly,  Prev: Cancellation,  Up: Develop with asyncio

5.18.5.102 Concurrency and multithreading
.........................................

An event loop runs in a thread and executes all callbacks and tasks in
the same thread.  While a task is running in the event loop, no other
task is running in the same thread.  But when the task uses ‘yield
from’, the task is suspended and the event loop executes the next task.

To schedule a callback from a different thread, the *note
BaseEventLoop.call_soon_threadsafe(): 1f0a. method should be used.
Example:

     loop.call_soon_threadsafe(callback, *args)

Most asyncio objects are not thread safe.  You should only worry if you
access objects outside the event loop.  For example, to cancel a future,
don’t call directly its *note Future.cancel(): 1f7a. method, but:

     loop.call_soon_threadsafe(fut.cancel)

To handle signals and to execute subprocesses, the event loop must be
run in the main thread.

To schedule a coroutine object from a different thread, the *note
run_coroutine_threadsafe(): 243. function should be used.  It returns a
*note concurrent.futures.Future: 76f. to access the result:

     future = asyncio.run_coroutine_threadsafe(coro_func(), loop)
     result = future.result(timeout)  # Wait for the result with a timeout

The *note BaseEventLoop.run_in_executor(): 1f3d. method can be used with
a thread pool executor to execute a callback in different thread to not
block the thread of the event loop.

See also
........

The *note Synchronization primitives: 1efa. section describes ways to
synchronize tasks.

The *note Subprocess and threads: 1ffc. section lists asyncio
limitations to run subprocesses from different threads.


File: python.info,  Node: Handle blocking functions correctly,  Next: Logging<3>,  Prev: Concurrency and multithreading,  Up: Develop with asyncio

5.18.5.103 Handle blocking functions correctly
..............................................

Blocking functions should not be called directly.  For example, if a
function blocks for 1 second, other tasks are delayed by 1 second which
can have an important impact on reactivity.

For networking and subprocesses, the *note asyncio: a. module provides
high-level APIs like *note protocols: 1ef9.

An executor can be used to run a task in a different thread or even in a
different process, to not block the thread of the event loop.  See the
*note BaseEventLoop.run_in_executor(): 1f3d. method.

See also
........

The *note Delayed calls: 1f0b. section details how the event loop
handles time.


File: python.info,  Node: Logging<3>,  Next: Detect coroutine objects never scheduled,  Prev: Handle blocking functions correctly,  Up: Develop with asyncio

5.18.5.104 Logging
..................

The *note asyncio: a. module logs information with the *note logging:
a8. module in the logger ‘'asyncio'’.


File: python.info,  Node: Detect coroutine objects never scheduled,  Next: Detect exceptions never consumed,  Prev: Logging<3>,  Up: Develop with asyncio

5.18.5.105 Detect coroutine objects never scheduled
...................................................

When a coroutine function is called and its result is not passed to
*note ensure_future(): 23c. or to the *note BaseEventLoop.create_task():
236. method, the execution of the coroutine object will never be
scheduled which is probably a bug.  *note Enable the debug mode of
asyncio: d1d. to *note log a warning: 203e. to detect it.

Example with the bug:

     import asyncio

     @asyncio.coroutine
     def test():
         print("never scheduled")

     test()

Output in debug mode:

     Coroutine test() at test.py:3 was never yielded from
     Coroutine object created at (most recent call last):
       File "test.py", line 7, in <module>
         test()

The fix is to call the *note ensure_future(): 23c. function or the *note
BaseEventLoop.create_task(): 236. method with the coroutine object.

See also
........

*note Pending task destroyed: 1f84.


File: python.info,  Node: Detect exceptions never consumed,  Next: Chain coroutines correctly,  Prev: Detect coroutine objects never scheduled,  Up: Develop with asyncio

5.18.5.106 Detect exceptions never consumed
...........................................

Python usually calls *note sys.displayhook(): ae5. on unhandled
exceptions.  If *note Future.set_exception(): 1f7f. is called, but the
exception is never consumed, *note sys.displayhook(): ae5. is not
called.  Instead, *note a log is emitted: 203e. when the future is
deleted by the garbage collector, with the traceback where the exception
was raised.

Example of unhandled exception:

     import asyncio

     @asyncio.coroutine
     def bug():
         raise Exception("not consumed")

     loop = asyncio.get_event_loop()
     asyncio.ensure_future(bug())
     loop.run_forever()
     loop.close()

Output:

     Task exception was never retrieved
     future: <Task finished coro=<coro() done, defined at asyncio/coroutines.py:139> exception=Exception('not consumed',)>
     Traceback (most recent call last):
       File "asyncio/tasks.py", line 237, in _step
         result = next(coro)
       File "asyncio/coroutines.py", line 141, in coro
         res = func(*args, **kw)
       File "test.py", line 5, in bug
         raise Exception("not consumed")
     Exception: not consumed

*note Enable the debug mode of asyncio: d1d. to get the traceback where
the task was created.  Output in debug mode:

     Task exception was never retrieved
     future: <Task finished coro=<bug() done, defined at test.py:3> exception=Exception('not consumed',) created at test.py:8>
     source_traceback: Object created at (most recent call last):
       File "test.py", line 8, in <module>
         asyncio.ensure_future(bug())
     Traceback (most recent call last):
       File "asyncio/tasks.py", line 237, in _step
         result = next(coro)
       File "asyncio/coroutines.py", line 79, in __next__
         return next(self.gen)
       File "asyncio/coroutines.py", line 141, in coro
         res = func(*args, **kw)
       File "test.py", line 5, in bug
         raise Exception("not consumed")
     Exception: not consumed

There are different options to fix this issue.  The first option is to
chain the coroutine in another coroutine and use classic try/except:

     @asyncio.coroutine
     def handle_exception():
         try:
             yield from bug()
         except Exception:
             print("exception consumed")

     loop = asyncio.get_event_loop()
     asyncio.ensure_future(handle_exception())
     loop.run_forever()
     loop.close()

Another option is to use the *note BaseEventLoop.run_until_complete():
242. function:

     task = asyncio.ensure_future(bug())
     try:
         loop.run_until_complete(task)
     except Exception:
         print("exception consumed")

See also
........

The *note Future.exception(): 1f78. method.


File: python.info,  Node: Chain coroutines correctly,  Next: Pending task destroyed,  Prev: Detect exceptions never consumed,  Up: Develop with asyncio

5.18.5.107 Chain coroutines correctly
.....................................

When a coroutine function calls other coroutine functions and tasks,
they should be chained explicitly with ‘yield from’.  Otherwise, the
execution is not guaranteed to be sequential.

Example with different bugs using *note asyncio.sleep(): 1f10. to
simulate slow operations:

     import asyncio

     @asyncio.coroutine
     def create():
         yield from asyncio.sleep(3.0)
         print("(1) create file")

     @asyncio.coroutine
     def write():
         yield from asyncio.sleep(1.0)
         print("(2) write into file")

     @asyncio.coroutine
     def close():
         print("(3) close file")

     @asyncio.coroutine
     def test():
         asyncio.ensure_future(create())
         asyncio.ensure_future(write())
         asyncio.ensure_future(close())
         yield from asyncio.sleep(2.0)
         loop.stop()

     loop = asyncio.get_event_loop()
     asyncio.ensure_future(test())
     loop.run_forever()
     print("Pending tasks at exit: %s" % asyncio.Task.all_tasks(loop))
     loop.close()

Expected output:

     (1) create file
     (2) write into file
     (3) close file
     Pending tasks at exit: set()

Actual output:

     (3) close file
     (2) write into file
     Pending tasks at exit: {<Task pending create() at test.py:7 wait_for=<Future pending cb=[Task._wakeup()]>>}
     Task was destroyed but it is pending!
     task: <Task pending create() done at test.py:5 wait_for=<Future pending cb=[Task._wakeup()]>>

The loop stopped before the ‘create()’ finished, ‘close()’ has been
called before ‘write()’, whereas coroutine functions were called in this
order: ‘create()’, ‘write()’, ‘close()’.

To fix the example, tasks must be marked with ‘yield from’:

     @asyncio.coroutine
     def test():
         yield from asyncio.ensure_future(create())
         yield from asyncio.ensure_future(write())
         yield from asyncio.ensure_future(close())
         yield from asyncio.sleep(2.0)
         loop.stop()

Or without ‘asyncio.ensure_future()’:

     @asyncio.coroutine
     def test():
         yield from create()
         yield from write()
         yield from close()
         yield from asyncio.sleep(2.0)
         loop.stop()


File: python.info,  Node: Pending task destroyed,  Next: Close transports and event loops,  Prev: Chain coroutines correctly,  Up: Develop with asyncio

5.18.5.108 Pending task destroyed
.................................

If a pending task is destroyed, the execution of its wrapped *note
coroutine: 1f03. did not complete.  It is probably a bug and so a
warning is logged.

Example of log:

     Task was destroyed but it is pending!
     task: <Task pending coro=<kill_me() done, defined at test.py:5> wait_for=<Future pending cb=[Task._wakeup()]>>

*note Enable the debug mode of asyncio: d1d. to get the traceback where
the task was created.  Example of log in debug mode:

     Task was destroyed but it is pending!
     source_traceback: Object created at (most recent call last):
       File "test.py", line 15, in <module>
         task = asyncio.ensure_future(coro, loop=loop)
     task: <Task pending coro=<kill_me() done, defined at test.py:5> wait_for=<Future pending cb=[Task._wakeup()] created at test.py:7> created at test.py:15>

See also
........

*note Detect coroutine objects never scheduled: 1f6e.


File: python.info,  Node: Close transports and event loops,  Prev: Pending task destroyed,  Up: Develop with asyncio

5.18.5.109 Close transports and event loops
...........................................

When a transport is no more needed, call its ‘close()’ method to release
resources.  Event loops must also be closed explicitly.

If a transport or an event loop is not closed explicitly, a *note
ResourceWarning: 166. warning will be emitted in its destructor.  By
default, *note ResourceWarning: 166. warnings are ignored.  The *note
Debug mode of asyncio: d1d. section explains how to display them.

See also
........

The *note asyncio: a. module was designed in PEP 3156(1).  For a
motivational primer on transports and protocols, see PEP 3153(2).

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3156

   (2) https://www.python.org/dev/peps/pep-3153


File: python.info,  Node: asyncore --- Asynchronous socket handler,  Next: asynchat --- Asynchronous socket command/response handler,  Prev: asyncio -- Asynchronous I/O event loop coroutines and tasks,  Up: Interprocess Communication and Networking

5.18.6 ‘asyncore’ — Asynchronous socket handler
-----------------------------------------------

`Source code:' Lib/asyncore.py(1)

__________________________________________________________________

     Note: This module exists for backwards compatibility only.  For new
     code we recommend using *note asyncio: a.

This module provides the basic infrastructure for writing asynchronous
socket service clients and servers.

There are only two ways to have a program on a single processor do "more
than one thing at a time."  Multi-threaded programming is the simplest
and most popular way to do it, but there is another very different
technique, that lets you have nearly all the advantages of
multi-threading, without actually using multiple threads.  It’s really
only practical if your program is largely I/O bound.  If your program is
processor bound, then pre-emptive scheduled threads are probably what
you really need.  Network servers are rarely processor bound, however.

If your operating system supports the ‘select()’ system call in its I/O
library (and nearly all do), then you can use it to juggle multiple
communication channels at once; doing other work while your I/O is
taking place in the "background."  Although this strategy can seem
strange and complex, especially at first, it is in many ways easier to
understand and control than multi-threaded programming.  The *note
asyncore: b. module solves many of the difficult problems for you,
making the task of building sophisticated high-performance network
servers and clients a snap.  For "conversational" applications and
protocols the companion *note asynchat: 9. module is invaluable.

The basic idea behind both modules is to create one or more network
`channels', instances of class *note asyncore.dispatcher: 821. and *note
asynchat.async_chat: 4b3.  Creating the channels adds them to a global
map, used by the *note loop(): 204c. function if you do not provide it
with your own `map'.

Once the initial channel(s) is(are) created, calling the *note loop():
204c. function activates channel service, which continues until the last
channel (including any that have been added to the map during
asynchronous service) is closed.

 -- Function: asyncore.loop ([timeout[, use_poll[, map[, count]]]])

     Enter a polling loop that terminates after count passes or all open
     channels have been closed.  All arguments are optional.  The
     `count' parameter defaults to None, resulting in the loop
     terminating only when all channels have been closed.  The `timeout'
     argument sets the timeout parameter for the appropriate *note
     select(): 209. or *note poll(): 1eaa. call, measured in seconds;
     the default is 30 seconds.  The `use_poll' parameter, if true,
     indicates that *note poll(): 1eaa. should be used in preference to
     *note select(): 209. (the default is ‘False’).

     The `map' parameter is a dictionary whose items are the channels to
     watch.  As channels are closed they are deleted from their map.  If
     `map' is omitted, a global map is used.  Channels (instances of
     *note asyncore.dispatcher: 821, *note asynchat.async_chat: 4b3. and
     subclasses thereof) can freely be mixed in the map.

 -- Class: asyncore.dispatcher

     The *note dispatcher: 821. class is a thin wrapper around a
     low-level socket object.  To make it more useful, it has a few
     methods for event-handling which are called from the asynchronous
     loop.  Otherwise, it can be treated as a normal non-blocking socket
     object.

     The firing of low-level events at certain times or in certain
     connection states tells the asynchronous loop that certain
     higher-level events have taken place.  For example, if we have
     asked for a socket to connect to another host, we know that the
     connection has been made when the socket becomes writable for the
     first time (at this point you know that you may write to it with
     the expectation of success).  The implied higher-level events are:

     Event                      Description
                                
     ------------------------------------------------------------------------
                                
     ‘handle_connect()’         Implied by the first read or write event
                                
                                
     ‘handle_close()’           Implied by a read event with no data
                                available
                                
                                
     ‘handle_accepted()’        Implied by a read event on a listening
                                socket
                                

     During asynchronous processing, each mapped channel’s *note
     readable(): 204d. and *note writable(): 204e. methods are used to
     determine whether the channel’s socket should be added to the list
     of channels ‘select()’ed or ‘poll()’ed for read and write events.

     Thus, the set of channel events is larger than the basic socket
     events.  The full set of methods that can be overridden in your
     subclass follows:

      -- Method: handle_read ()

          Called when the asynchronous loop detects that a ‘read()’ call
          on the channel’s socket will succeed.

      -- Method: handle_write ()

          Called when the asynchronous loop detects that a writable
          socket can be written.  Often this method will implement the
          necessary buffering for performance.  For example:

               def handle_write(self):
                   sent = self.send(self.buffer)
                   self.buffer = self.buffer[sent:]

      -- Method: handle_expt ()

          Called when there is out of band (OOB) data for a socket
          connection.  This will almost never happen, as OOB is
          tenuously supported and rarely used.

      -- Method: handle_connect ()

          Called when the active opener’s socket actually makes a
          connection.  Might send a "welcome" banner, or initiate a
          protocol negotiation with the remote endpoint, for example.

      -- Method: handle_close ()

          Called when the socket is closed.

      -- Method: handle_error ()

          Called when an exception is raised and not otherwise handled.
          The default version prints a condensed traceback.

      -- Method: handle_accept ()

          Called on listening channels (passive openers) when a
          connection can be established with a new remote endpoint that
          has issued a *note connect(): 2055. call for the local
          endpoint.  Deprecated in version 3.2; use *note
          handle_accepted(): 822. instead.

          Deprecated since version 3.2.

      -- Method: handle_accepted (sock, addr)

          Called on listening channels (passive openers) when a
          connection has been established with a new remote endpoint
          that has issued a *note connect(): 2055. call for the local
          endpoint.  `sock' is a `new' socket object usable to send and
          receive data on the connection, and `addr' is the address
          bound to the socket on the other end of the connection.

          New in version 3.2.

      -- Method: readable ()

          Called each time around the asynchronous loop to determine
          whether a channel’s socket should be added to the list on
          which read events can occur.  The default method simply
          returns ‘True’, indicating that by default, all channels will
          be interested in read events.

      -- Method: writable ()

          Called each time around the asynchronous loop to determine
          whether a channel’s socket should be added to the list on
          which write events can occur.  The default method simply
          returns ‘True’, indicating that by default, all channels will
          be interested in write events.

     In addition, each channel delegates or extends many of the socket
     methods.  Most of these are nearly identical to their socket
     partners.

      -- Method: create_socket (family=socket.AF_INET,
               type=socket.SOCK_STREAM)

          This is identical to the creation of a normal socket, and will
          use the same options for creation.  Refer to the *note socket:
          ed. documentation for information on creating sockets.

          Changed in version 3.3: `family' and `type' arguments can be
          omitted.

      -- Method: connect (address)

          As with the normal socket object, `address' is a tuple with
          the first element the host to connect to, and the second the
          port number.

      -- Method: send (data)

          Send `data' to the remote end-point of the socket.

      -- Method: recv (buffer_size)

          Read at most `buffer_size' bytes from the socket’s remote
          end-point.  An empty bytes object implies that the channel has
          been closed from the other end.

          Note that *note recv(): 2058. may raise *note BlockingIOError:
          5b5. , even though *note select.select(): 209. or *note
          select.poll(): 1eaa. has reported the socket ready for
          reading.

      -- Method: listen (backlog)

          Listen for connections made to the socket.  The `backlog'
          argument specifies the maximum number of queued connections
          and should be at least 1; the maximum value is
          system-dependent (usually 5).

      -- Method: bind (address)

          Bind the socket to `address'.  The socket must not already be
          bound.  (The format of `address' depends on the address family
          — refer to the *note socket: ed. documentation for more
          information.)  To mark the socket as re-usable (setting the
          ‘SO_REUSEADDR’ option), call the *note dispatcher: 821.
          object’s ‘set_reuse_addr()’ method.

      -- Method: accept ()

          Accept a connection.  The socket must be bound to an address
          and listening for connections.  The return value can be either
          ‘None’ or a pair ‘(conn, address)’ where `conn' is a `new'
          socket object usable to send and receive data on the
          connection, and `address' is the address bound to the socket
          on the other end of the connection.  When ‘None’ is returned
          it means the connection didn’t take place, in which case the
          server should just ignore this event and keep listening for
          further incoming connections.

      -- Method: close ()

          Close the socket.  All future operations on the socket object
          will fail.  The remote end-point will receive no more data
          (after queued data is flushed).  Sockets are automatically
          closed when they are garbage-collected.

 -- Class: asyncore.dispatcher_with_send

     A *note dispatcher: 821. subclass which adds simple buffered output
     capability, useful for simple clients.  For more sophisticated
     usage use *note asynchat.async_chat: 4b3.

 -- Class: asyncore.file_dispatcher

     A file_dispatcher takes a file descriptor or *note file object:
     78b. along with an optional map argument and wraps it for use with
     the ‘poll()’ or ‘loop()’ functions.  If provided a file object or
     anything with a ‘fileno()’ method, that method will be called and
     passed to the *note file_wrapper: 205e. constructor.  Availability:
     UNIX.

 -- Class: asyncore.file_wrapper

     A file_wrapper takes an integer file descriptor and calls *note
     os.dup(): 187f. to duplicate the handle so that the original handle
     may be closed independently of the file_wrapper.  This class
     implements sufficient methods to emulate a socket for use by the
     *note file_dispatcher: 205d. class.  Availability: UNIX.

* Menu:

* asyncore Example basic HTTP client:: 
* asyncore Example basic echo server:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/asyncore.py


File: python.info,  Node: asyncore Example basic HTTP client,  Next: asyncore Example basic echo server,  Up: asyncore --- Asynchronous socket handler

5.18.6.1 asyncore Example basic HTTP client
...........................................

Here is a very basic HTTP client that uses the *note dispatcher: 821.
class to implement its socket handling:

     import asyncore

     class HTTPClient(asyncore.dispatcher):

         def __init__(self, host, path):
             asyncore.dispatcher.__init__(self)
             self.create_socket()
             self.connect( (host, 80) )
             self.buffer = bytes('GET %s HTTP/1.0\r\nHost: %s\r\n\r\n' %
                                 (path, host), 'ascii')

         def handle_connect(self):
             pass

         def handle_close(self):
             self.close()

         def handle_read(self):
             print(self.recv(8192))

         def writable(self):
             return (len(self.buffer) > 0)

         def handle_write(self):
             sent = self.send(self.buffer)
             self.buffer = self.buffer[sent:]


      client = HTTPClient('www.python.org', '/')
      asyncore.loop()


File: python.info,  Node: asyncore Example basic echo server,  Prev: asyncore Example basic HTTP client,  Up: asyncore --- Asynchronous socket handler

5.18.6.2 asyncore Example basic echo server
...........................................

Here is a basic echo server that uses the *note dispatcher: 821. class
to accept connections and dispatches the incoming connections to a
handler:

     import asyncore

     class EchoHandler(asyncore.dispatcher_with_send):

         def handle_read(self):
             data = self.recv(8192)
             if data:
                 self.send(data)

     class EchoServer(asyncore.dispatcher):

         def __init__(self, host, port):
             asyncore.dispatcher.__init__(self)
             self.create_socket()
             self.set_reuse_addr()
             self.bind((host, port))
             self.listen(5)

         def handle_accepted(self, sock, addr):
             print('Incoming connection from %s' % repr(addr))
             handler = EchoHandler(sock)

     server = EchoServer('localhost', 8080)
     asyncore.loop()


File: python.info,  Node: asynchat --- Asynchronous socket command/response handler,  Next: signal --- Set handlers for asynchronous events,  Prev: asyncore --- Asynchronous socket handler,  Up: Interprocess Communication and Networking

5.18.7 ‘asynchat’ — Asynchronous socket command/response handler
----------------------------------------------------------------

`Source code:' Lib/asynchat.py(1)

__________________________________________________________________

     Note: This module exists for backwards compatibility only.  For new
     code we recommend using *note asyncio: a.

This module builds on the *note asyncore: b. infrastructure, simplifying
asynchronous clients and servers and making it easier to handle
protocols whose elements are terminated by arbitrary strings, or are of
variable length.  *note asynchat: 9. defines the abstract class *note
async_chat: 4b3. that you subclass, providing implementations of the
‘collect_incoming_data()’ and ‘found_terminator()’ methods.  It uses the
same asynchronous loop as *note asyncore: b, and the two types of
channel, *note asyncore.dispatcher: 821. and *note asynchat.async_chat:
4b3, can freely be mixed in the channel map.  Typically an *note
asyncore.dispatcher: 821. server channel generates new *note
asynchat.async_chat: 4b3. channel objects as it receives incoming
connection requests.

 -- Class: asynchat.async_chat

     This class is an abstract subclass of *note asyncore.dispatcher:
     821.  To make practical use of the code you must subclass *note
     async_chat: 4b3, providing meaningful *note
     collect_incoming_data(): 2065. and *note found_terminator(): 2066.
     methods.  The *note asyncore.dispatcher: 821. methods can be used,
     although not all make sense in a message/response context.

     Like *note asyncore.dispatcher: 821, *note async_chat: 4b3. defines
     a set of events that are generated by an analysis of socket
     conditions after a ‘select()’ call.  Once the polling loop has been
     started the *note async_chat: 4b3. object’s methods are called by
     the event-processing framework with no action on the part of the
     programmer.

     Two class attributes can be modified, to improve performance, or
     possibly even to conserve memory.

      -- Data: ac_in_buffer_size

          The asynchronous input buffer size (default ‘4096’).

      -- Data: ac_out_buffer_size

          The asynchronous output buffer size (default ‘4096’).

     Unlike *note asyncore.dispatcher: 821, *note async_chat: 4b3.
     allows you to define a first-in-first-out queue (fifo) of
     `producers'.  A producer need have only one method, ‘more()’, which
     should return data to be transmitted on the channel.  The producer
     indicates exhaustion (`i.e.'  that it contains no more data) by
     having its ‘more()’ method return the empty bytes object.  At this
     point the *note async_chat: 4b3. object removes the producer from
     the fifo and starts using the next producer, if any.  When the
     producer fifo is empty the ‘handle_write()’ method does nothing.
     You use the channel object’s *note set_terminator(): 2069. method
     to describe how to recognize the end of, or an important breakpoint
     in, an incoming transmission from the remote endpoint.

     To build a functioning *note async_chat: 4b3. subclass your input
     methods *note collect_incoming_data(): 2065. and *note
     found_terminator(): 2066. must handle the data that the channel
     receives asynchronously.  The methods are described below.

 -- Method: async_chat.close_when_done ()

     Pushes a ‘None’ on to the producer fifo.  When this producer is
     popped off the fifo it causes the channel to be closed.

 -- Method: async_chat.collect_incoming_data (data)

     Called with `data' holding an arbitrary amount of received data.
     The default method, which must be overridden, raises a *note
     NotImplementedError: 569. exception.

 -- Method: async_chat.discard_buffers ()

     In emergencies this method will discard any data held in the input
     and/or output buffers and the producer fifo.

 -- Method: async_chat.found_terminator ()

     Called when the incoming data stream matches the termination
     condition set by *note set_terminator(): 2069.  The default method,
     which must be overridden, raises a *note NotImplementedError: 569.
     exception.  The buffered input data should be available via an
     instance attribute.

 -- Method: async_chat.get_terminator ()

     Returns the current terminator for the channel.

 -- Method: async_chat.push (data)

     Pushes data on to the channel’s fifo to ensure its transmission.
     This is all you need to do to have the channel write the data out
     to the network, although it is possible to use your own producers
     in more complex schemes to implement encryption and chunking, for
     example.

 -- Method: async_chat.push_with_producer (producer)

     Takes a producer object and adds it to the producer fifo associated
     with the channel.  When all currently-pushed producers have been
     exhausted the channel will consume this producer’s data by calling
     its ‘more()’ method and send the data to the remote endpoint.

 -- Method: async_chat.set_terminator (term)

     Sets the terminating condition to be recognized on the channel.
     ‘term’ may be any of three types of value, corresponding to three
     different ways to handle incoming protocol data.

     term            Description
                     
     ------------------------------------------------------------------
                     
     `string'        Will call *note found_terminator(): 2066. when
                     the string is found in the input stream
                     
                     
     `integer'       Will call *note found_terminator(): 2066. when
                     the indicated number of characters have been
                     received
                     
                     
     ‘None’          The channel continues to collect data forever
                     

     Note that any data following the terminator will be available for
     reading by the channel after *note found_terminator(): 2066. is
     called.

* Menu:

* asynchat Example:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/asynchat.py


File: python.info,  Node: asynchat Example,  Up: asynchat --- Asynchronous socket command/response handler

5.18.7.1 asynchat Example
.........................

The following partial example shows how HTTP requests can be read with
*note async_chat: 4b3.  A web server might create an
‘http_request_handler’ object for each incoming client connection.
Notice that initially the channel terminator is set to match the blank
line at the end of the HTTP headers, and a flag indicates that the
headers are being read.

Once the headers have been read, if the request is of type POST
(indicating that further data are present in the input stream) then the
‘Content-Length:’ header is used to set a numeric terminator to read the
right amount of data from the channel.

The ‘handle_request()’ method is called once all relevant input has been
marshalled, after setting the channel terminator to ‘None’ to ensure
that any extraneous data sent by the web client are ignored.

     import asynchat

     class http_request_handler(asynchat.async_chat):

         def __init__(self, sock, addr, sessions, log):
             asynchat.async_chat.__init__(self, sock=sock)
             self.addr = addr
             self.sessions = sessions
             self.ibuffer = []
             self.obuffer = b""
             self.set_terminator(b"\r\n\r\n")
             self.reading_headers = True
             self.handling = False
             self.cgi_data = None
             self.log = log

         def collect_incoming_data(self, data):
             """Buffer the data"""
             self.ibuffer.append(data)

         def found_terminator(self):
             if self.reading_headers:
                 self.reading_headers = False
                 self.parse_headers(b"".join(self.ibuffer))
                 self.ibuffer = []
                 if self.op.upper() == b"POST":
                     clen = self.headers.getheader("content-length")
                     self.set_terminator(int(clen))
                 else:
                     self.handling = True
                     self.set_terminator(None)
                     self.handle_request()
             elif not self.handling:
                 self.set_terminator(None) # browsers sometimes over-send
                 self.cgi_data = parse(self.headers, b"".join(self.ibuffer))
                 self.handling = True
                 self.ibuffer = []
                 self.handle_request()


File: python.info,  Node: signal --- Set handlers for asynchronous events,  Next: mmap --- Memory-mapped file support,  Prev: asynchat --- Asynchronous socket command/response handler,  Up: Interprocess Communication and Networking

5.18.8 ‘signal’ — Set handlers for asynchronous events
------------------------------------------------------

This module provides mechanisms to use signal handlers in Python.

* Menu:

* General rules:: 
* Module contents: Module contents<2>. 
* Example: Example<8>. 


File: python.info,  Node: General rules,  Next: Module contents<2>,  Up: signal --- Set handlers for asynchronous events

5.18.8.1 General rules
......................

The *note signal.signal(): 6b5. function allows defining custom handlers
to be executed when a signal is received.  A small number of default
handlers are installed: ‘SIGPIPE’ is ignored (so write errors on pipes
and sockets can be reported as ordinary Python exceptions) and ‘SIGINT’
is translated into a *note KeyboardInterrupt: 1a3. exception.

A handler for a particular signal, once set, remains installed until it
is explicitly reset (Python emulates the BSD style interface regardless
of the underlying implementation), with the exception of the handler for
‘SIGCHLD’, which follows the underlying implementation.

* Menu:

* Execution of Python signal handlers:: 
* Signals and threads:: 


File: python.info,  Node: Execution of Python signal handlers,  Next: Signals and threads,  Up: General rules

5.18.8.2 Execution of Python signal handlers
............................................

A Python signal handler does not get executed inside the low-level (C)
signal handler.  Instead, the low-level signal handler sets a flag which
tells the *note virtual machine: 2075. to execute the corresponding
Python signal handler at a later point(for example at the next *note
bytecode: d06. instruction).  This has consequences:

   * It makes little sense to catch synchronous errors like ‘SIGFPE’ or
     ‘SIGSEGV’ that are caused by an invalid operation in C code.
     Python will return from the signal handler to the C code, which is
     likely to raise the same signal again, causing Python to apparently
     hang.  From Python 3.3 onwards, you can use the *note faulthandler:
     7b. module to report on synchronous errors.

   * A long-running calculation implemented purely in C (such as regular
     expression matching on a large body of text) may run uninterrupted
     for an arbitrary amount of time, regardless of any signals
     received.  The Python signal handlers will be called when the
     calculation finishes.


File: python.info,  Node: Signals and threads,  Prev: Execution of Python signal handlers,  Up: General rules

5.18.8.3 Signals and threads
............................

Python signal handlers are always executed in the main Python thread,
even if the signal was received in another thread.  This means that
signals can’t be used as a means of inter-thread communication.  You can
use the synchronization primitives from the *note threading: 106. module
instead.

Besides, only the main thread is allowed to set a new signal handler.


File: python.info,  Node: Module contents<2>,  Next: Example<8>,  Prev: General rules,  Up: signal --- Set handlers for asynchronous events

5.18.8.4 Module contents
........................

Changed in version 3.5: signal (SIG*), handler (*note SIG_DFL: 2079,
*note SIG_IGN: 207a.) and sigmask (*note SIG_BLOCK: 207b, *note
SIG_UNBLOCK: 207c, *note SIG_SETMASK: 207d.) related constants listed
below were turned into *note enums: 1393.  *note getsignal(): 207e,
*note pthread_sigmask(): 6b1, *note sigpending(): 6b3. and *note
sigwait(): 6b4. functions return human-readable *note enums: 1393.

The variables defined in the *note signal: e8. module are:

 -- Data: signal.SIG_DFL

     This is one of two standard signal handling options; it will simply
     perform the default function for the signal.  For example, on most
     systems the default action for ‘SIGQUIT’ is to dump core and exit,
     while the default action for ‘SIGCHLD’ is to simply ignore it.

 -- Data: signal.SIG_IGN

     This is another standard signal handler, which will simply ignore
     the given signal.

 -- Data: SIG*

     All the signal numbers are defined symbolically.  For example, the
     hangup signal is defined as ‘signal.SIGHUP’; the variable names are
     identical to the names used in C programs, as found in
     ‘<signal.h>’.  The Unix man page for ’‘signal()’’ lists the
     existing signals (on some systems this is ‘signal(2)’, on others
     the list is in ‘signal(7)’).  Note that not all systems define the
     same set of signal names; only those names defined by the system
     are defined by this module.

 -- Data: signal.CTRL_C_EVENT

     The signal corresponding to the ‘Ctrl+C’ keystroke event.  This
     signal can only be used with *note os.kill(): 96e.

     Availability: Windows.

     New in version 3.2.

 -- Data: signal.CTRL_BREAK_EVENT

     The signal corresponding to the ‘Ctrl+Break’ keystroke event.  This
     signal can only be used with *note os.kill(): 96e.

     Availability: Windows.

     New in version 3.2.

 -- Data: signal.NSIG

     One more than the number of the highest signal number.

 -- Data: signal.ITIMER_REAL

     Decrements interval timer in real time, and delivers ‘SIGALRM’ upon
     expiration.

 -- Data: signal.ITIMER_VIRTUAL

     Decrements interval timer only when the process is executing, and
     delivers SIGVTALRM upon expiration.

 -- Data: signal.ITIMER_PROF

     Decrements interval timer both when the process executes and when
     the system is executing on behalf of the process.  Coupled with
     ITIMER_VIRTUAL, this timer is usually used to profile the time
     spent by the application in user and kernel space.  SIGPROF is
     delivered upon expiration.

 -- Data: signal.SIG_BLOCK

     A possible value for the `how' parameter to *note
     pthread_sigmask(): 6b1. indicating that signals are to be blocked.

     New in version 3.3.

 -- Data: signal.SIG_UNBLOCK

     A possible value for the `how' parameter to *note
     pthread_sigmask(): 6b1. indicating that signals are to be
     unblocked.

     New in version 3.3.

 -- Data: signal.SIG_SETMASK

     A possible value for the `how' parameter to *note
     pthread_sigmask(): 6b1. indicating that the signal mask is to be
     replaced.

     New in version 3.3.

The *note signal: e8. module defines one exception:

 -- Exception: signal.ItimerError

     Raised to signal an error from the underlying *note setitimer():
     2084. or *note getitimer(): 2085. implementation.  Expect this
     error if an invalid interval timer or a negative time is passed to
     *note setitimer(): 2084.  This error is a subtype of *note OSError:
     4b6.

     New in version 3.3: This error used to be a subtype of *note
     IOError: 5b0, which is now an alias of *note OSError: 4b6.

The *note signal: e8. module defines the following functions:

 -- Function: signal.alarm (time)

     If `time' is non-zero, this function requests that a ‘SIGALRM’
     signal be sent to the process in `time' seconds.  Any previously
     scheduled alarm is canceled (only one alarm can be scheduled at any
     time).  The returned value is then the number of seconds before any
     previously set alarm was to have been delivered.  If `time' is
     zero, no alarm is scheduled, and any scheduled alarm is canceled.
     If the return value is zero, no alarm is currently scheduled.  (See
     the Unix man page ‘alarm(2)’.)  Availability: Unix.

 -- Function: signal.getsignal (signalnum)

     Return the current signal handler for the signal `signalnum'.  The
     returned value may be a callable Python object, or one of the
     special values *note signal.SIG_IGN: 207a, *note signal.SIG_DFL:
     2079. or *note None: 19d.  Here, *note signal.SIG_IGN: 207a. means
     that the signal was previously ignored, *note signal.SIG_DFL: 2079.
     means that the default way of handling the signal was previously in
     use, and ‘None’ means that the previous signal handler was not
     installed from Python.

 -- Function: signal.pause ()

     Cause the process to sleep until a signal is received; the
     appropriate handler will then be called.  Returns nothing.  Not on
     Windows.  (See the Unix man page ‘signal(2)’.)

     See also *note sigwait(): 6b4, *note sigwaitinfo(): 215, *note
     sigtimedwait(): 214. and *note sigpending(): 6b3.

 -- Function: signal.pthread_kill (thread_id, signalnum)

     Send the signal `signalnum' to the thread `thread_id', another
     thread in the same process as the caller.  The target thread can be
     executing any code (Python or not).  However, if the target thread
     is executing the Python interpreter, the Python signal handlers
     will be *note executed by the main thread: 2077.  Therefore, the
     only point of sending a signal to a particular Python thread would
     be to force a running system call to fail with *note
     InterruptedError: 1e7.

     Use *note threading.get_ident(): 6e9. or the *note ident: 1cc5.
     attribute of *note threading.Thread: 4f0. objects to get a suitable
     value for `thread_id'.

     If `signalnum' is 0, then no signal is sent, but error checking is
     still performed; this can be used to check if the target thread is
     still running.

     Availability: Unix (see the man page ‘pthread_kill(3)’ for further
     information).

     See also *note os.kill(): 96e.

     New in version 3.3.

 -- Function: signal.pthread_sigmask (how, mask)

     Fetch and/or change the signal mask of the calling thread.  The
     signal mask is the set of signals whose delivery is currently
     blocked for the caller.  Return the old signal mask as a set of
     signals.

     The behavior of the call is dependent on the value of `how', as
     follows.

        * *note SIG_BLOCK: 207b.: The set of blocked signals is the
          union of the current set and the `mask' argument.

        * *note SIG_UNBLOCK: 207c.: The signals in `mask' are removed
          from the current set of blocked signals.  It is permissible to
          attempt to unblock a signal which is not blocked.

        * *note SIG_SETMASK: 207d.: The set of blocked signals is set to
          the `mask' argument.

     `mask' is a set of signal numbers (e.g.  {‘signal.SIGINT’,
     ‘signal.SIGTERM’}).  Use ‘range(1, signal.NSIG)’ for a full mask
     including all signals.

     For example, ‘signal.pthread_sigmask(signal.SIG_BLOCK, [])’ reads
     the signal mask of the calling thread.

     Availability: Unix.  See the man page ‘sigprocmask(3)’ and
     ‘pthread_sigmask(3)’ for further information.

     See also *note pause(): 2087, *note sigpending(): 6b3. and *note
     sigwait(): 6b4.

     New in version 3.3.

 -- Function: signal.setitimer (which, seconds[, interval])

     Sets given interval timer (one of *note signal.ITIMER_REAL: 2080,
     *note signal.ITIMER_VIRTUAL: 2081. or *note signal.ITIMER_PROF:
     2082.) specified by `which' to fire after `seconds' (float is
     accepted, different from *note alarm(): 2086.) and after that every
     `interval' seconds.  The interval timer specified by `which' can be
     cleared by setting seconds to zero.

     When an interval timer fires, a signal is sent to the process.  The
     signal sent is dependent on the timer being used; *note
     signal.ITIMER_REAL: 2080. will deliver ‘SIGALRM’, *note
     signal.ITIMER_VIRTUAL: 2081. sends ‘SIGVTALRM’, and *note
     signal.ITIMER_PROF: 2082. will deliver ‘SIGPROF’.

     The old values are returned as a tuple: (delay, interval).

     Attempting to pass an invalid interval timer will cause an *note
     ItimerError: 2083.  Availability: Unix.

 -- Function: signal.getitimer (which)

     Returns current value of a given interval timer specified by
     `which'.  Availability: Unix.

 -- Function: signal.set_wakeup_fd (fd)

     Set the wakeup file descriptor to `fd'.  When a signal is received,
     the signal number is written as a single byte into the fd.  This
     can be used by a library to wakeup a poll or select call, allowing
     the signal to be fully processed.

     The old wakeup fd is returned.  `fd' must be non-blocking.  It is
     up to the library to remove any bytes before calling poll or select
     again.

     Use for example ‘struct.unpack('%uB' % len(data), data)’ to decode
     the signal numbers list.

     When threads are enabled, this function can only be called from the
     main thread; attempting to call it from other threads will cause a
     *note ValueError: 19c. exception to be raised.

     Changed in version 3.5: On Windows, the function now also supports
     socket handles.

 -- Function: signal.siginterrupt (signalnum, flag)

     Change system call restart behaviour: if `flag' is *note False:
     60d, system calls will be restarted when interrupted by signal
     `signalnum', otherwise system calls will be interrupted.  Returns
     nothing.  Availability: Unix (see the man page ‘siginterrupt(3)’
     for further information).

     Note that installing a signal handler with *note signal(): e8. will
     reset the restart behaviour to interruptible by implicitly calling
     ‘siginterrupt()’ with a true `flag' value for the given signal.

 -- Function: signal.signal (signalnum, handler)

     Set the handler for signal `signalnum' to the function `handler'.
     `handler' can be a callable Python object taking two arguments (see
     below), or one of the special values *note signal.SIG_IGN: 207a. or
     *note signal.SIG_DFL: 2079.  The previous signal handler will be
     returned (see the description of *note getsignal(): 207e. above).
     (See the Unix man page ‘signal(2)’.)

     When threads are enabled, this function can only be called from the
     main thread; attempting to call it from other threads will cause a
     *note ValueError: 19c. exception to be raised.

     The `handler' is called with two arguments: the signal number and
     the current stack frame (‘None’ or a frame object; for a
     description of frame objects, see the *note description in the type
     hierarchy: df7. or see the attribute descriptions in the *note
     inspect: 9e. module).

     On Windows, *note signal(): e8. can only be called with ‘SIGABRT’,
     ‘SIGFPE’, ‘SIGILL’, ‘SIGINT’, ‘SIGSEGV’, or ‘SIGTERM’.  A *note
     ValueError: 19c. will be raised in any other case.  Note that not
     all systems define the same set of signal names; an *note
     AttributeError: 356. will be raised if a signal name is not defined
     as ‘SIG*’ module level constant.

 -- Function: signal.sigpending ()

     Examine the set of signals that are pending for delivery to the
     calling thread (i.e., the signals which have been raised while
     blocked).  Return the set of the pending signals.

     Availability: Unix (see the man page ‘sigpending(2)’ for further
     information).

     See also *note pause(): 2087, *note pthread_sigmask(): 6b1. and
     *note sigwait(): 6b4.

     New in version 3.3.

 -- Function: signal.sigwait (sigset)

     Suspend execution of the calling thread until the delivery of one
     of the signals specified in the signal set `sigset'.  The function
     accepts the signal (removes it from the pending list of signals),
     and returns the signal number.

     Availability: Unix (see the man page ‘sigwait(3)’ for further
     information).

     See also *note pause(): 2087, *note pthread_sigmask(): 6b1, *note
     sigpending(): 6b3, *note sigwaitinfo(): 215. and *note
     sigtimedwait(): 214.

     New in version 3.3.

 -- Function: signal.sigwaitinfo (sigset)

     Suspend execution of the calling thread until the delivery of one
     of the signals specified in the signal set `sigset'.  The function
     accepts the signal and removes it from the pending list of signals.
     If one of the signals in `sigset' is already pending for the
     calling thread, the function will return immediately with
     information about that signal.  The signal handler is not called
     for the delivered signal.  The function raises an *note
     InterruptedError: 1e7. if it is interrupted by a signal that is not
     in `sigset'.

     The return value is an object representing the data contained in
     the ‘siginfo_t’ structure, namely: ‘si_signo’, ‘si_code’,
     ‘si_errno’, ‘si_pid’, ‘si_uid’, ‘si_status’, ‘si_band’.

     Availability: Unix (see the man page ‘sigwaitinfo(2)’ for further
     information).

     See also *note pause(): 2087, *note sigwait(): 6b4. and *note
     sigtimedwait(): 214.

     New in version 3.3.

     Changed in version 3.5: The function is now retried if interrupted
     by a signal not in `sigset' and the signal handler does not raise
     an exception (see PEP 475(1) for the rationale).

 -- Function: signal.sigtimedwait (sigset, timeout)

     Like *note sigwaitinfo(): 215, but takes an additional `timeout'
     argument specifying a timeout.  If `timeout' is specified as ‘0’, a
     poll is performed.  Returns *note None: 19d. if a timeout occurs.

     Availability: Unix (see the man page ‘sigtimedwait(2)’ for further
     information).

     See also *note pause(): 2087, *note sigwait(): 6b4. and *note
     sigwaitinfo(): 215.

     New in version 3.3.

     Changed in version 3.5: The function is now retried with the
     recomputed `timeout' if interrupted by a signal not in `sigset' and
     the signal handler does not raise an exception (see PEP 475(2) for
     the rationale).

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475

   (2) https://www.python.org/dev/peps/pep-0475


File: python.info,  Node: Example<8>,  Prev: Module contents<2>,  Up: signal --- Set handlers for asynchronous events

5.18.8.5 Example
................

Here is a minimal example program.  It uses the *note alarm(): 2086.
function to limit the time spent waiting to open a file; this is useful
if the file is for a serial device that may not be turned on, which
would normally cause the *note os.open(): 1f4. to hang indefinitely.
The solution is to set a 5-second alarm before opening the file; if the
operation takes too long, the alarm signal will be sent, and the handler
raises an exception.

     import signal, os

     def handler(signum, frame):
         print('Signal handler called with signal', signum)
         raise OSError("Couldn't open device!")

     # Set the signal handler and a 5-second alarm
     signal.signal(signal.SIGALRM, handler)
     signal.alarm(5)

     # This open() may hang indefinitely
     fd = os.open('/dev/ttyS0', os.O_RDWR)

     signal.alarm(0)          # Disable the alarm


File: python.info,  Node: mmap --- Memory-mapped file support,  Prev: signal --- Set handlers for asynchronous events,  Up: Interprocess Communication and Networking

5.18.9 ‘mmap’ — Memory-mapped file support
------------------------------------------

Memory-mapped file objects behave like both *note bytearray: 1dc. and
like *note file objects: 78b.  You can use mmap objects in most places
where *note bytearray: 1dc. are expected; for example, you can use the
*note re: db. module to search through a memory-mapped file.  You can
also change a single byte by doing ‘obj[index] = 97’, or change a
subsequence by assigning to a slice: ‘obj[i1:i2] = b'...'’.  You can
also read and write data starting at the current file position, and
‘seek()’ through the file to different positions.

A memory-mapped file is created by the *note mmap: b2. constructor,
which is different on Unix and on Windows.  In either case you must
provide a file descriptor for a file opened for update.  If you wish to
map an existing Python file object, use its ‘fileno()’ method to obtain
the correct value for the `fileno' parameter.  Otherwise, you can open
the file using the *note os.open(): 1f4. function, which returns a file
descriptor directly (the file still needs to be closed when done).

     Note: If you want to create a memory-mapping for a writable,
     buffered file, you should *note flush(): 194a. the file first.
     This is necessary to ensure that local modifications to the buffers
     are actually available to the mapping.

For both the Unix and Windows versions of the constructor, `access' may
be specified as an optional keyword parameter.  `access' accepts one of
three values: ‘ACCESS_READ’, ‘ACCESS_WRITE’, or ‘ACCESS_COPY’ to specify
read-only, write-through or copy-on-write memory respectively.  `access'
can be used on both Unix and Windows.  If `access' is not specified,
Windows mmap returns a write-through mapping.  The initial memory values
for all three access types are taken from the specified file.
Assignment to an ‘ACCESS_READ’ memory map raises a *note TypeError: 562.
exception.  Assignment to an ‘ACCESS_WRITE’ memory map affects both
memory and the underlying file.  Assignment to an ‘ACCESS_COPY’ memory
map affects memory but does not update the underlying file.

To map anonymous memory, -1 should be passed as the fileno along with
the length.

 -- Class: mmap.mmap (fileno, length, tagname=None,
          access=ACCESS_DEFAULT[, offset])

     `(Windows version)' Maps `length' bytes from the file specified by
     the file handle `fileno', and creates a mmap object.  If `length'
     is larger than the current size of the file, the file is extended
     to contain `length' bytes.  If `length' is ‘0’, the maximum length
     of the map is the current size of the file, except that if the file
     is empty Windows raises an exception (you cannot create an empty
     mapping on Windows).

     `tagname', if specified and not ‘None’, is a string giving a tag
     name for the mapping.  Windows allows you to have many different
     mappings against the same file.  If you specify the name of an
     existing tag, that tag is opened, otherwise a new tag of this name
     is created.  If this parameter is omitted or ‘None’, the mapping is
     created without a name.  Avoiding the use of the tag parameter will
     assist in keeping your code portable between Unix and Windows.

     `offset' may be specified as a non-negative integer offset.  mmap
     references will be relative to the offset from the beginning of the
     file.  `offset' defaults to 0.  `offset' must be a multiple of the
     ALLOCATIONGRANULARITY.

 -- Class: mmap.mmap (fileno, length, flags=MAP_SHARED,
          prot=PROT_WRITE|PROT_READ, access=ACCESS_DEFAULT[, offset])

     `(Unix version)' Maps `length' bytes from the file specified by the
     file descriptor `fileno', and returns a mmap object.  If `length'
     is ‘0’, the maximum length of the map will be the current size of
     the file when *note mmap: b2. is called.

     `flags' specifies the nature of the mapping.  ‘MAP_PRIVATE’ creates
     a private copy-on-write mapping, so changes to the contents of the
     mmap object will be private to this process, and ‘MAP_SHARED’
     creates a mapping that’s shared with all other processes mapping
     the same areas of the file.  The default value is ‘MAP_SHARED’.

     `prot', if specified, gives the desired memory protection; the two
     most useful values are ‘PROT_READ’ and ‘PROT_WRITE’, to specify
     that the pages may be read or written.  `prot' defaults to
     ‘PROT_READ | PROT_WRITE’.

     `access' may be specified in lieu of `flags' and `prot' as an
     optional keyword parameter.  It is an error to specify both
     `flags', `prot' and `access'.  See the description of `access'
     above for information on how to use this parameter.

     `offset' may be specified as a non-negative integer offset.  mmap
     references will be relative to the offset from the beginning of the
     file.  `offset' defaults to 0.  `offset' must be a multiple of the
     PAGESIZE or ALLOCATIONGRANULARITY.

     To ensure validity of the created memory mapping the file specified
     by the descriptor `fileno' is internally automatically synchronized
     with physical backing store on Mac OS X and OpenVMS.

     This example shows a simple way of using *note mmap: b2.:

          import mmap

          # write a simple example file
          with open("hello.txt", "wb") as f:
              f.write(b"Hello Python!\n")

          with open("hello.txt", "r+b") as f:
              # memory-map the file, size 0 means whole file
              mm = mmap.mmap(f.fileno(), 0)
              # read content via standard file methods
              print(mm.readline())  # prints b"Hello Python!\n"
              # read content via slice notation
              print(mm[:5])  # prints b"Hello"
              # update content using slice notation;
              # note that new content must have same size
              mm[6:] = b" world!\n"
              # ... and read again using standard file methods
              mm.seek(0)
              print(mm.readline())  # prints b"Hello  world!\n"
              # close the map
              mm.close()

     *note mmap: b2. can also be used as a context manager in a *note
     with: 29d. statement.:

          import mmap

          with mmap.mmap(-1, 13) as mm:
              mm.write(b"Hello world!")

     New in version 3.2: Context manager support.

     The next example demonstrates how to create an anonymous map and
     exchange data between the parent and child processes:

          import mmap
          import os

          mm = mmap.mmap(-1, 13)
          mm.write(b"Hello world!")

          pid = os.fork()

          if pid == 0: # In a child process
              mm.seek(0)
              print(mm.readline())

              mm.close()

     Memory-mapped file objects support the following methods:

      -- Method: close ()

          Closes the mmap.  Subsequent calls to other methods of the
          object will result in a ValueError exception being raised.
          This will not close the open file.

      -- Attribute: closed

          ‘True’ if the file is closed.

          New in version 3.2.

      -- Method: find (sub[, start[, end]])

          Returns the lowest index in the object where the subsequence
          `sub' is found, such that `sub' is contained in the range
          [`start', `end'].  Optional arguments `start' and `end' are
          interpreted as in slice notation.  Returns ‘-1’ on failure.

          Changed in version 3.5: Writable *note bytes-like object: 36b.
          is now accepted.

      -- Method: flush ([offset[, size]])

          Flushes changes made to the in-memory copy of a file back to
          disk.  Without use of this call there is no guarantee that
          changes are written back before the object is destroyed.  If
          `offset' and `size' are specified, only changes to the given
          range of bytes will be flushed to disk; otherwise, the whole
          extent of the mapping is flushed.

          `(Windows version)' A nonzero value returned indicates
          success; zero indicates failure.

          `(Unix version)' A zero value is returned to indicate success.
          An exception is raised when the call failed.

      -- Method: move (dest, src, count)

          Copy the `count' bytes starting at offset `src' to the
          destination index `dest'.  If the mmap was created with
          ‘ACCESS_READ’, then calls to move will raise a *note
          TypeError: 562. exception.

      -- Method: read ([n])

          Return a *note bytes: 1db. containing up to `n' bytes starting
          from the current file position.  If the argument is omitted,
          `None' or negative, return all bytes from the current file
          position to the end of the mapping.  The file position is
          updated to point after the bytes that were returned.

          Changed in version 3.3: Argument can be omitted or `None'.

      -- Method: read_byte ()

          Returns a byte at the current file position as an integer, and
          advances the file position by 1.

      -- Method: readline ()

          Returns a single line, starting at the current file position
          and up to the next newline.

      -- Method: resize (newsize)

          Resizes the map and the underlying file, if any.  If the mmap
          was created with ‘ACCESS_READ’ or ‘ACCESS_COPY’, resizing the
          map will raise a *note TypeError: 562. exception.

      -- Method: rfind (sub[, start[, end]])

          Returns the highest index in the object where the subsequence
          `sub' is found, such that `sub' is contained in the range
          [`start', `end'].  Optional arguments `start' and `end' are
          interpreted as in slice notation.  Returns ‘-1’ on failure.

          Changed in version 3.5: Writable *note bytes-like object: 36b.
          is now accepted.

      -- Method: seek (pos[, whence])

          Set the file’s current position.  `whence' argument is
          optional and defaults to ‘os.SEEK_SET’ or ‘0’ (absolute file
          positioning); other values are ‘os.SEEK_CUR’ or ‘1’ (seek
          relative to the current position) and ‘os.SEEK_END’ or ‘2’
          (seek relative to the file’s end).

      -- Method: size ()

          Return the length of the file, which can be larger than the
          size of the memory-mapped area.

      -- Method: tell ()

          Returns the current position of the file pointer.

      -- Method: write (bytes)

          Write the bytes in `bytes' into memory at the current position
          of the file pointer and return the number of bytes written
          (never less than ‘len(bytes)’, since if the write fails, a
          *note ValueError: 19c. will be raised).  The file position is
          updated to point after the bytes that were written.  If the
          mmap was created with ‘ACCESS_READ’, then writing to it will
          raise a *note TypeError: 562. exception.

          Changed in version 3.5: Writable *note bytes-like object: 36b.
          is now accepted.

          Changed in version 3.6: The number of bytes written is now
          returned.

      -- Method: write_byte (byte)

          Write the integer `byte' into memory at the current position
          of the file pointer; the file position is advanced by ‘1’.  If
          the mmap was created with ‘ACCESS_READ’, then writing to it
          will raise a *note TypeError: 562. exception.

