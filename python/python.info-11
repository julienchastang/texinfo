This is python.info, produced by makeinfo version 6.0 from python.texi.

     Python 3.6.0a0, May 06, 2016

     Georg Brandl

     Copyright © 2001-2016, Python Software Foundation

INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.4.1.


File: python.info,  Node: Dictionary view objects,  Up: Mapping Types --- dict

5.4.10.1 Dictionary view objects
................................

The objects returned by *note dict.keys(): 88f, *note dict.values():
891. and *note dict.items(): 890. are `view objects'.  They provide a
dynamic view on the dictionary’s entries, which means that when the
dictionary changes, the view reflects these changes.

Dictionary views can be iterated over to yield their respective data,
and support membership tests:

 -- Describe: len(dictview)

     Return the number of entries in the dictionary.

 -- Describe: iter(dictview)

     Return an iterator over the keys, values or items (represented as
     tuples of ‘(key, value)’) in the dictionary.

     Keys and values are iterated over in an arbitrary order which is
     non-random, varies across Python implementations, and depends on
     the dictionary’s history of insertions and deletions.  If keys,
     values and items views are iterated over with no intervening
     modifications to the dictionary, the order of items will directly
     correspond.  This allows the creation of ‘(value, key)’ pairs using
     *note zip(): 897.: ‘pairs = zip(d.values(), d.keys())’.  Another
     way to create the same list is ‘pairs = [(v, k) for (k, v) in
     d.items()]’.

     Iterating views while adding or deleting entries in the dictionary
     may raise a *note RuntimeError: 193. or fail to iterate over all
     entries.

 -- Describe: x in dictview

     Return ‘True’ if `x' is in the underlying dictionary’s keys, values
     or items (in the latter case, `x' should be a ‘(key, value)’
     tuple).

Keys views are set-like since their entries are unique and hashable.  If
all values are hashable, so that ‘(key, value)’ pairs are unique and
hashable, then the items view is also set-like.  (Values views are not
treated as set-like since the entries are generally not unique.)  For
set-like views, all of the operations defined for the abstract base
class *note collections.abc.Set: 108e. are available (for example, ‘==’,
‘<’, or ‘^’).

An example of dictionary view usage:

     >>> dishes = {'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500}
     >>> keys = dishes.keys()
     >>> values = dishes.values()

     >>> # iteration
     >>> n = 0
     >>> for val in values:
     ...     n += val
     >>> print(n)
     504

     >>> # keys and values are iterated over in the same order
     >>> list(keys)
     ['eggs', 'bacon', 'sausage', 'spam']
     >>> list(values)
     [2, 1, 1, 500]

     >>> # view objects are dynamic and reflect dict changes
     >>> del dishes['eggs']
     >>> del dishes['sausage']
     >>> list(keys)
     ['spam', 'bacon']

     >>> # set operations
     >>> keys & {'eggs', 'bacon', 'salad'}
     {'bacon'}
     >>> keys ^ {'sausage', 'juice'}
     {'juice', 'sausage', 'bacon', 'spam'}


File: python.info,  Node: Context Manager Types,  Next: Other Built-in Types,  Prev: Mapping Types --- dict,  Up: Built-in Types

5.4.11 Context Manager Types
----------------------------

Python’s *note with: 29d. statement supports the concept of a runtime
context defined by a context manager.  This is implemented using a pair
of methods that allow user-defined classes to define a runtime context
that is entered before the statement body is executed and exited when
the statement ends:

 -- Method: contextmanager.__enter__ ()

     Enter the runtime context and return either this object or another
     object related to the runtime context.  The value returned by this
     method is bound to the identifier in the *note as: 8aa. clause of
     *note with: 29d. statements using this context manager.

     An example of a context manager that returns itself is a *note file
     object: 78b.  File objects return themselves from __enter__() to
     allow *note open(): 1e8. to be used as the context expression in a
     *note with: 29d. statement.

     An example of a context manager that returns a related object is
     the one returned by *note decimal.localcontext(): 1091.  These
     managers set the active decimal context to a copy of the original
     decimal context and then return the copy.  This allows changes to
     be made to the current decimal context in the body of the *note
     with: 29d. statement without affecting code outside the *note with:
     29d. statement.

 -- Method: contextmanager.__exit__ (exc_type, exc_val, exc_tb)

     Exit the runtime context and return a Boolean flag indicating if
     any exception that occurred should be suppressed.  If an exception
     occurred while executing the body of the *note with: 29d.
     statement, the arguments contain the exception type, value and
     traceback information.  Otherwise, all three arguments are ‘None’.

     Returning a true value from this method will cause the *note with:
     29d. statement to suppress the exception and continue execution
     with the statement immediately following the *note with: 29d.
     statement.  Otherwise the exception continues propagating after
     this method has finished executing.  Exceptions that occur during
     execution of this method will replace any exception that occurred
     in the body of the *note with: 29d. statement.

     The exception passed in should never be reraised explicitly -
     instead, this method should return a false value to indicate that
     the method completed successfully and does not want to suppress the
     raised exception.  This allows context management code to easily
     detect whether or not an *note __exit__(): 1092. method has
     actually failed.

Python defines several context managers to support easy thread
synchronisation, prompt closure of files or other objects, and simpler
manipulation of the active decimal arithmetic context.  The specific
types are not treated specially beyond their implementation of the
context management protocol.  See the *note contextlib: 24. module for
some examples.

Python’s *note generator: 5c0.s and the *note contextlib.contextmanager:
7ce. decorator provide a convenient way to implement these protocols.
If a generator function is decorated with the *note
contextlib.contextmanager: 7ce. decorator, it will return a context
manager implementing the necessary *note __enter__(): 907. and *note
__exit__(): 908. methods, rather than the iterator produced by an
undecorated generator function.

Note that there is no specific slot for any of these methods in the type
structure for Python objects in the Python/C API. Extension types
wanting to define these methods must provide them as a normal Python
accessible method.  Compared to the overhead of setting up the runtime
context, the overhead of a single class dictionary lookup is negligible.


File: python.info,  Node: Other Built-in Types,  Next: Special Attributes,  Prev: Context Manager Types,  Up: Built-in Types

5.4.12 Other Built-in Types
---------------------------

The interpreter supports several other kinds of objects.  Most of these
support only one or two operations.

* Menu:

* Modules: Modules<2>. 
* Classes and Class Instances:: 
* Functions:: 
* Methods:: 
* Code Objects:: 
* Type Objects:: 
* The Null Object:: 
* The Ellipsis Object:: 
* The NotImplemented Object:: 
* Boolean Values:: 
* Internal Objects:: 


File: python.info,  Node: Modules<2>,  Next: Classes and Class Instances,  Up: Other Built-in Types

5.4.12.1 Modules
................

The only special operation on a module is attribute access: ‘m.name’,
where `m' is a module and `name' accesses a name defined in `m'’s symbol
table.  Module attributes can be assigned to.  (Note that the *note
import: 881. statement is not, strictly speaking, an operation on a
module object; ‘import foo’ does not require a module object named `foo'
to exist, rather it requires an (external) `definition' for a module
named `foo' somewhere.)

A special attribute of every module is *note __dict__: df4.  This is the
dictionary containing the module’s symbol table.  Modifying this
dictionary will actually change the module’s symbol table, but direct
assignment to the ‘__dict__’ attribute is not possible (you can write
‘m.__dict__['a'] = 1’, which defines ‘m.a’ to be ‘1’, but you can’t
write ‘m.__dict__ = {}’).  Modifying ‘__dict__’ directly is not
recommended.

Modules built into the interpreter are written like this: ‘<module 'sys'
(built-in)>’.  If loaded from a file, they are written as ‘<module 'os'
from '/usr/local/lib/pythonX.Y/os.pyc'>’.


File: python.info,  Node: Classes and Class Instances,  Next: Functions,  Prev: Modules<2>,  Up: Other Built-in Types

5.4.12.2 Classes and Class Instances
....................................

See *note Objects, values and types: ddc. and *note Class definitions:
8d6. for these.


File: python.info,  Node: Functions,  Next: Methods,  Prev: Classes and Class Instances,  Up: Other Built-in Types

5.4.12.3 Functions
..................

Function objects are created by function definitions.  The only
operation on a function object is to call it: ‘func(argument-list)’.

There are really two flavors of function objects: built-in functions and
user-defined functions.  Both support the same operation (to call the
function), but the implementation is different, hence the different
object types.

See *note Function definitions: c1e. for more information.


File: python.info,  Node: Methods,  Next: Code Objects,  Prev: Functions,  Up: Other Built-in Types

5.4.12.4 Methods
................

Methods are functions that are called using the attribute notation.
There are two flavors: built-in methods (such as ‘append()’ on lists)
and class instance methods.  Built-in methods are described with the
types that support them.

If you access a method (a function defined in a class namespace) through
an instance, you get a special object: a `bound method' (also called
`instance method') object.  When called, it will add the ‘self’ argument
to the argument list.  Bound methods have two special read-only
attributes: ‘m.__self__’ is the object on which the method operates, and
‘m.__func__’ is the function implementing the method.  Calling ‘m(arg-1,
arg-2, ..., arg-n)’ is completely equivalent to calling
‘m.__func__(m.__self__, arg-1, arg-2, ..., arg-n)’.

Like function objects, bound method objects support getting arbitrary
attributes.  However, since method attributes are actually stored on the
underlying function object (‘meth.__func__’), setting method attributes
on bound methods is disallowed.  Attempting to set an attribute on a
method results in an *note AttributeError: 356. being raised.  In order
to set a method attribute, you need to explicitly set it on the
underlying function object:

     >>> class C:
     ...     def method(self):
     ...         pass
     ...
     >>> c = C()
     >>> c.method.whoami = 'my name is method'  # can't set on the method
     Traceback (most recent call last):
       File "<stdin>", line 1, in <module>
     AttributeError: 'method' object has no attribute 'whoami'
     >>> c.method.__func__.whoami = 'my name is method'
     >>> c.method.whoami
     'my name is method'

See *note The standard type hierarchy: de0. for more information.


File: python.info,  Node: Code Objects,  Next: Type Objects,  Prev: Methods,  Up: Other Built-in Types

5.4.12.5 Code Objects
.....................

Code objects are used by the implementation to represent
"pseudo-compiled" executable Python code such as a function body.  They
differ from function objects because they don’t contain a reference to
their global execution environment.  Code objects are returned by the
built-in *note compile(): 903. function and can be extracted from
function objects through their ‘__code__’ attribute.  See also the *note
code: 1b. module.

A code object can be executed or evaluated by passing it (instead of a
source string) to the *note exec(): 8ac. or *note eval(): 7e8. built-in
functions.

See *note The standard type hierarchy: de0. for more information.


File: python.info,  Node: Type Objects,  Next: The Null Object,  Prev: Code Objects,  Up: Other Built-in Types

5.4.12.6 Type Objects
.....................

Type objects represent the various object types.  An object’s type is
accessed by the built-in function *note type(): 376.  There are no
special operations on types.  The standard module *note types: 115.
defines names for all standard built-in types.

Types are written like this: ‘<class 'int'>’.


File: python.info,  Node: The Null Object,  Next: The Ellipsis Object,  Prev: Type Objects,  Up: Other Built-in Types

5.4.12.7 The Null Object
........................

This object is returned by functions that don’t explicitly return a
value.  It supports no special operations.  There is exactly one null
object, named ‘None’ (a built-in name).  ‘type(None)()’ produces the
same singleton.

It is written as ‘None’.


File: python.info,  Node: The Ellipsis Object,  Next: The NotImplemented Object,  Prev: The Null Object,  Up: Other Built-in Types

5.4.12.8 The Ellipsis Object
............................

This object is commonly used by slicing (see *note Slicings: ed5.).  It
supports no special operations.  There is exactly one ellipsis object,
named *note Ellipsis: fc2. (a built-in name).  ‘type(Ellipsis)()’
produces the *note Ellipsis: fc2. singleton.

It is written as ‘Ellipsis’ or ‘...’.


File: python.info,  Node: The NotImplemented Object,  Next: Boolean Values,  Prev: The Ellipsis Object,  Up: Other Built-in Types

5.4.12.9 The NotImplemented Object
..................................

This object is returned from comparisons and binary operations when they
are asked to operate on types they don’t support.  See *note
Comparisons: efc. for more information.  There is exactly one
‘NotImplemented’ object.  ‘type(NotImplemented)()’ produces the
singleton instance.

It is written as ‘NotImplemented’.


File: python.info,  Node: Boolean Values,  Next: Internal Objects,  Prev: The NotImplemented Object,  Up: Other Built-in Types

5.4.12.10 Boolean Values
........................

Boolean values are the two constant objects ‘False’ and ‘True’.  They
are used to represent truth values (although other values can also be
considered false or true).  In numeric contexts (for example when used
as the argument to an arithmetic operator), they behave like the
integers 0 and 1, respectively.  The built-in function *note bool():
a72. can be used to convert any value to a Boolean, if the value can be
interpreted as a truth value (see section *note Truth Value Testing:
f9a. above).

They are written as ‘False’ and ‘True’, respectively.


File: python.info,  Node: Internal Objects,  Prev: Boolean Values,  Up: Other Built-in Types

5.4.12.11 Internal Objects
..........................

See *note The standard type hierarchy: de0. for this information.  It
describes stack frame objects, traceback objects, and slice objects.


File: python.info,  Node: Special Attributes,  Prev: Other Built-in Types,  Up: Built-in Types

5.4.13 Special Attributes
-------------------------

The implementation adds a few special read-only attributes to several
object types, where they are relevant.  Some of these are not reported
by the *note dir(): 16a. built-in function.

 -- Attribute: object.__dict__

     A dictionary or other mapping object used to store an object’s
     (writable) attributes.

 -- Attribute: instance.__class__

     The class to which a class instance belongs.

 -- Attribute: class.__bases__

     The tuple of base classes of a class object.

 -- Attribute: class.__name__

     The name of the class or type.

 -- Attribute: class.__qualname__

     The *note qualified name: dec. of the class or type.

     New in version 3.3.

 -- Attribute: class.__mro__

     This attribute is a tuple of classes that are considered when
     looking for base classes during method resolution.

 -- Method: class.mro ()

     This method can be overridden by a metaclass to customize the
     method resolution order for its instances.  It is called at class
     instantiation, and its result is stored in *note __mro__: fbb.

 -- Method: class.__subclasses__ ()

     Each class keeps a list of weak references to its immediate
     subclasses.  This method returns a list of all those references
     still alive.  Example:

          >>> int.__subclasses__()
          [<class 'bool'>]


File: python.info,  Node: Built-in Exceptions,  Next: Text Processing Services,  Prev: Built-in Types,  Up: The Python Standard Library

5.5 Built-in Exceptions
=======================

In Python, all exceptions must be instances of a class that derives from
*note BaseException: 8c9.  In a *note try: 9e9. statement with an *note
except: 785. clause that mentions a particular class, that clause also
handles any exception classes derived from that class (but not exception
classes from which `it' is derived).  Two exception classes that are not
related via subclassing are never equivalent, even if they have the same
name.

The built-in exceptions listed below can be generated by the interpreter
or built-in functions.  Except where mentioned, they have an "associated
value" indicating the detailed cause of the error.  This may be a string
or a tuple of several items of information (e.g., an error code and a
string explaining the code).  The associated value is usually passed as
arguments to the exception class’s constructor.

User code can raise built-in exceptions.  This can be used to test an
exception handler or to report an error condition "just like" the
situation in which the interpreter raises the same exception; but beware
that there is nothing to prevent user code from raising an inappropriate
error.

The built-in exception classes can be subclassed to define new
exceptions; programmers are encouraged to derive new exceptions from the
*note Exception: 1a1. class or one of its subclasses, and not from *note
BaseException: 8c9.  More information on defining exceptions is
available in the Python Tutorial under *note User-defined Exceptions:
c6f.

When raising (or re-raising) an exception in an *note except: 785. or
*note finally: 526. clause ‘__context__’ is automatically set to the
last exception caught; if the new exception is not handled the traceback
that is eventually displayed will include the originating exception(s)
and the final exception.

When raising a new exception (rather than using a bare ‘raise’ to
re-raise the exception currently being handled), the implicit exception
context can be supplemented with an explicit cause by using *note from:
8ad. with *note raise: 8a9.:

     raise new_exc from original_exc

The expression following *note from: 8ad. must be an exception or
‘None’.  It will be set as ‘__cause__’ on the raised exception.  Setting
‘__cause__’ also implicitly sets the ‘__suppress_context__’ attribute to
‘True’, so that using ‘raise new_exc from None’ effectively replaces the
old exception with the new one for display purposes (e.g.  converting
*note KeyError: 1a7. to *note AttributeError: 356, while leaving the old
exception available in ‘__context__’ for introspection when debugging.

The default traceback display code shows these chained exceptions in
addition to the traceback for the exception itself.  An explicitly
chained exception in ‘__cause__’ is always shown when present.  An
implicitly chained exception in ‘__context__’ is shown only if
‘__cause__’ is *note None: 19d. and ‘__suppress_context__’ is false.

In either case, the exception itself is always shown after any chained
exceptions so that the final line of the traceback always shows the last
exception that was raised.

* Menu:

* Base classes:: 
* Concrete exceptions:: 
* Warnings:: 
* Exception hierarchy:: 


File: python.info,  Node: Base classes,  Next: Concrete exceptions,  Up: Built-in Exceptions

5.5.1 Base classes
------------------

The following exceptions are used mostly as base classes for other
exceptions.

 -- Exception: BaseException

     The base class for all built-in exceptions.  It is not meant to be
     directly inherited by user-defined classes (for that, use *note
     Exception: 1a1.).  If *note str(): 25a. is called on an instance of
     this class, the representation of the argument(s) to the instance
     are returned, or the empty string when there were no arguments.

      -- Attribute: args

          The tuple of arguments given to the exception constructor.
          Some built-in exceptions (like *note OSError: 4b6.) expect a
          certain number of arguments and assign a special meaning to
          the elements of this tuple, while others are usually called
          only with a single string giving an error message.

      -- Method: with_traceback (tb)

          This method sets `tb' as the new traceback for the exception
          and returns the exception object.  It is usually used in
          exception handling code like this:

               try:
                   ...
               except SomeException:
                   tb = sys.exc_info()[2]
                   raise OtherException(...).with_traceback(tb)

 -- Exception: Exception

     All built-in, non-system-exiting exceptions are derived from this
     class.  All user-defined exceptions should also be derived from
     this class.

 -- Exception: ArithmeticError

     The base class for those built-in exceptions that are raised for
     various arithmetic errors: *note OverflowError: 578, *note
     ZeroDivisionError: c6a, *note FloatingPointError: 10b4.

 -- Exception: BufferError

     Raised when a *note buffer: ff5. related operation cannot be
     performed.

 -- Exception: LookupError

     The base class for the exceptions that are raised when a key or
     index used on a mapping or sequence is invalid: *note IndexError:
     afb, *note KeyError: 1a7.  This can be raised directly by *note
     codecs.lookup(): 10b6.


File: python.info,  Node: Concrete exceptions,  Next: Warnings,  Prev: Base classes,  Up: Built-in Exceptions

5.5.2 Concrete exceptions
-------------------------

The following exceptions are the exceptions that are usually raised.

 -- Exception: AssertionError

     Raised when an *note assert: a87. statement fails.

 -- Exception: AttributeError

     Raised when an attribute reference (see *note Attribute references:
     ecf.) or assignment fails.  (When an object does not support
     attribute references or attribute assignments at all, *note
     TypeError: 562. is raised.)

 -- Exception: EOFError

     Raised when the *note input(): 8d7. function hits an end-of-file
     condition (EOF) without reading any data.  (N.B.: the
     ‘io.IOBase.read()’ and *note io.IOBase.readline(): 10b8. methods
     return an empty string when they hit EOF.)

 -- Exception: FloatingPointError

     Raised when a floating point operation fails.  This exception is
     always defined, but can only be raised when Python is configured
     with the ‘--with-fpectl’ option, or the ‘WANT_SIGFPE_HANDLER’
     symbol is defined in the ‘pyconfig.h’ file.

 -- Exception: GeneratorExit

     Raised when a *note generator: 5c0. or *note coroutine: 2ad. is
     closed; see *note generator.close(): e58. and *note
     coroutine.close(): e57.  It directly inherits from *note
     BaseException: 8c9. instead of *note Exception: 1a1. since it is
     technically not an error.

 -- Exception: ImportError

     Raised when an *note import: 881. statement fails to find the
     module definition or when a ‘from ... import’ fails to find a name
     that is to be imported.

     The ‘name’ and ‘path’ attributes can be set using keyword-only
     arguments to the constructor.  When set they represent the name of
     the module that was attempted to be imported and the path to any
     file which triggered the exception, respectively.

     Changed in version 3.3: Added the ‘name’ and ‘path’ attributes.

 -- Exception: IndexError

     Raised when a sequence subscript is out of range.  (Slice indices
     are silently truncated to fall in the allowed range; if an index is
     not an integer, *note TypeError: 562. is raised.)

 -- Exception: KeyError

     Raised when a mapping (dictionary) key is not found in the set of
     existing keys.

 -- Exception: KeyboardInterrupt

     Raised when the user hits the interrupt key (normally ‘Control-C’
     or ‘Delete’).  During execution, a check for interrupts is made
     regularly.  The exception inherits from *note BaseException: 8c9.
     so as to not be accidentally caught by code that catches *note
     Exception: 1a1. and thus prevent the interpreter from exiting.

 -- Exception: MemoryError

     Raised when an operation runs out of memory but the situation may
     still be rescued (by deleting some objects).  The associated value
     is a string indicating what kind of (internal) operation ran out of
     memory.  Note that because of the underlying memory management
     architecture (C’s ‘malloc()’ function), the interpreter may not
     always be able to completely recover from this situation; it
     nevertheless raises an exception so that a stack traceback can be
     printed, in case a run-away program was the cause.

 -- Exception: NameError

     Raised when a local or global name is not found.  This applies only
     to unqualified names.  The associated value is an error message
     that includes the name that could not be found.

 -- Exception: NotImplementedError

     This exception is derived from *note RuntimeError: 193.  In user
     defined base classes, abstract methods should raise this exception
     when they require derived classes to override the method.

 -- Exception: OSError ([arg])

 -- Exception: OSError (errno, strerror[, filename[, winerror[,
          filename2]]])

     This exception is raised when a system function returns a
     system-related error, including I/O failures such as "file not
     found" or "disk full" (not for illegal argument types or other
     incidental errors).

     The second form of the constructor sets the corresponding
     attributes, described below.  The attributes default to *note None:
     19d. if not specified.  For backwards compatibility, if three
     arguments are passed, the *note args: 10b1. attribute contains only
     a 2-tuple of the first two constructor arguments.

     The constructor often actually returns a subclass of *note OSError:
     4b6, as described in *note OS exceptions: 10ba. below.  The
     particular subclass depends on the final *note errno: 10bb. value.
     This behaviour only occurs when constructing *note OSError: 4b6.
     directly or via an alias, and is not inherited when subclassing.

      -- Attribute: errno

          A numeric error code from the C variable ‘errno’.

      -- Attribute: winerror

          Under Windows, this gives you the native Windows error code.
          The *note errno: 10bb. attribute is then an approximate
          translation, in POSIX terms, of that native error code.

          Under Windows, if the `winerror' constructor argument is an
          integer, the *note errno: 10bb. attribute is determined from
          the Windows error code, and the `errno' argument is ignored.
          On other platforms, the `winerror' argument is ignored, and
          the *note winerror: 10bc. attribute does not exist.

      -- Attribute: strerror

          The corresponding error message, as provided by the operating
          system.  It is formatted by the C functions ‘perror()’ under
          POSIX, and ‘FormatMessage()’ under Windows.

      -- Attribute: filename
      -- Attribute: filename2

          For exceptions that involve a file system path (such as *note
          open(): 1e8. or *note os.unlink(): 670.), *note filename:
          10be. is the file name passed to the function.  For functions
          that involve two file system paths (such as *note os.rename():
          66c.), *note filename2: 10bf. corresponds to the second file
          name passed to the function.

     Changed in version 3.3: *note EnvironmentError: 5b1, *note IOError:
     5b0, *note WindowsError: 5b2, *note socket.error: 5b3, *note
     select.error: 5b4. and ‘mmap.error’ have been merged into *note
     OSError: 4b6, and the constructor may return a subclass.

     Changed in version 3.4: The *note filename: 10be. attribute is now
     the original file name passed to the function, instead of the name
     encoded to or decoded from the filesystem encoding.  Also, the
     `filename2' constructor argument and attribute was added.

 -- Exception: OverflowError

     Raised when the result of an arithmetic operation is too large to
     be represented.  This cannot occur for integers (which would rather
     raise *note MemoryError: 10b9. than give up).  However, for
     historical reasons, OverflowError is sometimes raised for integers
     that are outside a required range.  Because of the lack of
     standardization of floating point exception handling in C, most
     floating point operations are not checked.

 -- Exception: RecursionError

     This exception is derived from *note RuntimeError: 193.  It is
     raised when the interpreter detects that the maximum recursion
     depth (see *note sys.getrecursionlimit(): b00.) is exceeded.

     New in version 3.5: Previously, a plain *note RuntimeError: 193.
     was raised.

 -- Exception: ReferenceError

     This exception is raised when a weak reference proxy, created by
     the *note weakref.proxy(): 10c0. function, is used to access an
     attribute of the referent after it has been garbage collected.  For
     more information on weak references, see the *note weakref: 125.
     module.

 -- Exception: RuntimeError

     Raised when an error is detected that doesn’t fall in any of the
     other categories.  The associated value is a string indicating what
     precisely went wrong.

 -- Exception: StopIteration

     Raised by built-in function *note next(): 218. and an *note
     iterator: e4f.’s *note __next__(): 8cf. method to signal that there
     are no further items produced by the iterator.

     The exception object has a single attribute ‘value’, which is given
     as an argument when constructing the exception, and defaults to
     *note None: 19d.

     When a *note generator: 5c0. or *note coroutine: 2ad. function
     returns, a new *note StopIteration: 191. instance is raised, and
     the value returned by the function is used as the ‘value’ parameter
     to the constructor of the exception.

     If a generator function defined in the presence of a ‘from
     __future__ import generator_stop’ directive raises *note
     StopIteration: 191, it will be converted into a *note RuntimeError:
     193. (retaining the *note StopIteration: 191. as the new
     exception’s cause).

     Changed in version 3.3: Added ‘value’ attribute and the ability for
     generator functions to use it to return a value.

     Changed in version 3.5: Introduced the RuntimeError transformation.

 -- Exception: StopAsyncIteration

     Must be raised by *note __anext__(): e5b. method of an *note
     asynchronous iterator: f76. object to stop the iteration.

     New in version 3.5.

 -- Exception: SyntaxError

     Raised when the parser encounters a syntax error.  This may occur
     in an *note import: 881. statement, in a call to the built-in
     functions *note exec(): 8ac. or *note eval(): 7e8, or when reading
     the initial script or standard input (also interactively).

     Instances of this class have attributes ‘filename’, ‘lineno’,
     ‘offset’ and ‘text’ for easier access to the details.  *note str():
     25a. of the exception instance returns only the message.

 -- Exception: IndentationError

     Base class for syntax errors related to incorrect indentation.
     This is a subclass of *note SyntaxError: 3a6.

 -- Exception: TabError

     Raised when indentation contains an inconsistent use of tabs and
     spaces.  This is a subclass of *note IndentationError: afe.

 -- Exception: SystemError

     Raised when the interpreter finds an internal error, but the
     situation does not look so serious to cause it to abandon all hope.
     The associated value is a string indicating what went wrong (in
     low-level terms).

     You should report this to the author or maintainer of your Python
     interpreter.  Be sure to report the version of the Python
     interpreter (‘sys.version’; it is also printed at the start of an
     interactive Python session), the exact error message (the
     exception’s associated value) and if possible the source of the
     program that triggered the error.

 -- Exception: SystemExit

     This exception is raised by the *note sys.exit(): 95a. function.
     It inherits from *note BaseException: 8c9. instead of *note
     Exception: 1a1. so that it is not accidentally caught by code that
     catches *note Exception: 1a1.  This allows the exception to
     properly propagate up and cause the interpreter to exit.  When it
     is not handled, the Python interpreter exits; no stack traceback is
     printed.  The constructor accepts the same optional argument passed
     to *note sys.exit(): 95a.  If the value is an integer, it specifies
     the system exit status (passed to C’s ‘exit()’ function); if it is
     ‘None’, the exit status is zero; if it has another type (such as a
     string), the object’s value is printed and the exit status is one.

     A call to *note sys.exit(): 95a. is translated into an exception so
     that clean-up handlers (*note finally: 526. clauses of *note try:
     9e9. statements) can be executed, and so that a debugger can
     execute a script without running the risk of losing control.  The
     *note os._exit(): 10c1. function can be used if it is absolutely
     positively necessary to exit immediately (for example, in the child
     process after a call to *note os.fork(): 57b.).

      -- Attribute: code

          The exit status or error message that is passed to the
          constructor.  (Defaults to ‘None’.)

 -- Exception: TypeError

     Raised when an operation or function is applied to an object of
     inappropriate type.  The associated value is a string giving
     details about the type mismatch.

 -- Exception: UnboundLocalError

     Raised when a reference is made to a local variable in a function
     or method, but no value has been bound to that variable.  This is a
     subclass of *note NameError: 9f2.

 -- Exception: UnicodeError

     Raised when a Unicode-related encoding or decoding error occurs.
     It is a subclass of *note ValueError: 19c.

     *note UnicodeError: 8a2. has attributes that describe the encoding
     or decoding error.  For example, ‘err.object[err.start:err.end]’
     gives the particular invalid input that the codec failed on.

      -- Attribute: encoding

          The name of the encoding that raised the error.

      -- Attribute: reason

          A string describing the specific codec error.

      -- Attribute: object

          The object the codec was attempting to encode or decode.

      -- Attribute: start

          The first index of invalid data in *note object: 5cb.

      -- Attribute: end

          The index after the last invalid data in *note object: 5cb.

 -- Exception: UnicodeEncodeError

     Raised when a Unicode-related error occurs during encoding.  It is
     a subclass of *note UnicodeError: 8a2.

 -- Exception: UnicodeDecodeError

     Raised when a Unicode-related error occurs during decoding.  It is
     a subclass of *note UnicodeError: 8a2.

 -- Exception: UnicodeTranslateError

     Raised when a Unicode-related error occurs during translating.  It
     is a subclass of *note UnicodeError: 8a2.

 -- Exception: ValueError

     Raised when a built-in operation or function receives an argument
     that has the right type but an inappropriate value, and the
     situation is not described by a more precise exception such as
     *note IndexError: afb.

 -- Exception: ZeroDivisionError

     Raised when the second argument of a division or modulo operation
     is zero.  The associated value is a string indicating the type of
     the operands and the operation.

The following exceptions are kept for compatibility with previous
versions; starting from Python 3.3, they are aliases of *note OSError:
4b6.

 -- Exception: EnvironmentError

 -- Exception: IOError

 -- Exception: WindowsError

     Only available on Windows.

* Menu:

* OS exceptions:: 


File: python.info,  Node: OS exceptions,  Up: Concrete exceptions

5.5.2.1 OS exceptions
.....................

The following exceptions are subclasses of *note OSError: 4b6, they get
raised depending on the system error code.

 -- Exception: BlockingIOError

     Raised when an operation would block on an object (e.g.  socket)
     set for non-blocking operation.  Corresponds to ‘errno’ ‘EAGAIN’,
     ‘EALREADY’, ‘EWOULDBLOCK’ and ‘EINPROGRESS’.

     In addition to those of *note OSError: 4b6, *note BlockingIOError:
     5b5. can have one more attribute:

      -- Attribute: characters_written

          An integer containing the number of characters written to the
          stream before it blocked.  This attribute is available when
          using the buffered I/O classes from the *note io: 9f. module.

 -- Exception: ChildProcessError

     Raised when an operation on a child process failed.  Corresponds to
     ‘errno’ ‘ECHILD’.

 -- Exception: ConnectionError

     A base class for connection-related issues.

     Subclasses are *note BrokenPipeError: 5bb, *note
     ConnectionAbortedError: 5bc, *note ConnectionRefusedError: 5bd. and
     *note ConnectionResetError: 5be.

 -- Exception: BrokenPipeError

     A subclass of *note ConnectionError: 299, raised when trying to
     write on a pipe while the other end has been closed, or trying to
     write on a socket which has been shutdown for writing.  Corresponds
     to ‘errno’ ‘EPIPE’ and ‘ESHUTDOWN’.

 -- Exception: ConnectionAbortedError

     A subclass of *note ConnectionError: 299, raised when a connection
     attempt is aborted by the peer.  Corresponds to ‘errno’
     ‘ECONNABORTED’.

 -- Exception: ConnectionRefusedError

     A subclass of *note ConnectionError: 299, raised when a connection
     attempt is refused by the peer.  Corresponds to ‘errno’
     ‘ECONNREFUSED’.

 -- Exception: ConnectionResetError

     A subclass of *note ConnectionError: 299, raised when a connection
     is reset by the peer.  Corresponds to ‘errno’ ‘ECONNRESET’.

 -- Exception: FileExistsError

     Raised when trying to create a file or directory which already
     exists.  Corresponds to ‘errno’ ‘EEXIST’.

 -- Exception: FileNotFoundError

     Raised when a file or directory is requested but doesn’t exist.
     Corresponds to ‘errno’ ‘ENOENT’.

 -- Exception: InterruptedError

     Raised when a system call is interrupted by an incoming signal.
     Corresponds to ‘errno’ *note EINTR: 1e6.

     Changed in version 3.5: Python now retries system calls when a
     syscall is interrupted by a signal, except if the signal handler
     raises an exception (see PEP 475(1) for the rationale), instead of
     raising *note InterruptedError: 1e7.

 -- Exception: IsADirectoryError

     Raised when a file operation (such as *note os.remove(): 66b.) is
     requested on a directory.  Corresponds to ‘errno’ ‘EISDIR’.

 -- Exception: NotADirectoryError

     Raised when a directory operation (such as *note os.listdir():
     675.) is requested on something which is not a directory.
     Corresponds to ‘errno’ ‘ENOTDIR’.

 -- Exception: PermissionError

     Raised when trying to run an operation without the adequate access
     rights - for example filesystem permissions.  Corresponds to
     ‘errno’ ‘EACCES’ and ‘EPERM’.

 -- Exception: ProcessLookupError

     Raised when a given process doesn’t exist.  Corresponds to ‘errno’
     ‘ESRCH’.

 -- Exception: TimeoutError

     Raised when a system function timed out at the system level.
     Corresponds to ‘errno’ ‘ETIMEDOUT’.

New in version 3.3: All the above *note OSError: 4b6. subclasses were
added.

See also
........

PEP 3151(2) - Reworking the OS and IO exception hierarchy

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0475

   (2) https://www.python.org/dev/peps/pep-3151


File: python.info,  Node: Warnings,  Next: Exception hierarchy,  Prev: Concrete exceptions,  Up: Built-in Exceptions

5.5.3 Warnings
--------------

The following exceptions are used as warning categories; see the *note
warnings: 123. module for more information.

 -- Exception: Warning

     Base class for warning categories.

 -- Exception: UserWarning

     Base class for warnings generated by user code.

 -- Exception: DeprecationWarning

     Base class for warnings about deprecated features.

 -- Exception: PendingDeprecationWarning

     Base class for warnings about features which will be deprecated in
     the future.

 -- Exception: SyntaxWarning

     Base class for warnings about dubious syntax.

 -- Exception: RuntimeWarning

     Base class for warnings about dubious runtime behavior.

 -- Exception: FutureWarning

     Base class for warnings about constructs that will change
     semantically in the future.

 -- Exception: ImportWarning

     Base class for warnings about probable mistakes in module imports.

 -- Exception: UnicodeWarning

     Base class for warnings related to Unicode.

 -- Exception: BytesWarning

     Base class for warnings related to *note bytes: 1db. and *note
     bytearray: 1dc.

 -- Exception: ResourceWarning

     Base class for warnings related to resource usage.

     New in version 3.2.


File: python.info,  Node: Exception hierarchy,  Prev: Warnings,  Up: Built-in Exceptions

5.5.4 Exception hierarchy
-------------------------

The class hierarchy for built-in exceptions is:

     BaseException
      +-- SystemExit
      +-- KeyboardInterrupt
      +-- GeneratorExit
      +-- Exception
           +-- StopIteration
           +-- StopAsyncIteration
           +-- ArithmeticError
           |    +-- FloatingPointError
           |    +-- OverflowError
           |    +-- ZeroDivisionError
           +-- AssertionError
           +-- AttributeError
           +-- BufferError
           +-- EOFError
           +-- ImportError
           +-- LookupError
           |    +-- IndexError
           |    +-- KeyError
           +-- MemoryError
           +-- NameError
           |    +-- UnboundLocalError
           +-- OSError
           |    +-- BlockingIOError
           |    +-- ChildProcessError
           |    +-- ConnectionError
           |    |    +-- BrokenPipeError
           |    |    +-- ConnectionAbortedError
           |    |    +-- ConnectionRefusedError
           |    |    +-- ConnectionResetError
           |    +-- FileExistsError
           |    +-- FileNotFoundError
           |    +-- InterruptedError
           |    +-- IsADirectoryError
           |    +-- NotADirectoryError
           |    +-- PermissionError
           |    +-- ProcessLookupError
           |    +-- TimeoutError
           +-- ReferenceError
           +-- RuntimeError
           |    +-- NotImplementedError
           |    +-- RecursionError
           +-- SyntaxError
           |    +-- IndentationError
           |         +-- TabError
           +-- SystemError
           +-- TypeError
           +-- ValueError
           |    +-- UnicodeError
           |         +-- UnicodeDecodeError
           |         +-- UnicodeEncodeError
           |         +-- UnicodeTranslateError
           +-- Warning
                +-- DeprecationWarning
                +-- PendingDeprecationWarning
                +-- RuntimeWarning
                +-- SyntaxWarning
                +-- UserWarning
                +-- FutureWarning
                +-- ImportWarning
                +-- UnicodeWarning
                +-- BytesWarning
                +-- ResourceWarning


File: python.info,  Node: Text Processing Services,  Next: Binary Data Services,  Prev: Built-in Exceptions,  Up: The Python Standard Library

5.6 Text Processing Services
============================

The modules described in this chapter provide a wide range of string
manipulation operations and other text processing services.

The *note codecs: 1c. module described under *note Binary Data Services:
10d2. is also highly relevant to text processing.  In addition, see the
documentation for Python’s built-in string type in *note Text Sequence
Type — str: bea.

* Menu:

* string: string --- Common string operations. Common string operations
* re: re --- Regular expression operations. Regular expression operations
* difflib: difflib --- Helpers for computing deltas. Helpers for computing deltas
* textwrap: textwrap --- Text wrapping and filling. Text wrapping and filling
* unicodedata: unicodedata --- Unicode Database. Unicode Database
* stringprep: stringprep --- Internet String Preparation. Internet String Preparation
* readline: readline --- GNU readline interface. GNU readline interface
* rlcompleter: rlcompleter --- Completion function for GNU readline. Completion function for GNU readline


File: python.info,  Node: string --- Common string operations,  Next: re --- Regular expression operations,  Up: Text Processing Services

5.6.1 ‘string’ — Common string operations
-----------------------------------------

`Source code:' Lib/string.py(1)

__________________________________________________________________

See also
........

*note Text Sequence Type — str: bea.

*note String Methods: beb.

* Menu:

* String constants:: 
* Custom String Formatting:: 
* Format String Syntax:: 
* Template strings:: 
* Helper functions:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/string.py


File: python.info,  Node: String constants,  Next: Custom String Formatting,  Up: string --- Common string operations

5.6.1.1 String constants
........................

The constants defined in this module are:

 -- Data: string.ascii_letters

     The concatenation of the *note ascii_lowercase: 10d6. and *note
     ascii_uppercase: 10d7. constants described below.  This value is
     not locale-dependent.

 -- Data: string.ascii_lowercase

     The lowercase letters ‘'abcdefghijklmnopqrstuvwxyz'’.  This value
     is not locale-dependent and will not change.

 -- Data: string.ascii_uppercase

     The uppercase letters ‘'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.  This value
     is not locale-dependent and will not change.

 -- Data: string.digits

     The string ‘'0123456789'’.

 -- Data: string.hexdigits

     The string ‘'0123456789abcdefABCDEF'’.

 -- Data: string.octdigits

     The string ‘'01234567'’.

 -- Data: string.punctuation

     String of ASCII characters which are considered punctuation
     characters in the ‘C’ locale.

 -- Data: string.printable

     String of ASCII characters which are considered printable.  This is
     a combination of *note digits: 10d8, *note ascii_letters: 8c6,
     *note punctuation: 10db, and *note whitespace: 10dd.

 -- Data: string.whitespace

     A string containing all ASCII characters that are considered
     whitespace.  This includes the characters space, tab, linefeed,
     return, formfeed, and vertical tab.


File: python.info,  Node: Custom String Formatting,  Next: Format String Syntax,  Prev: String constants,  Up: string --- Common string operations

5.6.1.2 Custom String Formatting
................................

The built-in string class provides the ability to do complex variable
substitutions and value formatting via the *note format(): 14d. method
described in PEP 3101(1).  The *note Formatter: 397. class in the *note
string: f4. module allows you to create and customize your own string
formatting behaviors using the same implementation as the built-in *note
format(): 14d. method.

 -- Class: string.Formatter

     The *note Formatter: 397. class has the following public methods:

      -- Method: format (format_string, *args, **kwargs)

          The primary API method.  It takes a format string and an
          arbitrary set of positional and keyword arguments.  It is just
          a wrapper that calls *note vformat(): 10df.

          Deprecated since version 3.5: Passing a format string as
          keyword argument `format_string' has been deprecated.

      -- Method: vformat (format_string, args, kwargs)

          This function does the actual work of formatting.  It is
          exposed as a separate function for cases where you want to
          pass in a predefined dictionary of arguments, rather than
          unpacking and repacking the dictionary as individual arguments
          using the ‘*args’ and ‘**kwargs’ syntax.  *note vformat():
          10df. does the work of breaking up the format string into
          character data and replacement fields.  It calls the various
          methods described below.

     In addition, the *note Formatter: 397. defines a number of methods
     that are intended to be replaced by subclasses:

      -- Method: parse (format_string)

          Loop over the format_string and return an iterable of tuples
          (`literal_text', `field_name', `format_spec', `conversion').
          This is used by *note vformat(): 10df. to break the string
          into either literal text, or replacement fields.

          The values in the tuple conceptually represent a span of
          literal text followed by a single replacement field.  If there
          is no literal text (which can happen if two replacement fields
          occur consecutively), then `literal_text' will be a
          zero-length string.  If there is no replacement field, then
          the values of `field_name', `format_spec' and `conversion'
          will be ‘None’.

      -- Method: get_field (field_name, args, kwargs)

          Given `field_name' as returned by *note parse(): 10e0. (see
          above), convert it to an object to be formatted.  Returns a
          tuple (obj, used_key).  The default version takes strings of
          the form defined in PEP 3101(2), such as "0[name]" or
          "label.title".  `args' and `kwargs' are as passed in to *note
          vformat(): 10df.  The return value `used_key' has the same
          meaning as the `key' parameter to *note get_value(): 10e2.

      -- Method: get_value (key, args, kwargs)

          Retrieve a given field value.  The `key' argument will be
          either an integer or a string.  If it is an integer, it
          represents the index of the positional argument in `args'; if
          it is a string, then it represents a named argument in
          `kwargs'.

          The `args' parameter is set to the list of positional
          arguments to *note vformat(): 10df, and the `kwargs' parameter
          is set to the dictionary of keyword arguments.

          For compound field names, these functions are only called for
          the first component of the field name; Subsequent components
          are handled through normal attribute and indexing operations.

          So for example, the field expression ’0.name’ would cause
          *note get_value(): 10e2. to be called with a `key' argument of
          0.  The ‘name’ attribute will be looked up after *note
          get_value(): 10e2. returns by calling the built-in *note
          getattr(): 781. function.

          If the index or keyword refers to an item that does not exist,
          then an *note IndexError: afb. or *note KeyError: 1a7. should
          be raised.

      -- Method: check_unused_args (used_args, args, kwargs)

          Implement checking for unused arguments if desired.  The
          arguments to this function is the set of all argument keys
          that were actually referred to in the format string (integers
          for positional arguments, and strings for named arguments),
          and a reference to the `args' and `kwargs' that was passed to
          vformat.  The set of unused args can be calculated from these
          parameters.  *note check_unused_args(): 10e3. is assumed to
          raise an exception if the check fails.

      -- Method: format_field (value, format_spec)

          *note format_field(): 10e4. simply calls the global *note
          format(): 14e. built-in.  The method is provided so that
          subclasses can override it.

      -- Method: convert_field (value, conversion)

          Converts the value (returned by *note get_field(): 10e1.)
          given a conversion type (as in the tuple returned by the *note
          parse(): 10e0. method).  The default version understands ’s’
          (str), ’r’ (repr) and ’a’ (ascii) conversion types.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3101

   (2) https://www.python.org/dev/peps/pep-3101


File: python.info,  Node: Format String Syntax,  Next: Template strings,  Prev: Custom String Formatting,  Up: string --- Common string operations

5.6.1.3 Format String Syntax
............................

The *note str.format(): 14d. method and the *note Formatter: 397. class
share the same syntax for format strings (although in the case of *note
Formatter: 397, subclasses can define their own format string syntax).
The syntax is related to that of *note formatted string literals: 14f,
but there are differences.

Format strings contain "replacement fields" surrounded by curly braces
‘{}’.  Anything that is not contained in braces is considered literal
text, which is copied unchanged to the output.  If you need to include a
brace character in the literal text, it can be escaped by doubling: ‘{{’
and ‘}}’.

The grammar for a replacement field is as follows:

          replacement_field ::= "{" [field_name] ["!" conversion] [":" format_spec] "}"
          field_name        ::= arg_name ("." attribute_name | "[" element_index "]")*
          arg_name          ::= [identifier | integer]
          attribute_name    ::= identifier
          element_index     ::= integer | index_string
          index_string      ::= <any source character except "]"> +
          conversion        ::= "r" | "s" | "a"
          format_spec       ::= <described in the next section>

In less formal terms, the replacement field can start with a
`field_name' that specifies the object whose value is to be formatted
and inserted into the output instead of the replacement field.  The
`field_name' is optionally followed by a `conversion' field, which is
preceded by an exclamation point ‘'!'’, and a `format_spec', which is
preceded by a colon ‘':'’.  These specify a non-default format for the
replacement value.

See also the *note Format Specification Mini-Language: dfc. section.

The `field_name' itself begins with an `arg_name' that is either a
number or a keyword.  If it’s a number, it refers to a positional
argument, and if it’s a keyword, it refers to a named keyword argument.
If the numerical arg_names in a format string are 0, 1, 2, ...  in
sequence, they can all be omitted (not just some) and the numbers 0, 1,
2, ...  will be automatically inserted in that order.  Because
`arg_name' is not quote-delimited, it is not possible to specify
arbitrary dictionary keys (e.g., the strings ‘'10'’ or ‘':-]'’) within a
format string.  The `arg_name' can be followed by any number of index or
attribute expressions.  An expression of the form ‘'.name'’ selects the
named attribute using *note getattr(): 781, while an expression of the
form ‘'[index]'’ does an index lookup using *note __getitem__(): a84.

Changed in version 3.1: The positional argument specifiers can be
omitted, so ‘'{} {}'’ is equivalent to ‘'{0} {1}'’.

Some simple format string examples:

     "First, thou shalt count to {0}" # References first positional argument
     "Bring me a {}"                  # Implicitly references the first positional argument
     "From {} to {}"                  # Same as "From {0} to {1}"
     "My quest is {name}"             # References keyword argument 'name'
     "Weight in tons {0.weight}"      # 'weight' attribute of first positional arg
     "Units destroyed: {players[0]}"  # First element of keyword argument 'players'.

The `conversion' field causes a type coercion before formatting.
Normally, the job of formatting a value is done by the *note
__format__(): 561. method of the value itself.  However, in some cases
it is desirable to force a type to be formatted as a string, overriding
its own definition of formatting.  By converting the value to a string
before calling *note __format__(): 561, the normal formatting logic is
bypassed.

Three conversion flags are currently supported: ‘'!s'’ which calls *note
str(): 25a. on the value, ‘'!r'’ which calls *note repr(): 3bb. and
‘'!a'’ which calls *note ascii(): 9c3.

Some examples:

     "Harold's a clever {0!s}"        # Calls str() on the argument first
     "Bring out the holy {name!r}"    # Calls repr() on the argument first
     "More {!a}"                      # Calls ascii() on the argument first

The `format_spec' field contains a specification of how the value should
be presented, including such details as field width, alignment, padding,
decimal precision and so on.  Each value type can define its own
"formatting mini-language" or interpretation of the `format_spec'.

Most built-in types support a common formatting mini-language, which is
described in the next section.

A `format_spec' field can also include nested replacement fields within
it.  These nested replacement fields may contain a field name,
conversion flag and format specification, but deeper nesting is not
allowed.  The replacement fields within the format_spec are substituted
before the `format_spec' string is interpreted.  This allows the
formatting of a value to be dynamically specified.

See the *note Format examples: 10ef. section for some examples.

* Menu:

* Format Specification Mini-Language:: 
* Format examples:: 


File: python.info,  Node: Format Specification Mini-Language,  Next: Format examples,  Up: Format String Syntax

5.6.1.4 Format Specification Mini-Language
..........................................

"Format specifications" are used within replacement fields contained
within a format string to define how individual values are presented
(see *note Format String Syntax: 98a. and *note Formatted string
literals: 14f.).  They can also be passed directly to the built-in *note
format(): 14e. function.  Each formattable type may define how the
format specification is to be interpreted.

Most built-in types implement the following options for format
specifications, although some of the formatting options are only
supported by the numeric types.

A general convention is that an empty format string (‘""’) produces the
same result as if you had called *note str(): 25a. on the value.  A
non-empty format string typically modifies the result.

The general form of a `standard format specifier' is:

     format_spec ::= [[fill]align][sign][#][0][width][,][.precision][type]
     fill        ::= <any character>
     align       ::= "<" | ">" | "=" | "^"
     sign        ::= "+" | "-" | " "
     width       ::= integer
     precision   ::= integer
     type        ::= "b" | "c" | "d" | "e" | "E" | "f" | "F" | "g" | "G" | "n" | "o" | "s" | "x" | "X" | "%"

If a valid `align' value is specified, it can be preceded by a `fill'
character that can be any character and defaults to a space if omitted.
It is not possible to use a literal curly brace ("‘{’" or "‘}’") as the
`fill' character in a *note formatted string literal: 14f. or when using
the *note str.format(): 14d. method.  However, it is possible to insert
a curly brace with a nested replacement field.  This limitation doesn’t
affect the *note format(): 14e. function.

The meaning of the various alignment options is as follows:

     Option        Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'<'’         Forces the field to be left-aligned within the available
                   space (this is the default for most objects).
                   
                   
     ‘'>'’         Forces the field to be right-aligned within the available
                   space (this is the default for numbers).
                   
                   
     ‘'='’         Forces the padding to be placed after the sign (if any) but
                   before the digits.  This is used for printing fields in the
                   form ’+000000120’.  This alignment option is only valid for
                   numeric types.  It becomes the default when ’0’ immediately
                   precedes the field width.
                   
                   
     ‘'^'’         Forces the field to be centered within the available space.
                   

Note that unless a minimum field width is defined, the field width will
always be the same size as the data to fill it, so that the alignment
option has no meaning in this case.

The `sign' option is only valid for number types, and can be one of the
following:

     Option        Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'+'’         indicates that a sign should be used for both positive as
                   well as negative numbers.
                   
                   
     ‘'-'’         indicates that a sign should be used only for negative
                   numbers (this is the default behavior).
                   
                   
     space         indicates that a leading space should be used on positive
                   numbers, and a minus sign on negative numbers.
                   

The ‘'#'’ option causes the "alternate form" to be used for the
conversion.  The alternate form is defined differently for different
types.  This option is only valid for integer, float, complex and
Decimal types.  For integers, when binary, octal, or hexadecimal output
is used, this option adds the prefix respective ‘'0b'’, ‘'0o'’, or
‘'0x'’ to the output value.  For floats, complex and Decimal the
alternate form causes the result of the conversion to always contain a
decimal-point character, even if no digits follow it.  Normally, a
decimal-point character appears in the result of these conversions only
if a digit follows it.  In addition, for ‘'g'’ and ‘'G'’ conversions,
trailing zeros are not removed from the result.

The ‘','’ option signals the use of a comma for a thousands separator.
For a locale aware separator, use the ‘'n'’ integer presentation type
instead.

Changed in version 3.1: Added the ‘','’ option (see also PEP 378(1)).

`width' is a decimal integer defining the minimum field width.  If not
specified, then the field width will be determined by the content.

When no explicit alignment is given, preceding the `width' field by a
zero (‘'0'’) character enables sign-aware zero-padding for numeric
types.  This is equivalent to a `fill' character of ‘'0'’ with an
`alignment' type of ‘'='’.

The `precision' is a decimal number indicating how many digits should be
displayed after the decimal point for a floating point value formatted
with ‘'f'’ and ‘'F'’, or before and after the decimal point for a
floating point value formatted with ‘'g'’ or ‘'G'’.  For non-number
types the field indicates the maximum field size - in other words, how
many characters will be used from the field content.  The `precision' is
not allowed for integer values.

Finally, the `type' determines how the data should be presented.

The available string presentation types are:

     Type          Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'s'’         String format.  This is the default type for strings and may
                   be omitted.
                   
                   
     None          The same as ‘'s'’.
                   

The available integer presentation types are:

     Type          Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'b'’         Binary format.  Outputs the number in base 2.
                   
                   
     ‘'c'’         Character.  Converts the integer to the corresponding
                   unicode character before printing.
                   
                   
     ‘'d'’         Decimal Integer.  Outputs the number in base 10.
                   
                   
     ‘'o'’         Octal format.  Outputs the number in base 8.
                   
                   
     ‘'x'’         Hex format.  Outputs the number in base 16, using lower-
                   case letters for the digits above 9.
                   
                   
     ‘'X'’         Hex format.  Outputs the number in base 16, using upper-
                   case letters for the digits above 9.
                   
                   
     ‘'n'’         Number.  This is the same as ‘'d'’, except that it uses the
                   current locale setting to insert the appropriate number
                   separator characters.
                   
                   
     None          The same as ‘'d'’.
                   

In addition to the above presentation types, integers can be formatted
with the floating point presentation types listed below (except ‘'n'’
and None).  When doing so, *note float(): 57a. is used to convert the
integer to a floating point number before formatting.

The available presentation types for floating point and decimal values
are:

     Type          Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'e'’         Exponent notation.  Prints the number in scientific notation
                   using the letter ’e’ to indicate the exponent.  The default
                   precision is ‘6’.
                   
                   
     ‘'E'’         Exponent notation.  Same as ‘'e'’ except it uses an upper
                   case ’E’ as the separator character.
                   
                   
     ‘'f'’         Fixed point.  Displays the number as a fixed-point number.
                   The default precision is ‘6’.
                   
                   
     ‘'F'’         Fixed point.  Same as ‘'f'’, but converts ‘nan’ to ‘NAN’ and
                   ‘inf’ to ‘INF’.
                   
                   
     ‘'g'’         General format.  For a given precision ‘p >= 1’, this rounds
                   the number to ‘p’ significant digits and then formats the
                   result in either fixed-point format or in scientific
                   notation, depending on its magnitude.
                   
                   The precise rules are as follows: suppose that the result
                   formatted with presentation type ‘'e'’ and precision ‘p-1’
                   would have exponent ‘exp’.  Then if ‘-4 <= exp < p’, the
                   number is formatted with presentation type ‘'f'’ and
                   precision ‘p-1-exp’.  Otherwise, the number is formatted
                   with presentation type ‘'e'’ and precision ‘p-1’.  In both
                   cases insignificant trailing zeros are removed from the
                   significand, and the decimal point is also removed if there
                   are no remaining digits following it.
                   
                   Positive and negative infinity, positive and negative zero,
                   and nans, are formatted as ‘inf’, ‘-inf’, ‘0’, ‘-0’ and
                   ‘nan’ respectively, regardless of the precision.
                   
                   A precision of ‘0’ is treated as equivalent to a precision
                   of ‘1’.  The default precision is ‘6’.
                   
                   
     ‘'G'’         General format.  Same as ‘'g'’ except switches to ‘'E'’ if
                   the number gets too large.  The representations of infinity
                   and NaN are uppercased, too.
                   
                   
     ‘'n'’         Number.  This is the same as ‘'g'’, except that it uses the
                   current locale setting to insert the appropriate number
                   separator characters.
                   
                   
     ‘'%'’         Percentage.  Multiplies the number by 100 and displays in
                   fixed (‘'f'’) format, followed by a percent sign.
                   
                   
     None          Similar to ‘'g'’, except that fixed-point notation, when
                   used, has at least one digit past the decimal point.  The
                   default precision is as high as needed to represent the
                   particular value.  The overall effect is to match the output
                   of *note str(): 25a. as altered by the other format
                   modifiers.
                   

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0378


File: python.info,  Node: Format examples,  Prev: Format Specification Mini-Language,  Up: Format String Syntax

5.6.1.5 Format examples
.......................

This section contains examples of the *note str.format(): 14d. syntax
and comparison with the old ‘%’-formatting.

In most of the cases the syntax is similar to the old ‘%’-formatting,
with the addition of the ‘{}’ and with ‘:’ used instead of ‘%’.  For
example, ‘'%03.2f'’ can be translated to ‘'{:03.2f}'’.

The new format syntax also supports new and different options, shown in
the follow examples.

Accessing arguments by position:

     >>> '{0}, {1}, {2}'.format('a', 'b', 'c')
     'a, b, c'
     >>> '{}, {}, {}'.format('a', 'b', 'c')  # 3.1+ only
     'a, b, c'
     >>> '{2}, {1}, {0}'.format('a', 'b', 'c')
     'c, b, a'
     >>> '{2}, {1}, {0}'.format(*'abc')      # unpacking argument sequence
     'c, b, a'
     >>> '{0}{1}{0}'.format('abra', 'cad')   # arguments' indices can be repeated
     'abracadabra'

Accessing arguments by name:

     >>> 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W')
     'Coordinates: 37.24N, -115.81W'
     >>> coord = {'latitude': '37.24N', 'longitude': '-115.81W'}
     >>> 'Coordinates: {latitude}, {longitude}'.format(**coord)
     'Coordinates: 37.24N, -115.81W'

Accessing arguments’ attributes:

     >>> c = 3-5j
     >>> ('The complex number {0} is formed from the real part {0.real} '
     ...  'and the imaginary part {0.imag}.').format(c)
     'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part -5.0.'
     >>> class Point:
     ...     def __init__(self, x, y):
     ...         self.x, self.y = x, y
     ...     def __str__(self):
     ...         return 'Point({self.x}, {self.y})'.format(self=self)
     ...
     >>> str(Point(4, 2))
     'Point(4, 2)'

Accessing arguments’ items:

     >>> coord = (3, 5)
     >>> 'X: {0[0]};  Y: {0[1]}'.format(coord)
     'X: 3;  Y: 5'

Replacing ‘%s’ and ‘%r’:

     >>> "repr() shows quotes: {!r}; str() doesn't: {!s}".format('test1', 'test2')
     "repr() shows quotes: 'test1'; str() doesn't: test2"

Aligning the text and specifying a width:

     >>> '{:<30}'.format('left aligned')
     'left aligned                  '
     >>> '{:>30}'.format('right aligned')
     '                 right aligned'
     >>> '{:^30}'.format('centered')
     '           centered           '
     >>> '{:*^30}'.format('centered')  # use '*' as a fill char
     '***********centered***********'

Replacing ‘%+f’, ‘%-f’, and ‘% f’ and specifying a sign:

     >>> '{:+f}; {:+f}'.format(3.14, -3.14)  # show it always
     '+3.140000; -3.140000'
     >>> '{: f}; {: f}'.format(3.14, -3.14)  # show a space for positive numbers
     ' 3.140000; -3.140000'
     >>> '{:-f}; {:-f}'.format(3.14, -3.14)  # show only the minus -- same as '{:f}; {:f}'
     '3.140000; -3.140000'

Replacing ‘%x’ and ‘%o’ and converting the value to different bases:

     >>> # format also supports binary numbers
     >>> "int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}".format(42)
     'int: 42;  hex: 2a;  oct: 52;  bin: 101010'
     >>> # with 0x, 0o, or 0b as prefix:
     >>> "int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}".format(42)
     'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010'

Using the comma as a thousands separator:

     >>> '{:,}'.format(1234567890)
     '1,234,567,890'

Expressing a percentage:

     >>> points = 19
     >>> total = 22
     >>> 'Correct answers: {:.2%}'.format(points/total)
     'Correct answers: 86.36%'

Using type-specific formatting:

     >>> import datetime
     >>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)
     >>> '{:%Y-%m-%d %H:%M:%S}'.format(d)
     '2010-07-04 12:15:58'

Nesting arguments and more complex examples:

     >>> for align, text in zip('<^>', ['left', 'center', 'right']):
     ...     '{0:{fill}{align}16}'.format(text, fill=align, align=align)
     ...
     'left<<<<<<<<<<<<'
     '^^^^^center^^^^^'
     '>>>>>>>>>>>right'
     >>>
     >>> octets = [192, 168, 0, 1]
     >>> '{:02X}{:02X}{:02X}{:02X}'.format(*octets)
     'C0A80001'
     >>> int(_, 16)
     3232235521
     >>>
     >>> width = 5
     >>> for num in range(5,12): #doctest: +NORMALIZE_WHITESPACE
     ...     for base in 'dXob':
     ...         print('{0:{width}{base}}'.format(num, base=base, width=width), end=' ')
     ...     print()
     ...
         5     5     5   101
         6     6     6   110
         7     7     7   111
         8     8    10  1000
         9     9    11  1001
        10     A    12  1010
        11     B    13  1011


File: python.info,  Node: Template strings,  Next: Helper functions,  Prev: Format String Syntax,  Up: string --- Common string operations

5.6.1.6 Template strings
........................

Templates provide simpler string substitutions as described in PEP
292(1).  Instead of the normal ‘%’-based substitutions, Templates
support ‘$’-based substitutions, using the following rules:

   * ‘$$’ is an escape; it is replaced with a single ‘$’.

   * ‘$identifier’ names a substitution placeholder matching a mapping
     key of ‘"identifier"’.  By default, ‘"identifier"’ is restricted to
     any case-insensitive ASCII alphanumeric string (including
     underscores) that starts with an underscore or ASCII letter.  The
     first non-identifier character after the ‘$’ character terminates
     this placeholder specification.

   * ‘${identifier}’ is equivalent to ‘$identifier’.  It is required
     when valid identifier characters follow the placeholder but are not
     part of the placeholder, such as ‘"${noun}ification"’.

Any other appearance of ‘$’ in the string will result in a *note
ValueError: 19c. being raised.

The *note string: f4. module provides a *note Template: 7c4. class that
implements these rules.  The methods of *note Template: 7c4. are:

 -- Class: string.Template (template)

     The constructor takes a single argument which is the template
     string.

      -- Method: substitute (mapping, **kwds)

          Performs the template substitution, returning a new string.
          `mapping' is any dictionary-like object with keys that match
          the placeholders in the template.  Alternatively, you can
          provide keyword arguments, where the keywords are the
          placeholders.  When both `mapping' and `kwds' are given and
          there are duplicates, the placeholders from `kwds' take
          precedence.

      -- Method: safe_substitute (mapping, **kwds)

          Like *note substitute(): cbe, except that if placeholders are
          missing from `mapping' and `kwds', instead of raising a *note
          KeyError: 1a7. exception, the original placeholder will appear
          in the resulting string intact.  Also, unlike with *note
          substitute(): cbe, any other appearances of the ‘$’ will
          simply return ‘$’ instead of raising *note ValueError: 19c.

          While other exceptions may still occur, this method is called
          "safe" because substitutions always tries to return a usable
          string instead of raising an exception.  In another sense,
          *note safe_substitute(): cbf. may be anything other than safe,
          since it will silently ignore malformed templates containing
          dangling delimiters, unmatched braces, or placeholders that
          are not valid Python identifiers.

     *note Template: 7c4. instances also provide one public data
     attribute:

      -- Attribute: template

          This is the object passed to the constructor’s `template'
          argument.  In general, you shouldn’t change it, but read-only
          access is not enforced.

Here is an example of how to use a Template:

     >>> from string import Template
     >>> s = Template('$who likes $what')
     >>> s.substitute(who='tim', what='kung pao')
     'tim likes kung pao'
     >>> d = dict(who='tim')
     >>> Template('Give $who $100').substitute(d)
     Traceback (most recent call last):
     ...
     ValueError: Invalid placeholder in string: line 1, col 11
     >>> Template('$who likes $what').substitute(d)
     Traceback (most recent call last):
     ...
     KeyError: 'what'
     >>> Template('$who likes $what').safe_substitute(d)
     'tim likes $what'

Advanced usage: you can derive subclasses of *note Template: 7c4. to
customize the placeholder syntax, delimiter character, or the entire
regular expression used to parse template strings.  To do this, you can
override these class attributes:

   * `delimiter' – This is the literal string describing a placeholder
     introducing delimiter.  The default value is ‘$’.  Note that this
     should `not' be a regular expression, as the implementation will
     call *note re.escape(): 10fc. on this string as needed.

   * `idpattern' – This is the regular expression describing the pattern
     for non-braced placeholders (the braces will be added automatically
     as appropriate).  The default value is the regular expression
     ‘[_a-z][_a-z0-9]*’.

   * `flags' – The regular expression flags that will be applied when
     compiling the regular expression used for recognizing
     substitutions.  The default value is ‘re.IGNORECASE’.  Note that
     ‘re.VERBOSE’ will always be added to the flags, so custom
     `idpattern's must follow conventions for verbose regular
     expressions.

     New in version 3.2.

Alternatively, you can provide the entire regular expression pattern by
overriding the class attribute `pattern'.  If you do this, the value
must be a regular expression object with four named capturing groups.
The capturing groups correspond to the rules given above, along with the
invalid placeholder rule:

   * `escaped' – This group matches the escape sequence, e.g.  ‘$$’, in
     the default pattern.

   * `named' – This group matches the unbraced placeholder name; it
     should not include the delimiter in capturing group.

   * `braced' – This group matches the brace enclosed placeholder name;
     it should not include either the delimiter or braces in the
     capturing group.

   * `invalid' – This group matches any other delimiter pattern (usually
     a single delimiter), and it should appear last in the regular
     expression.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0292


File: python.info,  Node: Helper functions,  Prev: Template strings,  Up: string --- Common string operations

5.6.1.7 Helper functions
........................

 -- Function: string.capwords (s, sep=None)

     Split the argument into words using *note str.split(): 37b,
     capitalize each word using *note str.capitalize(): ffa, and join
     the capitalized words using *note str.join(): fe9.  If the optional
     second argument `sep' is absent or ‘None’, runs of whitespace
     characters are replaced by a single space and leading and trailing
     whitespace are removed, otherwise `sep' is used to split and join
     the words.


File: python.info,  Node: re --- Regular expression operations,  Next: difflib --- Helpers for computing deltas,  Prev: string --- Common string operations,  Up: Text Processing Services

5.6.2 ‘re’ — Regular expression operations
------------------------------------------

This module provides regular expression matching operations similar to
those found in Perl.

Both patterns and strings to be searched can be Unicode strings as well
as 8-bit strings.  However, Unicode strings and 8-bit strings cannot be
mixed: that is, you cannot match a Unicode string with a byte pattern or
vice-versa; similarly, when asking for a substitution, the replacement
string must be of the same type as both the pattern and the search
string.

Regular expressions use the backslash character (‘'\'’) to indicate
special forms or to allow special characters to be used without invoking
their special meaning.  This collides with Python’s usage of the same
character for the same purpose in string literals; for example, to match
a literal backslash, one might have to write ‘'\\\\'’ as the pattern
string, because the regular expression must be ‘\\’, and each backslash
must be expressed as ‘\\’ inside a regular Python string literal.

The solution is to use Python’s raw string notation for regular
expression patterns; backslashes are not handled in any special way in a
string literal prefixed with ‘'r'’.  So ‘r"\n"’ is a two-character
string containing ‘'\'’ and ‘'n'’, while ‘"\n"’ is a one-character
string containing a newline.  Usually patterns will be expressed in
Python code using this raw string notation.

It is important to note that most regular expression operations are
available as module-level functions and methods on *note compiled
regular expressions: 499.  The functions are shortcuts that don’t
require you to compile a regex object first, but miss some fine-tuning
parameters.

* Menu:

* Regular Expression Syntax:: 
* Module Contents:: 
* Regular Expression Objects:: 
* Match Objects:: 
* Regular Expression Examples:: 


File: python.info,  Node: Regular Expression Syntax,  Next: Module Contents,  Up: re --- Regular expression operations

5.6.2.1 Regular Expression Syntax
.................................

A regular expression (or RE) specifies a set of strings that matches it;
the functions in this module let you check if a particular string
matches a given regular expression (or if a given regular expression
matches a particular string, which comes down to the same thing).

Regular expressions can be concatenated to form new regular expressions;
if `A' and `B' are both regular expressions, then `AB' is also a regular
expression.  In general, if a string `p' matches `A' and another string
`q' matches `B', the string `pq' will match AB. This holds unless `A' or
`B' contain low precedence operations; boundary conditions between `A'
and `B'; or have numbered group references.  Thus, complex expressions
can easily be constructed from simpler primitive expressions like the
ones described here.  For details of the theory and implementation of
regular expressions, consult the Friedl book referenced above, or almost
any textbook about compiler construction.

A brief explanation of the format of regular expressions follows.  For
further information and a gentler presentation, consult the *note
Regular Expression HOWTO: 1103.

Regular expressions can contain both special and ordinary characters.
Most ordinary characters, like ‘'A'’, ‘'a'’, or ‘'0'’, are the simplest
regular expressions; they simply match themselves.  You can concatenate
ordinary characters, so ‘last’ matches the string ‘'last'’.  (In the
rest of this section, we’ll write RE’s in ‘this special style’, usually
without quotes, and strings to be matched ‘'in single quotes'’.)

Some characters, like ‘'|'’ or ‘'('’, are special.  Special characters
either stand for classes of ordinary characters, or affect how the
regular expressions around them are interpreted.  Regular expression
pattern strings may not contain null bytes, but can specify the null
byte using a ‘\number’ notation such as ‘'\x00'’.

The special characters are:

‘'.'’

     (Dot.)  In the default mode, this matches any character except a
     newline.  If the *note DOTALL: 1104. flag has been specified, this
     matches any character including a newline.

‘'^'’

     (Caret.)  Matches the start of the string, and in *note MULTILINE:
     1105. mode also matches immediately after each newline.

‘'$'’

     Matches the end of the string or just before the newline at the end
     of the string, and in *note MULTILINE: 1105. mode also matches
     before a newline.  ‘foo’ matches both ’foo’ and ’foobar’, while the
     regular expression ‘foo$’ matches only ’foo’.  More interestingly,
     searching for ‘foo.$’ in ‘'foo1\nfoo2\n'’ matches ’foo2’ normally,
     but ’foo1’ in *note MULTILINE: 1105. mode; searching for a single
     ‘$’ in ‘'foo\n'’ will find two (empty) matches: one just before the
     newline, and one at the end of the string.

‘'*'’

     Causes the resulting RE to match 0 or more repetitions of the
     preceding RE, as many repetitions as are possible.  ‘ab*’ will
     match ’a’, ’ab’, or ’a’ followed by any number of ’b’s.

‘'+'’

     Causes the resulting RE to match 1 or more repetitions of the
     preceding RE. ‘ab+’ will match ’a’ followed by any non-zero number
     of ’b’s; it will not match just ’a’.

‘'?'’

     Causes the resulting RE to match 0 or 1 repetitions of the
     preceding RE. ‘ab?’ will match either ’a’ or ’ab’.

‘*?’, ‘+?’, ‘??’

     The ‘'*'’, ‘'+'’, and ‘'?'’ qualifiers are all `greedy'; they match
     as much text as possible.  Sometimes this behaviour isn’t desired;
     if the RE ‘<.*>’ is matched against ‘<a> b <c>’, it will match the
     entire string, and not just ‘<a>’.  Adding ‘?’ after the qualifier
     makes it perform the match in `non-greedy' or `minimal' fashion; as
     `few' characters as possible will be matched.  Using the RE ‘<.*?>’
     will match only ‘<a>’.

‘{m}’

     Specifies that exactly `m' copies of the previous RE should be
     matched; fewer matches cause the entire RE not to match.  For
     example, ‘a{6}’ will match exactly six ‘'a'’ characters, but not
     five.

‘{m,n}’

     Causes the resulting RE to match from `m' to `n' repetitions of the
     preceding RE, attempting to match as many repetitions as possible.
     For example, ‘a{3,5}’ will match from 3 to 5 ‘'a'’ characters.
     Omitting `m' specifies a lower bound of zero, and omitting `n'
     specifies an infinite upper bound.  As an example, ‘a{4,}b’ will
     match ‘aaaab’ or a thousand ‘'a'’ characters followed by a ‘b’, but
     not ‘aaab’.  The comma may not be omitted or the modifier would be
     confused with the previously described form.

‘{m,n}?’

     Causes the resulting RE to match from `m' to `n' repetitions of the
     preceding RE, attempting to match as `few' repetitions as possible.
     This is the non-greedy version of the previous qualifier.  For
     example, on the 6-character string ‘'aaaaaa'’, ‘a{3,5}’ will match
     5 ‘'a'’ characters, while ‘a{3,5}?’ will only match 3 characters.

‘'\'’

     Either escapes special characters (permitting you to match
     characters like ‘'*'’, ‘'?'’, and so forth), or signals a special
     sequence; special sequences are discussed below.

     If you’re not using a raw string to express the pattern, remember
     that Python also uses the backslash as an escape sequence in string
     literals; if the escape sequence isn’t recognized by Python’s
     parser, the backslash and subsequent character are included in the
     resulting string.  However, if Python would recognize the resulting
     sequence, the backslash should be repeated twice.  This is
     complicated and hard to understand, so it’s highly recommended that
     you use raw strings for all but the simplest expressions.

‘[]’

     Used to indicate a set of characters.  In a set:

        * Characters can be listed individually, e.g.  ‘[amk]’ will
          match ‘'a'’, ‘'m'’, or ‘'k'’.

        * Ranges of characters can be indicated by giving two characters
          and separating them by a ‘'-'’, for example ‘[a-z]’ will match
          any lowercase ASCII letter, ‘[0-5][0-9]’ will match all the
          two-digits numbers from ‘00’ to ‘59’, and ‘[0-9A-Fa-f]’ will
          match any hexadecimal digit.  If ‘-’ is escaped (e.g.
          ‘[a\-z]’) or if it’s placed as the first or last character
          (e.g.  ‘[a-]’), it will match a literal ‘'-'’.

        * Special characters lose their special meaning inside sets.
          For example, ‘[(+*)]’ will match any of the literal characters
          ‘'('’, ‘'+'’, ‘'*'’, or ‘')'’.

        * Character classes such as ‘\w’ or ‘\S’ (defined below) are
          also accepted inside a set, although the characters they match
          depends on whether *note ASCII: 3a1. or *note LOCALE: 3a0.
          mode is in force.

        * Characters that are not within a range can be matched by
          `complementing' the set.  If the first character of the set is
          ‘'^'’, all the characters that are `not' in the set will be
          matched.  For example, ‘[^5]’ will match any character except
          ‘'5'’, and ‘[^^]’ will match any character except ‘'^'’.  ‘^’
          has no special meaning if it’s not the first character in the
          set.

        * To match a literal ‘']'’ inside a set, precede it with a
          backslash, or place it at the beginning of the set.  For
          example, both ‘[()[\]{}]’ and ‘[]()[{}]’ will both match a
          parenthesis.

‘'|'’

     ‘A|B’, where A and B can be arbitrary REs, creates a regular
     expression that will match either A or B. An arbitrary number of
     REs can be separated by the ‘'|'’ in this way.  This can be used
     inside groups (see below) as well.  As the target string is
     scanned, REs separated by ‘'|'’ are tried from left to right.  When
     one pattern completely matches, that branch is accepted.  This
     means that once ‘A’ matches, ‘B’ will not be tested further, even
     if it would produce a longer overall match.  In other words, the
     ‘'|'’ operator is never greedy.  To match a literal ‘'|'’, use
     ‘\|’, or enclose it inside a character class, as in ‘[|]’.

‘(...)’

     Matches whatever regular expression is inside the parentheses, and
     indicates the start and end of a group; the contents of a group can
     be retrieved after a match has been performed, and can be matched
     later in the string with the ‘\number’ special sequence, described
     below.  To match the literals ‘'('’ or ‘')'’, use ‘\(’ or ‘\)’, or
     enclose them inside a character class: ‘[(] [)]’.

‘(?...)’

     This is an extension notation (a ‘'?'’ following a ‘'('’ is not
     meaningful otherwise).  The first character after the ‘'?'’
     determines what the meaning and further syntax of the construct is.
     Extensions usually do not create a new group; ‘(?P<name>...)’ is
     the only exception to this rule.  Following are the currently
     supported extensions.

‘(?aiLmsux)’

     (One or more letters from the set ‘'a'’, ‘'i'’, ‘'L'’, ‘'m'’,
     ‘'s'’, ‘'u'’, ‘'x'’.)  The group matches the empty string; the
     letters set the corresponding flags: *note re.A: 1106. (ASCII-only
     matching), *note re.I: 1107. (ignore case), *note re.L: 1108.
     (locale dependent), *note re.M: 1109. (multi-line), *note re.S:
     110a. (dot matches all), and *note re.X: 110b. (verbose), for the
     entire regular expression.  (The flags are described in *note
     Module Contents: 110c.)  This is useful if you wish to include the
     flags as part of the regular expression, instead of passing a
     `flag' argument to the *note re.compile(): 110d. function.

     Note that the ‘(?x)’ flag changes how the expression is parsed.  It
     should be used first in the expression string, or after one or more
     whitespace characters.  If there are non-whitespace characters
     before the flag, the results are undefined.

‘(?:...)’

     A non-capturing version of regular parentheses.  Matches whatever
     regular expression is inside the parentheses, but the substring
     matched by the group `cannot' be retrieved after performing a match
     or referenced later in the pattern.

‘(?P<name>...)’

     Similar to regular parentheses, but the substring matched by the
     group is accessible via the symbolic group name `name'.  Group
     names must be valid Python identifiers, and each group name must be
     defined only once within a regular expression.  A symbolic group is
     also a numbered group, just as if the group were not named.

     Named groups can be referenced in three contexts.  If the pattern
     is ‘(?P<quote>['"]).*?(?P=quote)’ (i.e.  matching a string quoted
     with either single or double quotes):

     Context of reference to group "quote"       Ways to reference it
                                                 
     -----------------------------------------------------------------------------------
                                                 
     in the same pattern itself                     * ‘(?P=quote)’ (as shown)
                                                 
                                                    * ‘\1’
                                                 
                                                 
     when processing match object ‘m’               * ‘m.group('quote')’
                                                 
                                                    * ‘m.end('quote')’ (etc.)
                                                 
                                                 
     in a string passed to the ‘repl’ argument      * ‘\g<quote>’
     of ‘re.sub()’                               
                                                    * ‘\g<1>’
                                                 
                                                    * ‘\1’
                                                 

‘(?P=name)’

     A backreference to a named group; it matches whatever text was
     matched by the earlier group named `name'.

‘(?#...)’

     A comment; the contents of the parentheses are simply ignored.

‘(?=...)’

     Matches if ‘...’ matches next, but doesn’t consume any of the
     string.  This is called a lookahead assertion.  For example, ‘Isaac
     (?=Asimov)’ will match ‘'Isaac '’ only if it’s followed by
     ‘'Asimov'’.

‘(?!...)’

     Matches if ‘...’ doesn’t match next.  This is a negative lookahead
     assertion.  For example, ‘Isaac (?!Asimov)’ will match ‘'Isaac '’
     only if it’s `not' followed by ‘'Asimov'’.

‘(?<=...)’

     Matches if the current position in the string is preceded by a
     match for ‘...’ that ends at the current position.  This is called
     a `positive lookbehind assertion'.  ‘(?<=abc)def’ will find a match
     in ‘abcdef’, since the lookbehind will back up 3 characters and
     check if the contained pattern matches.  The contained pattern must
     only match strings of some fixed length, meaning that ‘abc’ or
     ‘a|b’ are allowed, but ‘a*’ and ‘a{3,4}’ are not.  Note that
     patterns which start with positive lookbehind assertions will not
     match at the beginning of the string being searched; you will most
     likely want to use the *note search(): 810. function rather than
     the *note match(): 811. function:

          >>> import re
          >>> m = re.search('(?<=abc)def', 'abcdef')
          >>> m.group(0)
          'def'

     This example looks for a word following a hyphen:

          >>> m = re.search('(?<=-)\w+', 'spam-egg')
          >>> m.group(0)
          'egg'

     Changed in version 3.5: Added support for group references of fixed
     length.

‘(?<!...)’

     Matches if the current position in the string is not preceded by a
     match for ‘...’.  This is called a `negative lookbehind assertion'.
     Similar to positive lookbehind assertions, the contained pattern
     must only match strings of some fixed length.  Patterns which start
     with negative lookbehind assertions may match at the beginning of
     the string being searched.

‘(?(id/name)yes-pattern|no-pattern)’

     Will try to match with ‘yes-pattern’ if the group with given `id'
     or `name' exists, and with ‘no-pattern’ if it doesn’t.
     ‘no-pattern’ is optional and can be omitted.  For example,
     ‘(<)?(\w+@\w+(?:\.\w+)+)(?(1)>|$)’ is a poor email matching
     pattern, which will match with ‘'<user@host.com>'’ as well as
     ‘'user@host.com'’, but not with ‘'<user@host.com'’ nor
     ‘'user@host.com>'’.

The special sequences consist of ‘'\'’ and a character from the list
below.  If the ordinary character is not on the list, then the resulting
RE will match the second character.  For example, ‘\$’ matches the
character ‘'$'’.

‘\number’

     Matches the contents of the group of the same number.  Groups are
     numbered starting from 1.  For example, ‘(.+) \1’ matches ‘'the
     the'’ or ‘'55 55'’, but not ‘'thethe'’ (note the space after the
     group).  This special sequence can only be used to match one of the
     first 99 groups.  If the first digit of `number' is 0, or `number'
     is 3 octal digits long, it will not be interpreted as a group
     match, but as the character with octal value `number'.  Inside the
     ‘'['’ and ‘']'’ of a character class, all numeric escapes are
     treated as characters.

‘\A’

     Matches only at the start of the string.

‘\b’

     Matches the empty string, but only at the beginning or end of a
     word.  A word is defined as a sequence of Unicode alphanumeric or
     underscore characters, so the end of a word is indicated by
     whitespace or a non-alphanumeric, non-underscore Unicode character.
     Note that formally, ‘\b’ is defined as the boundary between a ‘\w’
     and a ‘\W’ character (or vice versa), or between ‘\w’ and the
     beginning/end of the string.  This means that ‘r'\bfoo\b'’ matches
     ‘'foo'’, ‘'foo.'’, ‘'(foo)'’, ‘'bar foo baz'’ but not ‘'foobar'’ or
     ‘'foo3'’.

     By default Unicode alphanumerics are the ones used, but this can be
     changed by using the *note ASCII: 3a1. flag.  Inside a character
     range, ‘\b’ represents the backspace character, for compatibility
     with Python’s string literals.

‘\B’

     Matches the empty string, but only when it is `not' at the
     beginning or end of a word.  This means that ‘r'py\B'’ matches
     ‘'python'’, ‘'py3'’, ‘'py2'’, but not ‘'py'’, ‘'py.'’, or ‘'py!'’.
     ‘\B’ is just the opposite of ‘\b’, so word characters are Unicode
     alphanumerics or the underscore, although this can be changed by
     using the *note ASCII: 3a1. flag.

‘\d’

     For Unicode (str) patterns:

          Matches any Unicode decimal digit (that is, any character in
          Unicode character category [Nd]).  This includes ‘[0-9]’, and
          also many other digit characters.  If the *note ASCII: 3a1.
          flag is used only ‘[0-9]’ is matched (but the flag affects the
          entire regular expression, so in such cases using an explicit
          ‘[0-9]’ may be a better choice).

     For 8-bit (bytes) patterns:

          Matches any decimal digit; this is equivalent to ‘[0-9]’.

‘\D’

     Matches any character which is not a Unicode decimal digit.  This
     is the opposite of ‘\d’.  If the *note ASCII: 3a1. flag is used
     this becomes the equivalent of ‘[^0-9]’ (but the flag affects the
     entire regular expression, so in such cases using an explicit
     ‘[^0-9]’ may be a better choice).

‘\s’

     For Unicode (str) patterns:

          Matches Unicode whitespace characters (which includes ‘[
          \t\n\r\f\v]’, and also many other characters, for example the
          non-breaking spaces mandated by typography rules in many
          languages).  If the *note ASCII: 3a1. flag is used, only ‘[
          \t\n\r\f\v]’ is matched (but the flag affects the entire
          regular expression, so in such cases using an explicit ‘[
          \t\n\r\f\v]’ may be a better choice).

     For 8-bit (bytes) patterns:

          Matches characters considered whitespace in the ASCII
          character set; this is equivalent to ‘[ \t\n\r\f\v]’.

‘\S’

     Matches any character which is not a Unicode whitespace character.
     This is the opposite of ‘\s’.  If the *note ASCII: 3a1. flag is
     used this becomes the equivalent of ‘[^ \t\n\r\f\v]’ (but the flag
     affects the entire regular expression, so in such cases using an
     explicit ‘[^ \t\n\r\f\v]’ may be a better choice).

‘\w’

     For Unicode (str) patterns:

          Matches Unicode word characters; this includes most characters
          that can be part of a word in any language, as well as numbers
          and the underscore.  If the *note ASCII: 3a1. flag is used,
          only ‘[a-zA-Z0-9_]’ is matched (but the flag affects the
          entire regular expression, so in such cases using an explicit
          ‘[a-zA-Z0-9_]’ may be a better choice).

     For 8-bit (bytes) patterns:

          Matches characters considered alphanumeric in the ASCII
          character set; this is equivalent to ‘[a-zA-Z0-9_]’.

‘\W’

     Matches any character which is not a Unicode word character.  This
     is the opposite of ‘\w’.  If the *note ASCII: 3a1. flag is used
     this becomes the equivalent of ‘[^a-zA-Z0-9_]’ (but the flag
     affects the entire regular expression, so in such cases using an
     explicit ‘[^a-zA-Z0-9_]’ may be a better choice).

‘\Z’

     Matches only at the end of the string.

Most of the standard escapes supported by Python string literals are
also accepted by the regular expression parser:

     \a      \b      \f      \n
     \r      \t      \u      \U
     \v      \x      \\

(Note that ‘\b’ is used to represent word boundaries, and means
"backspace" only inside character classes.)

‘'\u'’ and ‘'\U'’ escape sequences are only recognized in Unicode
patterns.  In bytes patterns they are not treated specially.

Octal escapes are included in a limited form.  If the first digit is a
0, or if there are three octal digits, it is considered an octal escape.
Otherwise, it is a group reference.  As for string literals, octal
escapes are always at most three digits in length.

Changed in version 3.3: The ‘'\u'’ and ‘'\U'’ escape sequences have been
added.

Deprecated since version 3.5, will be removed in version 3.6: Unknown
escapes consist of ‘'\'’ and ASCII letter now raise a deprecation
warning and will be forbidden in Python 3.6.

See also
........

Mastering Regular Expressions

     Book on regular expressions by Jeffrey Friedl, published by
     O’Reilly.  The second edition of the book no longer covers Python
     at all, but the first edition covered writing good regular
     expression patterns in great detail.


File: python.info,  Node: Module Contents,  Next: Regular Expression Objects,  Prev: Regular Expression Syntax,  Up: re --- Regular expression operations

5.6.2.2 Module Contents
.......................

The module defines several functions, constants, and an exception.  Some
of the functions are simplified versions of the full featured methods
for compiled regular expressions.  Most non-trivial applications always
use the compiled form.

 -- Function: re.compile (pattern, flags=0)

     Compile a regular expression pattern into a regular expression
     object, which can be used for matching using its *note match():
     110f. and *note search(): 1110. methods, described below.

     The expression’s behaviour can be modified by specifying a `flags'
     value.  Values can be any of the following variables, combined
     using bitwise OR (the ‘|’ operator).

     The sequence

          prog = re.compile(pattern)
          result = prog.match(string)

     is equivalent to

          result = re.match(pattern, string)

     but using *note re.compile(): 110d. and saving the resulting
     regular expression object for reuse is more efficient when the
     expression will be used several times in a single program.

          Note: The compiled versions of the most recent patterns passed
          to *note re.compile(): 110d. and the module-level matching
          functions are cached, so programs that use only a few regular
          expressions at a time needn’t worry about compiling regular
          expressions.

 -- Data: re.A
 -- Data: re.ASCII

     Make ‘\w’, ‘\W’, ‘\b’, ‘\B’, ‘\d’, ‘\D’, ‘\s’ and ‘\S’ perform
     ASCII-only matching instead of full Unicode matching.  This is only
     meaningful for Unicode patterns, and is ignored for byte patterns.

     Note that for backward compatibility, the ‘re.U’ flag still exists
     (as well as its synonym ‘re.UNICODE’ and its embedded counterpart
     ‘(?u)’), but these are redundant in Python 3 since matches are
     Unicode by default for strings (and Unicode matching isn’t allowed
     for bytes).

 -- Data: re.DEBUG

     Display debug information about compiled expression.

 -- Data: re.I
 -- Data: re.IGNORECASE

     Perform case-insensitive matching; expressions like ‘[A-Z]’ will
     match lowercase letters, too.  This is not affected by the current
     locale and works for Unicode characters as expected.

 -- Data: re.L
 -- Data: re.LOCALE

     Make ‘\w’, ‘\W’, ‘\b’, ‘\B’, ‘\s’ and ‘\S’ dependent on the current
     locale.  The use of this flag is discouraged as the locale
     mechanism is very unreliable, and it only handles one "culture" at
     a time anyway; you should use Unicode matching instead, which is
     the default in Python 3 for Unicode (str) patterns.  This flag
     makes sense only with bytes patterns.

     Deprecated since version 3.5, will be removed in version 3.6:
     Deprecated the use of *note re.LOCALE: 3a0. with string patterns or
     *note re.ASCII: 3a1.

 -- Data: re.M
 -- Data: re.MULTILINE

     When specified, the pattern character ‘'^'’ matches at the
     beginning of the string and at the beginning of each line
     (immediately following each newline); and the pattern character
     ‘'$'’ matches at the end of the string and at the end of each line
     (immediately preceding each newline).  By default, ‘'^'’ matches
     only at the beginning of the string, and ‘'$'’ only at the end of
     the string and immediately before the newline (if any) at the end
     of the string.

 -- Data: re.S
 -- Data: re.DOTALL

     Make the ‘'.'’ special character match any character at all,
     including a newline; without this flag, ‘'.'’ will match anything
     `except' a newline.

 -- Data: re.X
 -- Data: re.VERBOSE

     This flag allows you to write regular expressions that look nicer
     and are more readable by allowing you to visually separate logical
     sections of the pattern and add comments.  Whitespace within the
     pattern is ignored, except when in a character class or when
     preceded by an unescaped backslash.  When a line contains a ‘#’
     that is not in a character class and is not preceded by an
     unescaped backslash, all characters from the leftmost such ‘#’
     through the end of the line are ignored.

     This means that the two following regular expression objects that
     match a decimal number are functionally equal:

          a = re.compile(r"""\d +  # the integral part
                             \.    # the decimal point
                             \d *  # some fractional digits""", re.X)
          b = re.compile(r"\d+\.\d*")

 -- Function: re.search (pattern, string, flags=0)

     Scan through `string' looking for the first location where the
     regular expression `pattern' produces a match, and return a
     corresponding *note match object: 49a.  Return ‘None’ if no
     position in the string matches the pattern; note that this is
     different from finding a zero-length match at some point in the
     string.

 -- Function: re.match (pattern, string, flags=0)

     If zero or more characters at the beginning of `string' match the
     regular expression `pattern', return a corresponding *note match
     object: 49a.  Return ‘None’ if the string does not match the
     pattern; note that this is different from a zero-length match.

     Note that even in *note MULTILINE: 1105. mode, *note re.match():
     811. will only match at the beginning of the string and not at the
     beginning of each line.

     If you want to locate a match anywhere in `string', use *note
     search(): 810. instead (see also *note search() vs.  match():
     1114.).

 -- Function: re.fullmatch (pattern, string, flags=0)

     If the whole `string' matches the regular expression `pattern',
     return a corresponding *note match object: 49a.  Return ‘None’ if
     the string does not match the pattern; note that this is different
     from a zero-length match.

     New in version 3.4.

 -- Function: re.split (pattern, string, maxsplit=0, flags=0)

     Split `string' by the occurrences of `pattern'.  If capturing
     parentheses are used in `pattern', then the text of all groups in
     the pattern are also returned as part of the resulting list.  If
     `maxsplit' is nonzero, at most `maxsplit' splits occur, and the
     remainder of the string is returned as the final element of the
     list.

          >>> re.split('\W+', 'Words, words, words.')
          ['Words', 'words', 'words', '']
          >>> re.split('(\W+)', 'Words, words, words.')
          ['Words', ', ', 'words', ', ', 'words', '.', '']
          >>> re.split('\W+', 'Words, words, words.', 1)
          ['Words', 'words, words.']
          >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE)
          ['0', '3', '9']

     If there are capturing groups in the separator and it matches at
     the start of the string, the result will start with an empty
     string.  The same holds for the end of the string:

          >>> re.split('(\W+)', '...words, words...')
          ['', '...', 'words', ', ', 'words', '...', '']

     That way, separator components are always found at the same
     relative indices within the result list.

          Note: *note split(): 3ae. doesn’t currently split a string on
          an empty pattern match.  For example:

               >>> re.split('x*', 'axbc')
               ['a', 'bc']

          Even though ‘'x*'’ also matches 0 ’x’ before ’a’, between ’b’
          and ’c’, and after ’c’, currently these matches are ignored.
          The correct behavior (i.e.  splitting on empty matches too and
          returning ‘['', 'a', 'b', 'c', '']’) will be implemented in
          future versions of Python, but since this is a backward
          incompatible change, a *note FutureWarning: 960. will be
          raised in the meanwhile.

          Patterns that can only match empty strings currently never
          split the string.  Since this doesn’t match the expected
          behavior, a *note ValueError: 19c. will be raised starting
          from Python 3.5:

               >>> re.split("^$", "foo\n\nbar\n", flags=re.M)
               Traceback (most recent call last):
                 File "<stdin>", line 1, in <module>
                 ...
               ValueError: split() requires a non-empty pattern match.

     Changed in version 3.1: Added the optional flags argument.

     Changed in version 3.5: Splitting on a pattern that could match an
     empty string now raises a warning.  Patterns that can only match
     empty strings are now rejected.

 -- Function: re.findall (pattern, string, flags=0)

     Return all non-overlapping matches of `pattern' in `string', as a
     list of strings.  The `string' is scanned left-to-right, and
     matches are returned in the order found.  If one or more groups are
     present in the pattern, return a list of groups; this will be a
     list of tuples if the pattern has more than one group.  Empty
     matches are included in the result unless they touch the beginning
     of another match.

 -- Function: re.finditer (pattern, string, flags=0)

     Return an *note iterator: e4f. yielding *note match objects: 49a.
     over all non-overlapping matches for the RE `pattern' in `string'.
     The `string' is scanned left-to-right, and matches are returned in
     the order found.  Empty matches are included in the result unless
     they touch the beginning of another match.

 -- Function: re.sub (pattern, repl, string, count=0, flags=0)

     Return the string obtained by replacing the leftmost
     non-overlapping occurrences of `pattern' in `string' by the
     replacement `repl'.  If the pattern isn’t found, `string' is
     returned unchanged.  `repl' can be a string or a function; if it is
     a string, any backslash escapes in it are processed.  That is, ‘\n’
     is converted to a single newline character, ‘\r’ is converted to a
     carriage return, and so forth.  Unknown escapes such as ‘\&’ are
     left alone.  Backreferences, such as ‘\6’, are replaced with the
     substring matched by group 6 in the pattern.  For example:

          >>> re.sub(r'def\s+([a-zA-Z_][a-zA-Z_0-9]*)\s*\(\s*\):',
          ...        r'static PyObject*\npy_\1(void)\n{',
          ...        'def myfunc():')
          'static PyObject*\npy_myfunc(void)\n{'

     If `repl' is a function, it is called for every non-overlapping
     occurrence of `pattern'.  The function takes a single match object
     argument, and returns the replacement string.  For example:

          >>> def dashrepl(matchobj):
          ...     if matchobj.group(0) == '-': return ' '
          ...     else: return '-'
          >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files')
          'pro--gram files'
          >>> re.sub(r'\sAND\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)
          'Baked Beans & Spam'

     The pattern may be a string or an RE object.

     The optional argument `count' is the maximum number of pattern
     occurrences to be replaced; `count' must be a non-negative integer.
     If omitted or zero, all occurrences will be replaced.  Empty
     matches for the pattern are replaced only when not adjacent to a
     previous match, so ‘sub('x*', '-', 'abc')’ returns ‘'-a-b-c-'’.

     In string-type `repl' arguments, in addition to the character
     escapes and backreferences described above, ‘\g<name>’ will use the
     substring matched by the group named ‘name’, as defined by the
     ‘(?P<name>...)’ syntax.  ‘\g<number>’ uses the corresponding group
     number; ‘\g<2>’ is therefore equivalent to ‘\2’, but isn’t
     ambiguous in a replacement such as ‘\g<2>0’.  ‘\20’ would be
     interpreted as a reference to group 20, not a reference to group 2
     followed by the literal character ‘'0'’.  The backreference ‘\g<0>’
     substitutes in the entire substring matched by the RE.

     Changed in version 3.1: Added the optional flags argument.

     Changed in version 3.5: Unmatched groups are replaced with an empty
     string.

     Deprecated since version 3.5, will be removed in version 3.6:
     Unknown escapes consist of ‘'\'’ and ASCII letter now raise a
     deprecation warning and will be forbidden in Python 3.6.

 -- Function: re.subn (pattern, repl, string, count=0, flags=0)

     Perform the same operation as *note sub(): 2f5, but return a tuple
     ‘(new_string, number_of_subs_made)’.

     Changed in version 3.1: Added the optional flags argument.

     Changed in version 3.5: Unmatched groups are replaced with an empty
     string.

 -- Function: re.escape (string)

     Escape all the characters in pattern except ASCII letters, numbers
     and ‘'_'’.  This is useful if you want to match an arbitrary
     literal string that may have regular expression metacharacters in
     it.

     Changed in version 3.3: The ‘'_'’ character is no longer escaped.

 -- Function: re.purge ()

     Clear the regular expression cache.

 -- Exception: re.error (msg, pattern=None, pos=None)

     Exception raised when a string passed to one of the functions here
     is not a valid regular expression (for example, it might contain
     unmatched parentheses) or when some other error occurs during
     compilation or matching.  It is never an error if a string contains
     no match for a pattern.  The error instance has the following
     additional attributes:

      -- Attribute: msg

          The unformatted error message.

      -- Attribute: pattern

          The regular expression pattern.

      -- Attribute: pos

          The index of `pattern' where compilation failed.

      -- Attribute: lineno

          The line corresponding to `pos'.

      -- Attribute: colno

          The column corresponding to `pos'.

     Changed in version 3.5: Added additional attributes.


File: python.info,  Node: Regular Expression Objects,  Next: Match Objects,  Prev: Module Contents,  Up: re --- Regular expression operations

5.6.2.3 Regular Expression Objects
..................................

Compiled regular expression objects support the following methods and
attributes:

 -- Method: regex.search (string[, pos[, endpos]])

     Scan through `string' looking for a location where this regular
     expression produces a match, and return a corresponding *note match
     object: 49a.  Return ‘None’ if no position in the string matches
     the pattern; note that this is different from finding a zero-length
     match at some point in the string.

     The optional second parameter `pos' gives an index in the string
     where the search is to start; it defaults to ‘0’.  This is not
     completely equivalent to slicing the string; the ‘'^'’ pattern
     character matches at the real beginning of the string and at
     positions just after a newline, but not necessarily at the index
     where the search is to start.

     The optional parameter `endpos' limits how far the string will be
     searched; it will be as if the string is `endpos' characters long,
     so only the characters from `pos' to ‘endpos - 1’ will be searched
     for a match.  If `endpos' is less than `pos', no match will be
     found; otherwise, if `rx' is a compiled regular expression object,
     ‘rx.search(string, 0, 50)’ is equivalent to ‘rx.search(string[:50],
     0)’.

          >>> pattern = re.compile("d")
          >>> pattern.search("dog")     # Match at index 0
          <_sre.SRE_Match object; span=(0, 1), match='d'>
          >>> pattern.search("dog", 1)  # No match; search doesn't include the "d"

 -- Method: regex.match (string[, pos[, endpos]])

     If zero or more characters at the `beginning' of `string' match
     this regular expression, return a corresponding *note match object:
     49a.  Return ‘None’ if the string does not match the pattern; note
     that this is different from a zero-length match.

     The optional `pos' and `endpos' parameters have the same meaning as
     for the *note search(): 1110. method.

          >>> pattern = re.compile("o")
          >>> pattern.match("dog")      # No match as "o" is not at the start of "dog".
          >>> pattern.match("dog", 1)   # Match as "o" is the 2nd character of "dog".
          <_sre.SRE_Match object; span=(1, 2), match='o'>

     If you want to locate a match anywhere in `string', use *note
     search(): 1110. instead (see also *note search() vs.  match():
     1114.).

 -- Method: regex.fullmatch (string[, pos[, endpos]])

     If the whole `string' matches this regular expression, return a
     corresponding *note match object: 49a.  Return ‘None’ if the string
     does not match the pattern; note that this is different from a
     zero-length match.

     The optional `pos' and `endpos' parameters have the same meaning as
     for the *note search(): 1110. method.

          >>> pattern = re.compile("o[gh]")
          >>> pattern.fullmatch("dog")      # No match as "o" is not at the start of "dog".
          >>> pattern.fullmatch("ogre")     # No match as not the full string matches.
          >>> pattern.fullmatch("doggie", 1, 3)   # Matches within given limits.
          <_sre.SRE_Match object; span=(1, 3), match='og'>

     New in version 3.4.

 -- Method: regex.split (string, maxsplit=0)

     Identical to the *note split(): 3ae. function, using the compiled
     pattern.

 -- Method: regex.findall (string[, pos[, endpos]])

     Similar to the *note findall(): 57d. function, using the compiled
     pattern, but also accepts optional `pos' and `endpos' parameters
     that limit the search region like for *note match(): 811.

 -- Method: regex.finditer (string[, pos[, endpos]])

     Similar to the *note finditer(): 1115. function, using the compiled
     pattern, but also accepts optional `pos' and `endpos' parameters
     that limit the search region like for *note match(): 811.

 -- Method: regex.sub (repl, string, count=0)

     Identical to the *note sub(): 2f5. function, using the compiled
     pattern.

 -- Method: regex.subn (repl, string, count=0)

     Identical to the *note subn(): 2f6. function, using the compiled
     pattern.

 -- Attribute: regex.flags

     The regex matching flags.  This is a combination of the flags given
     to *note compile(): 110d, any ‘(?...)’ inline flags in the pattern,
     and implicit flags such as ‘UNICODE’ if the pattern is a Unicode
     string.

 -- Attribute: regex.groups

     The number of capturing groups in the pattern.

 -- Attribute: regex.groupindex

     A dictionary mapping any symbolic group names defined by ‘(?P<id>)’
     to group numbers.  The dictionary is empty if no symbolic groups
     were used in the pattern.

 -- Attribute: regex.pattern

     The pattern string from which the RE object was compiled.


File: python.info,  Node: Match Objects,  Next: Regular Expression Examples,  Prev: Regular Expression Objects,  Up: re --- Regular expression operations

5.6.2.4 Match Objects
.....................

Match objects always have a boolean value of ‘True’.  Since *note
match(): 110f. and *note search(): 1110. return ‘None’ when there is no
match, you can test whether there was a match with a simple ‘if’
statement:

     match = re.search(pattern, string)
     if match:
         process(match)

Match objects support the following methods and attributes:

 -- Method: match.expand (template)

     Return the string obtained by doing backslash substitution on the
     template string `template', as done by the *note sub(): 111b.
     method.  Escapes such as ‘\n’ are converted to the appropriate
     characters, and numeric backreferences (‘\1’, ‘\2’) and named
     backreferences (‘\g<1>’, ‘\g<name>’) are replaced by the contents
     of the corresponding group.

     Changed in version 3.5: Unmatched groups are replaced with an empty
     string.

 -- Method: match.group ([group1, ...])

     Returns one or more subgroups of the match.  If there is a single
     argument, the result is a single string; if there are multiple
     arguments, the result is a tuple with one item per argument.
     Without arguments, `group1' defaults to zero (the whole match is
     returned).  If a `groupN' argument is zero, the corresponding
     return value is the entire matching string; if it is in the
     inclusive range [1..99], it is the string matching the
     corresponding parenthesized group.  If a group number is negative
     or larger than the number of groups defined in the pattern, an
     *note IndexError: afb. exception is raised.  If a group is
     contained in a part of the pattern that did not match, the
     corresponding result is ‘None’.  If a group is contained in a part
     of the pattern that matched multiple times, the last match is
     returned.

          >>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")
          >>> m.group(0)       # The entire match
          'Isaac Newton'
          >>> m.group(1)       # The first parenthesized subgroup.
          'Isaac'
          >>> m.group(2)       # The second parenthesized subgroup.
          'Newton'
          >>> m.group(1, 2)    # Multiple arguments give us a tuple.
          ('Isaac', 'Newton')

     If the regular expression uses the ‘(?P<name>...)’ syntax, the
     `groupN' arguments may also be strings identifying groups by their
     group name.  If a string argument is not used as a group name in
     the pattern, an *note IndexError: afb. exception is raised.

     A moderately complicated example:

          >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
          >>> m.group('first_name')
          'Malcolm'
          >>> m.group('last_name')
          'Reynolds'

     Named groups can also be referred to by their index:

          >>> m.group(1)
          'Malcolm'
          >>> m.group(2)
          'Reynolds'

     If a group matches multiple times, only the last match is
     accessible:

          >>> m = re.match(r"(..)+", "a1b2c3")  # Matches 3 times.
          >>> m.group(1)                        # Returns only the last match.
          'c3'

 -- Method: match.groups (default=None)

     Return a tuple containing all the subgroups of the match, from 1 up
     to however many groups are in the pattern.  The `default' argument
     is used for groups that did not participate in the match; it
     defaults to ‘None’.

     For example:

          >>> m = re.match(r"(\d+)\.(\d+)", "24.1632")
          >>> m.groups()
          ('24', '1632')

     If we make the decimal place and everything after it optional, not
     all groups might participate in the match.  These groups will
     default to ‘None’ unless the `default' argument is given:

          >>> m = re.match(r"(\d+)\.?(\d+)?", "24")
          >>> m.groups()      # Second group defaults to None.
          ('24', None)
          >>> m.groups('0')   # Now, the second group defaults to '0'.
          ('24', '0')

 -- Method: match.groupdict (default=None)

     Return a dictionary containing all the `named' subgroups of the
     match, keyed by the subgroup name.  The `default' argument is used
     for groups that did not participate in the match; it defaults to
     ‘None’.  For example:

          >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
          >>> m.groupdict()
          {'first_name': 'Malcolm', 'last_name': 'Reynolds'}

 -- Method: match.start ([group])
 -- Method: match.end ([group])

     Return the indices of the start and end of the substring matched by
     `group'; `group' defaults to zero (meaning the whole matched
     substring).  Return ‘-1’ if `group' exists but did not contribute
     to the match.  For a match object `m', and a group `g' that did
     contribute to the match, the substring matched by group `g'
     (equivalent to ‘m.group(g)’) is

          m.string[m.start(g):m.end(g)]

     Note that ‘m.start(group)’ will equal ‘m.end(group)’ if `group'
     matched a null string.  For example, after ‘m = re.search('b(c?)',
     'cba')’, ‘m.start(0)’ is 1, ‘m.end(0)’ is 2, ‘m.start(1)’ and
     ‘m.end(1)’ are both 2, and ‘m.start(2)’ raises an *note IndexError:
     afb. exception.

     An example that will remove `remove_this' from email addresses:

          >>> email = "tony@tiremove_thisger.net"
          >>> m = re.search("remove_this", email)
          >>> email[:m.start()] + email[m.end():]
          'tony@tiger.net'

 -- Method: match.span ([group])

     For a match `m', return the 2-tuple ‘(m.start(group),
     m.end(group))’.  Note that if `group' did not contribute to the
     match, this is ‘(-1, -1)’.  `group' defaults to zero, the entire
     match.

 -- Attribute: match.pos

     The value of `pos' which was passed to the *note search(): 1110. or
     *note match(): 110f. method of a *note regex object: 499.  This is
     the index into the string at which the RE engine started looking
     for a match.

 -- Attribute: match.endpos

     The value of `endpos' which was passed to the *note search(): 1110.
     or *note match(): 110f. method of a *note regex object: 499.  This
     is the index into the string beyond which the RE engine will not
     go.

 -- Attribute: match.lastindex

     The integer index of the last matched capturing group, or ‘None’ if
     no group was matched at all.  For example, the expressions ‘(a)b’,
     ‘((a)(b))’, and ‘((ab))’ will have ‘lastindex == 1’ if applied to
     the string ‘'ab'’, while the expression ‘(a)(b)’ will have
     ‘lastindex == 2’, if applied to the same string.

 -- Attribute: match.lastgroup

     The name of the last matched capturing group, or ‘None’ if the
     group didn’t have a name, or if no group was matched at all.

 -- Attribute: match.re

     The regular expression object whose *note match(): 110f. or *note
     search(): 1110. method produced this match instance.

 -- Attribute: match.string

     The string passed to *note match(): 110f. or *note search(): 1110.


File: python.info,  Node: Regular Expression Examples,  Prev: Match Objects,  Up: re --- Regular expression operations

5.6.2.5 Regular Expression Examples
...................................

* Menu:

* Checking for a Pair:: 
* Simulating scanf(): Simulating scanf. 
* search() vs. match(): search vs match. 
* Making a Phonebook:: 
* Text Munging:: 
* Finding all Adverbs:: 
* Finding all Adverbs and their Positions:: 
* Raw String Notation:: 
* Writing a Tokenizer:: 


File: python.info,  Node: Checking for a Pair,  Next: Simulating scanf,  Up: Regular Expression Examples

5.6.2.6 Checking for a Pair
...........................

In this example, we’ll use the following helper function to display
match objects a little more gracefully:

     def displaymatch(match):
         if match is None:
             return None
         return '<Match: %r, groups=%r>' % (match.group(), match.groups())

Suppose you are writing a poker program where a player’s hand is
represented as a 5-character string with each character representing a
card, "a" for ace, "k" for king, "q" for queen, "j" for jack, "t" for
10, and "2" through "9" representing the card with that value.

To see if a given string is a valid hand, one could do the following:

     >>> valid = re.compile(r"^[a2-9tjqk]{5}$")
     >>> displaymatch(valid.match("akt5q"))  # Valid.
     "<Match: 'akt5q', groups=()>"
     >>> displaymatch(valid.match("akt5e"))  # Invalid.
     >>> displaymatch(valid.match("akt"))    # Invalid.
     >>> displaymatch(valid.match("727ak"))  # Valid.
     "<Match: '727ak', groups=()>"

That last hand, ‘"727ak"’, contained a pair, or two of the same valued
cards.  To match this with a regular expression, one could use
backreferences as such:

     >>> pair = re.compile(r".*(.).*\1")
     >>> displaymatch(pair.match("717ak"))     # Pair of 7s.
     "<Match: '717', groups=('7',)>"
     >>> displaymatch(pair.match("718ak"))     # No pairs.
     >>> displaymatch(pair.match("354aa"))     # Pair of aces.
     "<Match: '354aa', groups=('a',)>"

To find out what card the pair consists of, one could use the *note
group(): 57e. method of the match object in the following manner:

     >>> pair.match("717ak").group(1)
     '7'

     # Error because re.match() returns None, which doesn't have a group() method:
     >>> pair.match("718ak").group(1)
     Traceback (most recent call last):
       File "<pyshell#23>", line 1, in <module>
         re.match(r".*(.).*\1", "718ak").group(1)
     AttributeError: 'NoneType' object has no attribute 'group'

     >>> pair.match("354aa").group(1)
     'a'


File: python.info,  Node: Simulating scanf,  Next: search vs match,  Prev: Checking for a Pair,  Up: Regular Expression Examples

5.6.2.7 Simulating scanf()
..........................

Python does not currently have an equivalent to ‘scanf()’.  Regular
expressions are generally more powerful, though also more verbose, than
‘scanf()’ format strings.  The table below offers some more-or-less
equivalent mappings between ‘scanf()’ format tokens and regular
expressions.

‘scanf()’ Token                      Regular Expression
                                     
---------------------------------------------------------------------------------------
                                     
‘%c’                                 ‘.’
                                     
                                     
‘%5c’                                ‘.{5}’
                                     
                                     
‘%d’                                 ‘[-+]?\d+’
                                     
                                     
‘%e’, ‘%E’, ‘%f’, ‘%g’               ‘[-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?’
                                     
                                     
‘%i’                                 ‘[-+]?(0[xX][\dA-Fa-f]+|0[0-7]*|\d+)’
                                     
                                     
‘%o’                                 ‘[-+]?[0-7]+’
                                     
                                     
‘%s’                                 ‘\S+’
                                     
                                     
‘%u’                                 ‘\d+’
                                     
                                     
‘%x’, ‘%X’                           ‘[-+]?(0[xX])?[\dA-Fa-f]+’
                                     

To extract the filename and numbers from a string like

     /usr/sbin/sendmail - 0 errors, 4 warnings

you would use a ‘scanf()’ format like

     %s - %d errors, %d warnings

The equivalent regular expression would be

     (\S+) - (\d+) errors, (\d+) warnings


File: python.info,  Node: search vs match,  Next: Making a Phonebook,  Prev: Simulating scanf,  Up: Regular Expression Examples

5.6.2.8 search() vs. match()
............................

Python offers two different primitive operations based on regular
expressions: *note re.match(): 811. checks for a match only at the
beginning of the string, while *note re.search(): 810. checks for a
match anywhere in the string (this is what Perl does by default).

For example:

     >>> re.match("c", "abcdef")  # No match
     >>> re.search("c", "abcdef") # Match
     <_sre.SRE_Match object; span=(2, 3), match='c'>

Regular expressions beginning with ‘'^'’ can be used with *note
search(): 810. to restrict the match at the beginning of the string:

     >>> re.match("c", "abcdef")  # No match
     >>> re.search("^c", "abcdef") # No match
     >>> re.search("^a", "abcdef")  # Match
     <_sre.SRE_Match object; span=(0, 1), match='a'>

Note however that in *note MULTILINE: 1105. mode *note match(): 811.
only matches at the beginning of the string, whereas using *note
search(): 810. with a regular expression beginning with ‘'^'’ will match
at the beginning of each line.

     >>> re.match('X', 'A\nB\nX', re.MULTILINE)  # No match
     >>> re.search('^X', 'A\nB\nX', re.MULTILINE)  # Match
     <_sre.SRE_Match object; span=(4, 5), match='X'>


File: python.info,  Node: Making a Phonebook,  Next: Text Munging,  Prev: search vs match,  Up: Regular Expression Examples

5.6.2.9 Making a Phonebook
..........................

*note split(): 3ae. splits a string into a list delimited by the passed
pattern.  The method is invaluable for converting textual data into data
structures that can be easily read and modified by Python as
demonstrated in the following example that creates a phonebook.

First, here is the input.  Normally it may come from a file, here we are
using triple-quoted string syntax:

     >>> text = """Ross McFluff: 834.345.1254 155 Elm Street
     ...
     ... Ronald Heathmore: 892.345.3428 436 Finley Avenue
     ... Frank Burger: 925.541.7625 662 South Dogwood Way
     ...
     ...
     ... Heather Albrecht: 548.326.4584 919 Park Place"""

The entries are separated by one or more newlines.  Now we convert the
string into a list with each nonempty line having its own entry:

     >>> entries = re.split("\n+", text)
     >>> entries
     ['Ross McFluff: 834.345.1254 155 Elm Street',
     'Ronald Heathmore: 892.345.3428 436 Finley Avenue',
     'Frank Burger: 925.541.7625 662 South Dogwood Way',
     'Heather Albrecht: 548.326.4584 919 Park Place']

Finally, split each entry into a list with first name, last name,
telephone number, and address.  We use the ‘maxsplit’ parameter of *note
split(): 3ae. because the address has spaces, our splitting pattern, in
it:

     >>> [re.split(":? ", entry, 3) for entry in entries]
     [['Ross', 'McFluff', '834.345.1254', '155 Elm Street'],
     ['Ronald', 'Heathmore', '892.345.3428', '436 Finley Avenue'],
     ['Frank', 'Burger', '925.541.7625', '662 South Dogwood Way'],
     ['Heather', 'Albrecht', '548.326.4584', '919 Park Place']]

The ‘:?’ pattern matches the colon after the last name, so that it does
not occur in the result list.  With a ‘maxsplit’ of ‘4’, we could
separate the house number from the street name:

     >>> [re.split(":? ", entry, 4) for entry in entries]
     [['Ross', 'McFluff', '834.345.1254', '155', 'Elm Street'],
     ['Ronald', 'Heathmore', '892.345.3428', '436', 'Finley Avenue'],
     ['Frank', 'Burger', '925.541.7625', '662', 'South Dogwood Way'],
     ['Heather', 'Albrecht', '548.326.4584', '919', 'Park Place']]


File: python.info,  Node: Text Munging,  Next: Finding all Adverbs,  Prev: Making a Phonebook,  Up: Regular Expression Examples

5.6.2.10 Text Munging
.....................

*note sub(): 2f5. replaces every occurrence of a pattern with a string
or the result of a function.  This example demonstrates using *note
sub(): 2f5. with a function to "munge" text, or randomize the order of
all the characters in each word of a sentence except for the first and
last characters:

     >>> def repl(m):
     ...   inner_word = list(m.group(2))
     ...   random.shuffle(inner_word)
     ...   return m.group(1) + "".join(inner_word) + m.group(3)
     >>> text = "Professor Abdolmalek, please report your absences promptly."
     >>> re.sub(r"(\w)(\w+)(\w)", repl, text)
     'Poefsrosr Aealmlobdk, pslaee reorpt your abnseces plmrptoy.'
     >>> re.sub(r"(\w)(\w+)(\w)", repl, text)
     'Pofsroser Aodlambelk, plasee reoprt yuor asnebces potlmrpy.'


File: python.info,  Node: Finding all Adverbs,  Next: Finding all Adverbs and their Positions,  Prev: Text Munging,  Up: Regular Expression Examples

5.6.2.11 Finding all Adverbs
............................

*note findall(): 57d. matches `all' occurrences of a pattern, not just
the first one as *note search(): 810. does.  For example, if one was a
writer and wanted to find all of the adverbs in some text, he or she
might use *note findall(): 57d. in the following manner:

     >>> text = "He was carefully disguised but captured quickly by police."
     >>> re.findall(r"\w+ly", text)
     ['carefully', 'quickly']


File: python.info,  Node: Finding all Adverbs and their Positions,  Next: Raw String Notation,  Prev: Finding all Adverbs,  Up: Regular Expression Examples

5.6.2.12 Finding all Adverbs and their Positions
................................................

If one wants more information about all matches of a pattern than the
matched text, *note finditer(): 1115. is useful as it provides *note
match objects: 49a. instead of strings.  Continuing with the previous
example, if one was a writer who wanted to find all of the adverbs `and
their positions' in some text, he or she would use *note finditer():
1115. in the following manner:

     >>> text = "He was carefully disguised but captured quickly by police."
     >>> for m in re.finditer(r"\w+ly", text):
     ...     print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))
     07-16: carefully
     40-47: quickly


File: python.info,  Node: Raw String Notation,  Next: Writing a Tokenizer,  Prev: Finding all Adverbs and their Positions,  Up: Regular Expression Examples

5.6.2.13 Raw String Notation
............................

Raw string notation (‘r"text"’) keeps regular expressions sane.  Without
it, every backslash (‘'\'’) in a regular expression would have to be
prefixed with another one to escape it.  For example, the two following
lines of code are functionally identical:

     >>> re.match(r"\W(.)\1\W", " ff ")
     <_sre.SRE_Match object; span=(0, 4), match=' ff '>
     >>> re.match("\\W(.)\\1\\W", " ff ")
     <_sre.SRE_Match object; span=(0, 4), match=' ff '>

When one wants to match a literal backslash, it must be escaped in the
regular expression.  With raw string notation, this means ‘r"\\"’.
Without raw string notation, one must use ‘"\\\\"’, making the following
lines of code functionally identical:

     >>> re.match(r"\\", r"\\")
     <_sre.SRE_Match object; span=(0, 1), match='\\'>
     >>> re.match("\\\\", r"\\")
     <_sre.SRE_Match object; span=(0, 1), match='\\'>


File: python.info,  Node: Writing a Tokenizer,  Prev: Raw String Notation,  Up: Regular Expression Examples

5.6.2.14 Writing a Tokenizer
............................

A tokenizer or scanner(1) analyzes a string to categorize groups of
characters.  This is a useful first step in writing a compiler or
interpreter.

The text categories are specified with regular expressions.  The
technique is to combine those into a single master regular expression
and to loop over successive matches:

     import collections
     import re

     Token = collections.namedtuple('Token', ['typ', 'value', 'line', 'column'])

     def tokenize(code):
         keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}
         token_specification = [
             ('NUMBER',  r'\d+(\.\d*)?'), # Integer or decimal number
             ('ASSIGN',  r':='),          # Assignment operator
             ('END',     r';'),           # Statement terminator
             ('ID',      r'[A-Za-z]+'),   # Identifiers
             ('OP',      r'[+\-*/]'),     # Arithmetic operators
             ('NEWLINE', r'\n'),          # Line endings
             ('SKIP',    r'[ \t]+'),      # Skip over spaces and tabs
             ('MISMATCH',r'.'),           # Any other character
         ]
         tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)
         line_num = 1
         line_start = 0
         for mo in re.finditer(tok_regex, code):
             kind = mo.lastgroup
             value = mo.group(kind)
             if kind == 'NEWLINE':
                 line_start = mo.end()
                 line_num += 1
             elif kind == 'SKIP':
                 pass
             elif kind == 'MISMATCH':
                 raise RuntimeError('%r unexpected on line %d' % (value, line_num))
             else:
                 if kind == 'ID' and value in keywords:
                     kind = value
                 column = mo.start() - line_start
                 yield Token(kind, value, line_num, column)

     statements = '''
         IF quantity THEN
             total := total + price * quantity;
             tax := price * 0.05;
         ENDIF;
     '''

     for token in tokenize(statements):
         print(token)

The tokenizer produces the following output:

     Token(typ='IF', value='IF', line=2, column=4)
     Token(typ='ID', value='quantity', line=2, column=7)
     Token(typ='THEN', value='THEN', line=2, column=16)
     Token(typ='ID', value='total', line=3, column=8)
     Token(typ='ASSIGN', value=':=', line=3, column=14)
     Token(typ='ID', value='total', line=3, column=17)
     Token(typ='OP', value='+', line=3, column=23)
     Token(typ='ID', value='price', line=3, column=25)
     Token(typ='OP', value='*', line=3, column=31)
     Token(typ='ID', value='quantity', line=3, column=33)
     Token(typ='END', value=';', line=3, column=41)
     Token(typ='ID', value='tax', line=4, column=8)
     Token(typ='ASSIGN', value=':=', line=4, column=12)
     Token(typ='ID', value='price', line=4, column=15)
     Token(typ='OP', value='*', line=4, column=21)
     Token(typ='NUMBER', value='0.05', line=4, column=23)
     Token(typ='END', value=';', line=4, column=27)
     Token(typ='ENDIF', value='ENDIF', line=5, column=4)
     Token(typ='END', value=';', line=5, column=9)

   ---------- Footnotes ----------

   (1) https://en.wikipedia.org/wiki/Lexical_analysis


File: python.info,  Node: difflib --- Helpers for computing deltas,  Next: textwrap --- Text wrapping and filling,  Prev: re --- Regular expression operations,  Up: Text Processing Services

5.6.3 ‘difflib’ — Helpers for computing deltas
----------------------------------------------

`Source code:' Lib/difflib.py(1)

This module provides classes and functions for comparing sequences.  It
can be used for example, for comparing files, and can produce difference
information in various formats, including HTML and context and unified
diffs.  For comparing directories and files, see also, the *note
filecmp: 7d. module.

 -- Class: difflib.SequenceMatcher

     This is a flexible class for comparing pairs of sequences of any
     type, so long as the sequence elements are *note hashable: de9.
     The basic algorithm predates, and is a little fancier than, an
     algorithm published in the late 1980’s by Ratcliff and Obershelp
     under the hyperbolic name "gestalt pattern matching."  The idea is
     to find the longest contiguous matching subsequence that contains
     no "junk" elements; these "junk" elements are ones that are
     uninteresting in some sense, such as blank lines or whitespace.
     (Handling junk is an extension to the Ratcliff and Obershelp
     algorithm.)  The same idea is then applied recursively to the
     pieces of the sequences to the left and to the right of the
     matching subsequence.  This does not yield minimal edit sequences,
     but does tend to yield matches that "look right" to people.

     `Timing:' The basic Ratcliff-Obershelp algorithm is cubic time in
     the worst case and quadratic time in the expected case.  *note
     SequenceMatcher: 563. is quadratic time for the worst case and has
     expected-case behavior dependent in a complicated way on how many
     elements the sequences have in common; best case time is linear.

     `Automatic junk heuristic:' *note SequenceMatcher: 563. supports a
     heuristic that automatically treats certain sequence items as junk.
     The heuristic counts how many times each individual item appears in
     the sequence.  If an item’s duplicates (after the first one)
     account for more than 1% of the sequence and the sequence is at
     least 200 items long, this item is marked as "popular" and is
     treated as junk for the purpose of sequence matching.  This
     heuristic can be turned off by setting the ‘autojunk’ argument to
     ‘False’ when creating the *note SequenceMatcher: 563.

     New in version 3.2: The `autojunk' parameter.

 -- Class: difflib.Differ

     This is a class for comparing sequences of lines of text, and
     producing human-readable differences or deltas.  Differ uses *note
     SequenceMatcher: 563. both to compare sequences of lines, and to
     compare sequences of characters within similar (near-matching)
     lines.

     Each line of a *note Differ: 1139. delta begins with a two-letter
     code:

     Code           Meaning
                    
     ---------------------------------------------------------------
                    
     ‘'- '’         line unique to sequence 1
                    
                    
     ‘'+ '’         line unique to sequence 2
                    
                    
     ‘' '’          line common to both sequences
                    
                    
     ‘'? '’         line not present in either input sequence
                    

     Lines beginning with ’‘?’’ attempt to guide the eye to intraline
     differences, and were not present in either input sequence.  These
     lines can be confusing if the sequences contain tab characters.

 -- Class: difflib.HtmlDiff

     This class can be used to create an HTML table (or a complete HTML
     file containing the table) showing a side by side, line by line
     comparison of text with inter-line and intra-line change
     highlights.  The table can be generated in either full or
     contextual difference mode.

     The constructor for this class is:

      -- Method: __init__ (tabsize=8, wrapcolumn=None, linejunk=None,
               charjunk=IS_CHARACTER_JUNK)

          Initializes instance of *note HtmlDiff: 113a.

          `tabsize' is an optional keyword argument to specify tab stop
          spacing and defaults to ‘8’.

          `wrapcolumn' is an optional keyword to specify column number
          where lines are broken and wrapped, defaults to ‘None’ where
          lines are not wrapped.

          `linejunk' and `charjunk' are optional keyword arguments
          passed into *note ndiff(): 113c. (used by *note HtmlDiff:
          113a. to generate the side by side HTML differences).  See
          *note ndiff(): 113c. documentation for argument default values
          and descriptions.

     The following methods are public:

      -- Method: make_file (fromlines, tolines, fromdesc='', todesc='',
               context=False, numlines=5, *, charset='utf-8')

          Compares `fromlines' and `tolines' (lists of strings) and
          returns a string which is a complete HTML file containing a
          table showing line by line differences with inter-line and
          intra-line changes highlighted.

          `fromdesc' and `todesc' are optional keyword arguments to
          specify from/to file column header strings (both default to an
          empty string).

          `context' and `numlines' are both optional keyword arguments.
          Set `context' to ‘True’ when contextual differences are to be
          shown, else the default is ‘False’ to show the full files.
          `numlines' defaults to ‘5’.  When `context' is ‘True’
          `numlines' controls the number of context lines which surround
          the difference highlights.  When `context' is ‘False’
          `numlines' controls the number of lines which are shown before
          a difference highlight when using the "next" hyperlinks
          (setting to zero would cause the "next" hyperlinks to place
          the next difference highlight at the top of the browser
          without any leading context).

          Changed in version 3.5: `charset' keyword-only argument was
          added.  The default charset of HTML document changed from
          ‘'ISO-8859-1'’ to ‘'utf-8'’.

      -- Method: make_table (fromlines, tolines, fromdesc='', todesc='',
               context=False, numlines=5)

          Compares `fromlines' and `tolines' (lists of strings) and
          returns a string which is a complete HTML table showing line
          by line differences with inter-line and intra-line changes
          highlighted.

          The arguments for this method are the same as those for the
          *note make_file(): 278. method.

     ‘Tools/scripts/diff.py’ is a command-line front-end to this class
     and contains a good example of its use.

 -- Function: difflib.context_diff (a, b, fromfile='', tofile='',
          fromfiledate='', tofiledate='', n=3, lineterm='\n')

     Compare `a' and `b' (lists of strings); return a delta (a *note
     generator: 5c0. generating the delta lines) in context diff format.

     Context diffs are a compact way of showing just the lines that have
     changed plus a few lines of context.  The changes are shown in a
     before/after style.  The number of context lines is set by `n'
     which defaults to three.

     By default, the diff control lines (those with ‘***’ or ‘---’) are
     created with a trailing newline.  This is helpful so that inputs
     created from *note io.IOBase.readlines(): 113f. result in diffs
     that are suitable for use with *note io.IOBase.writelines(): 1140.
     since both the inputs and outputs have trailing newlines.

     For inputs that do not have trailing newlines, set the `lineterm'
     argument to ‘""’ so that the output will be uniformly newline free.

     The context diff format normally has a header for filenames and
     modification times.  Any or all of these may be specified using
     strings for `fromfile', `tofile', `fromfiledate', and `tofiledate'.
     The modification times are normally expressed in the ISO 8601
     format.  If not specified, the strings default to blanks.

          >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
          >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
          >>> for line in context_diff(s1, s2, fromfile='before.py', tofile='after.py'):
          ...     sys.stdout.write(line)  # doctest: +NORMALIZE_WHITESPACE
          *** before.py
          --- after.py
          ***************
          *** 1,4 ****
          ! bacon
          ! eggs
          ! ham
            guido
          --- 1,4 ----
          ! python
          ! eggy
          ! hamster
            guido

     See *note A command-line interface to difflib: 1141. for a more
     detailed example.

 -- Function: difflib.get_close_matches (word, possibilities, n=3,
          cutoff=0.6)

     Return a list of the best "good enough" matches.  `word' is a
     sequence for which close matches are desired (typically a string),
     and `possibilities' is a list of sequences against which to match
     `word' (typically a list of strings).

     Optional argument `n' (default ‘3’) is the maximum number of close
     matches to return; `n' must be greater than ‘0’.

     Optional argument `cutoff' (default ‘0.6’) is a float in the range
     [0, 1].  Possibilities that don’t score at least that similar to
     `word' are ignored.

     The best (no more than `n') matches among the possibilities are
     returned in a list, sorted by similarity score, most similar first.

          >>> get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])
          ['apple', 'ape']
          >>> import keyword
          >>> get_close_matches('wheel', keyword.kwlist)
          ['while']
          >>> get_close_matches('apple', keyword.kwlist)
          []
          >>> get_close_matches('accept', keyword.kwlist)
          ['except']

 -- Function: difflib.ndiff (a, b, linejunk=None,
          charjunk=IS_CHARACTER_JUNK)

     Compare `a' and `b' (lists of strings); return a *note Differ:
     1139.-style delta (a *note generator: 5c0. generating the delta
     lines).

     Optional keyword parameters `linejunk' and `charjunk' are filtering
     functions (or ‘None’):

     `linejunk': A function that accepts a single string argument, and
     returns true if the string is junk, or false if not.  The default
     is ‘None’.  There is also a module-level function *note
     IS_LINE_JUNK(): 1143, which filters out lines without visible
     characters, except for at most one pound character (‘'#'’) –
     however the underlying *note SequenceMatcher: 563. class does a
     dynamic analysis of which lines are so frequent as to constitute
     noise, and this usually works better than using this function.

     `charjunk': A function that accepts a character (a string of length
     1), and returns if the character is junk, or false if not.  The
     default is module-level function *note IS_CHARACTER_JUNK(): 1144,
     which filters out whitespace characters (a blank or tab; it’s a bad
     idea to include newline in this!).

     ‘Tools/scripts/ndiff.py’ is a command-line front-end to this
     function.

          >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
          ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
          >>> print(''.join(diff), end="")
          - one
          ?  ^
          + ore
          ?  ^
          - two
          - three
          ?  -
          + tree
          + emu

 -- Function: difflib.restore (sequence, which)

     Return one of the two sequences that generated a delta.

     Given a `sequence' produced by *note Differ.compare(): 1146. or
     *note ndiff(): 113c, extract lines originating from file 1 or 2
     (parameter `which'), stripping off line prefixes.

     Example:

          >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
          ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
          >>> diff = list(diff) # materialize the generated delta into a list
          >>> print(''.join(restore(diff, 1)), end="")
          one
          two
          three
          >>> print(''.join(restore(diff, 2)), end="")
          ore
          tree
          emu

 -- Function: difflib.unified_diff (a, b, fromfile='', tofile='',
          fromfiledate='', tofiledate='', n=3, lineterm='\n')

     Compare `a' and `b' (lists of strings); return a delta (a *note
     generator: 5c0. generating the delta lines) in unified diff format.

     Unified diffs are a compact way of showing just the lines that have
     changed plus a few lines of context.  The changes are shown in an
     inline style (instead of separate before/after blocks).  The number
     of context lines is set by `n' which defaults to three.

     By default, the diff control lines (those with ‘---’, ‘+++’, or
     ‘@@’) are created with a trailing newline.  This is helpful so that
     inputs created from *note io.IOBase.readlines(): 113f. result in
     diffs that are suitable for use with *note io.IOBase.writelines():
     1140. since both the inputs and outputs have trailing newlines.

     For inputs that do not have trailing newlines, set the `lineterm'
     argument to ‘""’ so that the output will be uniformly newline free.

     The context diff format normally has a header for filenames and
     modification times.  Any or all of these may be specified using
     strings for `fromfile', `tofile', `fromfiledate', and `tofiledate'.
     The modification times are normally expressed in the ISO 8601
     format.  If not specified, the strings default to blanks.

          >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
          >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
          >>> for line in unified_diff(s1, s2, fromfile='before.py', tofile='after.py'):
          ...     sys.stdout.write(line)   # doctest: +NORMALIZE_WHITESPACE
          --- before.py
          +++ after.py
          @@ -1,4 +1,4 @@
          -bacon
          -eggs
          -ham
          +python
          +eggy
          +hamster
           guido

     See *note A command-line interface to difflib: 1141. for a more
     detailed example.

 -- Function: difflib.diff_bytes (dfunc, a, b, fromfile=b'', tofile=b'',
          fromfiledate=b'', tofiledate=b'', n=3, lineterm=b'\n')

     Compare `a' and `b' (lists of bytes objects) using `dfunc'; yield a
     sequence of delta lines (also bytes) in the format returned by
     `dfunc'.  `dfunc' must be a callable, typically either *note
     unified_diff(): 1147. or *note context_diff(): 113e.

     Allows you to compare data with unknown or inconsistent encoding.
     All inputs except `n' must be bytes objects, not str.  Works by
     losslessly converting all inputs (except `n') to str, and calling
     ‘dfunc(a, b, fromfile, tofile, fromfiledate, tofiledate, n,
     lineterm)’.  The output of `dfunc' is then converted back to bytes,
     so the delta lines that you receive have the same
     unknown/inconsistent encodings as `a' and `b'.

     New in version 3.5.

 -- Function: difflib.IS_LINE_JUNK (line)

     Return true for ignorable lines.  The line `line' is ignorable if
     `line' is blank or contains a single ‘'#'’, otherwise it is not
     ignorable.  Used as a default for parameter `linejunk' in *note
     ndiff(): 113c. in older versions.

 -- Function: difflib.IS_CHARACTER_JUNK (ch)

     Return true for ignorable characters.  The character `ch' is
     ignorable if `ch' is a space or tab, otherwise it is not ignorable.
     Used as a default for parameter `charjunk' in *note ndiff(): 113c.

See also
........

Pattern Matching: The Gestalt Approach(2)

     Discussion of a similar algorithm by John W. Ratcliff and D. E.
     Metzener.  This was published in Dr.  Dobb’s Journal(3) in July,
     1988.

* Menu:

* SequenceMatcher Objects:: 
* SequenceMatcher Examples:: 
* Differ Objects:: 
* Differ Example:: 
* A command-line interface to difflib:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/difflib.py

   (2) 
http://www.drdobbs.com/database/pattern-matching-the-gestalt-approach/184407970

   (3) http://www.drdobbs.com/


File: python.info,  Node: SequenceMatcher Objects,  Next: SequenceMatcher Examples,  Up: difflib --- Helpers for computing deltas

5.6.3.1 SequenceMatcher Objects
...............................

The *note SequenceMatcher: 563. class has this constructor:

 -- Class: difflib.SequenceMatcher (isjunk=None, a='', b='',
          autojunk=True)

     Optional argument `isjunk' must be ‘None’ (the default) or a
     one-argument function that takes a sequence element and returns
     true if and only if the element is "junk" and should be ignored.
     Passing ‘None’ for `isjunk' is equivalent to passing ‘lambda x: 0’;
     in other words, no elements are ignored.  For example, pass:

          lambda x: x in " \t"

     if you’re comparing lines as sequences of characters, and don’t
     want to synch up on blanks or hard tabs.

     The optional arguments `a' and `b' are sequences to be compared;
     both default to empty strings.  The elements of both sequences must
     be *note hashable: de9.

     The optional argument `autojunk' can be used to disable the
     automatic junk heuristic.

     New in version 3.2: The `autojunk' parameter.

     SequenceMatcher objects get three data attributes: `bjunk' is the
     set of elements of `b' for which `isjunk' is ‘True’; `bpopular' is
     the set of non-junk elements considered popular by the heuristic
     (if it is not disabled); `b2j' is a dict mapping the remaining
     elements of `b' to a list of positions where they occur.  All three
     are reset whenever `b' is reset with *note set_seqs(): 114a. or
     *note set_seq2(): 114b.

     New in version 3.2: The `bjunk' and `bpopular' attributes.

     *note SequenceMatcher: 563. objects have the following methods:

      -- Method: set_seqs (a, b)

          Set the two sequences to be compared.

     *note SequenceMatcher: 563. computes and caches detailed
     information about the second sequence, so if you want to compare
     one sequence against many sequences, use *note set_seq2(): 114b. to
     set the commonly used sequence once and call *note set_seq1():
     114c. repeatedly, once for each of the other sequences.

      -- Method: set_seq1 (a)

          Set the first sequence to be compared.  The second sequence to
          be compared is not changed.

      -- Method: set_seq2 (b)

          Set the second sequence to be compared.  The first sequence to
          be compared is not changed.

      -- Method: find_longest_match (alo, ahi, blo, bhi)

          Find longest matching block in ‘a[alo:ahi]’ and ‘b[blo:bhi]’.

          If `isjunk' was omitted or ‘None’, *note find_longest_match():
          114d. returns ‘(i, j, k)’ such that ‘a[i:i+k]’ is equal to
          ‘b[j:j+k]’, where ‘alo <= i <= i+k <= ahi’ and ‘blo <= j <=
          j+k <= bhi’.  For all ‘(i', j', k')’ meeting those conditions,
          the additional conditions ‘k >= k'’, ‘i <= i'’, and if ‘i ==
          i'’, ‘j <= j'’ are also met.  In other words, of all maximal
          matching blocks, return one that starts earliest in `a', and
          of all those maximal matching blocks that start earliest in
          `a', return the one that starts earliest in `b'.

               >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
               >>> s.find_longest_match(0, 5, 0, 9)
               Match(a=0, b=4, size=5)

          If `isjunk' was provided, first the longest matching block is
          determined as above, but with the additional restriction that
          no junk element appears in the block.  Then that block is
          extended as far as possible by matching (only) junk elements
          on both sides.  So the resulting block never matches on junk
          except as identical junk happens to be adjacent to an
          interesting match.

          Here’s the same example as before, but considering blanks to
          be junk.  That prevents ‘' abcd'’ from matching the ‘' abcd'’
          at the tail end of the second sequence directly.  Instead only
          the ‘'abcd'’ can match, and matches the leftmost ‘'abcd'’ in
          the second sequence:

               >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
               >>> s.find_longest_match(0, 5, 0, 9)
               Match(a=1, b=0, size=4)

          If no blocks match, this returns ‘(alo, blo, 0)’.

          This method returns a *note named tuple: 787. ‘Match(a, b,
          size)’.

      -- Method: get_matching_blocks ()

          Return list of triples describing matching subsequences.  Each
          triple is of the form ‘(i, j, n)’, and means that ‘a[i:i+n] ==
          b[j:j+n]’.  The triples are monotonically increasing in `i'
          and `j'.

          The last triple is a dummy, and has the value ‘(len(a),
          len(b), 0)’.  It is the only triple with ‘n == 0’.  If ‘(i, j,
          n)’ and ‘(i', j', n')’ are adjacent triples in the list, and
          the second is not the last triple in the list, then ‘i+n !=
          i'’ or ‘j+n != j'’; in other words, adjacent triples always
          describe non-adjacent equal blocks.

               >>> s = SequenceMatcher(None, "abxcd", "abcd")
               >>> s.get_matching_blocks()
               [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]

      -- Method: get_opcodes ()

          Return list of 5-tuples describing how to turn `a' into `b'.
          Each tuple is of the form ‘(tag, i1, i2, j1, j2)’.  The first
          tuple has ‘i1 == j1 == 0’, and remaining tuples have `i1'
          equal to the `i2' from the preceding tuple, and, likewise,
          `j1' equal to the previous `j2'.

          The `tag' values are strings, with these meanings:

          Value               Meaning
                              
          ----------------------------------------------------------------------
                              
          ‘'replace'’         ‘a[i1:i2]’ should be replaced by ‘b[j1:j2]’.
                              
                              
          ‘'delete'’          ‘a[i1:i2]’ should be deleted.  Note that ‘j1 ==
                              j2’ in this case.
                              
                              
          ‘'insert'’          ‘b[j1:j2]’ should be inserted at ‘a[i1:i1]’.
                              Note that ‘i1 == i2’ in this case.
                              
                              
          ‘'equal'’           ‘a[i1:i2] == b[j1:j2]’ (the sub-sequences are
                              equal).
                              

          For example:

               >>> a = "qabxcd"
               >>> b = "abycdf"
               >>> s = SequenceMatcher(None, a, b)
               >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
               ...     print('{:7}   a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format(
               ...         tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))
               delete    a[0:1] --> b[0:0]      'q' --> ''
               equal     a[1:3] --> b[0:2]     'ab' --> 'ab'
               replace   a[3:4] --> b[2:3]      'x' --> 'y'
               equal     a[4:6] --> b[3:5]     'cd' --> 'cd'
               insert    a[6:6] --> b[5:6]       '' --> 'f'

      -- Method: get_grouped_opcodes (n=3)

          Return a *note generator: 5c0. of groups with up to `n' lines
          of context.

          Starting with the groups returned by *note get_opcodes():
          114f, this method splits out smaller change clusters and
          eliminates intervening ranges which have no changes.

          The groups are returned in the same format as *note
          get_opcodes(): 114f.

      -- Method: ratio ()

          Return a measure of the sequences’ similarity as a float in
          the range [0, 1].

          Where T is the total number of elements in both sequences, and
          M is the number of matches, this is 2.0*M / T. Note that this
          is ‘1.0’ if the sequences are identical, and ‘0.0’ if they
          have nothing in common.

          This is expensive to compute if *note get_matching_blocks():
          114e. or *note get_opcodes(): 114f. hasn’t already been
          called, in which case you may want to try *note quick_ratio():
          1152. or *note real_quick_ratio(): 1153. first to get an upper
          bound.

      -- Method: quick_ratio ()

          Return an upper bound on *note ratio(): 1151. relatively
          quickly.

      -- Method: real_quick_ratio ()

          Return an upper bound on *note ratio(): 1151. very quickly.

The three methods that return the ratio of matching to total characters
can give different results due to differing levels of approximation,
although ‘quick_ratio()’ and ‘real_quick_ratio()’ are always at least as
large as ‘ratio()’:

     >>> s = SequenceMatcher(None, "abcd", "bcde")
     >>> s.ratio()
     0.75
     >>> s.quick_ratio()
     0.75
     >>> s.real_quick_ratio()
     1.0


File: python.info,  Node: SequenceMatcher Examples,  Next: Differ Objects,  Prev: SequenceMatcher Objects,  Up: difflib --- Helpers for computing deltas

5.6.3.2 SequenceMatcher Examples
................................

This example compares two strings, considering blanks to be "junk":

     >>> s = SequenceMatcher(lambda x: x == " ",
     ...                     "private Thread currentThread;",
     ...                     "private volatile Thread currentThread;")

‘ratio()’ returns a float in [0, 1], measuring the similarity of the
sequences.  As a rule of thumb, a ‘ratio()’ value over 0.6 means the
sequences are close matches:

     >>> print(round(s.ratio(), 3))
     0.866

If you’re only interested in where the sequences match,
‘get_matching_blocks()’ is handy:

     >>> for block in s.get_matching_blocks():
     ...     print("a[%d] and b[%d] match for %d elements" % block)
     a[0] and b[0] match for 8 elements
     a[8] and b[17] match for 21 elements
     a[29] and b[38] match for 0 elements

Note that the last tuple returned by ‘get_matching_blocks()’ is always a
dummy, ‘(len(a), len(b), 0)’, and this is the only case in which the
last tuple element (number of elements matched) is ‘0’.

If you want to know how to change the first sequence into the second,
use ‘get_opcodes()’:

     >>> for opcode in s.get_opcodes():
     ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
      equal a[0:8] b[0:8]
     insert a[8:8] b[8:17]
      equal a[8:29] b[17:38]

See also
........

   * The *note get_close_matches(): 1142. function in this module which
     shows how simple code building on *note SequenceMatcher: 563. can
     be used to do useful work.

   * Simple version control recipe(1) for a small application built with
     *note SequenceMatcher: 563.

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/576729/


File: python.info,  Node: Differ Objects,  Next: Differ Example,  Prev: SequenceMatcher Examples,  Up: difflib --- Helpers for computing deltas

5.6.3.3 Differ Objects
......................

Note that *note Differ: 1139.-generated deltas make no claim to be
`minimal' diffs.  To the contrary, minimal diffs are often
counter-intuitive, because they synch up anywhere possible, sometimes
accidental matches 100 pages apart.  Restricting synch points to
contiguous matches preserves some notion of locality, at the occasional
cost of producing a longer diff.

The *note Differ: 1139. class has this constructor:

 -- Class: difflib.Differ (linejunk=None, charjunk=None)

     Optional keyword parameters `linejunk' and `charjunk' are for
     filter functions (or ‘None’):

     `linejunk': A function that accepts a single string argument, and
     returns true if the string is junk.  The default is ‘None’, meaning
     that no line is considered junk.

     `charjunk': A function that accepts a single character argument (a
     string of length 1), and returns true if the character is junk.
     The default is ‘None’, meaning that no character is considered
     junk.

     These junk-filtering functions speed up matching to find
     differences and do not cause any differing lines or characters to
     be ignored.  Read the description of the *note
     find_longest_match(): 114d. method’s `isjunk' parameter for an
     explanation.

     *note Differ: 1139. objects are used (deltas generated) via a
     single method:

      -- Method: compare (a, b)

          Compare two sequences of lines, and generate the delta (a
          sequence of lines).

          Each sequence must contain individual single-line strings
          ending with newlines.  Such sequences can be obtained from the
          *note readlines(): 113f. method of file-like objects.  The
          delta generated also consists of newline-terminated strings,
          ready to be printed as-is via the *note writelines(): 1140.
          method of a file-like object.


File: python.info,  Node: Differ Example,  Next: A command-line interface to difflib,  Prev: Differ Objects,  Up: difflib --- Helpers for computing deltas

5.6.3.4 Differ Example
......................

This example compares two texts.  First we set up the texts, sequences
of individual single-line strings ending with newlines (such sequences
can also be obtained from the ‘readlines()’ method of file-like
objects):

     >>> text1 = '''  1. Beautiful is better than ugly.
     ...   2. Explicit is better than implicit.
     ...   3. Simple is better than complex.
     ...   4. Complex is better than complicated.
     ... '''.splitlines(keepends=True)
     >>> len(text1)
     4
     >>> text1[0][-1]
     '\n'
     >>> text2 = '''  1. Beautiful is better than ugly.
     ...   3.   Simple is better than complex.
     ...   4. Complicated is better than complex.
     ...   5. Flat is better than nested.
     ... '''.splitlines(keepends=True)

Next we instantiate a Differ object:

     >>> d = Differ()

Note that when instantiating a *note Differ: 1139. object we may pass
functions to filter out line and character "junk."  See the *note
Differ(): 1139. constructor for details.

Finally, we compare the two:

     >>> result = list(d.compare(text1, text2))

‘result’ is a list of strings, so let’s pretty-print it:

     >>> from pprint import pprint
     >>> pprint(result)
     ['    1. Beautiful is better than ugly.\n',
      '-   2. Explicit is better than implicit.\n',
      '-   3. Simple is better than complex.\n',
      '+   3.   Simple is better than complex.\n',
      '?     ++\n',
      '-   4. Complex is better than complicated.\n',
      '?            ^                     ---- ^\n',
      '+   4. Complicated is better than complex.\n',
      '?           ++++ ^                      ^\n',
      '+   5. Flat is better than nested.\n']

As a single multi-line string it looks like this:

     >>> import sys
     >>> sys.stdout.writelines(result)
         1. Beautiful is better than ugly.
     -   2. Explicit is better than implicit.
     -   3. Simple is better than complex.
     +   3.   Simple is better than complex.
     ?     ++
     -   4. Complex is better than complicated.
     ?            ^                     ---- ^
     +   4. Complicated is better than complex.
     ?           ++++ ^                      ^
     +   5. Flat is better than nested.


File: python.info,  Node: A command-line interface to difflib,  Prev: Differ Example,  Up: difflib --- Helpers for computing deltas

5.6.3.5 A command-line interface to difflib
...........................................

This example shows how to use difflib to create a ‘diff’-like utility.
It is also contained in the Python source distribution, as
‘Tools/scripts/diff.py’.

     #!/usr/bin/env python3
     """ Command line interface to difflib.py providing diffs in four formats:

     * ndiff:    lists every line and highlights interline changes.
     * context:  highlights clusters of changes in a before/after format.
     * unified:  highlights clusters of changes in an inline format.
     * html:     generates side by side comparison with change highlights.

     """

     import sys, os, difflib, argparse
     from datetime import datetime, timezone

     def file_mtime(path):
         t = datetime.fromtimestamp(os.stat(path).st_mtime,
                                    timezone.utc)
         return t.astimezone().isoformat()

     def main():

         parser = argparse.ArgumentParser()
         parser.add_argument('-c', action='store_true', default=False,
                             help='Produce a context format diff (default)')
         parser.add_argument('-u', action='store_true', default=False,
                             help='Produce a unified format diff')
         parser.add_argument('-m', action='store_true', default=False,
                             help='Produce HTML side by side diff '
                                  '(can use -c and -l in conjunction)')
         parser.add_argument('-n', action='store_true', default=False,
                             help='Produce a ndiff format diff')
         parser.add_argument('-l', '--lines', type=int, default=3,
                             help='Set number of context lines (default 3)')
         parser.add_argument('fromfile')
         parser.add_argument('tofile')
         options = parser.parse_args()

         n = options.lines
         fromfile = options.fromfile
         tofile = options.tofile

         fromdate = file_mtime(fromfile)
         todate = file_mtime(tofile)
         with open(fromfile) as ff:
             fromlines = ff.readlines()
         with open(tofile) as tf:
             tolines = tf.readlines()

         if options.u:
             diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n)
         elif options.n:
             diff = difflib.ndiff(fromlines, tolines)
         elif options.m:
             diff = difflib.HtmlDiff().make_file(fromlines,tolines,fromfile,tofile,context=options.c,numlines=n)
         else:
             diff = difflib.context_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n)

         sys.stdout.writelines(diff)

     if __name__ == '__main__':
         main()


File: python.info,  Node: textwrap --- Text wrapping and filling,  Next: unicodedata --- Unicode Database,  Prev: difflib --- Helpers for computing deltas,  Up: Text Processing Services

5.6.4 ‘textwrap’ — Text wrapping and filling
--------------------------------------------

`Source code:' Lib/textwrap.py(1)

__________________________________________________________________

The *note textwrap: 105. module provides some convenience functions, as
well as *note TextWrapper: 4eb, the class that does all the work.  If
you’re just wrapping or filling one or two text strings, the convenience
functions should be good enough; otherwise, you should use an instance
of *note TextWrapper: 4eb. for efficiency.

 -- Function: textwrap.wrap (text, width=70, **kwargs)

     Wraps the single paragraph in `text' (a string) so every line is at
     most `width' characters long.  Returns a list of output lines,
     without final newlines.

     Optional keyword arguments correspond to the instance attributes of
     *note TextWrapper: 4eb, documented below.  `width' defaults to
     ‘70’.

     See the *note TextWrapper.wrap(): 115e. method for additional
     details on how *note wrap(): 115d. behaves.

 -- Function: textwrap.fill (text, width=70, **kwargs)

     Wraps the single paragraph in `text', and returns a single string
     containing the wrapped paragraph.  *note fill(): 115f. is shorthand
     for

          "\n".join(wrap(text, ...))

     In particular, *note fill(): 115f. accepts exactly the same keyword
     arguments as *note wrap(): 115d.

 -- Function: textwrap.shorten (text, width, **kwargs)

     Collapse and truncate the given `text' to fit in the given `width'.

     First the whitespace in `text' is collapsed (all whitespace is
     replaced by single spaces).  If the result fits in the `width', it
     is returned.  Otherwise, enough words are dropped from the end so
     that the remaining words plus the ‘placeholder’ fit within ‘width’:

          >>> textwrap.shorten("Hello  world!", width=12)
          'Hello world!'
          >>> textwrap.shorten("Hello  world!", width=11)
          'Hello [...]'
          >>> textwrap.shorten("Hello world", width=10, placeholder="...")
          'Hello...'

     Optional keyword arguments correspond to the instance attributes of
     *note TextWrapper: 4eb, documented below.  Note that the whitespace
     is collapsed before the text is passed to the *note TextWrapper:
     4eb. *note fill(): 115f. function, so changing the value of *note
     tabsize: 1160, *note expand_tabs: 1161, *note drop_whitespace:
     1162, and *note replace_whitespace: 1163. will have no effect.

     New in version 3.4.

 -- Function: textwrap.dedent (text)

     Remove any common leading whitespace from every line in `text'.

     This can be used to make triple-quoted strings line up with the
     left edge of the display, while still presenting them in the source
     code in indented form.

     Note that tabs and spaces are both treated as whitespace, but they
     are not equal: the lines ‘" hello"’ and ‘"\thello"’ are considered
     to have no common leading whitespace.

     For example:

          def test():
              # end first line with \ to avoid the empty line!
              s = '''\
              hello
                world
              '''
              print(repr(s))          # prints '    hello\n      world\n    '
              print(repr(dedent(s)))  # prints 'hello\n  world\n'

 -- Function: textwrap.indent (text, prefix, predicate=None)

     Add `prefix' to the beginning of selected lines in `text'.

     Lines are separated by calling ‘text.splitlines(True)’.

     By default, `prefix' is added to all lines that do not consist
     solely of whitespace (including any line endings).

     For example:

          >>> s = 'hello\n\n \nworld'
          >>> indent(s, '  ')
          '  hello\n\n \n  world'

     The optional `predicate' argument can be used to control which
     lines are indented.  For example, it is easy to add `prefix' to
     even empty and whitespace-only lines:

          >>> print(indent(s, '+ ', lambda line: True))
          + hello
          +
          +
          + world

     New in version 3.3.

*note wrap(): 115d, *note fill(): 115f. and *note shorten(): 4ee. work
by creating a *note TextWrapper: 4eb. instance and calling a single
method on it.  That instance is not reused, so for applications that
process many text strings using *note wrap(): 115d. and/or *note fill():
115f, it may be more efficient to create your own *note TextWrapper:
4eb. object.

Text is preferably wrapped on whitespaces and right after the hyphens in
hyphenated words; only then will long words be broken if necessary,
unless *note TextWrapper.break_long_words: 1165. is set to false.

 -- Class: textwrap.TextWrapper (**kwargs)

     The *note TextWrapper: 4eb. constructor accepts a number of
     optional keyword arguments.  Each keyword argument corresponds to
     an instance attribute, so for example

          wrapper = TextWrapper(initial_indent="* ")

     is the same as

          wrapper = TextWrapper()
          wrapper.initial_indent = "* "

     You can re-use the same *note TextWrapper: 4eb. object many times,
     and you can change any of its options through direct assignment to
     instance attributes between uses.

     The *note TextWrapper: 4eb. instance attributes (and keyword
     arguments to the constructor) are as follows:

      -- Attribute: width

          (default: ‘70’) The maximum length of wrapped lines.  As long
          as there are no individual words in the input text longer than
          *note width: 1166, *note TextWrapper: 4eb. guarantees that no
          output line will be longer than *note width: 1166. characters.

      -- Attribute: expand_tabs

          (default: ‘True’) If true, then all tab characters in `text'
          will be expanded to spaces using the ‘expandtabs()’ method of
          `text'.

      -- Attribute: tabsize

          (default: ‘8’) If *note expand_tabs: 1161. is true, then all
          tab characters in `text' will be expanded to zero or more
          spaces, depending on the current column and the given tab
          size.

          New in version 3.3.

      -- Attribute: replace_whitespace

          (default: ‘True’) If true, after tab expansion but before
          wrapping, the *note wrap(): 115d. method will replace each
          whitespace character with a single space.  The whitespace
          characters replaced are as follows: tab, newline, vertical
          tab, formfeed, and carriage return (‘'\t\n\v\f\r'’).

               Note: If *note expand_tabs: 1161. is false and *note
               replace_whitespace: 1163. is true, each tab character
               will be replaced by a single space, which is `not' the
               same as tab expansion.

               Note: If *note replace_whitespace: 1163. is false,
               newlines may appear in the middle of a line and cause
               strange output.  For this reason, text should be split
               into paragraphs (using *note str.splitlines(): 1011. or
               similar) which are wrapped separately.

      -- Attribute: drop_whitespace

          (default: ‘True’) If true, whitespace at the beginning and
          ending of every line (after wrapping but before indenting) is
          dropped.  Whitespace at the beginning of the paragraph,
          however, is not dropped if non-whitespace follows it.  If
          whitespace being dropped takes up an entire line, the whole
          line is dropped.

      -- Attribute: initial_indent

          (default: ‘''’) String that will be prepended to the first
          line of wrapped output.  Counts towards the length of the
          first line.  The empty string is not indented.

      -- Attribute: subsequent_indent

          (default: ‘''’) String that will be prepended to all lines of
          wrapped output except the first.  Counts towards the length of
          each line except the first.

      -- Attribute: fix_sentence_endings

          (default: ‘False’) If true, *note TextWrapper: 4eb. attempts
          to detect sentence endings and ensure that sentences are
          always separated by exactly two spaces.  This is generally
          desired for text in a monospaced font.  However, the sentence
          detection algorithm is imperfect: it assumes that a sentence
          ending consists of a lowercase letter followed by one of
          ‘'.'’, ‘'!'’, or ‘'?'’, possibly followed by one of ‘'"'’ or
          ‘"'"’, followed by a space.  One problem with this is
          algorithm is that it is unable to detect the difference
          between "Dr."  in

               [...] Dr. Frankenstein's monster [...]

          and "Spot."  in

               [...] See Spot. See Spot run [...]

          *note fix_sentence_endings: 1169. is false by default.

          Since the sentence detection algorithm relies on
          ‘string.lowercase’ for the definition of "lowercase letter,"
          and a convention of using two spaces after a period to
          separate sentences on the same line, it is specific to
          English-language texts.

      -- Attribute: break_long_words

          (default: ‘True’) If true, then words longer than *note width:
          1166. will be broken in order to ensure that no lines are
          longer than *note width: 1166.  If it is false, long words
          will not be broken, and some lines may be longer than *note
          width: 1166.  (Long words will be put on a line by themselves,
          in order to minimize the amount by which *note width: 1166. is
          exceeded.)

      -- Attribute: break_on_hyphens

          (default: ‘True’) If true, wrapping will occur preferably on
          whitespaces and right after hyphens in compound words, as it
          is customary in English.  If false, only whitespaces will be
          considered as potentially good places for line breaks, but you
          need to set *note break_long_words: 1165. to false if you want
          truly insecable words.  Default behaviour in previous versions
          was to always allow breaking hyphenated words.

      -- Attribute: max_lines

          (default: ‘None’) If not ‘None’, then the output will contain
          at most `max_lines' lines, with `placeholder' appearing at the
          end of the output.

          New in version 3.4.

      -- Attribute: placeholder

          (default: ‘' [...]'’) String that will appear at the end of
          the output text if it has been truncated.

          New in version 3.4.

     *note TextWrapper: 4eb. also provides some public methods,
     analogous to the module-level convenience functions:

      -- Method: wrap (text)

          Wraps the single paragraph in `text' (a string) so every line
          is at most *note width: 1166. characters long.  All wrapping
          options are taken from instance attributes of the *note
          TextWrapper: 4eb. instance.  Returns a list of output lines,
          without final newlines.  If the wrapped output has no content,
          the returned list is empty.

      -- Method: fill (text)

          Wraps the single paragraph in `text', and returns a single
          string containing the wrapped paragraph.

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/textwrap.py


File: python.info,  Node: unicodedata --- Unicode Database,  Next: stringprep --- Internet String Preparation,  Prev: textwrap --- Text wrapping and filling,  Up: Text Processing Services

5.6.5 ‘unicodedata’ — Unicode Database
--------------------------------------

This module provides access to the Unicode Character Database (UCD)
which defines character properties for all Unicode characters.  The data
contained in this database is compiled from the UCD version 8.0.0(1).

The module uses the same names and symbols as defined by Unicode
Standard Annex #44, "Unicode Character Database"(2).  It defines the
following functions:

 -- Function: unicodedata.lookup (name)

     Look up character by name.  If a character with the given name is
     found, return the corresponding character.  If not found, *note
     KeyError: 1a7. is raised.

     Changed in version 3.3: Support for name aliases (3) and named
     sequences (4) has been added.

 -- Function: unicodedata.name (chr[, default])

     Returns the name assigned to the character `chr' as a string.  If
     no name is defined, `default' is returned, or, if not given, *note
     ValueError: 19c. is raised.

 -- Function: unicodedata.decimal (chr[, default])

     Returns the decimal value assigned to the character `chr' as
     integer.  If no such value is defined, `default' is returned, or,
     if not given, *note ValueError: 19c. is raised.

 -- Function: unicodedata.digit (chr[, default])

     Returns the digit value assigned to the character `chr' as integer.
     If no such value is defined, `default' is returned, or, if not
     given, *note ValueError: 19c. is raised.

 -- Function: unicodedata.numeric (chr[, default])

     Returns the numeric value assigned to the character `chr' as float.
     If no such value is defined, `default' is returned, or, if not
     given, *note ValueError: 19c. is raised.

 -- Function: unicodedata.category (chr)

     Returns the general category assigned to the character `chr' as
     string.

 -- Function: unicodedata.bidirectional (chr)

     Returns the bidirectional class assigned to the character `chr' as
     string.  If no such value is defined, an empty string is returned.

 -- Function: unicodedata.combining (chr)

     Returns the canonical combining class assigned to the character
     `chr' as integer.  Returns ‘0’ if no combining class is defined.

 -- Function: unicodedata.east_asian_width (chr)

     Returns the east asian width assigned to the character `chr' as
     string.

 -- Function: unicodedata.mirrored (chr)

     Returns the mirrored property assigned to the character `chr' as
     integer.  Returns ‘1’ if the character has been identified as a
     "mirrored" character in bidirectional text, ‘0’ otherwise.

 -- Function: unicodedata.decomposition (chr)

     Returns the character decomposition mapping assigned to the
     character `chr' as string.  An empty string is returned in case no
     such mapping is defined.

 -- Function: unicodedata.normalize (form, unistr)

     Return the normal form `form' for the Unicode string `unistr'.
     Valid values for `form' are ’NFC’, ’NFKC’, ’NFD’, and ’NFKD’.

     The Unicode standard defines various normalization forms of a
     Unicode string, based on the definition of canonical equivalence
     and compatibility equivalence.  In Unicode, several characters can
     be expressed in various way.  For example, the character U+00C7
     (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as the
     sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING
     CEDILLA).

     For each character, there are two normal forms: normal form C and
     normal form D. Normal form D (NFD) is also known as canonical
     decomposition, and translates each character into its decomposed
     form.  Normal form C (NFC) first applies a canonical decomposition,
     then composes pre-combined characters again.

     In addition to these two forms, there are two additional normal
     forms based on compatibility equivalence.  In Unicode, certain
     characters are supported which normally would be unified with other
     characters.  For example, U+2160 (ROMAN NUMERAL ONE) is really the
     same thing as U+0049 (LATIN CAPITAL LETTER I). However, it is
     supported in Unicode for compatibility with existing character sets
     (e.g.  gb2312).

     The normal form KD (NFKD) will apply the compatibility
     decomposition, i.e.  replace all compatibility characters with
     their equivalents.  The normal form KC (NFKC) first applies the
     compatibility decomposition, followed by the canonical composition.

     Even if two unicode strings are normalized and look the same to a
     human reader, if one has combining characters and the other
     doesn’t, they may not compare equal.

In addition, the module exposes the following constant:

 -- Data: unicodedata.unidata_version

     The version of the Unicode database used in this module.

 -- Data: unicodedata.ucd_3_2_0

     This is an object that has the same methods as the entire module,
     but uses the Unicode database version 3.2 instead, for applications
     that require this specific version of the Unicode database (such as
     IDNA).

Examples:

     >>> import unicodedata
     >>> unicodedata.lookup('LEFT CURLY BRACKET')
     '{'
     >>> unicodedata.name('/')
     'SOLIDUS'
     >>> unicodedata.decimal('9')
     9
     >>> unicodedata.decimal('a')
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     ValueError: not a decimal
     >>> unicodedata.category('A')  # 'L'etter, 'u'ppercase
     'Lu'
     >>> unicodedata.bidirectional('\u0660') # 'A'rabic, 'N'umber
     'AN'

   ---------- Footnotes ----------

   (1) http://www.unicode.org/Public/8.0.0/ucd

   (2) http://www.unicode.org/reports/tr44/tr44-6.html

   (3) ‘http://www.unicode.org/Public/8.0.0/ucd/NameAliases.txt’

   (4) ‘http://www.unicode.org/Public/8.0.0/ucd/NamedSequences.txt’


File: python.info,  Node: stringprep --- Internet String Preparation,  Next: readline --- GNU readline interface,  Prev: unicodedata --- Unicode Database,  Up: Text Processing Services

5.6.6 ‘stringprep’ — Internet String Preparation
------------------------------------------------

When identifying things (such as host names) in the internet, it is
often necessary to compare such identifications for "equality".  Exactly
how this comparison is executed may depend on the application domain,
e.g.  whether it should be case-insensitive or not.  It may be also
necessary to restrict the possible identifications, to allow only
identifications consisting of "printable" characters.

RFC 3454(1) defines a procedure for "preparing" Unicode strings in
internet protocols.  Before passing strings onto the wire, they are
processed with the preparation procedure, after which they have a
certain normalized form.  The RFC defines a set of tables, which can be
combined into profiles.  Each profile must define which tables it uses,
and what other optional parts of the ‘stringprep’ procedure are part of
the profile.  One example of a ‘stringprep’ profile is ‘nameprep’, which
is used for internationalized domain names.

The module *note stringprep: f5. only exposes the tables from RFC 3454.
As these tables would be very large to represent them as dictionaries or
lists, the module uses the Unicode character database internally.  The
module source code itself was generated using the ‘mkstringprep.py’
utility.

As a result, these tables are exposed as functions, not as data
structures.  There are two kinds of tables in the RFC: sets and
mappings.  For a set, *note stringprep: f5. provides the "characteristic
function", i.e.  a function that returns true if the parameter is part
of the set.  For mappings, it provides the mapping function: given the
key, it returns the associated value.  Below is a list of all functions
available in the module.

 -- Function: stringprep.in_table_a1 (code)

     Determine whether `code' is in tableA.1 (Unassigned code points in
     Unicode 3.2).

 -- Function: stringprep.in_table_b1 (code)

     Determine whether `code' is in tableB.1 (Commonly mapped to
     nothing).

 -- Function: stringprep.map_table_b2 (code)

     Return the mapped value for `code' according to tableB.2 (Mapping
     for case-folding used with NFKC).

 -- Function: stringprep.map_table_b3 (code)

     Return the mapped value for `code' according to tableB.3 (Mapping
     for case-folding used with no normalization).

 -- Function: stringprep.in_table_c11 (code)

     Determine whether `code' is in tableC.1.1 (ASCII space characters).

 -- Function: stringprep.in_table_c12 (code)

     Determine whether `code' is in tableC.1.2 (Non-ASCII space
     characters).

 -- Function: stringprep.in_table_c11_c12 (code)

     Determine whether `code' is in tableC.1 (Space characters, union of
     C.1.1 and C.1.2).

 -- Function: stringprep.in_table_c21 (code)

     Determine whether `code' is in tableC.2.1 (ASCII control
     characters).

 -- Function: stringprep.in_table_c22 (code)

     Determine whether `code' is in tableC.2.2 (Non-ASCII control
     characters).

 -- Function: stringprep.in_table_c21_c22 (code)

     Determine whether `code' is in tableC.2 (Control characters, union
     of C.2.1 and C.2.2).

 -- Function: stringprep.in_table_c3 (code)

     Determine whether `code' is in tableC.3 (Private use).

 -- Function: stringprep.in_table_c4 (code)

     Determine whether `code' is in tableC.4 (Non-character code
     points).

 -- Function: stringprep.in_table_c5 (code)

     Determine whether `code' is in tableC.5 (Surrogate codes).

 -- Function: stringprep.in_table_c6 (code)

     Determine whether `code' is in tableC.6 (Inappropriate for plain
     text).

 -- Function: stringprep.in_table_c7 (code)

     Determine whether `code' is in tableC.7 (Inappropriate for
     canonical representation).

 -- Function: stringprep.in_table_c8 (code)

     Determine whether `code' is in tableC.8 (Change display properties
     or are deprecated).

 -- Function: stringprep.in_table_c9 (code)

     Determine whether `code' is in tableC.9 (Tagging characters).

 -- Function: stringprep.in_table_d1 (code)

     Determine whether `code' is in tableD.1 (Characters with
     bidirectional property "R" or "AL").

 -- Function: stringprep.in_table_d2 (code)

     Determine whether `code' is in tableD.2 (Characters with
     bidirectional property "L").

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc3454.html


File: python.info,  Node: readline --- GNU readline interface,  Next: rlcompleter --- Completion function for GNU readline,  Prev: stringprep --- Internet String Preparation,  Up: Text Processing Services

5.6.7 ‘readline’ — GNU readline interface
-----------------------------------------

The *note readline: dc. module defines a number of functions to
facilitate completion and reading/writing of history files from the
Python interpreter.  This module can be used directly, or via the *note
rlcompleter: df. module, which supports completion of Python identifiers
at the interactive prompt.  Settings made using this module affect the
behaviour of both the interpreter’s interactive prompt and the prompts
offered by the built-in *note input(): 8d7. function.

     Note: The underlying Readline library API may be implemented by the
     ‘libedit’ library instead of GNU readline.  On MacOS X the *note
     readline: dc. module detects which library is being used at run
     time.

     The configuration file for ‘libedit’ is different from that of GNU
     readline.  If you programmatically load configuration strings you
     can check for the text "libedit" in ‘readline.__doc__’ to
     differentiate between GNU readline and libedit.

* Menu:

* Init file:: 
* Line buffer:: 
* History file:: 
* History list:: 
* Startup hooks:: 
* Completion:: 
* Example:: 


File: python.info,  Node: Init file,  Next: Line buffer,  Up: readline --- GNU readline interface

5.6.7.1 Init file
.................

The following functions relate to the init file and user configuration:

 -- Function: readline.parse_and_bind (string)

     Execute the init line provided in the `string' argument.  This
     calls ‘rl_parse_and_bind()’ in the underlying library.

 -- Function: readline.read_init_file ([filename])

     Execute a readline initialization file.  The default filename is
     the last filename used.  This calls ‘rl_read_init_file()’ in the
     underlying library.


File: python.info,  Node: Line buffer,  Next: History file,  Prev: Init file,  Up: readline --- GNU readline interface

5.6.7.2 Line buffer
...................

The following functions operate on the line buffer:

 -- Function: readline.get_line_buffer ()

     Return the current contents of the line buffer (‘rl_line_buffer’ in
     the underlying library).

 -- Function: readline.insert_text (string)

     Insert text into the line buffer at the cursor position.  This
     calls ‘rl_insert_text()’ in the underlying library, but ignores the
     return value.

 -- Function: readline.redisplay ()

     Change what’s displayed on the screen to reflect the current
     contents of the line buffer.  This calls ‘rl_redisplay()’ in the
     underlying library.


File: python.info,  Node: History file,  Next: History list,  Prev: Line buffer,  Up: readline --- GNU readline interface

5.6.7.3 History file
....................

The following functions operate on a history file:

 -- Function: readline.read_history_file ([filename])

     Load a readline history file, and append it to the history list.
     The default filename is ‘~/.history’.  This calls ‘read_history()’
     in the underlying library.

 -- Function: readline.write_history_file ([filename])

     Save the history list to a readline history file, overwriting any
     existing file.  The default filename is ‘~/.history’.  This calls
     ‘write_history()’ in the underlying library.

 -- Function: readline.append_history_file (nelements[, filename])

     Append the last `nelements' items of history to a file.  The
     default filename is ‘~/.history’.  The file must already exist.
     This calls ‘append_history()’ in the underlying library.

     New in version 3.5.

 -- Function: readline.get_history_length ()
 -- Function: readline.set_history_length (length)

     Set or return the desired number of lines to save in the history
     file.  The *note write_history_file(): 1198. function uses this
     value to truncate the history file, by calling
     ‘history_truncate_file()’ in the underlying library.  Negative
     values imply unlimited history file size.


File: python.info,  Node: History list,  Next: Startup hooks,  Prev: History file,  Up: readline --- GNU readline interface

5.6.7.4 History list
....................

The following functions operate on a global history list:

 -- Function: readline.clear_history ()

     Clear the current history.  This calls ‘clear_history()’ in the
     underlying library.  The Python function only exists if Python was
     compiled for a version of the library that supports it.

 -- Function: readline.get_current_history_length ()

     Return the number of items currently in the history.  (This is
     different from *note get_history_length(): 1199, which returns the
     maximum number of lines that will be written to a history file.)

 -- Function: readline.get_history_item (index)

     Return the current contents of history item at `index'.  The item
     index is one-based.  This calls ‘history_get()’ in the underlying
     library.

 -- Function: readline.remove_history_item (pos)

     Remove history item specified by its position from the history.
     The position is zero-based.  This calls ‘remove_history()’ in the
     underlying library.

 -- Function: readline.replace_history_item (pos, line)

     Replace history item specified by its position with `line'.  The
     position is zero-based.  This calls ‘replace_history_entry()’ in
     the underlying library.

 -- Function: readline.add_history (line)

     Append `line' to the history buffer, as if it was the last line
     typed.  This calls ‘add_history()’ in the underlying library.


File: python.info,  Node: Startup hooks,  Next: Completion,  Prev: History list,  Up: readline --- GNU readline interface

5.6.7.5 Startup hooks
.....................

 -- Function: readline.set_startup_hook ([function])

     Set or remove the function invoked by the ‘rl_startup_hook’
     callback of the underlying library.  If `function' is specified, it
     will be used as the new hook function; if omitted or ‘None’, any
     function already installed is removed.  The hook is called with no
     arguments just before readline prints the first prompt.

 -- Function: readline.set_pre_input_hook ([function])

     Set or remove the function invoked by the ‘rl_pre_input_hook’
     callback of the underlying library.  If `function' is specified, it
     will be used as the new hook function; if omitted or ‘None’, any
     function already installed is removed.  The hook is called with no
     arguments after the first prompt has been printed and just before
     readline starts reading input characters.


File: python.info,  Node: Completion,  Next: Example,  Prev: Startup hooks,  Up: readline --- GNU readline interface

5.6.7.6 Completion
..................

The following functions relate to implementing a custom word completion
function.  This is typically operated by the Tab key, and can suggest
and automatically complete a word being typed.  By default, Readline is
set up to be used by *note rlcompleter: df. to complete Python
identifiers for the interactive interpreter.  If the *note readline: dc.
module is to be used with a custom completer, a different set of word
delimiters should be set.

 -- Function: readline.set_completer ([function])

     Set or remove the completer function.  If `function' is specified,
     it will be used as the new completer function; if omitted or
     ‘None’, any completer function already installed is removed.  The
     completer function is called as ‘function(text, state)’, for
     `state' in ‘0’, ‘1’, ‘2’, ..., until it returns a non-string value.
     It should return the next possible completion starting with `text'.

     The installed completer function is invoked by the `entry_func'
     callback passed to ‘rl_completion_matches()’ in the underlying
     library.  The `text' string comes from the first parameter to the
     ‘rl_attempted_completion_function’ callback of the underlying
     library.

 -- Function: readline.get_completer ()

     Get the completer function, or ‘None’ if no completer function has
     been set.

 -- Function: readline.get_completion_type ()

     Get the type of completion being attempted.  This returns the
     ‘rl_completion_type’ variable in the underlying library as an
     integer.

 -- Function: readline.get_begidx ()
 -- Function: readline.get_endidx ()

     Get the beginning or ending index of the completion scope.  These
     indexes are the `start' and `end' arguments passed to the
     ‘rl_attempted_completion_function’ callback of the underlying
     library.

 -- Function: readline.set_completer_delims (string)
 -- Function: readline.get_completer_delims ()

     Set or get the word delimiters for completion.  These determine the
     start of the word to be considered for completion (the completion
     scope).  These functions access the
     ‘rl_completer_word_break_characters’ variable in the underlying
     library.

 -- Function: readline.set_completion_display_matches_hook ([function])

     Set or remove the completion display function.  If `function' is
     specified, it will be used as the new completion display function;
     if omitted or ‘None’, any completion display function already
     installed is removed.  This sets or clears the
     ‘rl_completion_display_matches_hook’ callback in the underlying
     library.  The completion display function is called as
     ‘function(substitution, [matches], longest_match_length)’ once each
     time matches need to be displayed.


File: python.info,  Node: Example,  Prev: Completion,  Up: readline --- GNU readline interface

5.6.7.7 Example
...............

The following example demonstrates how to use the *note readline: dc.
module’s history reading and writing functions to automatically load and
save a history file named ‘.python_history’ from the user’s home
directory.  The code below would normally be executed automatically
during interactive sessions from the user’s *note PYTHONSTARTUP: 4e6.
file.

     import atexit
     import os
     import readline

     histfile = os.path.join(os.path.expanduser("~"), ".python_history")
     try:
         readline.read_history_file(histfile)
         # default history len is -1 (infinite), which may grow unruly
         readline.set_history_length(1000)
     except FileNotFoundError:
         pass

     atexit.register(readline.write_history_file, histfile)

This code is actually automatically run when Python is run in *note
interactive mode: 4e4. (see *note Readline configuration: 4e7.).

The following example achieves the same goal but supports concurrent
interactive sessions, by only appending the new history.

     import atexit
     import os
     import readline
     histfile = os.path.join(os.path.expanduser("~"), ".python_history")

     try:
         readline.read_history_file(histfile)
         h_len = readline.get_history_length()
     except FileNotFoundError:
         open(histfile, 'wb').close()
         h_len = 0

     def save(prev_h_len, histfile):
         new_h_len = readline.get_history_length()
         readline.set_history_length(1000)
         readline.append_history_file(new_h_len - prev_h_len, histfile)
     atexit.register(save, h_len, histfile)

The following example extends the *note code.InteractiveConsole: 11b0.
class to support history save/restore.

     import atexit
     import code
     import os
     import readline

     class HistoryConsole(code.InteractiveConsole):
         def __init__(self, locals=None, filename="<console>",
                      histfile=os.path.expanduser("~/.console-history")):
             code.InteractiveConsole.__init__(self, locals, filename)
             self.init_history(histfile)

         def init_history(self, histfile):
             readline.parse_and_bind("tab: complete")
             if hasattr(readline, "read_history_file"):
                 try:
                     readline.read_history_file(histfile)
                 except FileNotFoundError:
                     pass
                 atexit.register(self.save_history, histfile)

         def save_history(self, histfile):
             readline.set_history_length(1000)
             readline.write_history_file(histfile)


File: python.info,  Node: rlcompleter --- Completion function for GNU readline,  Prev: readline --- GNU readline interface,  Up: Text Processing Services

5.6.8 ‘rlcompleter’ — Completion function for GNU readline
----------------------------------------------------------

`Source code:' Lib/rlcompleter.py(1)

__________________________________________________________________

The *note rlcompleter: df. module defines a completion function suitable
for the *note readline: dc. module by completing valid Python
identifiers and keywords.

When this module is imported on a Unix platform with the *note readline:
dc. module available, an instance of the ‘Completer’ class is
automatically created and its ‘complete()’ method is set as the *note
readline: dc. completer.

Example:

     >>> import rlcompleter
     >>> import readline
     >>> readline.parse_and_bind("tab: complete")
     >>> readline. <TAB PRESSED>
     readline.__doc__          readline.get_line_buffer(  readline.read_init_file(
     readline.__file__         readline.insert_text(      readline.set_completer(
     readline.__name__         readline.parse_and_bind(
     >>> readline.

The *note rlcompleter: df. module is designed for use with Python’s
*note interactive mode: 4e4.  Unless Python is run with the *note -S:
766. option, the module is automatically imported and configured (see
*note Readline configuration: 4e7.).

On platforms without *note readline: dc, the ‘Completer’ class defined
by this module can still be used for custom purposes.

* Menu:

* Completer Objects:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/rlcompleter.py


File: python.info,  Node: Completer Objects,  Up: rlcompleter --- Completion function for GNU readline

5.6.8.1 Completer Objects
.........................

Completer objects have the following method:

 -- Method: Completer.complete (text, state)

     Return the `state'th completion for `text'.

     If called for `text' that doesn’t include a period character
     (‘'.'’), it will complete from names currently defined in *note
     __main__: 1, *note builtins: 13. and keywords (as defined by the
     *note keyword: a4. module).

     If called for a dotted name, it will try to evaluate anything
     without obvious side-effects (functions will not be evaluated, but
     it can generate calls to *note __getattr__(): 782.) up to the last
     part, and find matches for the rest via the *note dir(): 16a.
     function.  Any exception raised during the evaluation of the
     expression is caught, silenced and *note None: 19d. is returned.


File: python.info,  Node: Binary Data Services,  Next: Data Types,  Prev: Text Processing Services,  Up: The Python Standard Library

5.7 Binary Data Services
========================

The modules described in this chapter provide some basic services
operations for manipulation of binary data.  Other operations on binary
data, specifically in relation to file formats and network protocols,
are described in the relevant sections.

Some libraries described under *note Text Processing Services: ff9. also
work with either ASCII-compatible binary formats (for example, *note re:
db.) or all binary data (for example, *note difflib: 35.).

In addition, see the documentation for Python’s built-in binary data
types in *note Binary Sequence Types — bytes, bytearray, memoryview:
f9f.

* Menu:

* struct: struct --- Interpret bytes as packed binary data. Interpret bytes as packed binary data
* codecs: codecs --- Codec registry and base classes. Codec registry and base classes


File: python.info,  Node: struct --- Interpret bytes as packed binary data,  Next: codecs --- Codec registry and base classes,  Up: Binary Data Services

5.7.1 ‘struct’ — Interpret bytes as packed binary data
------------------------------------------------------

This module performs conversions between Python values and C structs
represented as Python *note bytes: 1db. objects.  This can be used in
handling binary data stored in files or from network connections, among
other sources.  It uses *note Format Strings: 11ba. as compact
descriptions of the layout of the C structs and the intended conversion
to/from Python values.

     Note: By default, the result of packing a given C struct includes
     pad bytes in order to maintain proper alignment for the C types
     involved; similarly, alignment is taken into account when
     unpacking.  This behavior is chosen so that the bytes of a packed
     struct correspond exactly to the layout in memory of the
     corresponding C struct.  To handle platform-independent data
     formats or omit implicit pad bytes, use ‘standard’ size and
     alignment instead of ‘native’ size and alignment: see *note Byte
     Order, Size, and Alignment: 11bb. for details.

Several *note struct: f6. functions (and methods of *note Struct: 11bc.)
take a `buffer' argument.  This refers to objects that implement the
*note Buffer Protocol: ff5. and provide either a readable or
read-writable buffer.  The most common types used for that purpose are
*note bytes: 1db. and *note bytearray: 1dc, but many other types that
can be viewed as an array of bytes implement the buffer protocol, so
that they can be read/filled without additional copying from a *note
bytes: 1db. object.

* Menu:

* Functions and Exceptions:: 
* Format Strings:: 
* Classes: Classes<2>. 


File: python.info,  Node: Functions and Exceptions,  Next: Format Strings,  Up: struct --- Interpret bytes as packed binary data

5.7.1.1 Functions and Exceptions
................................

The module defines the following exception and functions:

 -- Exception: struct.error

     Exception raised on various occasions; argument is a string
     describing what is wrong.

 -- Function: struct.pack (fmt, v1, v2, ...)

     Return a bytes object containing the values `v1', `v2', ...  packed
     according to the format string `fmt'.  The arguments must match the
     values required by the format exactly.

 -- Function: struct.pack_into (fmt, buffer, offset, v1, v2, ...)

     Pack the values `v1', `v2', ...  according to the format string
     `fmt' and write the packed bytes into the writable buffer `buffer'
     starting at position `offset'.  Note that `offset' is a required
     argument.

 -- Function: struct.unpack (fmt, buffer)

     Unpack from the buffer `buffer' (presumably packed by ‘pack(fmt,
     ...)’) according to the format string `fmt'.  The result is a tuple
     even if it contains exactly one item.  The buffer’s size in bytes
     must match the size required by the format, as reflected by *note
     calcsize(): 11bf.

 -- Function: struct.unpack_from (fmt, buffer, offset=0)

     Unpack from `buffer' starting at position `offset', according to
     the format string `fmt'.  The result is a tuple even if it contains
     exactly one item.  The buffer’s size in bytes, minus `offset', must
     be at least the size required by the format, as reflected by *note
     calcsize(): 11bf.

 -- Function: struct.iter_unpack (fmt, buffer)

     Iteratively unpack from the buffer `buffer' according to the format
     string `fmt'.  This function returns an iterator which will read
     equally-sized chunks from the buffer until all its contents have
     been consumed.  The buffer’s size in bytes must be a multiple of
     the size required by the format, as reflected by *note calcsize():
     11bf.

     Each iteration yields a tuple as specified by the format string.

     New in version 3.4.

 -- Function: struct.calcsize (fmt)

     Return the size of the struct (and hence of the bytes object
     produced by ‘pack(fmt, ...)’) corresponding to the format string
     `fmt'.


File: python.info,  Node: Format Strings,  Next: Classes<2>,  Prev: Functions and Exceptions,  Up: struct --- Interpret bytes as packed binary data

5.7.1.2 Format Strings
......................

Format strings are the mechanism used to specify the expected layout
when packing and unpacking data.  They are built up from *note Format
Characters: 11c2, which specify the type of data being packed/unpacked.
In addition, there are special characters for controlling the *note Byte
Order, Size, and Alignment: 11bb.

* Menu:

* Byte Order, Size, and Alignment: Byte Order Size and Alignment. 
* Format Characters:: 
* Examples: Examples<2>. 


File: python.info,  Node: Byte Order Size and Alignment,  Next: Format Characters,  Up: Format Strings

5.7.1.3 Byte Order, Size, and Alignment
.......................................

By default, C types are represented in the machine’s native format and
byte order, and properly aligned by skipping pad bytes if necessary
(according to the rules used by the C compiler).

Alternatively, the first character of the format string can be used to
indicate the byte order, size and alignment of the packed data,
according to the following table:

Character       Byte order                   Size           Alignment
                                                            
----------------------------------------------------------------------------
                                                            
‘@’             native                       native         native
                                                            
                                                            
‘=’             native                       standard       none
                                                            
                                                            
‘<’             little-endian                standard       none
                                                            
                                                            
‘>’             big-endian                   standard       none
                                                            
                                                            
‘!’             network (= big-endian)       standard       none
                                                            

If the first character is not one of these, ‘'@'’ is assumed.

Native byte order is big-endian or little-endian, depending on the host
system.  For example, Intel x86 and AMD64 (x86-64) are little-endian;
Motorola 68000 and PowerPC G5 are big-endian; ARM and Intel Itanium
feature switchable endianness (bi-endian).  Use ‘sys.byteorder’ to check
the endianness of your system.

Native size and alignment are determined using the C compiler’s ‘sizeof’
expression.  This is always combined with native byte order.

Standard size depends only on the format character; see the table in the
*note Format Characters: 11c2. section.

Note the difference between ‘'@'’ and ‘'='’: both use native byte order,
but the size and alignment of the latter is standardized.

The form ‘'!'’ is available for those poor souls who claim they can’t
remember whether network byte order is big-endian or little-endian.

There is no way to indicate non-native byte order (force byte-swapping);
use the appropriate choice of ‘'<'’ or ‘'>'’.

Notes:

  1. Padding is only automatically added between successive structure
     members.  No padding is added at the beginning or the end of the
     encoded struct.

  2. No padding is added when using non-native size and alignment, e.g.
     with ’<’, ’>’, ’=’, and ’!’.

  3. To align the end of a structure to the alignment requirement of a
     particular type, end the format with the code for that type with a
     repeat count of zero.  See *note Examples: 11c4.


File: python.info,  Node: Format Characters,  Next: Examples<2>,  Prev: Byte Order Size and Alignment,  Up: Format Strings

5.7.1.4 Format Characters
.........................

Format characters have the following meaning; the conversion between C
and Python values should be obvious given their types.  The ’Standard
size’ column refers to the size of the packed value in bytes when using
standard size; that is, when the format string starts with one of ‘'<'’,
‘'>'’, ‘'!'’ or ‘'='’.  When using native size, the size of the packed
value is platform-dependent.

Format       C Type                         Python type              Standard size        Notes
                                                                                          
-----------------------------------------------------------------------------------------------------------
                                                                                          
‘x’          pad byte                       no value
                                            
                                                                                          
‘c’          ‘char’                         bytes of length 1        1
                                                                     
                                                                                          
‘b’          ‘signed char’                  integer                  1                    (1),(3)
                                                                                          
                                                                                          
‘B’          ‘unsigned char’                integer                  1                    (3)
                                                                                          
                                                                                          
‘?’          ‘_Bool’                        bool                     1                    (1)
                                                                                          
                                                                                          
‘h’          ‘short’                        integer                  2                    (3)
                                                                                          
                                                                                          
‘H’          ‘unsigned short’               integer                  2                    (3)
                                                                                          
                                                                                          
‘i’          ‘int’                          integer                  4                    (3)
                                                                                          
                                                                                          
‘I’          ‘unsigned int’                 integer                  4                    (3)
                                                                                          
                                                                                          
‘l’          ‘long’                         integer                  4                    (3)
                                                                                          
                                                                                          
‘L’          ‘unsigned long’                integer                  4                    (3)
                                                                                          
                                                                                          
‘q’          ‘long long’                    integer                  8                    (2), (3)
                                                                                          
                                                                                          
‘Q’          ‘unsigned long long’           integer                  8                    (2), (3)
                                                                                          
                                                                                          
‘n’          ‘ssize_t’                      integer                                       (4)
                                                                                          
                                                                                          
‘N’          ‘size_t’                       integer                                       (4)
                                                                                          
                                                                                          
‘f’          ‘float’                        float                    4                    (5)
                                                                                          
                                                                                          
‘d’          ‘double’                       float                    8                    (5)
                                                                                          
                                                                                          
‘s’          ‘char[]’                       bytes
                                            
                                                                                          
‘p’          ‘char[]’                       bytes
                                            
                                                                                          
‘P’          ‘void *’                       integer                                       (6)
                                                                                          

Changed in version 3.3: Added support for the ‘'n'’ and ‘'N'’ formats.

Notes:

  1. The ‘'?'’ conversion code corresponds to the ‘_Bool’ type defined
     by C99.  If this type is not available, it is simulated using a
     ‘char’.  In standard mode, it is always represented by one byte.

  2. The ‘'q'’ and ‘'Q'’ conversion codes are available in native mode
     only if the platform C compiler supports C ‘long long’, or, on
     Windows, ‘__int64’.  They are always available in standard modes.

  3. When attempting to pack a non-integer using any of the integer
     conversion codes, if the non-integer has a *note __index__(): 8d2.
     method then that method is called to convert the argument to an
     integer before packing.

     Changed in version 3.2: Use of the *note __index__(): 8d2. method
     for non-integers is new in 3.2.

  4. The ‘'n'’ and ‘'N'’ conversion codes are only available for the
     native size (selected as the default or with the ‘'@'’ byte order
     character).  For the standard size, you can use whichever of the
     other integer formats fits your application.

  5. For the ‘'f'’ and ‘'d'’ conversion codes, the packed representation
     uses the IEEE 754 binary32 (for ‘'f'’) or binary64 (for ‘'d'’)
     format, regardless of the floating-point format used by the
     platform.

  6. The ‘'P'’ format character is only available for the native byte
     ordering (selected as the default or with the ‘'@'’ byte order
     character).  The byte order character ‘'='’ chooses to use little-
     or big-endian ordering based on the host system.  The struct module
     does not interpret this as native ordering, so the ‘'P'’ format is
     not available.

A format character may be preceded by an integral repeat count.  For
example, the format string ‘'4h'’ means exactly the same as ‘'hhhh'’.

Whitespace characters between formats are ignored; a count and its
format must not contain whitespace though.

For the ‘'s'’ format character, the count is interpreted as the length
of the bytes, not a repeat count like for the other format characters;
for example, ‘'10s'’ means a single 10-byte string, while ‘'10c'’ means
10 characters.  If a count is not given, it defaults to 1.  For packing,
the string is truncated or padded with null bytes as appropriate to make
it fit.  For unpacking, the resulting bytes object always has exactly
the specified number of bytes.  As a special case, ‘'0s'’ means a
single, empty string (while ‘'0c'’ means 0 characters).

When packing a value ‘x’ using one of the integer formats (‘'b'’, ‘'B'’,
‘'h'’, ‘'H'’, ‘'i'’, ‘'I'’, ‘'l'’, ‘'L'’, ‘'q'’, ‘'Q'’), if ‘x’ is
outside the valid range for that format then *note struct.error: 928. is
raised.

Changed in version 3.1: In 3.0, some of the integer formats wrapped
out-of-range values and raised *note DeprecationWarning: 192. instead of
*note struct.error: 928.

The ‘'p'’ format character encodes a "Pascal string", meaning a short
variable-length string stored in a `fixed number of bytes', given by the
count.  The first byte stored is the length of the string, or 255,
whichever is smaller.  The bytes of the string follow.  If the string
passed in to *note pack(): 86c. is too long (longer than the count minus
1), only the leading ‘count-1’ bytes of the string are stored.  If the
string is shorter than ‘count-1’, it is padded with null bytes so that
exactly count bytes in all are used.  Note that for *note unpack(): cc2,
the ‘'p'’ format character consumes ‘count’ bytes, but that the string
returned can never contain more than 255 bytes.

For the ‘'?'’ format character, the return value is either *note True:
9ff. or *note False: 60d.  When packing, the truth value of the argument
object is used.  Either 0 or 1 in the native or standard bool
representation will be packed, and any non-zero value will be ‘True’
when unpacking.


File: python.info,  Node: Examples<2>,  Prev: Format Characters,  Up: Format Strings

5.7.1.5 Examples
................

     Note: All examples assume a native byte order, size, and alignment
     with a big-endian machine.

A basic example of packing/unpacking three integers:

     >>> from struct import *
     >>> pack('hhl', 1, 2, 3)
     b'\x00\x01\x00\x02\x00\x00\x00\x03'
     >>> unpack('hhl', b'\x00\x01\x00\x02\x00\x00\x00\x03')
     (1, 2, 3)
     >>> calcsize('hhl')
     8

Unpacked fields can be named by assigning them to variables or by
wrapping the result in a named tuple:

     >>> record = b'raymond   \x32\x12\x08\x01\x08'
     >>> name, serialnum, school, gradelevel = unpack('<10sHHb', record)

     >>> from collections import namedtuple
     >>> Student = namedtuple('Student', 'name serialnum school gradelevel')
     >>> Student._make(unpack('<10sHHb', record))
     Student(name=b'raymond   ', serialnum=4658, school=264, gradelevel=8)

The ordering of format characters may have an impact on size since the
padding needed to satisfy alignment requirements is different:

     >>> pack('ci', b'*', 0x12131415)
     b'*\x00\x00\x00\x12\x13\x14\x15'
     >>> pack('ic', 0x12131415, b'*')
     b'\x12\x13\x14\x15*'
     >>> calcsize('ci')
     8
     >>> calcsize('ic')
     5

The following format ‘'llh0l'’ specifies two pad bytes at the end,
assuming longs are aligned on 4-byte boundaries:

     >>> pack('llh0l', 1, 2, 3)
     b'\x00\x00\x00\x01\x00\x00\x00\x02\x00\x03\x00\x00'

This only works when native size and alignment are in effect; standard
size and alignment does not enforce any alignment.

See also
........

Module *note array: 7.

     Packed binary storage of homogeneous data.

Module *note xdrlib: 12f.

     Packing and unpacking of XDR data.


File: python.info,  Node: Classes<2>,  Prev: Format Strings,  Up: struct --- Interpret bytes as packed binary data

5.7.1.6 Classes
...............

The *note struct: f6. module also defines the following type:

 -- Class: struct.Struct (format)

     Return a new Struct object which writes and reads binary data
     according to the format string `format'.  Creating a Struct object
     once and calling its methods is more efficient than calling the
     *note struct: f6. functions with the same format since the format
     string only needs to be compiled once.

     Compiled Struct objects support the following methods and
     attributes:

      -- Method: pack (v1, v2, ...)

          Identical to the *note pack(): 86c. function, using the
          compiled format.  (‘len(result)’ will equal *note size: 11ca.)

      -- Method: pack_into (buffer, offset, v1, v2, ...)

          Identical to the *note pack_into(): 11be. function, using the
          compiled format.

      -- Method: unpack (buffer)

          Identical to the *note unpack(): cc2. function, using the
          compiled format.  The buffer’s size in bytes must equal *note
          size: 11ca.

      -- Method: unpack_from (buffer, offset=0)

          Identical to the *note unpack_from(): 11c0. function, using
          the compiled format.  The buffer’s size in bytes, minus
          `offset', must be at least *note size: 11ca.

      -- Method: iter_unpack (buffer)

          Identical to the *note iter_unpack(): 4d8. function, using the
          compiled format.  The buffer’s size in bytes must be a
          multiple of *note size: 11ca.

          New in version 3.4.

      -- Attribute: format

          The format string used to construct this Struct object.

      -- Attribute: size

          The calculated size of the struct (and hence of the bytes
          object produced by the *note pack(): 86c. method)
          corresponding to *note format: 14e.


File: python.info,  Node: codecs --- Codec registry and base classes,  Prev: struct --- Interpret bytes as packed binary data,  Up: Binary Data Services

5.7.2 ‘codecs’ — Codec registry and base classes
------------------------------------------------

`Source code:' Lib/codecs.py(1)

This module defines base classes for standard Python codecs (encoders
and decoders) and provides access to the internal Python codec registry,
which manages the codec and error handling lookup process.  Most
standard codecs are *note text encodings: fb1, which encode text to
bytes, but there are also codecs provided that encode text to text, and
bytes to bytes.  Custom codecs may encode and decode between arbitrary
types, but some module features are restricted to use specifically with
*note text encodings: fb1, or with codecs that encode to *note bytes:
1db.

The module defines the following functions for encoding and decoding
with any codec:

 -- Function: codecs.encode (obj, encoding='utf-8', errors='strict')

     Encodes `obj' using the codec registered for `encoding'.

     `Errors' may be given to set the desired error handling scheme.
     The default error handler is ‘'strict'’ meaning that encoding
     errors raise *note ValueError: 19c. (or a more codec specific
     subclass, such as *note UnicodeEncodeError: 852.).  Refer to *note
     Codec Base Classes: 11d1. for more information on codec error
     handling.

 -- Function: codecs.decode (obj, encoding='utf-8', errors='strict')

     Decodes `obj' using the codec registered for `encoding'.

     `Errors' may be given to set the desired error handling scheme.
     The default error handler is ‘'strict'’ meaning that decoding
     errors raise *note ValueError: 19c. (or a more codec specific
     subclass, such as *note UnicodeDecodeError: 571.).  Refer to *note
     Codec Base Classes: 11d1. for more information on codec error
     handling.

The full details for each codec can also be looked up directly:

 -- Function: codecs.lookup (encoding)

     Looks up the codec info in the Python codec registry and returns a
     *note CodecInfo: 11d2. object as defined below.

     Encodings are first looked up in the registry’s cache.  If not
     found, the list of registered search functions is scanned.  If no
     *note CodecInfo: 11d2. object is found, a *note LookupError: 1015.
     is raised.  Otherwise, the *note CodecInfo: 11d2. object is stored
     in the cache and returned to the caller.

 -- Class: codecs.CodecInfo (encode, decode, streamreader=None,
          streamwriter=None, incrementalencoder=None,
          incrementaldecoder=None, name=None)

     Codec details when looking up the codec registry.  The constructor
     arguments are stored in attributes of the same name:

      -- Attribute: name

          The name of the encoding.

      -- Attribute: encode
      -- Attribute: decode

          The stateless encoding and decoding functions.  These must be
          functions or methods which have the same interface as the
          *note encode(): 11d6. and *note decode(): 11d7. methods of
          Codec instances (see *note Codec Interface: 11d8.).  The
          functions or methods are expected to work in a stateless mode.

      -- Attribute: incrementalencoder
      -- Attribute: incrementaldecoder

          Incremental encoder and decoder classes or factory functions.
          These have to provide the interface defined by the base
          classes *note IncrementalEncoder: 11db. and *note
          IncrementalDecoder: 11dc, respectively.  Incremental codecs
          can maintain state.

      -- Attribute: streamwriter
      -- Attribute: streamreader

          Stream writer and reader classes or factory functions.  These
          have to provide the interface defined by the base classes
          *note StreamWriter: 11df. and *note StreamReader: 11e0,
          respectively.  Stream codecs can maintain state.

To simplify access to the various codec components, the module provides
these additional functions which use *note lookup(): 10b6. for the codec
lookup:

 -- Function: codecs.getencoder (encoding)

     Look up the codec for the given encoding and return its encoder
     function.

     Raises a *note LookupError: 1015. in case the encoding cannot be
     found.

 -- Function: codecs.getdecoder (encoding)

     Look up the codec for the given encoding and return its decoder
     function.

     Raises a *note LookupError: 1015. in case the encoding cannot be
     found.

 -- Function: codecs.getincrementalencoder (encoding)

     Look up the codec for the given encoding and return its incremental
     encoder class or factory function.

     Raises a *note LookupError: 1015. in case the encoding cannot be
     found or the codec doesn’t support an incremental encoder.

 -- Function: codecs.getincrementaldecoder (encoding)

     Look up the codec for the given encoding and return its incremental
     decoder class or factory function.

     Raises a *note LookupError: 1015. in case the encoding cannot be
     found or the codec doesn’t support an incremental decoder.

 -- Function: codecs.getreader (encoding)

     Look up the codec for the given encoding and return its
     StreamReader class or factory function.

     Raises a *note LookupError: 1015. in case the encoding cannot be
     found.

 -- Function: codecs.getwriter (encoding)

     Look up the codec for the given encoding and return its
     StreamWriter class or factory function.

     Raises a *note LookupError: 1015. in case the encoding cannot be
     found.

Custom codecs are made available by registering a suitable codec search
function:

 -- Function: codecs.register (search_function)

     Register a codec search function.  Search functions are expected to
     take one argument, being the encoding name in all lower case
     letters, and return a *note CodecInfo: 11d2. object.  In case a
     search function cannot find a given encoding, it should return
     ‘None’.

          Note: Search function registration is not currently
          reversible, which may cause problems in some cases, such as
          unit testing or module reloading.

While the builtin *note open(): 1e8. and the associated *note io: 9f.
module are the recommended approach for working with encoded text files,
this module provides additional utility functions and classes that allow
the use of a wider range of codecs when working with binary files:

 -- Function: codecs.open (filename, mode='r', encoding=None,
          errors='strict', buffering=1)

     Open an encoded file using the given `mode' and return an instance
     of *note StreamReaderWriter: 11e9, providing transparent
     encoding/decoding.  The default file mode is ‘'r'’, meaning to open
     the file in read mode.

          Note: Underlying encoded files are always opened in binary
          mode.  No automatic conversion of ‘'\n'’ is done on reading
          and writing.  The `mode' argument may be any binary mode
          acceptable to the built-in *note open(): 1e8. function; the
          ‘'b'’ is automatically added.

     `encoding' specifies the encoding which is to be used for the file.
     Any encoding that encodes to and decodes from bytes is allowed, and
     the data types supported by the file methods depend on the codec
     used.

     `errors' may be given to define the error handling.  It defaults to
     ‘'strict'’ which causes a *note ValueError: 19c. to be raised in
     case an encoding error occurs.

     `buffering' has the same meaning as for the built-in *note open():
     1e8. function.  It defaults to line buffered.

 -- Function: codecs.EncodedFile (file, data_encoding,
          file_encoding=None, errors='strict')

     Return a *note StreamRecoder: 11eb. instance, a wrapped version of
     `file' which provides transparent transcoding.  The original file
     is closed when the wrapped version is closed.

     Data written to the wrapped file is decoded according to the given
     `data_encoding' and then written to the original file as bytes
     using `file_encoding'.  Bytes read from the original file are
     decoded according to `file_encoding', and the result is encoded
     using `data_encoding'.

     If `file_encoding' is not given, it defaults to `data_encoding'.

     `errors' may be given to define the error handling.  It defaults to
     ‘'strict'’, which causes *note ValueError: 19c. to be raised in
     case an encoding error occurs.

 -- Function: codecs.iterencode (iterator, encoding, errors='strict',
          **kwargs)

     Uses an incremental encoder to iteratively encode the input
     provided by `iterator'.  This function is a *note generator: 5c0.
     The `errors' argument (as well as any other keyword argument) is
     passed through to the incremental encoder.

 -- Function: codecs.iterdecode (iterator, encoding, errors='strict',
          **kwargs)

     Uses an incremental decoder to iteratively decode the input
     provided by `iterator'.  This function is a *note generator: 5c0.
     The `errors' argument (as well as any other keyword argument) is
     passed through to the incremental decoder.

The module also provides the following constants which are useful for
reading and writing to platform dependent files:

 -- Data: codecs.BOM
 -- Data: codecs.BOM_BE
 -- Data: codecs.BOM_LE
 -- Data: codecs.BOM_UTF8
 -- Data: codecs.BOM_UTF16
 -- Data: codecs.BOM_UTF16_BE
 -- Data: codecs.BOM_UTF16_LE
 -- Data: codecs.BOM_UTF32
 -- Data: codecs.BOM_UTF32_BE
 -- Data: codecs.BOM_UTF32_LE

     These constants define various byte sequences, being Unicode byte
     order marks (BOMs) for several encodings.  They are used in UTF-16
     and UTF-32 data streams to indicate the byte order used, and in
     UTF-8 as a Unicode signature.  *note BOM_UTF16: 11f2. is either
     *note BOM_UTF16_BE: 11f3. or *note BOM_UTF16_LE: 11f4. depending on
     the platform’s native byte order, *note BOM: 11ee. is an alias for
     *note BOM_UTF16: 11f2, *note BOM_LE: 11f0. for *note BOM_UTF16_LE:
     11f4. and *note BOM_BE: 11ef. for *note BOM_UTF16_BE: 11f3.  The
     others represent the BOM in UTF-8 and UTF-32 encodings.

* Menu:

* Codec Base Classes:: 
* Encodings and Unicode:: 
* Standard Encodings:: 
* Python Specific Encodings:: 
* encodings.idna: encodings idna --- Internationalized Domain Names in Applications. Internationalized Domain Names in Applications
* encodings.mbcs: encodings mbcs --- Windows ANSI codepage. Windows ANSI codepage
* encodings.utf_8_sig: encodings utf_8_sig --- UTF-8 codec with BOM signature. UTF-8 codec with BOM signature

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/default/Lib/codecs.py


File: python.info,  Node: Codec Base Classes,  Next: Encodings and Unicode,  Up: codecs --- Codec registry and base classes

5.7.2.1 Codec Base Classes
..........................

The *note codecs: 1c. module defines a set of base classes which define
the interfaces for working with codec objects, and can also be used as
the basis for custom codec implementations.

Each codec has to define four interfaces to make it usable as codec in
Python: stateless encoder, stateless decoder, stream reader and stream
writer.  The stream reader and writers typically reuse the stateless
encoder/decoder to implement the file protocols.  Codec authors also
need to define how the codec will handle encoding and decoding errors.
* Menu:

* Error Handlers:: 
* Stateless Encoding and Decoding:: 
* Incremental Encoding and Decoding:: 
* Stream Encoding and Decoding:: 


File: python.info,  Node: Error Handlers,  Next: Stateless Encoding and Decoding,  Up: Codec Base Classes

5.7.2.2 Error Handlers
......................

To simplify and standardize error handling, codecs may implement
different error handling schemes by accepting the `errors' string
argument.  The following string values are defined and implemented by
all standard Python codecs:

Value                         Meaning
                              
----------------------------------------------------------------------------------
                              
‘'strict'’                    Raise *note UnicodeError: 8a2. (or a subclass);
                              this is the default.  Implemented in
                              *note strict_errors(): 11fb.
                              
                              
‘'ignore'’                    Ignore the malformed data and continue without
                              further notice.  Implemented in
                              *note ignore_errors(): 11fc.
                              

The following error handlers are only applicable to *note text
encodings: fb1.:

Value                         Meaning
                              
----------------------------------------------------------------------------------
                              
‘'replace'’                   Replace with a suitable replacement marker;
                              Python will use the official ‘U+FFFD’ REPLACEMENT
                              CHARACTER for the built-in codecs on decoding,
                              and ’?’ on encoding.  Implemented in
                              *note replace_errors(): 11fd.
                              
                              
‘'xmlcharrefreplace'’         Replace with the appropriate XML character
                              reference (only for encoding).  Implemented in
                              *note xmlcharrefreplace_errors(): 11fe.
                              
                              
‘'backslashreplace'’          Replace with backslashed escape sequences.
                              Implemented in
                              *note backslashreplace_errors(): 11ff.
                              
                              
‘'namereplace'’               Replace with ‘\N{...}’ escape sequences (only for
                              encoding).  Implemented in
                              *note namereplace_errors(): 1200.
                              
                              
‘'surrogateescape'’           On decoding, replace byte with individual
                              surrogate code ranging from ‘U+DC80’ to ‘U+DCFF’.
                              This code will then be turned back into the same
                              byte when the ‘'surrogateescape'’ error handler
                              is used when encoding the data.  (See PEP 383(1)
                              for more.)
                              

In addition, the following error handler is specific to the given
codecs:

Value                   Codecs                       Meaning
                                                     
-----------------------------------------------------------------------------------------------------
                                                     
‘'surrogatepass'’       utf-8, utf-16, utf-32,       Allow encoding and decoding of surrogate
                        utf-16-be, utf-16-le,        codes.  These codecs normally treat the
                        utf-32-be, utf-32-le         presence of surrogates as an error.
                                                     

New in version 3.1: The ‘'surrogateescape'’ and ‘'surrogatepass'’ error
handlers.

Changed in version 3.4: The ‘'surrogatepass'’ error handlers now works
with utf-16* and utf-32* codecs.

New in version 3.5: The ‘'namereplace'’ error handler.

Changed in version 3.5: The ‘'backslashreplace'’ error handlers now
works with decoding and translating.

The set of allowed values can be extended by registering a new named
error handler:

 -- Function: codecs.register_error (name, error_handler)

     Register the error handling function `error_handler' under the name
     `name'.  The `error_handler' argument will be called during
     encoding and decoding in case of an error, when `name' is specified
     as the errors parameter.

     For encoding, `error_handler' will be called with a *note
     UnicodeEncodeError: 852. instance, which contains information about
     the location of the error.  The error handler must either raise
     this or a different exception, or return a tuple with a replacement
     for the unencodable part of the input and a position where encoding
     should continue.  The replacement may be either *note str: 25a. or
     *note bytes: 1db.  If the replacement is bytes, the encoder will
     simply copy them into the output buffer.  If the replacement is a
     string, the encoder will encode the replacement.  Encoding
     continues on original input at the specified position.  Negative
     position values will be treated as being relative to the end of the
     input string.  If the resulting position is out of bound an *note
     IndexError: afb. will be raised.

     Decoding and translating works similarly, except *note
     UnicodeDecodeError: 571. or *note UnicodeTranslateError: 10c8. will
     be passed to the handler and that the replacement from the error
     handler will be put into the output directly.

Previously registered error handlers (including the standard error
handlers) can be looked up by name:

 -- Function: codecs.lookup_error (name)

     Return the error handler previously registered under the name
     `name'.

     Raises a *note LookupError: 1015. in case the handler cannot be
     found.

The following standard error handlers are also made available as module
level functions:

 -- Function: codecs.strict_errors (exception)

     Implements the ‘'strict'’ error handling: each encoding or decoding
     error raises a *note UnicodeError: 8a2.

 -- Function: codecs.replace_errors (exception)

     Implements the ‘'replace'’ error handling (for *note text
     encodings: fb1. only): substitutes ‘'?'’ for encoding errors (to be
     encoded by the codec), and ‘'\ufffd'’ (the Unicode replacement
     character) for decoding errors.

 -- Function: codecs.ignore_errors (exception)

     Implements the ‘'ignore'’ error handling: malformed data is ignored
     and encoding or decoding is continued without further notice.

 -- Function: codecs.xmlcharrefreplace_errors (exception)

     Implements the ‘'xmlcharrefreplace'’ error handling (for encoding
     with *note text encodings: fb1. only): the unencodable character is
     replaced by an appropriate XML character reference.

 -- Function: codecs.backslashreplace_errors (exception)

     Implements the ‘'backslashreplace'’ error handling (for *note text
     encodings: fb1. only): malformed data is replaced by a backslashed
     escape sequence.

 -- Function: codecs.namereplace_errors (exception)

     Implements the ‘'namereplace'’ error handling (for encoding with
     *note text encodings: fb1. only): the unencodable character is
     replaced by a ‘\N{...}’ escape sequence.

     New in version 3.5.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0383


File: python.info,  Node: Stateless Encoding and Decoding,  Next: Incremental Encoding and Decoding,  Prev: Error Handlers,  Up: Codec Base Classes

5.7.2.3 Stateless Encoding and Decoding
.......................................

The base ‘Codec’ class defines these methods which also define the
function interfaces of the stateless encoder and decoder:

 -- Method: Codec.encode (input[, errors])

     Encodes the object `input' and returns a tuple (output object,
     length consumed).  For instance, *note text encoding: fb1. converts
     a string object to a bytes object using a particular character set
     encoding (e.g., ‘cp1252’ or ‘iso-8859-1’).

     The `errors' argument defines the error handling to apply.  It
     defaults to ‘'strict'’ handling.

     The method may not store state in the ‘Codec’ instance.  Use *note
     StreamWriter: 11df. for codecs which have to keep state in order to
     make encoding efficient.

     The encoder must be able to handle zero length input and return an
     empty object of the output object type in this situation.

 -- Method: Codec.decode (input[, errors])

     Decodes the object `input' and returns a tuple (output object,
     length consumed).  For instance, for a *note text encoding: fb1,
     decoding converts a bytes object encoded using a particular
     character set encoding to a string object.

     For text encodings and bytes-to-bytes codecs, `input' must be a
     bytes object or one which provides the read-only buffer interface –
     for example, buffer objects and memory mapped files.

     The `errors' argument defines the error handling to apply.  It
     defaults to ‘'strict'’ handling.

     The method may not store state in the ‘Codec’ instance.  Use *note
     StreamReader: 11e0. for codecs which have to keep state in order to
     make decoding efficient.

     The decoder must be able to handle zero length input and return an
     empty object of the output object type in this situation.


File: python.info,  Node: Incremental Encoding and Decoding,  Next: Stream Encoding and Decoding,  Prev: Stateless Encoding and Decoding,  Up: Codec Base Classes

5.7.2.4 Incremental Encoding and Decoding
.........................................

The *note IncrementalEncoder: 11db. and *note IncrementalDecoder: 11dc.
classes provide the basic interface for incremental encoding and
decoding.  Encoding/decoding the input isn’t done with one call to the
stateless encoder/decoder function, but with multiple calls to the *note
encode(): 1203./*note decode(): 1204. method of the incremental
encoder/decoder.  The incremental encoder/decoder keeps track of the
encoding/decoding process during method calls.

The joined output of calls to the *note encode(): 1203./*note decode():
1204. method is the same as if all the single inputs were joined into
one, and this input was encoded/decoded with the stateless
encoder/decoder.

* Menu:

* IncrementalEncoder Objects:: 
* IncrementalDecoder Objects:: 


File: python.info,  Node: IncrementalEncoder Objects,  Next: IncrementalDecoder Objects,  Up: Incremental Encoding and Decoding

5.7.2.5 IncrementalEncoder Objects
..................................

The *note IncrementalEncoder: 11db. class is used for encoding an input
in multiple steps.  It defines the following methods which every
incremental encoder must define in order to be compatible with the
Python codec registry.

 -- Class: codecs.IncrementalEncoder (errors='strict')

     Constructor for an *note IncrementalEncoder: 11db. instance.

     All incremental encoders must provide this constructor interface.
     They are free to add additional keyword arguments, but only the
     ones defined here are used by the Python codec registry.

     The *note IncrementalEncoder: 11db. may implement different error
     handling schemes by providing the `errors' keyword argument.  See
     *note Error Handlers: fb2. for possible values.

     The `errors' argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note IncrementalEncoder: 11db. object.

      -- Method: encode (object[, final])

          Encodes `object' (taking the current state of the encoder into
          account) and returns the resulting encoded object.  If this is
          the last call to *note encode(): 3f2. `final' must be true
          (the default is false).

      -- Method: reset ()

          Reset the encoder to the initial state.  The output is
          discarded: call ‘.encode(object, final=True)’, passing an
          empty byte or text string if necessary, to reset the encoder
          and to get the output.

 -- Method: IncrementalEncoder.getstate ()

     Return the current state of the encoder which must be an integer.
     The implementation should make sure that ‘0’ is the most common
     state.  (States that are more complicated than integers can be
     converted into an integer by marshaling/pickling the state and
     encoding the bytes of the resulting string into an integer).

 -- Method: IncrementalEncoder.setstate (state)

     Set the state of the encoder to `state'.  `state' must be an
     encoder state returned by *note getstate(): 1208.


File: python.info,  Node: IncrementalDecoder Objects,  Prev: IncrementalEncoder Objects,  Up: Incremental Encoding and Decoding

5.7.2.6 IncrementalDecoder Objects
..................................

The *note IncrementalDecoder: 11dc. class is used for decoding an input
in multiple steps.  It defines the following methods which every
incremental decoder must define in order to be compatible with the
Python codec registry.

 -- Class: codecs.IncrementalDecoder (errors='strict')

     Constructor for an *note IncrementalDecoder: 11dc. instance.

     All incremental decoders must provide this constructor interface.
     They are free to add additional keyword arguments, but only the
     ones defined here are used by the Python codec registry.

     The *note IncrementalDecoder: 11dc. may implement different error
     handling schemes by providing the `errors' keyword argument.  See
     *note Error Handlers: fb2. for possible values.

     The `errors' argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note IncrementalDecoder: 11dc. object.

      -- Method: decode (object[, final])

          Decodes `object' (taking the current state of the decoder into
          account) and returns the resulting decoded object.  If this is
          the last call to *note decode(): 3f3. `final' must be true
          (the default is false).  If `final' is true the decoder must
          decode the input completely and must flush all buffers.  If
          this isn’t possible (e.g.  because of incomplete byte
          sequences at the end of the input) it must initiate error
          handling just like in the stateless case (which might raise an
          exception).

      -- Method: reset ()

          Reset the decoder to the initial state.

      -- Method: getstate ()

          Return the current state of the decoder.  This must be a tuple
          with two items, the first must be the buffer containing the
          still undecoded input.  The second must be an integer and can
          be additional state info.  (The implementation should make
          sure that ‘0’ is the most common additional state info.)  If
          this additional state info is ‘0’ it must be possible to set
          the decoder to the state which has no input buffered and ‘0’
          as the additional state info, so that feeding the previously
          buffered input to the decoder returns it to the previous state
          without producing any output.  (Additional state info that is
          more complicated than integers can be converted into an
          integer by marshaling/pickling the info and encoding the bytes
          of the resulting string into an integer.)

      -- Method: setstate (state)

          Set the state of the encoder to `state'.  `state' must be a
          decoder state returned by *note getstate(): 120d.


File: python.info,  Node: Stream Encoding and Decoding,  Prev: Incremental Encoding and Decoding,  Up: Codec Base Classes

5.7.2.7 Stream Encoding and Decoding
....................................

The *note StreamWriter: 11df. and *note StreamReader: 11e0. classes
provide generic working interfaces which can be used to implement new
encoding submodules very easily.  See ‘encodings.utf_8’ for an example
of how this is done.

* Menu:

* StreamWriter Objects:: 
* StreamReader Objects:: 
* StreamReaderWriter Objects:: 
* StreamRecoder Objects:: 


File: python.info,  Node: StreamWriter Objects,  Next: StreamReader Objects,  Up: Stream Encoding and Decoding

5.7.2.8 StreamWriter Objects
............................

The *note StreamWriter: 11df. class is a subclass of ‘Codec’ and defines
the following methods which every stream writer must define in order to
be compatible with the Python codec registry.

 -- Class: codecs.StreamWriter (stream, errors='strict')

     Constructor for a *note StreamWriter: 11df. instance.

     All stream writers must provide this constructor interface.  They
     are free to add additional keyword arguments, but only the ones
     defined here are used by the Python codec registry.

     The `stream' argument must be a file-like object open for writing
     text or binary data, as appropriate for the specific codec.

     The *note StreamWriter: 11df. may implement different error
     handling schemes by providing the `errors' keyword argument.  See
     *note Error Handlers: fb2. for the standard error handlers the
     underlying stream codec may support.

     The `errors' argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note StreamWriter: 11df. object.

      -- Method: write (object)

          Writes the object’s contents encoded to the stream.

      -- Method: writelines (list)

          Writes the concatenated list of strings to the stream
          (possibly by reusing the *note write(): 1212. method).  The
          standard bytes-to-bytes codecs do not support this method.

      -- Method: reset ()

          Flushes and resets the codec buffers used for keeping state.

          Calling this method should ensure that the data on the output
          is put into a clean state that allows appending of new fresh
          data without having to rescan the whole stream to recover
          state.

In addition to the above methods, the *note StreamWriter: 11df. must
also inherit all other methods and attributes from the underlying
stream.


File: python.info,  Node: StreamReader Objects,  Next: StreamReaderWriter Objects,  Prev: StreamWriter Objects,  Up: Stream Encoding and Decoding

5.7.2.9 StreamReader Objects
............................

The *note StreamReader: 11e0. class is a subclass of ‘Codec’ and defines
the following methods which every stream reader must define in order to
be compatible with the Python codec registry.

 -- Class: codecs.StreamReader (stream, errors='strict')

     Constructor for a *note StreamReader: 11e0. instance.

     All stream readers must provide this constructor interface.  They
     are free to add additional keyword arguments, but only the ones
     defined here are used by the Python codec registry.

     The `stream' argument must be a file-like object open for reading
     text or binary data, as appropriate for the specific codec.

     The *note StreamReader: 11e0. may implement different error
     handling schemes by providing the `errors' keyword argument.  See
     *note Error Handlers: fb2. for the standard error handlers the
     underlying stream codec may support.

     The `errors' argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note StreamReader: 11e0. object.

     The set of allowed values for the `errors' argument can be extended
     with *note register_error(): a74.

      -- Method: read ([size[, chars[, firstline]]])

          Decodes data from the stream and returns the resulting object.

          The `chars' argument indicates the number of decoded code
          points or bytes to return.  The *note read(): 1217. method
          will never return more data than requested, but it might
          return less, if there is not enough available.

          The `size' argument indicates the approximate maximum number
          of encoded bytes or code points to read for decoding.  The
          decoder can modify this setting as appropriate.  The default
          value -1 indicates to read and decode as much as possible.
          This parameter is intended to prevent having to decode huge
          files in one step.

          The `firstline' flag indicates that it would be sufficient to
          only return the first line, if there are decoding errors on
          later lines.

          The method should use a greedy read strategy meaning that it
          should read as much data as is allowed within the definition
          of the encoding and the given size, e.g.  if optional encoding
          endings or state markers are available on the stream, these
          should be read too.

      -- Method: readline ([size[, keepends]])

          Read one line from the input stream and return the decoded
          data.

          `size', if given, is passed as size argument to the stream’s
          *note read(): 1217. method.

          If `keepends' is false line-endings will be stripped from the
          lines returned.

      -- Method: readlines ([sizehint[, keepends]])

          Read all lines available on the input stream and return them
          as a list of lines.

          Line-endings are implemented using the codec’s decoder method
          and are included in the list entries if `keepends' is true.

          `sizehint', if given, is passed as the `size' argument to the
          stream’s *note read(): 1217. method.

      -- Method: reset ()

          Resets the codec buffers used for keeping state.

          Note that no stream repositioning should take place.  This
          method is primarily intended to be able to recover from
          decoding errors.

In addition to the above methods, the *note StreamReader: 11e0. must
also inherit all other methods and attributes from the underlying
stream.


File: python.info,  Node: StreamReaderWriter Objects,  Next: StreamRecoder Objects,  Prev: StreamReader Objects,  Up: Stream Encoding and Decoding

5.7.2.10 StreamReaderWriter Objects
...................................

The *note StreamReaderWriter: 11e9. is a convenience class that allows
wrapping streams which work in both read and write modes.

The design is such that one can use the factory functions returned by
the *note lookup(): 10b6. function to construct the instance.

 -- Class: codecs.StreamReaderWriter (stream, Reader, Writer, errors)

     Creates a *note StreamReaderWriter: 11e9. instance.  `stream' must
     be a file-like object.  `Reader' and `Writer' must be factory
     functions or classes providing the *note StreamReader: 11e0. and
     *note StreamWriter: 11df. interface resp.  Error handling is done
     in the same way as defined for the stream readers and writers.

*note StreamReaderWriter: 11e9. instances define the combined interfaces
of *note StreamReader: 11e0. and *note StreamWriter: 11df. classes.
They inherit all other methods and attributes from the underlying
stream.


File: python.info,  Node: StreamRecoder Objects,  Prev: StreamReaderWriter Objects,  Up: Stream Encoding and Decoding

5.7.2.11 StreamRecoder Objects
..............................

The *note StreamRecoder: 11eb. translates data from one encoding to
another, which is sometimes useful when dealing with different encoding
environments.

The design is such that one can use the factory functions returned by
the *note lookup(): 10b6. function to construct the instance.

 -- Class: codecs.StreamRecoder (stream, encode, decode, Reader, Writer,
          errors)

     Creates a *note StreamRecoder: 11eb. instance which implements a
     two-way conversion: `encode' and `decode' work on the frontend —
     the data visible to code calling ‘read()’ and ‘write()’, while
     `Reader' and `Writer' work on the backend — the data in `stream'.

     You can use these objects to do transparent transcodings from e.g.
     Latin-1 to UTF-8 and back.

     The `stream' argument must be a file-like object.

     The `encode' and `decode' arguments must adhere to the ‘Codec’
     interface.  `Reader' and `Writer' must be factory functions or
     classes providing objects of the *note StreamReader: 11e0. and
     *note StreamWriter: 11df. interface respectively.

     Error handling is done in the same way as defined for the stream
     readers and writers.

*note StreamRecoder: 11eb. instances define the combined interfaces of
*note StreamReader: 11e0. and *note StreamWriter: 11df. classes.  They
inherit all other methods and attributes from the underlying stream.


File: python.info,  Node: Encodings and Unicode,  Next: Standard Encodings,  Prev: Codec Base Classes,  Up: codecs --- Codec registry and base classes

5.7.2.12 Encodings and Unicode
..............................

Strings are stored internally as sequences of code points in range
‘0x0’-‘0x10FFFF’.  (See PEP 393(1) for more details about the
implementation.)  Once a string object is used outside of CPU and
memory, endianness and how these arrays are stored as bytes become an
issue.  As with other codecs, serialising a string into a sequence of
bytes is known as `encoding', and recreating the string from the
sequence of bytes is known as `decoding'.  There are a variety of
different text serialisation codecs, which are collectivity referred to
as *note text encodings: fb1.

The simplest text encoding (called ‘'latin-1'’ or ‘'iso-8859-1'’) maps
the code points 0-255 to the bytes ‘0x0’-‘0xff’, which means that a
string object that contains code points above ‘U+00FF’ can’t be encoded
with this codec.  Doing so will raise a *note UnicodeEncodeError: 852.
that looks like the following (although the details of the error message
may differ): ‘UnicodeEncodeError: 'latin-1' codec can't encode character
'\u1234' in position 3: ordinal not in range(256)’.

There’s another group of encodings (the so called charmap encodings)
that choose a different subset of all Unicode code points and how these
code points are mapped to the bytes ‘0x0’-‘0xff’.  To see how this is
done simply open e.g.  ‘encodings/cp1252.py’ (which is an encoding that
is used primarily on Windows).  There’s a string constant with 256
characters that shows you which character is mapped to which byte value.

All of these encodings can only encode 256 of the 1114112 code points
defined in Unicode.  A simple and straightforward way that can store
each Unicode code point, is to store each code point as four consecutive
bytes.  There are two possibilities: store the bytes in big endian or in
little endian order.  These two encodings are called ‘UTF-32-BE’ and
‘UTF-32-LE’ respectively.  Their disadvantage is that if e.g.  you use
‘UTF-32-BE’ on a little endian machine you will always have to swap
bytes on encoding and decoding.  ‘UTF-32’ avoids this problem: bytes
will always be in natural endianness.  When these bytes are read by a
CPU with a different endianness, then bytes have to be swapped though.
To be able to detect the endianness of a ‘UTF-16’ or ‘UTF-32’ byte
sequence, there’s the so called BOM ("Byte Order Mark").  This is the
Unicode character ‘U+FEFF’.  This character can be prepended to every
‘UTF-16’ or ‘UTF-32’ byte sequence.  The byte swapped version of this
character (‘0xFFFE’) is an illegal character that may not appear in a
Unicode text.  So when the first character in an ‘UTF-16’ or ‘UTF-32’
byte sequence appears to be a ‘U+FFFE’ the bytes have to be swapped on
decoding.  Unfortunately the character ‘U+FEFF’ had a second purpose as
a ‘ZERO WIDTH NO-BREAK SPACE’: a character that has no width and doesn’t
allow a word to be split.  It can e.g.  be used to give hints to a
ligature algorithm.  With Unicode 4.0 using ‘U+FEFF’ as a ‘ZERO WIDTH
NO-BREAK SPACE’ has been deprecated (with ‘U+2060’ (‘WORD JOINER’)
assuming this role).  Nevertheless Unicode software still must be able
to handle ‘U+FEFF’ in both roles: as a BOM it’s a device to determine
the storage layout of the encoded bytes, and vanishes once the byte
sequence has been decoded into a string; as a ‘ZERO WIDTH NO-BREAK
SPACE’ it’s a normal character that will be decoded like any other.

There’s another encoding that is able to encoding the full range of
Unicode characters: UTF-8.  UTF-8 is an 8-bit encoding, which means
there are no issues with byte order in UTF-8.  Each byte in a UTF-8 byte
sequence consists of two parts: marker bits (the most significant bits)
and payload bits.  The marker bits are a sequence of zero to four ‘1’
bits followed by a ‘0’ bit.  Unicode characters are encoded like this
(with x being payload bits, which when concatenated give the Unicode
character):

Range                                   Encoding
                                        
-------------------------------------------------------------------------------------------
                                        
‘U-00000000’ ...  ‘U-0000007F’          0xxxxxxx
                                        
                                        
‘U-00000080’ ...  ‘U-000007FF’          110xxxxx 10xxxxxx
                                        
                                        
‘U-00000800’ ...  ‘U-0000FFFF’          1110xxxx 10xxxxxx 10xxxxxx
                                        
                                        
‘U-00010000’ ...  ‘U-0010FFFF’          11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
                                        

The least significant bit of the Unicode character is the rightmost x
bit.

As UTF-8 is an 8-bit encoding no BOM is required and any ‘U+FEFF’
character in the decoded string (even if it’s the first character) is
treated as a ‘ZERO WIDTH NO-BREAK SPACE’.

Without external information it’s impossible to reliably determine which
encoding was used for encoding a string.  Each charmap encoding can
decode any random byte sequence.  However that’s not possible with
UTF-8, as UTF-8 byte sequences have a structure that doesn’t allow
arbitrary byte sequences.  To increase the reliability with which a
UTF-8 encoding can be detected, Microsoft invented a variant of UTF-8
(that Python 2.5 calls ‘"utf-8-sig"’) for its Notepad program: Before
any of the Unicode characters is written to the file, a UTF-8 encoded
BOM (which looks like this as a byte sequence: ‘0xef’, ‘0xbb’, ‘0xbf’)
is written.  As it’s rather improbable that any charmap encoded file
starts with these byte values (which would e.g.  map to

          LATIN SMALL LETTER I WITH DIAERESIS 
          RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK 
          INVERTED QUESTION MARK 

in iso-8859-1), this increases the probability that a ‘utf-8-sig’
encoding can be correctly guessed from the byte sequence.  So here the
BOM is not used to be able to determine the byte order used for
generating the byte sequence, but as a signature that helps in guessing
the encoding.  On encoding the utf-8-sig codec will write ‘0xef’,
‘0xbb’, ‘0xbf’ as the first three bytes to the file.  On decoding
‘utf-8-sig’ will skip those three bytes if they appear as the first
three bytes in the file.  In UTF-8, the use of the BOM is discouraged
and should generally be avoided.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0393


File: python.info,  Node: Standard Encodings,  Next: Python Specific Encodings,  Prev: Encodings and Unicode,  Up: codecs --- Codec registry and base classes

5.7.2.13 Standard Encodings
...........................

Python comes with a number of codecs built-in, either implemented as C
functions or with dictionaries as mapping tables.  The following table
lists the codecs by name, together with a few common aliases, and the
languages for which the encoding is likely used.  Neither the list of
aliases nor the list of languages is meant to be exhaustive.  Notice
that spelling alternatives that only differ in case or use a hyphen
instead of an underscore are also valid aliases; therefore, e.g.
‘'utf-8'’ is a valid alias for the ‘'utf_8'’ codec.

`CPython implementation detail:' Some common encodings can bypass the
codecs lookup machinery to improve performance.  These optimization
opportunities are only recognized by CPython for a limited set of
aliases: utf-8, utf8, latin-1, latin1, iso-8859-1, mbcs (Windows only),
ascii, utf-16, and utf-32.  Using alternative spellings for these
encodings may result in slower execution.

Many of the character sets support the same languages.  They vary in
individual characters (e.g.  whether the EURO SIGN is supported or not),
and in the assignment of characters to code positions.  For the European
languages in particular, the following variants typically exist:

   * an ISO 8859 codeset

   * a Microsoft Windows code page, which is typically derived from a
     8859 codeset, but replaces control characters with additional
     graphic characters

   * an IBM EBCDIC code page

   * an IBM PC code page, which is ASCII compatible

Codec                 Aliases                              Languages
                                                           
------------------------------------------------------------------------------------------------
                                                           
ascii                 646, us-ascii                        English
                                                           
                                                           
big5                  big5-tw, csbig5                      Traditional Chinese
                                                           
                                                           
big5hkscs             big5-hkscs, hkscs                    Traditional Chinese
                                                           
                                                           
cp037                 IBM037, IBM039                       English
                                                           
                                                           
cp273                 273, IBM273, csIBM273                German
                                                           
                                                           New in version 3.4.
                                                           
                                                           
cp424                 EBCDIC-CP-HE, IBM424                 Hebrew
                                                           
                                                           
cp437                 437, IBM437                          English
                                                           
                                                           
cp500                 EBCDIC-CP-BE, EBCDIC-CP-CH, IBM500   Western Europe
                                                           
                                                           
cp720                                                      Arabic
                                                           
                                                           
cp737                                                      Greek
                                                           
                                                           
cp775                 IBM775                               Baltic languages
                                                           
                                                           
cp850                 850, IBM850                          Western Europe
                                                           
                                                           
cp852                 852, IBM852                          Central and Eastern Europe
                                                           
                                                           
cp855                 855, IBM855                          Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
cp856                                                      Hebrew
                                                           
                                                           
cp857                 857, IBM857                          Turkish
                                                           
                                                           
cp858                 858, IBM858                          Western Europe
                                                           
                                                           
cp860                 860, IBM860                          Portuguese
                                                           
                                                           
cp861                 861, CP-IS, IBM861                   Icelandic
                                                           
                                                           
cp862                 862, IBM862                          Hebrew
                                                           
                                                           
cp863                 863, IBM863                          Canadian
                                                           
                                                           
cp864                 IBM864                               Arabic
                                                           
                                                           
cp865                 865, IBM865                          Danish, Norwegian
                                                           
                                                           
cp866                 866, IBM866                          Russian
                                                           
                                                           
cp869                 869, CP-GR, IBM869                   Greek
                                                           
                                                           
cp874                                                      Thai
                                                           
                                                           
cp875                                                      Greek
                                                           
                                                           
cp932                 932, ms932, mskanji, ms-kanji        Japanese
                                                           
                                                           
cp949                 949, ms949, uhc                      Korean
                                                           
                                                           
cp950                 950, ms950                           Traditional Chinese
                                                           
                                                           
cp1006                                                     Urdu
                                                           
                                                           
cp1026                ibm1026                              Turkish
                                                           
                                                           
cp1125                1125, ibm1125, cp866u, ruscii        Ukrainian
                                                           
                                                           New in version 3.4.
                                                           
                                                           
cp1140                ibm1140                              Western Europe
                                                           
                                                           
cp1250                windows-1250                         Central and Eastern Europe
                                                           
                                                           
cp1251                windows-1251                         Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
cp1252                windows-1252                         Western Europe
                                                           
                                                           
cp1253                windows-1253                         Greek
                                                           
                                                           
cp1254                windows-1254                         Turkish
                                                           
                                                           
cp1255                windows-1255                         Hebrew
                                                           
                                                           
cp1256                windows-1256                         Arabic
                                                           
                                                           
cp1257                windows-1257                         Baltic languages
                                                           
                                                           
cp1258                windows-1258                         Vietnamese
                                                           
                                                           
cp65001                                                    Windows only: Windows UTF-8
                                                           (‘CP_UTF8’)
                                                           
                                                           New in version 3.3.
                                                           
                                                           
euc_jp                eucjp, ujis, u-jis                   Japanese
                                                           
                                                           
euc_jis_2004          jisx0213, eucjis2004                 Japanese
                                                           
                                                           
euc_jisx0213          eucjisx0213                          Japanese
                                                           
                                                           
euc_kr                euckr, korean, ksc5601, ks_c-5601,   Korean
                      ks_c-5601-1987, ksx1001, ks_x-1001   
                      
                                                           
gb2312                chinese, csiso58gb231280, euc- cn,   Simplified Chinese
                      euccn, eucgb2312-cn, gb2312-1980,    
                      gb2312-80, iso- ir-58
                      
                                                           
gbk                   936, cp936, ms936                    Unified Chinese
                                                           
                                                           
gb18030               gb18030-2000                         Unified Chinese
                                                           
                                                           
hz                    hzgb, hz-gb, hz-gb-2312              Simplified Chinese
                                                           
                                                           
iso2022_jp            csiso2022jp, iso2022jp,              Japanese
                      iso-2022-jp                          
                      
                                                           
iso2022_jp_1          iso2022jp-1, iso-2022-jp-1           Japanese
                                                           
                                                           
iso2022_jp_2          iso2022jp-2, iso-2022-jp-2           Japanese, Korean, Simplified
                                                           Chinese, Western Europe, Greek
                                                           
                                                           
iso2022_jp_2004       iso2022jp-2004, iso-2022-jp-2004     Japanese
                                                           
                                                           
iso2022_jp_3          iso2022jp-3, iso-2022-jp-3           Japanese
                                                           
                                                           
iso2022_jp_ext        iso2022jp-ext, iso-2022-jp-ext       Japanese
                                                           
                                                           
iso2022_kr            csiso2022kr, iso2022kr,              Korean
                      iso-2022-kr                          
                      
                                                           
latin_1               iso-8859-1, iso8859-1, 8859,         West Europe
                      cp819, latin, latin1, L1             
                      
                                                           
iso8859_2             iso-8859-2, latin2, L2               Central and Eastern Europe
                                                           
                                                           
iso8859_3             iso-8859-3, latin3, L3               Esperanto, Maltese
                                                           
                                                           
iso8859_4             iso-8859-4, latin4, L4               Baltic languages
                                                           
                                                           
iso8859_5             iso-8859-5, cyrillic                 Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
iso8859_6             iso-8859-6, arabic                   Arabic
                                                           
                                                           
iso8859_7             iso-8859-7, greek, greek8            Greek
                                                           
                                                           
iso8859_8             iso-8859-8, hebrew                   Hebrew
                                                           
                                                           
iso8859_9             iso-8859-9, latin5, L5               Turkish
                                                           
                                                           
iso8859_10            iso-8859-10, latin6, L6              Nordic languages
                                                           
                                                           
iso8859_11            iso-8859-11, thai                    Thai languages
                                                           
                                                           
iso8859_13            iso-8859-13, latin7, L7              Baltic languages
                                                           
                                                           
iso8859_14            iso-8859-14, latin8, L8              Celtic languages
                                                           
                                                           
iso8859_15            iso-8859-15, latin9, L9              Western Europe
                                                           
                                                           
iso8859_16            iso-8859-16, latin10, L10            South-Eastern Europe
                                                           
                                                           
johab                 cp1361, ms1361                       Korean
                                                           
                                                           
koi8_r                                                     Russian
                                                           
                                                           
koi8_t                                                     Tajik
                                                           
                                                           New in version 3.5.
                                                           
                                                           
koi8_u                                                     Ukrainian
                                                           
                                                           
kz1048                kz_1048, strk1048_2002, rk1048       Kazakh
                                                           
                                                           New in version 3.5.
                                                           
                                                           
mac_cyrillic          maccyrillic                          Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
mac_greek             macgreek                             Greek
                                                           
                                                           
mac_iceland           maciceland                           Icelandic
                                                           
                                                           
mac_latin2            maclatin2, maccentraleurope          Central and Eastern Europe
                                                           
                                                           
mac_roman             macroman, macintosh                  Western Europe
                                                           
                                                           
mac_turkish           macturkish                           Turkish
                                                           
                                                           
ptcp154               csptcp154, pt154, cp154,             Kazakh
                      cyrillic-asian                       
                      
                                                           
shift_jis             csshiftjis, shiftjis, sjis, s_jis    Japanese
                                                           
                                                           
shift_jis_2004        shiftjis2004, sjis_2004, sjis2004    Japanese
                                                           
                                                           
shift_jisx0213        shiftjisx0213, sjisx0213,            Japanese
                      s_jisx0213                           
                      
                                                           
utf_32                U32, utf32                           all languages
                                                           
                                                           
utf_32_be             UTF-32BE                             all languages
                                                           
                                                           
utf_32_le             UTF-32LE                             all languages
                                                           
                                                           
utf_16                U16, utf16                           all languages
                                                           
                                                           
utf_16_be             UTF-16BE                             all languages
                                                           
                                                           
utf_16_le             UTF-16LE                             all languages
                                                           
                                                           
utf_7                 U7, unicode-1-1-utf-7                all languages
                                                           
                                                           
utf_8                 U8, UTF, utf8                        all languages
                                                           
                                                           
utf_8_sig                                                  all languages
                                                           

Changed in version 3.4: The utf-16* and utf-32* encoders no longer allow
surrogate code points (‘U+D800’–‘U+DFFF’) to be encoded.  The utf-32*
decoders no longer decode byte sequences that correspond to surrogate
code points.

